
[{"content":"","date":"23 March 2025","externalUrl":null,"permalink":"/","section":"Blog homepage","summary":"","title":"Blog homepage","type":"page"},{"content":"","date":"23 March 2025","externalUrl":null,"permalink":"/tags/example/","section":"Tags","summary":"","title":"Example","type":"tags"},{"content":"","date":"23 March 2025","externalUrl":null,"permalink":"/posts/","section":"Posts","summary":"","title":"Posts","type":"posts"},{"content":" 缓存基础 # 1.1 双写一致性 # 1.1.1 概念 # 缓存不一致问题是指当发生数据变更后该数据在数据库和缓存中是不一致的，此时查询缓存得到的并不是与数据库一致的数据。Redis的双写一致性，一般是基于两种场景，第一个是追求强一致性，第二个允许延迟一致（保证数据的最终一致性）\n写数据库和写缓存导致不一致称为双写不一致，比如：先更新数据库成功了，更新缓存时失败了，最终导致不一致。\n1.1.2 解决方案 # 1.1.2.1 使用分布式锁 # 流程：\n线程1申请分布式锁，拿到锁。此时其它线程无法获取同一把锁。 线程1写数据库，写缓存，操作完成释放锁。 线程2申请分布锁成功，写数据库，写缓存。 对双写的操作每个线程顺序执行。 对操作异常问题仍需要解决：写数据库成功写缓存失败了，数据库需要回滚，此时就需要使用分布式事务组件。\n使用分布式锁解决双写一致性不仅性能低下，而且复杂度也会增加。\n1.1.2.2 延迟双删 # 既然双写操作存在不一致，我们把写缓存改为删除缓存呢？\n先写数据库再删除缓存，如果删除缓存失败了缓存也就不一致了，那我们改为：先删除缓存再写数据库，如下图：\n执行流程：\n线程1删除缓存 线程2读缓存发现没有数据此时查询数据库拿到旧数据写入缓存 线程1写入数据库 即使线程1删除缓存、写数据库操作后线程2再去查询缓存也可能存在问题，如下图：\n线程1向主数据库写，线程2向从数据库查询，流程如下：\n线程1删除缓存 线程1向主数据库写，数据向从数据库同步 线程2查询缓存没有数据，查询从数据库，得到旧数据 线程2将旧数据写入缓存 解决上边的问题采用延迟双删：\n线程1先删除缓存，再写入主数据库，延迟一定时间再删除缓存。\n上图线程1的动作简化为下图：\n延迟多长时间呢？\n延迟主数据向从数据库同步的时间间隔，如果延迟时间设置不合理也会导致数据不一致。\n延迟时间设置的不合理，可能会带来更多问题\n过短：脏数据 过长：更新失效不及时 1.1.2.3 异步同步 # 延迟双删的目的也是为了保证最终一致性，即允许缓存短暂不一致，最终保证一致性。\n保证最终一致性的方案有很多，比如：通过MQ、Canal、定时任务都可以实现。\nCanal是一个数据同步工具，读取MySQL的binlog日志拿到更新的数据，再通过MQ发送给异步同步程序，最终由异步同步程序写到redis。此方案适用于对数据实时性有一定要求的场景。\n通过Canal加MQ异步任务方式流程如下：\n流程如下：\n线程1写数据库 canal读取binlog日志，将数据变化日志写入mq 同步程序监听mq接收到数据变化的消息 同步程序解析消息内容写入redis，写入redis成功正常消费完成，消息从mq删除。 定时任务方式流程如下：\n专门启动一个数据同步任务定时读取数据同步到redis，此方式适用于对数据实时性要求不强更新不频繁的数据。\n线程1写入数据库（业务数据表，变化日志表）\n同步程序读取数据库（变化日志表），根据变化日志内容写入redis，同步完成删除变化日志。\nRedis常见面试题 # 2.1 Redis基础 # 2.1.1 什么是Redis? # ==Redis （REmote DIctionary Server）是一个基于 C 语言开发的开源 NoSQL 数据库（BSD 许可）。与传统数据库不同的是，Redis 的数据是保存在内存中的（内存数据库，支持持久化），因此读写速度非常快，被广泛应用于分布式缓存方向。==并且，Redis 存储的是 KV 键值对数据。\n为了满足不同的业务场景，Redis 内置了多种数据类型实现（比如 String、Hash、Sorted Set、Bitmap、HyperLogLog、GEO）。并且，Redis 还支持事务、持久化、Lua 脚本、发布订阅模型、多种开箱即用的集群方案（Redis Sentinel、Redis Cluster）。\nRedis 没有外部依赖，Linux 和 OS X 是 Redis 开发和测试最多的两个操作系统，官方推荐生产环境使用 Linux 部署 Redis。\n个人学习的话，你可以自己本机安装 Redis 或者通过 Redis 官网提供的在线 Redis 环境（少部分命令无法使用）来实际体验 Redis。\n全世界有非常多的网站使用到了 Redis ，techstacks.io 专门维护了一个使用 Redis 的热门站点列表 ，感兴趣的话可以看看。\n2.1.2 Redis为什么这么快？ # Redis 内部做了非常多的性能优化，比较重要的有下面 3 点：\nRedis 基于内存，内存的访问速度比磁盘快很多； Redis 基于 Reactor 模式设计开发了一套高效的事件处理模型，主要是单线程事件循环和 IO 多路复用（Redis 线程模式后面会详细介绍到）； Redis 内置了多种优化过后的数据类型/结构实现，性能非常高。 Redis 通信协议实现简单且解析高效。 那既然都这么快了，为什么不直接用 Redis 当主数据库呢？主要是因为内存成本太高且 Redis 提供的数据持久化仍然有数据丢失的风险\n2.1.3 其他分布式缓存方案 # 如果面试中被问到这个问题的话，面试官主要想看看：\n你在选择 Redis 作为分布式缓存方案时，是否是经过严谨的调研和思考，还是只是因为 Redis 是当前的“热门”技术。 你在分布式缓存方向的技术广度。 如果你了解其他方案，并且能解释为什么最终选择了 Redis（更进一步！），这会对你面试表现加分不少！\n下面简单聊聊常见的分布式缓存技术选型。\n分布式缓存的话，比较老牌同时也是使用的比较多的还是 Memcached 和 Redis。不过，现在基本没有看过还有项目使用 Memcached 来做缓存，都是直接用 Redis。\nMemcached 是分布式缓存最开始兴起的那会，比较常用的。后来，随着 Redis 的发展，大家慢慢都转而使用更加强大的 Redis 了。\n有一些大厂也开源了类似于 Redis 的分布式高性能 KV 存储数据库，例如，腾讯开源的 Tendis 。Tendis 基于知名开源项目 RocksDB 作为存储引擎 ，100% 兼容 Redis 协议和 Redis4.0 所有数据模型。关于 Redis 和 Tendis 的对比，腾讯官方曾经发过一篇文章：Redis vs Tendis：冷热混合存储版架构揭秘 ，可以简单参考一下。\n不过，从 Tendis 这个项目的 Github 提交记录可以看出，Tendis 开源版几乎已经没有被维护更新了，加上其关注度并不高，使用的公司也比较少。因此，不建议你使用 Tendis 来实现分布式缓存。\n目前，比较业界认可的 Redis 替代品还是下面这两个开源分布式缓存（都是通过碰瓷 Redis 火的）：\nDragonfly（/ˈdræɡənflaɪ/）：一种针对现代应用程序负荷需求而构建的内存数据库，完全兼容 Redis 和 Memcached 的 API，迁移时无需修改任何代码，号称全世界最快的内存数据库。 KeyDB： Redis 的一个高性能分支，专注于多线程、内存效率和高吞吐量。 不过，个人还是建议分布式缓存首选 Redis ，毕竟经过这么多年的生考验，生态也这么优秀，资料也很全面！\n2.1.4 说一下Redis和Memcached的区别和共同点 # 现在公司一般都是用 Redis 来实现缓存，而且 Redis 自身也越来越强大了！不过，了解 Redis 和 Memcached 的区别和共同点，有助于我们在做相应的技术选型的时候，能够做到有理有据！\n共同点：\n都是基于内存的数据库，一般都用来当做缓存使用。 都有过期策略。 两者的性能都非常高。 区别：\n数据类型：Redis 支持更丰富的数据类型（支持更复杂的应用场景）。Redis 不仅仅支持简单的 k/v 类型的数据，同时还提供 list，set，zset，hash 等数据结构的存储。Memcached 只支持最简单的 k/v 数据类型。 数据持久化：**Redis 支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用，而 Memcached 把数据全部存在内存之中。**也就是说，Redis 有灾难恢复机制而 Memcached 没有。 集群模式支持：Memcached 没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据；但是 Redis 自 3.0 版本起是原生支持集群模式的。 线程模型：Memcached 是多线程，非阻塞 IO 复用的网络模型；Redis 使用单线程的多路 IO 复用模型。 （Redis 6.0 针对网络数据的读写引入了多线程） 特性支持：Redis 支持发布订阅模型、Lua 脚本、事务等功能，而 Memcached 不支持。并且，Redis 支持更多的编程语言。 过期数据删除：Memcached 过期数据的删除策略只用了惰性删除，而 Redis 同时使用了惰性删除与定期删除。 相信看了上面的对比之后，我们已经没有什么理由可以选择使用 Memcached 来作为自己项目的分布式缓存了。\n2.1.5 为什么要用redis? # 1、访问速度更快\n传统数据库数据保存在磁盘，而 Redis 基于内存，内存的访问速度比磁盘快很多。引入 Redis 之后，我们可以把一些高频访问的数据放到 Redis 中，这样下次就可以直接从内存中读取，速度可以提升几十倍甚至上百倍。\n2、高并发\n一般像 MySQL 这类的数据库的 QPS 大概都在 4k 左右（4 核 8g） ，但是使用 Redis 缓存之后很容易达到 5w+，甚至能达到 10w+（就单机 Redis 的情况，Redis 集群的话会更高）。\nQPS（Query Per Second）：服务器每秒可以执行的查询次数；\n由此可见，直接操作缓存能够承受的数据库请求数量是远远大于直接访问数据库的，所以我们可以考虑把数据库中的部分数据转移到缓存中去，这样用户的一部分请求会直接到缓存这里而不用经过数据库。进而，我们也就提高了系统整体的并发。\n3、功能全面\nRedis 除了可以用作缓存之外，还可以用于分布式锁、限流、消息队列、延时队列等场景，功能强大！\n2.1.7 什么是Redis Module？有什么用？ # Redis 从 4.0 版本开始，支持通过 Module 来扩展其功能以满足特殊的需求。这些 Module 以动态链接库（so 文件）的形式被加载到 Redis 中，这是一种非常灵活的动态扩展功能的实现方式，值得借鉴学习！\n我们每个人都可以基于 Redis 去定制化开发自己的 Module，比如实现搜索引擎功能、自定义分布式锁和分布式限流。\n目前，被 Redis 官方推荐的 Module 有：\nRediSearch：用于实现搜索引擎的模块。 RedisJSON：用于处理 JSON 数据的模块。 RedisGraph：用于实现图形数据库的模块。 RedisTimeSeries：用于处理时间序列数据的模块。 RedisBloom：用于实现布隆过滤器的模块。 RedisAI：用于执行深度学习/机器学习模型并管理其数据的模块。 RedisCell：用于实现分布式限流的模块。 …… 关于 Redis 模块的详细介绍，可以查看官方文档：https://redis.io/modules。\n2.2 Redis应用 # 2.2.1 Redis除了做缓存，还能做什么？ # 分布式锁：通过 Redis 来做分布式锁是一种比较常见的方式。通常情况下，我们都是基于 Redisson 来实现分布式锁 。 限流：一般是通过 Redis + Lua 脚本的方式来实现限流。如果不想自己写 Lua 脚本的话，也可以直接利用 Redisson 中的 RRateLimiter 来实现分布式限流，其底层实现就是基于 Lua 代码+令牌桶算法。 消息队列：Redis 自带的 List 数据结构可以作为一个简单的队列使用。Redis 5.0 中增加的 Stream 类型的数据结构更加适合用来做消息队列。它比较类似于 Kafka，有主题和消费组的概念，支持消息持久化以及 ACK 机制。 延时队列：Redisson 内置了延时队列（基于 Sorted Set 实现的）。 分布式 Session ：利用 String 或者 Hash 数据类型保存 Session 数据，所有的服务器都可以访问。 复杂业务场景：通过 Redis 以及 Redis 扩展（比如 Redisson）提供的数据结构，我们可以很方便地完成很多复杂的业务场景比如通过 Bitmap 统计活跃用户、通过 Sorted Set 维护排行榜。 …… 2.2.3 Redis可以做消息队列吗？ # 实际项目中使用 Redis 来做消息队列的非常少，毕竟有更成熟的消息队列中间件可以用。\n先说结论：可以是可以，但不建议使用 Redis 来做消息队列。和专业的消息队列相比，还是有很多欠缺的地方。\nRedis 2.0 之前，如果想要使用 Redis 来做消息队列的话，只能通过 List 来实现。\n通过 RPUSH/LPOP 或者 LPUSH/RPOP即可实现简易版消息队列：\n# 生产者生产消息 \u0026gt; RPUSH myList msg1 msg2 (integer) 2 \u0026gt; RPUSH myList msg3 (integer) 3 # 消费者消费消息 \u0026gt; LPOP myList \u0026#34;msg1\u0026#34; 不过，通过 RPUSH/LPOP 或者 LPUSH/RPOP这样的方式存在性能问题，我们需要不断轮询去调用 RPOP 或 LPOP 来消费消息。当 List 为空时，大部分的轮询的请求都是无效请求，这种方式大量浪费了系统资源。\n因此，Redis 还提供了 BLPOP、BRPOP 这种阻塞式读取的命令（带 B-Blocking 的都是阻塞式），并且还支持一个超时参数。如果 List 为空，Redis 服务端不会立刻返回结果，它会等待 List 中有新数据后再返回或者是等待最多一个超时时间后返回空。如果将超时时间设置为 0 时，即可无限等待，直到弹出消息\n# 超时时间为 10s # 如果有数据立刻返回，否则最多等待10秒 \u0026gt; BRPOP myList 10 null List 实现消息队列功能太简单，像消息确认机制等功能还需要我们自己实现，最要命的是没有广播机制，消息也只能被消费一次。\nRedis 2.0 引入了发布订阅 (pub/sub) 功能，解决了 List 实现消息队列没有广播机制的问题。\nRedis 发布订阅 (pub/sub) 功能\npub/sub 中引入了一个概念叫 channel（频道），发布订阅机制的实现就是基于这个 channel 来做的。\npub/sub 涉及发布者（Publisher）和订阅者（Subscriber，也叫消费者）两个角色：\n发布者通过 PUBLISH 投递消息给指定 channel。 订阅者通过SUBSCRIBE订阅它关心的 channel。并且，订阅者可以订阅一个或者多个 channel。 我们这里启动 3 个 Redis 客户端来简单演示一下：\npub/sub 实现消息队列演示\npub/sub 既能单播又能广播，还支持 channel 的简单正则匹配。不过，消息丢失（客户端断开连接或者 Redis 宕机都会导致消息丢失）、消息堆积（发布者发布消息的时候不会管消费者的具体消费能力如何）等问题依然没有一个比较好的解决办法。\n为此，Redis 5.0 新增加的一个数据结构 Stream 来做消息队列。Stream 支持：\n发布 / 订阅模式 按照消费者组进行消费（借鉴了 Kafka 消费者组的概念） 消息持久化（ RDB 和 AOF） ACK 机制（通过确认机制来告知已经成功处理了消息） 阻塞式获取消息 Stream 的结构如下：\n这是一个有序的消息链表，每个消息都有一个唯一的 ID 和对应的内容。ID 是一个时间戳和序列号的组合，用来保证消息的唯一性和递增性。内容是一个或多个键值对（类似 Hash 基本数据类型），用来存储消息的数据。\n这里再对图中涉及到的一些概念，进行简单解释：\nConsumer Group：消费者组用于组织和管理多个消费者。消费者组本身不处理消息，而是再将消息分发给消费者，由消费者进行真正的消费 last_delivered_id：标识消费者组当前消费位置的游标，消费者组中任意一个消费者读取了消息都会使 last_delivered_id 往前移动。 pending_ids：记录已经被客户端消费但没有 ack 的消息的 ID。 下面是Stream 用作消息队列时常用的命令：\nXADD：向流中添加新的消息。 XREAD：从流中读取消息。 XREADGROUP：从消费组中读取消息。 XRANGE：根据消息 ID 范围读取流中的消息。 XREVRANGE：与 XRANGE 类似，但以相反顺序返回结果。 XDEL：从流中删除消息。 XTRIM：修剪流的长度，可以指定修建策略（MAXLEN/MINID）。 XLEN：获取流的长度。 XGROUP CREATE：创建消费者组。 XGROUP DESTROY ： 删除消费者组 XGROUP DELCONSUMER：从消费者组中删除一个消费者。 XGROUP SETID：为消费者组设置新的最后递送消息 ID XACK：确认消费组中的消息已被处理。 XPENDING：查询消费组中挂起（未确认）的消息。 XCLAIM：将挂起的消息从一个消费者转移到另一个消费者。 XINFO：获取流(XINFO STREAM)、消费组(XINFO GROUPS)或消费者(XINFO CONSUMERS)的详细信息。 Stream 使用起来相对要麻烦一些，这里就不演示了。\n总的来说，Stream 已经可以满足一个消息队列的基本要求了。不过，Stream 在实际使用中依然会有一些小问题不太好解决比如在 Redis 发生故障恢复后不能保证消息至少被消费一次。\n综上，和专业的消息队列相比，使用 Redis 来实现消息队列还是有很多欠缺的地方比如消息丢失和堆积问题不好解决。因此，我们通常建议不要使用 Redis 来做消息队列，你完全可以选择市面上比较成熟的一些消息队列比如 RocketMQ、Kafka。不过，如果你就是想要用 Redis 来做消息队列的话，那我建议你优先考虑 Stream，这是目前相对最优的 Redis 消息队列实现。\n相关阅读：Redis 消息队列发展历程 - 阿里开发者 - 2022。\n2.2.4 Redis可以做搜索引擎吗？ # Redis 是可以实现全文搜索引擎功能的，需要借助 RediSearch ，这是一个基于 Redis 的搜索引擎模块。\nRediSearch 支持中文分词、聚合统计、停用词、同义词、拼写检查、标签查询、向量相似度查询、多关键词搜索、分页搜索等功能，算是一个功能比较完善的全文搜索引擎了。\n相比较于 Elasticsearch 来说，RediSearch 主要在下面两点上表现更优异一些：\n性能更优秀：依赖 Redis 自身的高性能，基于内存操作（Elasticsearch 基于磁盘）。 较低内存占用实现快速索引：RediSearch 内部使用压缩的倒排索引，所以可以用较低的内存占用来实现索引的快速构建。 对于小型项目的简单搜索场景来说，使用 RediSearch 来作为搜索引擎还是没有问题的（搭配 RedisJSON 使用）。\n对于比较复杂或者数据规模较大的搜索场景还是不太建议使用 RediSearch 来作为搜索引擎，主要是因为下面这些限制和问题：\n数据量限制：Elasticsearch 可以支持 PB 级别的数据量，可以轻松扩展到多个节点，利用分片机制提高可用性和性能。RedisSearch 是基于 Redis 实现的，其能存储的数据量受限于 Redis 的内存容量，不太适合存储大规模的数据（内存昂贵，扩展能力较差）。 分布式能力较差：Elasticsearch 是为分布式环境设计的，可以轻松扩展到多个节点。虽然 RedisSearch 支持分布式部署，但在实际应用中可能会面临一些挑战，如数据分片、节点间通信、数据一致性等问题。 聚合功能较弱：Elasticsearch 提供了丰富的聚合功能，而 RediSearch 的聚合功能相对较弱，只支持简单的聚合操作。 生态较差：Elasticsearch 可以轻松和常见的一些系统/软件集成比如 Hadoop、Spark、Kibana，而 RedisSearch 则不具备该优势。 Elasticsearch 适用于全文搜索、复杂查询、实时数据分析和聚合的场景，而 RediSearch 适用于快速数据存储、缓存和简单查询的场景。\n2.2.5 如何基于Redis实现延时任务？ # 类似的问题：\n订单在 10 分钟后未支付就失效，如何用 Redis 实现？ 红包 24 小时未被查收自动退还，如何用 Redis 实现？ 基于 Redis 实现延时任务的功能无非就下面两种方案：\nRedis 过期事件监听 Redisson 内置的延时队列 Redis 过期事件监听的存在时效性较差、丢消息、多服务实例下消息重复消费等问题，不被推荐使用。\nRedisson 内置的延时队列具备下面这些优势：\n减少了丢消息的可能：DelayedQueue 中的消息会被持久化，即使 Redis 宕机了，根据持久化机制，也只可能丢失一点消息，影响不大。当然了，你也可以使用扫描数据库的方法作为补偿机制。 消息不存在重复消费问题：每个客户端都是从同一个目标队列中获取任务的，不存在重复消费的问题。 2.3 Redis数据类型 # 关于 Redis 5 种基础数据类型和 3 种特殊数据类型的详细介绍请看Reids重要知识点以及 Redis 官方文档 。\n2.3.1 Redis常用的数据类型 # Redis 中比较常见的数据类型有下面这些：\n5 种基础数据类型：String（字符串）、List（列表）、Set（集合）、Hash（散列）、Zset（有序集合）。 3 种特殊数据类型：HyperLogLog（基数统计）、Bitmap （位图）、Geospatial (地理位置)。 除了上面提到的之外，还有一些其他的比如 Bloom filter（布隆过滤器）、Bitfield（位域）。\n2.3.2 String的应用场景 # String 是 Redis 中最简单同时也是最常用的一个数据类型。它是一种二进制安全的数据类型，可以用来存储任何类型的数据比如字符串、整数、浮点数、图片（图片的 base64 编码或者解码或者图片的路径）、序列化后的对象。\nString 的常见应用场景如下：\n常规数据（比如 Session、Token、序列化后的对象、图片的路径）的缓存； 计数比如用户单位时间的请求数（简单限流可以用到）、页面单位时间的访问数； 分布式锁(利用 SETNX key value 命令可以实现一个最简易的分布式锁)； …… 2.3.3 String还是Hash存储对象数据更好 # 简单对比一下二者：\n对象存储方式：String 存储的是序列化后的对象数据，存放的是整个对象，操作简单直接。Hash 是对对象的每个字段单独存储，可以获取部分字段的信息，也可以修改或者添加部分字段，节省网络流量。如果对象中某些字段需要经常变动或者经常需要单独查询对象中的个别字段信息，Hash 就非常适合。 内存消耗：Hash 通常比 String 更节省内存，特别是在字段较多且字段长度较短时。Redis 对小型 Hash 进行优化（如使用 ziplist 存储），进一步降低内存占用。 复杂对象存储：String 在处理多层嵌套或复杂结构的对象时更方便，因为无需处理每个字段的独立存储和操作。 性能：String 的操作通常具有 O(1) 的时间复杂度，因为它存储的是整个对象，操作简单直接，整体读写的性能较好。Hash 由于需要处理多个字段的增删改查操作，在字段较多且经常变动的情况下，可能会带来额外的性能开销。 总结：\n在绝大多数情况下，String 更适合存储对象数据，尤其是当对象结构简单且整体读写是主要操作时。 如果你需要频繁操作对象的部分字段或节省内存，Hash 可能是更好的选择。 2.3.4 String的底层实现 # Redis 是基于 C 语言编写的，但 Redis 的 String 类型的底层实现并不是 C 语言中的字符串（即以空字符 \\0 结尾的字符数组），而是自己编写了 SDS（Simple Dynamic String，简单动态字符串） 来作为底层实现。\nSDS 最早是 Redis 作者为日常 C 语言开发而设计的 C 字符串，后来被应用到了 Redis 上，并经过了大量的修改完善以适合高性能操作。\nRedis7.0 的 SDS 的部分源码如下（https://github.com/redis/redis/blob/7.0/src/sds.h）:\n/* Note: sdshdr5 is never used, we just access the flags byte directly. * However is here to document the layout of type 5 SDS strings. */ struct __attribute__ ((__packed__)) sdshdr5 { unsigned char flags; /* 3 lsb of type, and 5 msb of string length */ char buf[]; }; struct __attribute__ ((__packed__)) sdshdr8 { uint8_t len; /* used */ uint8_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[]; }; struct __attribute__ ((__packed__)) sdshdr16 { uint16_t len; /* used */ uint16_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[]; }; struct __attribute__ ((__packed__)) sdshdr32 { uint32_t len; /* used */ uint32_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[]; }; struct __attribute__ ((__packed__)) sdshdr64 { uint64_t len; /* used */ uint64_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[]; }; 通过源码可以看出，SDS 共有五种实现方式 SDS_TYPE_5（并未用到）、SDS_TYPE_8、SDS_TYPE_16、SDS_TYPE_32、SDS_TYPE_64，其中只有后四种实际用到。Redis 会根据初始化的长度决定使用哪种类型，从而减少内存的使用。\n类型 字节 位 sdshdr5 \u0026lt; 1 \u0026lt;8 sdshdr8 1 8 sdshdr16 2 16 sdshdr32 4 32 sdshdr64 8 64 对于后四种实现都包含了下面这 4 个属性：\nlen：字符串的长度也就是已经使用的字节数 alloc：总共可用的字符空间大小，alloc-len 就是 SDS 剩余的空间大小 buf[]：实际存储字符串的数组 flags：低三位保存类型标志 SDS 相比于 C 语言中的字符串有如下提升：\n可以避免缓冲区溢出：C 语言中的字符串被修改（比如拼接）时，一旦没有分配足够长度的内存空间，就会造成缓冲区溢出。SDS 被修改时，会先根据 len 属性检查空间大小是否满足要求，如果不满足，则先扩展至所需大小再进行修改操作。 获取字符串长度的复杂度较低：C 语言中的字符串的长度通常是经过遍历计数来实现的，时间复杂度为 O(n)。SDS 的长度获取直接读取 len 属性即可，时间复杂度为 O(1)。 减少内存分配次数：为了避免修改（增加/减少）字符串时，每次都需要重新分配内存（C 语言的字符串是这样的），SDS 实现了空间预分配和惰性空间释放两种优化策略。当 SDS 需要增加字符串时，Redis 会为 SDS 分配好内存，并且根据特定的算法分配多余的内存，这样可以减少连续执行字符串增长操作所需的内存重分配次数。当 SDS 需要减少字符串时，这部分内存不会立即被回收，会被记录下来，等待后续使用（支持手动释放，有对应的 API）。 二进制安全：C 语言中的字符串以空字符 \\0 作为字符串结束的标识，这存在一些问题，像一些二进制文件（比如图片、视频、音频）就可能包括空字符，C 字符串无法正确保存。SDS 使用 len 属性判断字符串是否结束，不存在这个问题。 🤐 多提一嘴，很多文章里 SDS 的定义是下面这样的：\nstruct sdshdr { unsigned int len; unsigned int free; char buf[]; }; 这个也没错，Redis 3.2 之前就是这样定义的。后来，由于这种方式的定义存在问题，len 和 free 的定义用了 4 个字节，造成了浪费。Redis 3.2 之后，Redis 改进了 SDS 的定义，将其划分为了现在的 5 种类型。\n2.3.6 购物车信息用String还是Hash存储更好 # 由于购物车中的商品频繁修改和变动，购物车信息建议使用 Hash 存储：\n用户 id 为 key 商品 id 为 field，商品数量为 value 那用户购物车信息的维护具体应该怎么操作呢？\n用户添加商品就是往 Hash 里面增加新的 field 与 value； 查询购物车信息就是遍历对应的 Hash； 更改商品数量直接修改对应的 value 值（直接 set 或者做运算皆可）； 删除商品就是删除 Hash 中对应的 field； 清空购物车直接删除对应的 key 即可。 这里只是以业务比较简单的购物车场景举例，实际电商场景下，field 只保存一个商品 id 是没办法满足需求的。\n2.3.7 使用Redis实现一个排行榜 # Redis 中有一个叫做 Sorted Set （有序集合）的数据类型经常被用在各种排行榜的场景，比如直播间送礼物的排行榜、朋友圈的微信步数排行榜、王者荣耀中的段位排行榜、话题热度排行榜等等。\n相关的一些 Redis 命令: ZRANGE (从小到大排序)、 ZREVRANGE （从大到小排序）、ZREVRANK (指定元素排名)。\n2.3.8 Redis的有序集合底层为什么要用跳表，而不用平衡树、红黑树或者B+树？ # 这道面试题很多大厂比较喜欢问，难度还是有点大的。\n平衡树 vs 跳表：平衡树的插入、删除和查询的时间复杂度和跳表一样都是 O(log n)。对于范围查询来说，平衡树也可以通过中序遍历的方式达到和跳表一样的效果。但是它的每一次插入或者删除操作都需要保证整颗树左右节点的绝对平衡，只要不平衡就要通过旋转操作来保持平衡，这个过程是比较耗时的。跳表诞生的初衷就是为了克服平衡树的一些缺点。跳表使用概率平衡而不是严格强制的平衡，因此，跳表中的插入和删除算法比平衡树的等效算法简单得多，速度也快得多。 红黑树 vs 跳表：相比较于红黑树来说，跳表的实现也更简单一些，不需要通过旋转和染色（红黑变换）来保证黑平衡。并且，按照区间来查找数据这个操作，红黑树的效率没有跳表高。 B+树 vs 跳表：B+树更适合作为数据库和文件系统中常用的索引结构之一，它的核心思想是通过可能少的 IO 定位到尽可能多的索引来获得查询数据。对于 Redis 这种内存数据库来说，它对这些并不感冒，因为 Redis 作为内存数据库它不可能存储大量的数据，所以对于索引不需要通过 B+树这种方式进行维护，只需按照概率进行随机维护即可，节约内存。而且使用跳表实现 zset 时相较前者来说更简单一些，在进行插入时只需通过索引将数据插入到链表中合适的位置再随机维护一定高度的索引即可，也不需要像 B+树那样插入时发现失衡时还需要对节点分裂与合并。 另外，我还单独写了一篇文章从有序集合的基本使用到跳表的源码分析和实现，让你会对 Redis 的有序集合底层实现的跳表有着更深刻的理解和掌握 ：Redis 为什么用跳表实现有序集合。\n2.3.9 Set的应用场景 # Redis 中 Set 是一种无序集合，集合中的元素没有先后顺序但都唯一，有点类似于 Java 中的 HashSet 。\nSet 的常见应用场景如下：\n存放的数据不能重复的场景：网站 UV 统计（数据量巨大的场景还是 HyperLogLog更适合一些）、文章点赞、动态点赞等等。 需要获取多个数据源交集、并集和差集的场景：共同好友(交集)、共同粉丝(交集)、共同关注(交集)、好友推荐（差集）、音乐推荐（差集）、订阅号推荐（差集+交集） 等等。 需要随机获取数据源中的元素的场景：抽奖系统、随机点名等等。 2.3.10 使用Set实现抽奖系统 # 如果想要使用 Set 实现一个简单的抽奖系统的话，直接使用下面这几个命令就可以了：\nSADD key member1 member2 ...：向指定集合添加一个或多个元素。 SPOP key count：随机移除并获取指定集合中一个或多个元素，适合不允许重复中奖的场景。 SRANDMEMBER key count : 随机获取指定集合中指定数量的元素，适合允许重复中奖的场景。 2.3.11 使用Bitmap统计活跃用户 # Bitmap 存储的是连续的二进制数字（0 和 1），通过 Bitmap, 只需要一个 bit 位来表示某个元素对应的值或者状态，key 就是对应元素本身 。我们知道 8 个 bit 可以组成一个 byte，所以 Bitmap 本身会极大的节省储存空间。\n你可以将 Bitmap 看作是一个存储二进制数字（0 和 1）的数组，数组中每个元素的下标叫做 offset（偏移量）。\n如果想要使用 Bitmap 统计活跃用户的话，可以使用日期（精确到天）作为 key，然后用户 ID 为 offset，如果当日活跃过就设置为 1。\n初始化数据：\n\u0026gt; SETBIT 20210308 1 1 (integer) 0 \u0026gt; SETBIT 20210308 2 1 (integer) 0 \u0026gt; SETBIT 20210309 1 1 (integer) 0 统计 20210308~20210309 总活跃用户数:\n\u0026gt; BITOP and desk1 20210308 20210309 (integer) 1 \u0026gt; BITCOUNT desk1 (integer) 1 统计 20210308~20210309 在线活跃用户数:\n\u0026gt; BITOP or desk2 20210308 20210309 (integer) 1 \u0026gt; BITCOUNT desk2 (integer) 2 2.3.12 使用HyperLogLog统计页面UV怎么做？ # 使用 HyperLogLog 统计页面 UV 主要需要用到下面这两个命令：\nPFADD key element1 element2 ...：添加一个或多个元素到 HyperLogLog 中。 PFCOUNT key1 key2：获取一个或者多个 HyperLogLog 的唯一计数。 1、将访问指定页面的每个用户 ID 添加到 HyperLogLog 中。\nPFADD PAGE_1:UV USER1 USER2 ...... USERn 2、统计指定页面的 UV。\nPFCOUNT PAGE_1:UV 2.5 Redis线程模型 # 对于读写命令来说，Redis 一直是单线程模型。不过，在 Redis 4.0 版本之后引入了多线程来执行一些大键值对的异步删除操作， Redis 6.0 版本之后引入了多线程来处理网络请求（提高网络 IO 读写性能）。\n2.5.1 Redis单线程模型 # Redis 基于 Reactor 模式设计开发了一套高效的事件处理模型 （Netty 的线程模型也基于 Reactor 模式，Reactor 模式不愧是高性能 IO 的基石），这套事件处理模型对应的是 Redis 中的文件事件处理器（file event handler）。由于文件事件处理器（file event handler）是单线程方式运行的，所以我们一般都说 Redis 是单线程模型。\n《Redis 设计与实现》有一段话是如是介绍文件事件处理器的，我觉得写得挺不错。\nRedis 基于 Reactor 模式开发了自己的网络事件处理器：这个处理器被称为文件事件处理器（file event handler）。\n文件事件处理器使用 I/O 多路复用（multiplexing）程序来同时监听多个套接字，并根据套接字目前执行的任务来为套接字关联不同的事件处理器。 当被监听的套接字准备好执行连接应答（accept）、读取（read）、写入（write）、关 闭（close）等操作时，与操作相对应的文件事件就会产生，这时文件事件处理器就会调用套接字之前关联好的事件处理器来处理这些事件。 虽然文件事件处理器以单线程方式运行，但通过使用 I/O 多路复用程序来监听多个套接字，文件事件处理器既实现了高性能的网络通信模型，又可以很好地与 Redis 服务器中其他同样以单线程方式运行的模块进行对接，这保持了 Redis 内部单线程设计的简单性。\n既然是单线程，那怎么监听大量的客户端连接呢？\nRedis 通过 IO 多路复用程序 来监听来自客户端的大量连接（或者说是监听多个 socket），它会将感兴趣的事件及类型（读、写）注册到内核中并监听每个事件是否发生。\n这样的好处非常明显：I/O 多路复用技术的使用让 Redis 不需要额外创建多余的线程来监听客户端的大量连接，降低了资源的消耗（和 NIO 中的 Selector 组件很像）。\n文件事件处理器（file event handler）主要是包含 4 个部分：\n多个 socket（客户端连接） IO 多路复用程序（支持多个客户端连接的关键） 文件事件分派器（将 socket 关联到相应的事件处理器） 事件处理器（连接应答处理器、命令请求处理器、命令回复处理器） 理器（file event handler)\n相关阅读：Redis 事件机制详解 。\n2.5.2 Redis6.0 之前为什么不使用多线程 # 虽然说 Redis 是单线程模型，但实际上，Redis 在 4.0 之后的版本中就已经加入了对多线程的支持。\n不过，Redis 4.0 增加的多线程主要是针对一些大键值对的删除操作的命令，使用这些命令就会使用主线程之外的其他线程来“异步处理”，从而减少对主线程的影响。\n为此，Redis 4.0 之后新增了几个异步命令：\nUNLINK：可以看作是 DEL 命令的异步版本。 FLUSHALL ASYNC：用于清空所有数据库的所有键，不限于当前 SELECT 的数据库。 FLUSHDB ASYNC：用于清空当前 SELECT 数据库中的所有键。 redis4.0 more thread\n总的来说，直到 Redis 6.0 之前，Redis 的主要操作仍然是单线程处理的。\n那 Redis6.0 之前为什么不使用多线程？ 我觉得主要原因有 3 点：\n单线程编程容易并且更容易维护； Redis 的性能瓶颈不在 CPU ，主要在内存和网络； 多线程就会存在死锁、线程上下文切换等问题，甚至会影响性能。 相关阅读：为什么 Redis 选择单线程模型？ 。\n2.5.3 Redis6.0 之后为何引入了多线程 # Redis6.0 引入多线程主要是为了提高网络 IO 读写性能，因为这个算是 Redis 中的一个性能瓶颈（Redis 的瓶颈主要受限于内存和网络）。\n虽然，Redis6.0 引入了多线程，但是 Redis 的多线程只是在网络数据的读写这类耗时操作上使用了，执行命令仍然是单线程顺序执行。因此，你也不需要担心线程安全问题。\nRedis6.0 的多线程默认是禁用的，只使用主线程。如需开启需要设置 IO 线程数 \u0026gt; 1，需要修改 redis 配置文件 redis.conf：\nio-threads 4 #设置1的话只会开启主线程，官网建议4核的机器建议设置为2或3个线程，8核的建议设置为6个线程 另外：\nio-threads 的个数一旦设置，不能通过 config 动态设置。 当设置 ssl 后，io-threads 将不工作。 开启多线程后，默认只会使用多线程进行 IO 写入 writes，即发送数据给客户端，如果需要开启多线程 IO 读取 reads，同样需要修改 redis 配置文件 redis.conf :\nio-threads-do-reads yes 但是官网描述开启多线程读并不能有太大提升，因此一般情况下并不建议开启\n相关阅读：\nRedis 6.0 新特性-多线程连环 13 问！ Redis 多线程网络模型全面揭秘（推荐） 2.5.4 Redis后台线程 # 我们虽然经常说 Redis 是单线程模型（主要逻辑是单线程完成的），但实际还有一些后台线程用于执行一些比较耗时的操作：\n通过 bio_close_file 后台线程来释放 AOF / RDB 等过程中产生的临时文件资源。 通过 bio_aof_fsync 后台线程调用 fsync 函数将系统内核缓冲区还未同步到到磁盘的数据强制刷到磁盘（ AOF 文件）。 通过 bio_lazy_free后台线程释放大对象（已删除）占用的内存空间. 在bio.h 文件中有定义（Redis 6.0 版本，源码地址：https://github.com/redis/redis/blob/6.0/src/bio.h）：\n#ifndef __BIO_H #define __BIO_H /* Exported API */ void bioInit(void); void bioCreateBackgroundJob(int type, void *arg1, void *arg2, void *arg3); unsigned long long bioPendingJobsOfType(int type); unsigned long long bioWaitStepOfType(int type); time_t bioOlderJobOfType(int type); void bioKillThreads(void); /* Background job opcodes */ #define BIO_CLOSE_FILE 0 /* Deferred close(2) syscall. */ #define BIO_AOF_FSYNC 1 /* Deferred AOF fsync. */ #define BIO_LAZY_FREE 2 /* Deferred objects freeing. */ #define BIO_NUM_OPS 3 #endif 关于 Redis 后台线程的详细介绍可以查看 Redis 6.0 后台线程有哪些？ 这篇就文章。\n2.6 Redis内存管理 # 2.6.1 Redis 给缓存数据设置过期时间有什么用 # 一般情况下，我们设置保存的缓存数据的时候都会设置一个过期时间。为什么呢？\n内存是有限且珍贵的，如果不对缓存数据设置过期时间，那内存占用就会一直增长，最终可能会导致 OOM 问题。通过设置合理的过期时间，Redis 会自动删除暂时不需要的数据，为新的缓存数据腾出空间。\nRedis 自带了给缓存数据设置过期时间的功能，比如：\n127.0.0.1:6379\u0026gt; expire key 60 # 数据在 60s 后过期 (integer) 1 127.0.0.1:6379\u0026gt; setex key 60 value # 数据在 60s 后过期 (setex:[set] + [ex]pire) OK 127.0.0.1:6379\u0026gt; ttl key # 查看数据还有多久过期 (integer) 56 注意 ⚠️：Redis 中除了字符串类型有自己独有设置过期时间的命令 setex 外，其他方法都需要依靠 expire 命令来设置过期时间 。另外， persist 命令可以移除一个键的过期时间。\n过期时间除了有助于缓解内存的消耗，还有什么其他用么？\n很多时候，我们的业务场景就是需要某个数据只在某一时间段内存在，比如我们的短信验证码可能只在 1 分钟内有效，用户登录的 Token 可能只在 1 天内有效。\n如果使用传统的数据库来处理的话，一般都是自己判断过期，这样更麻烦并且性能要差很多。\n2.6.2 Redis是如何判断数据是否过期的 # Redis 通过一个叫做过期字典（可以看作是 hash 表）来保存数据过期的时间。过期字典的键指向 Redis 数据库中的某个 key(键)，过期字典的值是一个 long long 类型的整数，这个整数保存了 key 所指向的数据库键的过期时间（毫秒精度的 UNIX 时间戳）。\nRedis 过期字典\n过期字典是存储在 redisDb 这个结构里的：\ntypedef struct redisDb { ... dict *dict; //数据库键空间,保存着数据库中所有键值对 dict *expires // 过期字典,保存着键的过期时间 ... } redisDb; 在查询一个 key 的时候，Redis 首先检查该 key 是否存在于过期字典中（时间复杂度为 O(1)），如果不在就直接返回，在的话需要判断一下这个 key 是否过期，过期直接删除 key 然后返回 null。\n2.6.3 Redis过期key删除策略 # 过期命令：\nRedis中通过expire命令可以给KEY设置TTL（过期时间），例如：\n# 写入一条数据 set num 123 # 设置20秒过期时间 expire num 20 不过set命令本身也可以支持过期时间的设置：\n# 写入一条数据并设置20s过期时间 set num EX 20 如果假设你设置了一批 key 只能存活 1 分钟，那么 1 分钟后，Redis 是怎么对这批 key 进行删除的呢？\n常用的过期数据的删除策略就下面这几种：\n惰性删除：只会在取出/查询 key 的时候才对数据进行过期检查。这种方式对 CPU 最友好，但是可能会造成太多过期 key 没有被删除。 定期删除：周期性地随机从设置了过期时间的 key 中抽查一批，然后逐个检查这些 key 是否过期，过期就删除 key。相比于惰性删除，定期删除对内存更友好，对 CPU 不太友好。 延迟队列：把设置过期时间的 key 放到一个延迟队列里，到期之后就删除 key。这种方式可以保证每个过期 key 都能被删除，但维护延迟队列太麻烦，队列本身也要占用资源。 定时删除：每个设置了过期时间的 key 都会在设置的时间到达时立即被删除。这种方法可以确保内存中不会有过期的键，但是它对 CPU 的压力最大，因为它需要为每个键都设置一个定时器。 Redis 采用的那种删除策略呢？\nRedis 采用的是 定期删除+惰性/懒汉式删除 结合的策略，这也是大部分缓存框架的选择。定期删除对内存更加友好，惰性删除对 CPU 更加友好。两者各有千秋，结合起来使用既能兼顾 CPU 友好，又能兼顾内存友好。\n下面是我们详细介绍一下 Redis 中的定期删除具体是如何做的。\nRedis 的定期删除过程是随机的（周期性地随机从设置了过期时间的 key 中抽查一批），所以并不保证所有过期键都会被立即删除。这也就解释了为什么有的 key 过期了，并没有被删除。并且，Redis 底层会通过限制删除操作执行的时长和频率来减少删除操作对 CPU 时间的影响。\n另外，定期删除还会受到执行时间和过期 key 的比例的影响：\n执行时间已经超过了阈值，那么就中断这一次定期删除循环，以避免使用过多的 CPU 时间。 如果这一批过期的 key 比例超过一个比例，就会重复执行此删除流程，以更积极地清理过期 key。相应地，如果过期的 key 比例低于这个比例，就会中断这一次定期删除循环，避免做过多的工作而获得很少的内存回收。 Redis 7.2 版本的执行时间阈值是 25ms，过期 key 比例设定值是 10%。\n#define ACTIVE_EXPIRE_CYCLE_FAST_DURATION 1000 /* Microseconds. */ #define ACTIVE_EXPIRE_CYCLE_SLOW_TIME_PERC 25 /* Max % of CPU to use. */ #define ACTIVE_EXPIRE_CYCLE_ACCEPTABLE_STALE 10 /* % of stale keys after which we do extra efforts. */ 每次随机抽查数量是多少？\nexpire.c中定义了每次随机抽查的数量，Redis 7.2 版本为 20 ，也就是说每次会随机选择 20 个设置了过期时间的 key 判断是否过期。\n#define ACTIVE_EXPIRE_CYCLE_KEYS_PER_LOOP 20 /* Keys for each DB loop. */ 如何控制定期删除的执行频率？\n在 Redis 中，定期删除的频率是由 hz 参数控制的。hz 默认为 10，代表每秒执行 10 次，也就是每秒钟进行 10 次尝试来查找并删除过期的 key。\nhz 的取值范围为 1~500。增大 hz 参数的值会提升定期删除的频率。如果你想要更频繁地执行定期删除任务，可以适当增加 hz 的值，但这会加 CPU 的使用率。根据 Redis 官方建议，hz 的值不建议超过 100，对于大部分用户使用默认的 10 就足够了。\n下面是 hz 参数的官方注释，我翻译了其中的重要信息（Redis 7.2 版本）。\nredis.conf 对于 hz 的注释\n类似的参数还有一个 dynamic-hz，这个参数开启之后 Redis 就会在 hz 的基础上动态计算一个值。Redis 提供并默认启用了使用自适应 hz 值的能力，\n这两个参数都在 Redis 配置文件 redis.conf中：\n# 默认为 10 hz 10 # 默认开启 dynamic-hz yes 多提一嘴，除了定期删除过期 key 这个定期任务之外，还有一些其他定期任务例如关闭超时的客户端连接、更新统计信息，这些定期任务的执行频率也是通过 hz 参数决定。\n为什么定期删除不是把所有过期 key 都删除呢？\n这样会对性能造成太大的影响。如果我们 key 数量非常庞大的话，挨个遍历检查是非常耗时的，会严重影响性能。Redis 设计这种策略的目的是为了平衡内存和性能。\n为什么 key 过期之后不立马把它删掉呢？这样不是会浪费很多内存空间吗？\n因为不太好办到，或者说这种删除方式的成本太高了。假如我们使用延迟队列作为删除策略，这样存在下面这些问题：\n队列本身的开销可能很大：key 多的情况下，一个延迟队列可能无法容纳。 维护延迟队列太麻烦：修改 key 的过期时间就需要调整期在延迟队列中的位置，并且，还需要引入并发控制。 2.6.4 大量key集中过期怎么办 # 当 Redis 中存在大量 key 在同一时间点集中过期时，可能会导致以下问题：\n请求延迟增加： Redis 在处理过期 key 时需要消耗 CPU 资源，如果过期 key 数量庞大，会导致 Redis 实例的 CPU 占用率升高，进而影响其他请求的处理速度，造成延迟增加。 内存占用过高： 过期的 key 虽然已经失效，但在 Redis 真正删除它们之前，仍然会占用内存空间。如果过期 key 没有及时清理，可能会导致内存占用过高，甚至引发内存溢出。 为了避免这些问题，可以采取以下方案：\n尽量避免 key 集中过期: 在设置键的过期时间时尽量随机一点。 开启 lazy free 机制: 修改 redis.conf 配置文件，将 lazyfree-lazy-expire 参数设置为 yes，即可开启 lazy free 机制。开启 lazy free 机制后，Redis 会在后台异步删除过期的 key，不会阻塞主线程的运行，从而降低对 Redis 性能的影响。 2.6.5 Redis内存淘汰策略 # 相关问题：MySQL 里有 2000w 数据，Redis 中只存 20w 的数据，如何保证 Redis 中的数据都是热点数据?\nRedis 的内存淘汰策略只有在运行内存达到了配置的最大内存阈值时才会触发，这个阈值是通过redis.conf的maxmemory参数来定义的。64 位操作系统下，maxmemory 默认为 0 ，表示不限制内存大小。32 位操作系统下，默认的最大内存值是 3GB。\n你可以使用命令 config get maxmemory 来查看 maxmemory的值。\n\u0026gt; config get maxmemory maxmemory 0 Redis 提供了 6 种内存淘汰策略：\nvolatile-lru（least recently used）：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰。 volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰。 volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰。 allkeys-lru（least recently used）：从数据集（server.db[i].dict）中移除最近最少使用的数据淘汰。 allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰。 no-eviction（默认内存淘汰策略）：禁止驱逐数据，当内存不足以容纳新写入数据时，新写入操作会报错。 4.0 版本后增加以下两种：\nvolatile-lfu（least frequently used）：从已设置过期时间的数据集（server.db[i].expires）中挑选最不经常使用的数据淘汰。 allkeys-lfu（least frequently used）：从数据集（server.db[i].dict）中移除最不经常使用的数据淘汰。 allkeys-xxx 表示从所有的键值中淘汰数据，而 volatile-xxx 表示从设置了过期时间的键值中淘汰数据。\nconfig.c中定义了内存淘汰策略的枚举数组：\nconfigEnum maxmemory_policy_enum[] = { {\u0026#34;volatile-lru\u0026#34;, MAXMEMORY_VOLATILE_LRU}, {\u0026#34;volatile-lfu\u0026#34;, MAXMEMORY_VOLATILE_LFU}, {\u0026#34;volatile-random\u0026#34;,MAXMEMORY_VOLATILE_RANDOM}, {\u0026#34;volatile-ttl\u0026#34;,MAXMEMORY_VOLATILE_TTL}, {\u0026#34;allkeys-lru\u0026#34;,MAXMEMORY_ALLKEYS_LRU}, {\u0026#34;allkeys-lfu\u0026#34;,MAXMEMORY_ALLKEYS_LFU}, {\u0026#34;allkeys-random\u0026#34;,MAXMEMORY_ALLKEYS_RANDOM}, {\u0026#34;noeviction\u0026#34;,MAXMEMORY_NO_EVICTION}, {NULL, 0} }; 你可以使用 config get maxmemory-policy 命令来查看当前 Redis 的内存淘汰策略。\n\u0026gt; config get maxmemory-policy maxmemory-policy noeviction 可以通过config set maxmemory-policy 内存淘汰策略 命令修改内存淘汰策略，立即生效，但这种方式重启 Redis 之后就失效了。修改 redis.conf 中的 maxmemory-policy 参数不会因为重启而失效，不过，需要重启之后修改才能生效。\nmaxmemory-policy noeviction 关于淘汰策略的详细说明可以参考 Redis 官方文档：https://redis.io/docs/reference/eviction/。\n2.7 Redis事务 # 2.7.1 什么是Redis事务？ # 你可以将 Redis 中的事务理解为：Redis 事务提供了一种将多个命令请求打包的功能。然后，再按顺序执行打包的所有命令，并且不会被中途打断。\nRedis 事务实际开发中使用的非常少，功能比较鸡肋，不要将其和我们平时理解的关系*/ˈdræɡənflaɪ/*型数据库的事务混淆了。\n除了不满足原子性和持久性之外，事务中的每条命令都会与 Redis 服务器进行网络交互，这是比较浪费资源的行为。明明一次批量执行多个命令就可以了，这种操作实在是看不懂。\n因此，Redis 事务是不建议在日常开发中使用的。\n2.7.2 如何使用Redis事务？ # Redis 可以通过 MULTI，EXEC，DISCARD 和 WATCH 等命令来实现事务(Transaction)功能。\n\u0026gt; MULTI OK \u0026gt; SET PROJECT \u0026#34;JavaGuide\u0026#34; QUEUED \u0026gt; GET PROJECT QUEUED \u0026gt; EXEC 1) OK 2) \u0026#34;JavaGuide\u0026#34; MULTI 命令后可以输入多个命令，Redis 不会立即执行这些命令，而是将它们放到队列，当调用了 EXEC 命令后，再执行所有的命令。\n这个过程是这样的：\n开始事务（MULTI）； 命令入队(批量操作 Redis 的命令，先进先出（FIFO）的顺序执行)； 执行事务(EXEC)。 你也可以通过 DISCARD 命令取消一个事务，它会清空事务队列中保存的所有命令。\n\u0026gt; MULTI OK \u0026gt; SET PROJECT \u0026#34;JavaGuide\u0026#34; QUEUED \u0026gt; GET PROJECT QUEUED \u0026gt; DISCARD OK 你可以通过WATCH 命令监听指定的 Key，当调用 EXEC 命令执行事务时，如果一个被 WATCH 命令监视的 Key 被 其他客户端/Session 修改的话，整个事务都不会被执行。\n# 客户端 1 \u0026gt; SET PROJECT \u0026#34;RustGuide\u0026#34; OK \u0026gt; WATCH PROJECT OK \u0026gt; MULTI OK \u0026gt; SET PROJECT \u0026#34;JavaGuide\u0026#34; QUEUED # 客户端 2 # 在客户端 1 执行 EXEC 命令提交事务之前修改 PROJECT 的值 \u0026gt; SET PROJECT \u0026#34;GoGuide\u0026#34; # 客户端 1 # 修改失败，因为 PROJECT 的值被客户端2修改了 \u0026gt; EXEC (nil) \u0026gt; GET PROJECT \u0026#34;GoGuide\u0026#34; 不过，如果 WATCH 与 事务 在同一个 Session 里，并且被 WATCH 监视的 Key 被修改的操作发生在事务内部，这个事务是可以被执行成功的（相关 issue：WATCH 命令碰到 MULTI 命令时的不同效果）。\n事务内部修改 WATCH 监视的 Key：\n\u0026gt; SET PROJECT \u0026#34;JavaGuide\u0026#34; OK \u0026gt; WATCH PROJECT OK \u0026gt; MULTI OK \u0026gt; SET PROJECT \u0026#34;JavaGuide1\u0026#34; QUEUED \u0026gt; SET PROJECT \u0026#34;JavaGuide2\u0026#34; QUEUED \u0026gt; SET PROJECT \u0026#34;JavaGuide3\u0026#34; QUEUED \u0026gt; EXEC 1) OK 2) OK 3) OK 127.0.0.1:6379\u0026gt; GET PROJECT \u0026#34;JavaGuide3\u0026#34; 事务外部修改 WATCH 监视的 Key：\n\u0026gt; SET PROJECT \u0026#34;JavaGuide\u0026#34; OK \u0026gt; WATCH PROJECT OK \u0026gt; SET PROJECT \u0026#34;JavaGuide2\u0026#34; OK \u0026gt; MULTI OK \u0026gt; GET USER QUEUED \u0026gt; EXEC (nil) Redis 官网相关介绍 https://redis.io/topics/transactions 如下：\n2.7.3 Redis事务支持原子性吗？ # Redis 的事务和我们平时理解的关系型数据库的事务不同。我们知道事务具有四大特性：1. 原子性，2. 隔离性，3. 持久性，4. 一致性。\n原子性（Atomicity）： 事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用； 隔离性（Isolation）： 并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的； 持久性（Durability）： 一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。 一致性（Consistency）： 执行事务前后，数据保持一致，多个事务对同一个数据读取的结果是相同的； Redis 事务在运行错误的情况下，除了执行过程中出现错误的命令外，其他命令都能正常执行。并且，Redis 事务是不支持回滚（roll back）操作的。因此，Redis 事务其实是不满足原子性的。\nRedis 官网也解释了自己为啥不支持回滚。简单来说就是 Redis 开发者们觉得没必要支持回滚，这样更简单便捷并且性能更好。Redis 开发者觉得即使命令执行错误也应该在开发过程中就被发现而不是生产过程中。\nRedis 为什么不支持回滚\n相关 issue :\nissue#452: 关于 Redis 事务不满足原子性的问题 。 Issue#491:关于 Redis 没有事务回滚？ 2.7.4 Redis事务支持持久性吗？ # Redis 不同于 Memcached 的很重要一点就是，Redis 支持持久化，而且支持 3 种持久化方式:\n快照（snapshotting，RDB） 只追加文件（append-only file, AOF） RDB 和 AOF 的混合持久化(Redis 4.0 新增) 与 RDB 持久化相比，AOF 持久化的实时性更好。在 Redis 的配置文件中存在三种不同的 AOF 持久化方式（ fsync策略），它们分别是：\nappendfsync always #每次有数据修改发生时都会调用fsync函数同步AOF文件,fsync完成后线程返回,这样会严重降低Redis的速度 appendfsync everysec #每秒钟调用fsync函数同步一次AOF文件 appendfsync no #让操作系统决定何时进行同步，一般为30秒一次 AOF 持久化的fsync策略为 no、everysec 时都会存在数据丢失的情况 。always 下可以基本是可以满足持久性要求的，但性能太差，实际开发过程中不会使用。\n因此，Redis 事务的持久性也是没办法保证的。\n2.7.5 如何解决Redis事务的缺陷 # Redis 从 2.6 版本开始支持执行 Lua 脚本，它的功能和事务非常类似。我们可以利用 Lua 脚本来批量执行多条 Redis 命令，这些 Redis 命令会被提交到 Redis 服务器一次性执行完成，大幅减小了网络开销。\n一段 Lua 脚本可以视作一条命令执行，一段 Lua 脚本执行过程中不会有其他脚本或 Redis 命令同时执行，保证了操作不会被其他指令插入或打扰。\n不过，如果 Lua 脚本运行时出错并中途结束，出错之后的命令是不会被执行的。并且，出错之前执行的命令是无法被撤销的，无法实现类似关系型数据库执行失败可以回滚的那种原子性效果。因此， 严格来说的话，通过 Lua 脚本来批量执行 Redis 命令实际也是不完全满足原子性的。\n如果想要让 Lua 脚本中的命令全部执行，必须保证语句语法和命令都是对的。\n另外，Redis 7.0 新增了 Redis functions 特性，你可以将 Redis functions 看作是比 Lua 更强大的脚本。\n2.8 Redis性能优化 # 除了下面介绍的内容之外，再推荐两篇不错的文章：\n你的 Redis 真的变慢了吗？性能优化如何做 - 阿里开发者 Redis 常见阻塞原因总结 - JavaGuide 2.8.1 使用批量操作减少网络传输 # 一个 Redis 命令的执行可以简化为以下 4 步：\n发送命令 命令排队 命令执行 返回结果 其中，第 1 步和第 4 步耗费时间之和称为 Round Trip Time (RTT,往返时间) ，也就是数据在网络上传输的时间。\n使用批量操作可以减少网络传输次数，进而有效减小网络开销，大幅减少 RTT。\n另外，除了能减少 RTT 之外，发送一次命令的 socket I/O 成本也比较高（涉及上下文切换，存在read()和write()系统调用），批量操作还可以减少 socket I/O 成本。这个在官方对 pipeline 的介绍中有提到：https://redis.io/docs/manual/pipelining/ 。\n2.8.1.1 原生批量操作命令 # Redis 中有一些原生支持批量操作的命令，比如：\nMGET(获取一个或多个指定 key 的值)、MSET(设置一个或多个指定 key 的值)、 HMGET(获取指定哈希表中一个或者多个指定字段的值)、HMSET(同时将一个或多个 field-value 对设置到指定哈希表中)、 SADD（向指定集合添加一个或多个元素） …… 不过，在 Redis 官方提供的分片集群解决方案 Redis Cluster 下，使用这些原生批量操作命令可能会存在一些小问题需要解决。就比如说 MGET 无法保证所有的 key 都在同一个 hash slot（哈希槽）上，MGET可能还是需要多次网络传输，原子操作也无法保证了。不过，相较于非批量操作，还是可以节省不少网络传输次数。\n整个步骤的简化版如下（通常由 Redis 客户端实现，无需我们自己再手动实现）：\n找到 key 对应的所有 hash slot； 分别向对应的 Redis 节点发起 MGET 请求获取数据； 等待所有请求执行结束，重新组装结果数据，保持跟入参 key 的顺序一致，然后返回结果。 如果想要解决这个多次网络传输的问题，比较常用的办法是自己维护 key 与 slot 的关系。不过这样不太灵活，虽然带来了性能提升，但同样让系统复杂性提升。\nRedis Cluster 并没有使用一致性哈希，采用的是 哈希槽分区 ，每一个键值对都属于一个 hash slot（哈希槽） 。当客户端发送命令请求的时候，需要先根据 key 通过上面的计算公示找到的对应的哈希槽，然后再查询哈希槽和节点的映射关系，即可找到目标 Redis 节点。\n我在 Redis 集群详解（付费） 这篇文章中详细介绍了 Redis Cluster 这部分的内容，感兴趣地可以看看。\n2.8.1.2 pipline # 对于不支持批量操作的命令，我们可以利用 pipeline（流水线) 将一批 Redis 命令封装成一组，这些 Redis 命令会被一次性提交到 Redis 服务器，只需要一次网络传输。不过，需要注意控制一次批量操作的 元素个数(例如 500 以内，实际也和元素字节数有关)，避免网络传输的数据量过大。\n与MGET、MSET等原生批量操作命令一样，pipeline 同样在 Redis Cluster 上使用会存在一些小问题。原因类似，无法保证所有的 key 都在同一个 hash slot（哈希槽）上。如果想要使用的话，客户端需要自己维护 key 与 slot 的关系。\n原生批量操作命令和 pipeline 的是有区别的，使用的时候需要注意：\n原生批量操作命令是原子操作，pipeline 是非原子操作。 pipeline 可以打包不同的命令，原生批量操作命令不可以。 原生批量操作命令是 Redis 服务端支持实现的，而 pipeline 需要服务端和客户端的共同实现。 顺带补充一下 pipeline 和 Redis 事务的对比：\n事务是原子操作，pipeline 是非原子操作。两个不同的事务不会同时运行，而 pipeline 可以同时以交错方式执行。 Redis 事务中每个命令都需要发送到服务端，而 Pipeline 只需要发送一次，请求次数更少。 事务可以看作是一个原子操作，但其实并不满足原子性。当我们提到 Redis 中的原子操作时，主要指的是这个操作（比如事务、Lua 脚本）不会被其他操作（比如其他事务、Lua 脚本）打扰，并不能完全保证这个操作中的所有写命令要么都执行要么都不执行。这主要也是因为 Redis 是不支持回滚操作。\n另外，pipeline 不适用于执行顺序有依赖关系的一批命令。就比如说，你需要将前一个命令的结果给后续的命令使用，pipeline 就没办法满足你的需求了。对于这种需求，我们可以使用 Lua 脚本 。\n2.8.1.3 lua脚本 # Lua 脚本同样支持批量操作多条命令。一段 Lua 脚本可以视作一条命令执行，可以看作是 原子操作 。也就是说，一段 Lua 脚本执行过程中不会有其他脚本或 Redis 命令同时执行，保证了操作不会被其他指令插入或打扰，这是 pipeline 所不具备的。\n并且，Lua 脚本中支持一些简单的逻辑处理比如使用命令读取值并在 Lua 脚本中进行处理，这同样是 pipeline 所不具备的。\n不过， Lua 脚本依然存在下面这些缺陷：\n如果 Lua 脚本运行时出错并中途结束，之后的操作不会进行，但是之前已经发生的写操作不会撤销，所以即使使用了 Lua 脚本，也不能实现类似数据库回滚的原子性。 Redis Cluster 下 Lua 脚本的原子操作也无法保证了，原因同样是无法保证所有的 key 都在同一个 hash slot（哈希槽）上。 2.8.2 大量key集中过期问题 # 我在前面提到过：对于过期 key，Redis 采用的是 定期删除+惰性/懒汉式删除 策略。\n定期删除执行过程中，如果突然遇到大量过期 key 的话，客户端请求必须等待定期清理过期 key 任务线程执行完成，因为这个这个定期任务线程是在 Redis 主线程中执行的。这就导致客户端请求没办法被及时处理，响应速度会比较慢。\n如何解决呢？ 下面是两种常见的方法：\n给 key 设置随机过期时间。 开启 lazy-free（惰性删除/延迟释放） 。lazy-free 特性是 Redis 4.0 开始引入的，指的是让 Redis 采用异步方式延迟释放 key 使用的内存，将该操作交给单独的子线程处理，避免阻塞主线程。 个人建议不管是否开启 lazy-free，我们都尽量给 key 设置随机过期时间。\n2.8.3 Redis bigkey（大 Key） # 2.8.3.1 什么是bigkey？ # 简单来说，如果一个 key 对应的 value 所占用的内存比较大，那这个 key 就可以看作是 bigkey。具体多大才算大呢？有一个不是特别精确的参考标准：\nString 类型的 value 超过 1MB 复合类型（List、Hash、Set、Sorted Set 等）的 value 包含的元素超过 5000 个（不过，对于复合类型的 value 来说，不一定包含的元素越多，占用的内存就越多）。 2.8.3.2 bigkey是怎么产生的？有什么危害？ # bigkey 通常是由于下面这些原因产生的：\n程序设计不当，比如直接使用 String 类型存储较大的文件对应的二进制数据。 对于业务的数据规模考虑不周到，比如使用集合类型的时候没有考虑到数据量的快速增长。 未及时清理垃圾数据，比如哈希中冗余了大量的无用键值对。 bigkey 除了会消耗更多的内存空间和带宽，还会对性能造成比较大的影响。\n在 Redis 常见阻塞原因总结这篇文章中我们提到：大 key 还会造成阻塞问题。具体来说，主要体现在下面三个方面：\n客户端超时阻塞：由于 Redis 执行命令是单线程处理，然后在操作大 key 时会比较耗时，那么就会阻塞 Redis，从客户端这一视角看，就是很久很久都没有响应。 网络阻塞：每次获取大 key 产生的网络流量较大，如果一个 key 的大小是 1 MB，每秒访问量为 1000，那么每秒会产生 1000MB 的流量，这对于普通千兆网卡的服务器来说是灾难性的。 工作线程阻塞：如果使用 del 删除大 key 时，会阻塞工作线程，这样就没办法处理后续的命令。 大 key 造成的阻塞问题还会进一步影响到主从同步和集群扩容。\n综上，大 key 带来的潜在问题是非常多的，我们应该尽量避免 Redis 中存在 bigkey。\n2.8.3.3 如何发现bugkey? # 1、使用 Redis 自带的 --bigkeys 参数来查找。\n# redis-cli -p 6379 --bigkeys # Scanning the entire keyspace to find biggest keys as well as # average sizes per key type. You can use -i 0.1 to sleep 0.1 sec # per 100 SCAN commands (not usually needed). [00.00%] Biggest string found so far \u0026#39;\u0026#34;ballcat:oauth:refresh_auth:f6cdb384-9a9d-4f2f-af01-dc3f28057c20\u0026#34;\u0026#39; with 4437 bytes [00.00%] Biggest list found so far \u0026#39;\u0026#34;my-list\u0026#34;\u0026#39; with 17 items -------- summary ------- Sampled 5 keys in the keyspace! Total key length in bytes is 264 (avg len 52.80) Biggest list found \u0026#39;\u0026#34;my-list\u0026#34;\u0026#39; has 17 items Biggest string found \u0026#39;\u0026#34;ballcat:oauth:refresh_auth:f6cdb384-9a9d-4f2f-af01-dc3f28057c20\u0026#34;\u0026#39; has 4437 bytes 1 lists with 17 items (20.00% of keys, avg size 17.00) 0 hashs with 0 fields (00.00% of keys, avg size 0.00) 4 strings with 4831 bytes (80.00% of keys, avg size 1207.75) 0 streams with 0 entries (00.00% of keys, avg size 0.00) 0 sets with 0 members (00.00% of keys, avg size 0.00) 0 zsets with 0 members (00.00% of keys, avg size 0.00 从这个命令的运行结果，我们可以看出：这个命令会扫描(Scan) Redis 中的所有 key ，会对 Redis 的性能有一点影响。并且，这种方式只能找出每种数据结构 top 1 bigkey（占用内存最大的 String 数据类型，包含元素最多的复合数据类型）。然而，一个 key 的元素多并不代表占用内存也多，需要我们根据具体的业务情况来进一步判断。\n在线上执行该命令时，为了降低对 Redis 的影响，需要指定 -i 参数控制扫描的频率。redis-cli -p 6379 --bigkeys -i 3 表示扫描过程中每次扫描后休息的时间间隔为 3 秒。\n2、使用 Redis 自带的 SCAN 命令\nSCAN 命令可以按照一定的模式和数量返回匹配的 key。获取了 key 之后，可以利用 STRLEN、HLEN、LLEN等命令返回其长度或成员数量。\n数据结构 命令 复杂度 结果（对应 key） String STRLEN O(1) 字符串值的长度 Hash HLEN O(1) 哈希表中字段的数量 List LLEN O(1) 列表元素数量 Set SCARD O(1) 集合元素数量 Sorted Set ZCARD O(1) 有序集合的元素数量 对于集合类型还可以使用 MEMORY USAGE 命令（Redis 4.0+），这个命令会返回键值对占用的内存空间。\n3、借助开源工具分析 RDB 文件。\n通过分析 RDB 文件来找出 big key。这种方案的前提是你的 Redis 采用的是 RDB 持久化。\n网上有现成的代码/工具可以直接拿来使用：\nredis-rdb-tools：Python 语言写的用来分析 Redis 的 RDB 快照文件用的工具 rdb_bigkeys : Go 语言写的用来分析 Redis 的 RDB 快照文件用的工具，性能更好。 4、借助公有云的 Redis 分析服务。\n如果你用的是公有云的 Redis 服务的话，可以看看其是否提供了 key 分析功能（一般都提供了）。\n这里以阿里云 Redis 为例说明，它支持 bigkey 实时分析、发现，文档地址：https://www.alibabacloud.com/help/zh/apsaradb-for-redis/latest/use-the-real-time-key-statistics-feature 。\n2.8.3.4 如何处理bigkey？ # bigkey 的常见处理以及优化办法如下（这些方法可以配合起来使用）：\n分割 bigkey：将一个 bigkey 分割为多个小 key。例如，将一个含有上万字段数量的 Hash 按照一定策略（比如二次哈希）拆分为多个 Hash。 手动清理：Redis 4.0+ 可以使用 UNLINK 命令来异步删除一个或多个指定的 key。Redis 4.0 以下可以考虑使用 SCAN 命令结合 DEL 命令来分批次删除。 采用合适的数据结构：例如，文件二进制数据不使用 String 保存、使用 HyperLogLog 统计页面 UV、Bitmap 保存状态信息（0/1）。 开启 lazy-free（惰性删除/延迟释放） ：lazy-free 特性是 Redis 4.0 开始引入的，指的是让 Redis 采用异步方式延迟释放 key 使用的内存，将该操作交给单独的子线程处理，避免阻塞主线程。 2.8.4 Redis hotkey（热 Key） # 2.8.4.1 什么是hotkey？ # 如果一个 key 的访问次数比较多且明显多于其他 key 的话，那这个 key 就可以看作是 hotkey（热 Key）。例如在 Redis 实例的每秒处理请求达到 5000 次，而其中某个 key 的每秒访问量就高达 2000 次，那这个 key 就可以看作是 hotkey。\nhotkey 出现的原因主要是某个热点数据访问量暴增，如重大的热搜事件、参与秒杀的商品。\n2.8.4.2 hotkey有什么危害 # 处理 hotkey 会占用大量的 CPU 和带宽，可能会影响 Redis 实例对其他请求的正常处理。此外，如果突然访问 hotkey 的请求超出了 Redis 的处理能力，Redis 就会直接宕机。这种情况下，大量请求将落到后面的数据库上，可能会导致数据库崩溃。\n因此，hotkey 很可能成为系统性能的瓶颈点，需要单独对其进行优化，以确保系统的高可用性和稳定性。\n2.8.4.3 如何发现hotkey？ # 1、使用 Redis 自带的 --hotkeys 参数来查找。\nRedis 4.0.3 版本中新增了 hotkeys 参数，该参数能够返回所有 key 的被访问次数。\n使用该方案的前提条件是 Redis Server 的 maxmemory-policy 参数设置为 LFU 算法，不然就会出现如下所示的错误。\n# redis-cli -p 6379 --hotkeys # Scanning the entire keyspace to find hot keys as well as # average sizes per key type. You can use -i 0.1 to sleep 0.1 sec # per 100 SCAN commands (not usually needed). Error: ERR An LFU maxmemory policy is not selected, access frequency not tracked. Please note that when switching between policies at runtime LRU and LFU data will take some time to adjust. Redis 中有两种 LFU 算法：\nvolatile-lfu（least frequently used）：从已设置过期时间的数据集（server.db[i].expires）中挑选最不经常使用的数据淘汰。 allkeys-lfu（least frequently used）：当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的 key。 以下是配置文件 redis.conf 中的示例：\n# 使用 volatile-lfu 策略 maxmemory-policy volatile-lfu # 或者使用 allkeys-lfu 策略 maxmemory-policy allkeys-lfu 需要注意的是，hotkeys 参数命令也会增加 Redis 实例的 CPU 和内存消耗（全局扫描），因此需要谨慎使用。\n2、使用MONITOR 命令。\nMONITOR 命令是 Redis 提供的一种实时查看 Redis 的所有操作的方式，可以用于临时监控 Redis 实例的操作情况，包括读写、删除等操作。\n由于该命令对 Redis 性能的影响比较大，因此禁止长时间开启 MONITOR（生产环境中建议谨慎使用该命令）。\n# redis-cli 127.0.0.1:6379\u0026gt; MONITOR OK 1683638260.637378 [0 172.17.0.1:61516] \u0026#34;ping\u0026#34; 1683638267.144236 [0 172.17.0.1:61518] \u0026#34;smembers\u0026#34; \u0026#34;mySet\u0026#34; 1683638268.941863 [0 172.17.0.1:61518] \u0026#34;smembers\u0026#34; \u0026#34;mySet\u0026#34; 1683638269.551671 [0 172.17.0.1:61518] \u0026#34;smembers\u0026#34; \u0026#34;mySet\u0026#34; 1683638270.646256 [0 172.17.0.1:61516] \u0026#34;ping\u0026#34; 1683638270.849551 [0 172.17.0.1:61518] \u0026#34;smembers\u0026#34; \u0026#34;mySet\u0026#34; 1683638271.926945 [0 172.17.0.1:61518] \u0026#34;smembers\u0026#34; \u0026#34;mySet\u0026#34; 1683638274.276599 [0 172.17.0.1:61518] \u0026#34;smembers\u0026#34; \u0026#34;mySet2\u0026#34; 1683638276.327234 [0 172.17.0.1:61518] \u0026#34;smembers\u0026#34; \u0026#34;mySet\u0026#34; 在发生紧急情况时，我们可以选择在合适的时机短暂执行 MONITOR 命令并将输出重定向至文件，在关闭 MONITOR 命令后通过对文件中请求进行归类分析即可找出这段时间中的 hotkey。\n3、借助开源项目。\n京东零售的 hotkey 这个项目不光支持 hotkey 的发现，还支持 hotkey 的处理。\n京东零售开源的 hotkey\n4、根据业务情况提前预估。\n可以根据业务情况来预估一些 hotkey，比如参与秒杀活动的商品数据等。不过，我们无法预估所有 hotkey 的出现，比如突发的热点新闻事件等。\n5、业务代码中记录分析。\n在业务代码中添加相应的逻辑对 key 的访问情况进行记录分析。不过，这种方式会让业务代码的复杂性增加，一般也不会采用。\n6、借助公有云的 Redis 分析服务。\n如果你用的是公有云的 Redis 服务的话，可以看看其是否提供了 key 分析功能（一般都提供了）。\n这里以阿里云 Redis 为例说明，它支持 hotkey 实时分析、发现，文档地址：https://www.alibabacloud.com/help/zh/apsaradb-for-redis/latest/use-the-real-time-key-statistics-feature 。\n2.8.4.4 如何解决hotkey？ # hotkey 的常见处理以及优化办法如下（这些方法可以配合起来使用）：\n读写分离：主节点处理写请求，从节点处理读请求。 使用 Redis Cluster：将热点数据分散存储在多个 Redis 节点上。 二级缓存：hotkey 采用二级缓存的方式进行处理，将 hotkey 存放一份到 JVM 本地内存中（可以用 Caffeine）。 除了这些方法之外，如果你使用的公有云的 Redis 服务话，还可以留意其提供的开箱即用的解决方案。\n这里以阿里云 Redis 为例说明，它支持通过代理查询缓存功能（Proxy Query Cache）优化热点 Key 问题。\n2.8.5 查询慢命令 # 2.8.5.1 为什么会有查询慢命令 # 我们知道一个 Redis 命令的执行可以简化为以下 4 步：\n发送命令 命令排队 命令执行 返回结果 Redis 慢查询统计的是命令执行这一步骤的耗时，慢查询命令也就是那些命令执行时间较长的命令。\nRedis 为什么会有慢查询命令呢？\nRedis 中的大部分命令都是 O(1)时间复杂度，但也有少部分 O(n) 时间复杂度的命令，例如：\nKEYS *：会返回所有符合规则的 key。 HGETALL：会返回一个 Hash 中所有的键值对。 LRANGE：会返回 List 中指定范围内的元素。 SMEMBERS：返回 Set 中的所有元素。 SINTER/SUNION/SDIFF：计算多个 Set 的交集/并集/差集。 …… 由于这些命令时间复杂度是 O(n)，有时候也会全表扫描，随着 n 的增大，执行耗时也会越长。不过， 这些命令并不是一定不能使用，但是需要明确 N 的值。另外，有遍历的需求可以使用 HSCAN、SSCAN、ZSCAN 代替。\n除了这些 O(n)时间复杂度的命令可能会导致慢查询之外， 还有一些时间复杂度可能在 O(N) 以上的命令，例如：\nZRANGE/ZREVRANGE：返回指定 Sorted Set 中指定排名范围内的所有元素。时间复杂度为 O(log(n)+m)，n 为所有元素的数量， m 为返回的元素数量，当 m 和 n 相当大时，O(n) 的时间复杂度更小。 ZREMRANGEBYRANK/ZREMRANGEBYSCORE：移除 Sorted Set 中指定排名范围/指定 score 范围内的所有元素。时间复杂度为 O(log(n)+m)，n 为所有元素的数量， m 被删除元素的数量，当 m 和 n 相当大时，O(n) 的时间复杂度更小。 …… 2.8.5.2 如何找到慢查询命令 # 在 redis.conf 文件中，我们可以使用 slowlog-log-slower-than 参数设置耗时命令的阈值，并使用 slowlog-max-len 参数设置耗时命令的最大记录条数。\n当 Redis 服务器检测到执行时间超过 slowlog-log-slower-than阈值的命令时，就会将该命令记录在慢查询日志(slow log) 中，这点和 MySQL 记录慢查询语句类似。当慢查询日志超过设定的最大记录条数之后，Redis 会把最早的执行命令依次舍弃。\n⚠️注意：由于慢查询日志会占用一定内存空间，如果设置最大记录条数过大，可能会导致内存占用过高的问题。\nslowlog-log-slower-than和slowlog-max-len的默认配置如下(可以自行修改)：\n# The following time is expressed in microseconds, so 1000000 is equivalent # to one second. Note that a negative number disables the slow log, while # a value of zero forces the logging of every command. slowlog-log-slower-than 10000 # There is no limit to this length. Just be aware that it will consume memory. # You can reclaim memory used by the slow log with SLOWLOG RESET. slowlog-max-len 128 除了修改配置文件之外，你也可以直接通过 CONFIG 命令直接设置：\n# 命令执行耗时超过 10000 微妙（即10毫秒）就会被记录 CONFIG SET slowlog-log-slower-than 10000 # 只保留最近 128 条耗时命令 CONFIG SET slowlog-max-len 128 获取慢查询日志的内容很简单，直接使用SLOWLOG GET 命令即可。\n127.0.0.1:6379\u0026gt; SLOWLOG GET #慢日志查询 1) 1) (integer) 5 2) (integer) 1684326682 3) (integer) 12000 4) 1) \u0026#34;KEYS\u0026#34; 2) \u0026#34;*\u0026#34; 5) \u0026#34;172.17.0.1:61152\u0026#34; 6) \u0026#34;\u0026#34; // ... 慢查询日志中的每个条目都由以下六个值组成：\n唯一渐进的日志标识符。 处理记录命令的 Unix 时间戳。 执行所需的时间量，以微秒为单位。 组成命令参数的数组。 客户端 IP 地址和端口。 客户端名称。 SLOWLOG GET 命令默认返回最近 10 条的的慢查询命令，你也自己可以指定返回的慢查询命令的数量 SLOWLOG GET N。\n下面是其他比较常用的慢查询相关的命令：\n# 返回慢查询命令的数量 127.0.0.1:6379\u0026gt; SLOWLOG LEN (integer) 128 # 清空慢查询命令 127.0.0.1:6379\u0026gt; SLOWLOG RESET OK 2.8.6 Redis 内存碎片 # 相关问题：\n什么是内存碎片?为什么会有 Redis 内存碎片? 如何清理 Redis 内存碎片？ 参考答案：Redis 内存碎片详解。\n2.9 Redis生产问题 # 2.9.1 缓存穿透 # 2.9.1.1 什么是缓存穿透？ # 缓存穿透说简单点就是大量请求的 key 是不合理的，根本不存在于缓存中，也不存在于数据库中 。这就导致这些请求直接到了数据库上，根本没有经过缓存这一层，对数据库造成了巨大的压力，可能直接就被这么多请求弄宕机了。\n举个例子：某个黑客故意制造一些非法的 key 发起大量请求，导致大量请求落到数据库，结果数据库上也没有查到对应的数据。也就是说这些请求最终都落到了数据库上，对数据库造成了巨大的压力。\n2.9.1.2 有哪些解决方法？ # 最基本的就是首先做好参数校验，一些不合法的参数请求直接抛出异常信息返回给客户端。比如查询的数据库 id 不能小于 0、传入的邮箱格式不对的时候直接返回错误消息给客户端等等。\n1）缓存无效 key\n如果缓存和数据库都查不到某个 key 的数据就写一个到 Redis 中去并设置过期时间，具体命令如下：SET key value EX 10086 。这种方式可以解决请求的 key 变化不频繁的情况，如果黑客恶意攻击，每次构建不同的请求 key，会导致 Redis 中缓存大量无效的 key 。很明显，这种方案并不能从根本上解决此问题。如果非要用这种方式来解决穿透问题的话，尽量将无效的 key 的过期时间设置短一点比如 1 分钟。\n另外，这里多说一嘴，一般情况下我们是这样设计 key 的：表名:列名:主键名:主键值 。\n如果用 Java 代码展示的话，差不多是下面这样的：\npublic Object getObjectInclNullById(Integer id) { // 从缓存中获取数据 Object cacheValue = cache.get(id); // 缓存为空 if (cacheValue == null) { // 从数据库中获取 Object storageValue = storage.get(key); // 缓存空对象 cache.set(key, storageValue); // 如果存储数据为空，需要设置一个过期时间(300秒) if (storageValue == null) { // 必须设置过期时间，否则有被攻击的风险 cache.expire(key, 60 * 5); } return storageValue; } return cacheValue; } 2）布隆过滤器\n布隆过滤器是一个非常神奇的数据结构，通过它我们可以非常方便地判断一个给定数据是否存在于海量数据中。我们可以把它看作由二进制向量（或者说位数组）和一系列随机映射函数（哈希函数）两部分组成的数据结构。相比于我们平时常用的 List、Map、Set 等数据结构，它占用空间更少并且效率更高，但是缺点是其返回的结果是概率性的，而不是非常准确的。理论情况下添加到集合中的元素越多，误报的可能性就越大。并且，存放在布隆过滤器的数据不容易删除。\nBloom Filter 会使用一个较大的 bit 数组来保存所有的数据，数组中的每个元素都只占用 1 bit ，并且每个元素只能是 0 或者 1（代表 false 或者 true），这也是 Bloom Filter 节省内存的核心所在。这样来算的话，申请一个 100w 个元素的位数组只占用 1000000Bit / 8 = 125000 Byte = 125000/1024 KB ≈ 122KB 的空间。\n具体是这样做的：把所有可能存在的请求的值都存放在布隆过滤器中，当用户请求过来，先判断用户发来的请求的值是否存在于布隆过滤器中。不存在的话，直接返回请求参数错误信息给客户端，存在的话才会走下面的流程。\n加入布隆过滤器之后的缓存处理流程图如下。\n更多关于布隆过滤器的详细介绍可以看看我的这篇原创：不了解布隆过滤器？一文给你整的明明白白！ ，强烈推荐。\n3）接口限流\n根据用户或者 IP 对接口进行限流，对于异常频繁的访问行为，还可以采取黑名单机制，例如将异常 IP 列入黑名单。\n后面提到的缓存击穿和雪崩都可以配合接口限流来解决，毕竟这些问题的关键都是有很多请求落到了数据库上造成数据库压力过大。\n限流的具体方案可以参考这篇文章：服务限流详解。\n2.9.2 缓存击穿 # 2.9.2.1 什么是缓存击穿？ # 缓存击穿中，请求的 key 对应的是 热点数据 ，该数据 存在于数据库中，但不存在于缓存中（通常是因为缓存中的那份数据已经过期） 。这就可能会导致瞬时大量的请求直接打到了数据库上，对数据库造成了巨大的压力，可能直接就被这么多请求弄宕机了。\n举个例子：秒杀进行过程中，缓存中的某个秒杀商品的数据突然过期，这就导致瞬时大量对该商品的请求直接落到数据库上，对数据库造成了巨大的压力。\n2.9.2.2 有哪些解决办法？ # 永不过期（不推荐）：设置热点数据永不过期或者过期时间比较长。\n提前预热（推荐）：针对热点数据提前预热，将其存入缓存中并设置合理的过期时间比如秒杀场景下的数据在秒杀结束之前不过期。\n加锁（看情况）：在缓存失效后，通过设置互斥锁确保只有一个请求去查询数据库并更新缓存。\n关于加锁的机制：\n使用互斥锁：当缓存失效时，不立即去 load db，先使用如Redis的 SETNX 去设置一个互斥锁。当操作成功返回时，再进行load db 的操作并回设缓存，否则重试get缓存的方法。 设置当前key逻辑过期，大概思路如下：1) 在设置key的时候，设置一个过期时间字段一块存入缓存中，不给当前key设置过期时间；2) 当查询的时候，从redis取出数据后判断时间是否过期；3) 如果过期，则开通另外一个线程进行数据同步，当前线程正常返回数据，这个数据可能不是最新的。 2.9.2.3 缓存穿透和缓存击穿有什么区别 # 缓存穿透中，请求的 key 既不存在于缓存中，也不存在于数据库中。\n缓存击穿中，请求的 key 对应的是 热点数据 ，该数据 存在于数据库中，但不存在于缓存中（通常是因为缓存中的那份数据已经过期） 。\n2.9.3 缓存雪崩 # 2.9.3.1 什么是缓存雪崩 # 我发现缓存雪崩这名字起的有点意思，哈哈。\n实际上，缓存雪崩描述的就是这样一个简单的场景：缓存在同一时间大面积的失效，导致大量的请求都直接落到了数据库上，对数据库造成了巨大的压力。 这就好比雪崩一样，摧枯拉朽之势，数据库的压力可想而知，可能直接就被这么多请求弄宕机了。\n另外，缓存服务宕机也会导致缓存雪崩现象，导致所有的请求都落到了数据库上。\n举个例子：数据库中的大量数据在同一时间过期，这个时候突然有大量的请求需要访问这些过期的数据。这就导致大量的请求直接落到数据库上，对数据库造成了巨大的压力。\n2.9.3.2 有哪些解决办法 # 针对 Redis 服务不可用的情况：\nRedis 集群：采用 Redis 集群，避免单机出现问题整个缓存服务都没办法使用。Redis Cluster 和 Redis Sentinel 是两种最常用的 Redis 集群实现方案，详细介绍可以参考：Redis 集群详解(付费)。 多级缓存：设置多级缓存，例如本地缓存+Redis 缓存的二级缓存组合，当 Redis 缓存出现问题时，还可以从本地缓存中获取到部分数据。 针对大量缓存同时失效的情况：\n设置随机失效时间（可选）：为缓存设置随机的失效时间，例如在固定过期时间的基础上加上一个随机值，这样可以避免大量缓存同时到期，从而减少缓存雪崩的风险。 提前预热（推荐）：针对热点数据提前预热，将其存入缓存中并设置合理的过期时间比如秒杀场景下的数据在秒杀结束之前不过期。 持久缓存策略（看情况）：虽然一般不推荐设置缓存永不过期，但对于某些关键性和变化不频繁的数据，可以考虑这种策略。 2.9.3.3 缓存预热如何实现 # 常见的缓存预热方式有两种：\n使用定时任务，比如 xxl-job，来定时触发缓存预热的逻辑，将数据库中的热点数据查询出来并存入缓存中。 使用消息队列，比如 Kafka，来异步地进行缓存预热，将数据库中的热点数据的主键或者 ID 发送到消息队列中，然后由缓存服务消费消息队列中的数据，根据主键或者 ID 查询数据库并更新缓存。 2.9.3.4 缓存雪崩和缓存击穿有什么区别 # 缓存雪崩和缓存击穿比较像，但缓存雪崩导致的原因是缓存中的大量或者所有数据失效，缓存击穿导致的原因主要是某个热点数据不存在与缓存中（通常是因为缓存中的那份数据已经过期）。\n2.9.4 如何保证缓存和数据库数据的一致性 # 细说的话可以扯很多，但是我觉得其实没太大必要（小声 BB：很多解决方案我也没太弄明白）。我个人觉得引入缓存之后，如果为了短时间的不一致性问题，选择让系统设计变得更加复杂的话，完全没必要。\n下面单独对 Cache Aside Pattern（旁路缓存模式） 来聊聊。\nCache Aside Pattern 中遇到写请求是这样的：更新数据库，然后直接删除缓存 。\n如果更新数据库成功，而删除缓存这一步失败的情况的话，简单说有两个解决方案：\n缓存失效时间变短（不推荐，治标不治本）：我们让缓存数据的过期时间变短，这样的话缓存就会从数据库中加载数据。另外，这种解决办法对于先操作缓存后操作数据库的场景不适用。 增加缓存更新重试机制（常用）：如果缓存服务当前不可用导致缓存删除失败的话，我们就隔一段时间进行重试，重试次数可以自己定。不过，这里更适合引入消息队列实现异步重试，将删除缓存重试的消息投递到消息队列，然后由专门的消费者来重试，直到成功。虽然说多引入了一个消息队列，但其整体带来的收益还是要更高一些。 相关文章推荐：缓存和数据库一致性问题，看这篇就够了 - 水滴与银弹。\n2.9.5 哪些情况可能会导致Redis阻塞 # 单独抽了一篇文章来总结可能会导致 Redis 阻塞的情况：Redis 常见阻塞原因总结。\n2.10 Redis集群 # Redis Sentinel：\n什么是 Sentinel？ 有什么用？ Sentinel 如何检测节点是否下线？主观下线与客观下线的区别? Sentinel 是如何实现故障转移的？ 为什么建议部署多个 sentinel 节点（哨兵集群）？ Sentinel 如何选择出新的 master（选举机制）? 如何从 Sentinel 集群中选择出 Leader ？ Sentinel 可以防止脑裂吗？ Redis Cluster：\n为什么需要 Redis Cluster？解决了什么问题？有什么优势？ Redis Cluster 是如何分片的？ 为什么 Redis Cluster 的哈希槽是 16384 个? 如何确定给定 key 的应该分布到哪个哈希槽中？ Redis Cluster 支持重新分配哈希槽吗？ Redis Cluster 扩容缩容期间可以提供服务吗？ Redis Cluster 中的节点是怎么进行通信的？ 参考答案：Redis 集群详解（付费）。\n2.11 Redis使用规范 # 实际使用 Redis 的过程中，我们尽量要准守一些常见的规范，比如：\n使用连接池：避免频繁创建关闭客户端连接。 尽量不使用 O(n)指令，使用 O(n) 命令时要关注 n 的数量：像 KEYS *、HGETALL、LRANGE、SMEMBERS、SINTER/SUNION/SDIFF等 O(n) 命令并非不能使用，但是需要明确 n 的值。另外，有遍历的需求可以使用 HSCAN、SSCAN、ZSCAN 代替。 使用批量操作减少网络传输：原生批量操作命令（比如 MGET、MSET等等）、pipeline、Lua 脚本。 尽量不适用 Redis 事务：Redis 事务实现的功能比较鸡肋，可以使用 Lua 脚本代替。 禁止长时间开启 monitor：对性能影响比较大。 控制 key 的生命周期：避免 Redis 中存放了太多不经常被访问的数据。 …… 相关文章推荐：阿里云 Redis 开发规范 。\n","date":"23 March 2025","externalUrl":null,"permalink":"/posts/1742706434897-redis/","section":"Posts","summary":"","title":"redis","type":"posts"},{"content":"","date":"23 March 2025","externalUrl":null,"permalink":"/tags/tag/","section":"Tags","summary":"","title":"Tag","type":"tags"},{"content":"","date":"23 March 2025","externalUrl":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"},{"content":" MySQL基础 # 1.1 MySQL基础 # 1.1.1 关系型数据库 # 数据库管理系统（DataBase Management System，简称DBMS）\nDBMS是操作和管理数据库的大型软件。将来我们只需要操作这个软件，就可以通过这个软件来操纵和管理数据库了。 顾名思义，==关系型数据库（RDB，Relational Database）就是一种建立在关系模型的基础上的数据库。关系模型表明了数据库中所存储的数据之间的联系（一对一、一对多、多对多）。==\n关系型数据库中，我们的数据都被存放在了各种表中（比如用户表），表中的每一行就存放着一条数据（比如一个用户的信息）。\n大部分关系型数据库都使用 SQL 来操作数据库中的数据。并且，大部分关系型数据库都支持事务的四大特性(ACID)。\n有哪些常见的关系型数据库呢？\nMySQL、PostgreSQL、Oracle、SQL Server、SQLite（微信本地的聊天记录的存储就是用的 SQLite） ……。\n1.1.2 SQL # SQL 是一种结构化查询语言(Structured Query Language)，专门用来与数据库打交道，目的是提供一种从数据库中读写数据的简单有效的方法。\n几乎所有的主流关系数据库都支持 SQL ，适用性非常强。并且，一些非关系型数据库也兼容 SQL 或者使用的是类似于 SQL 的查询语言。\nSQL 可以帮助我们：\n新建数据库、数据表、字段； 在数据库中增加，删除，修改，查询数据； 新建视图、函数、存储过程； 对数据库中的数据进行简单的数据分析； 搭配 Hive，Spark SQL 做大数据； 搭配 SQLFlow 做机器学习； …… 1.1.3.1 SQL 分类 # SQL语句根据其功能被分为四大类：DDL、DML、DQL、DCL\n分类 全称 说明 DDL Data Definition Language 数据定义语言，用来定义数据库对象(数据库，表，字段) DML Data Manipulation Language 数据操作语言，用来对数据库表中的数据进行增删改 DQL Data Query Language 数据查询语言，用来查询数据库中表的记录 DCL Data Control Language 数据控制语言，用来创建数据库用户、控制数据库的访问权限 1.1.3 MySQL # MySQL 是一种关系型数据库，主要用于持久化存储我们的系统中的一些数据比如用户信息。\n由于 MySQL 是开源免费并且比较成熟的数据库，因此，MySQL 被大量使用在各种系统中。任何人都可以在 GPL(General Public License) 的许可下下载并根据个性化的需要对其进行修改。MySQL 的默认端口号是3306。\n1.1.4 MySQL优点 # 这个问题本质上是在问 MySQL 如此流行的原因。\nMySQL 主要具有下面这些优点：\n成熟稳定，功能完善。 开源免费。 文档丰富，既有详细的官方文档，又有非常多优质文章可供参考学习。 开箱即用，操作简单，维护成本低。 兼容性好，支持常见的操作系统，支持多种开发语言。 社区活跃，生态完善。 事务支持优秀， InnoDB 存储引擎默认使用 REPEATABLE-READ 并不会有任何性能损失，并且，InnoDB 实现的 REPEATABLE-READ 隔离级别其实是可以解决幻读问题发生的。 支持分库分表、读写分离、高可用。 1.2 MySQL字段类型 # MySQL 字段类型可以简单分为三大类：\n数值类型：整型（TINYINT、SMALLINT、MEDIUMINT、INT 和 BIGINT）、浮点型（FLOAT 和 DOUBLE）、定点型（DECIMAL） 字符串类型：CHAR、VARCHAR、TINYTEXT、TEXT、MEDIUMTEXT、LONGTEXT、TINYBLOB、BLOB、MEDIUMBLOB 和 LONGBLOB 等，最常用的是 CHAR 和 VARCHAR。 日期时间类型：YEAR、TIME、DATE、DATETIME 和 TIMESTAMP 等。 MySQL 字段类型比较多，我这里会挑选一些日常开发使用很频繁且面试常问的字段类型，以面试问题的形式来详细介绍。如无特殊说明，针对的都是 InnoDB 存储引擎。\n另外，推荐阅读一下《高性能 MySQL(第三版)》的第四章，有详细介绍 MySQL 字段类型优化。\n1.2.1 UNSIGNED 属性 # MySQL 中的整数类型可以使用可选的 UNSIGNED 属性来表示不允许负值的无符号整数。使用 UNSIGNED 属性可以将正整数的上限提高一倍，因为它不需要存储负数值。\n例如， TINYINT UNSIGNED 类型的取值范围是 0 ~ 255，而普通的 TINYINT 类型的值范围是 -128 ~ 127。INT UNSIGNED 类型的取值范围是 0 ~ 4,294,967,295，而普通的 INT 类型的值范围是 -2,147,483,648 ~ 2,147,483,647。\n对于从 0 开始递增的 ID 列，使用 UNSIGNED 属性可以非常适合，因为不允许负值并且可以拥有更大的上限范围，提供了更多的 ID 值可用。\n1.2.2 CHAR和 VARCHEAR的区别 # CHAR 和 VARCHAR 是最常用到的字符串类型，两者的主要区别在于：CHAR 是定长字符串，VARCHAR 是变长字符串。\nCHAR 在存储时会在右边填充空格以达到指定的长度，检索时会去掉空格；VARCHAR 在存储时需要使用 1 或 2 个额外字节记录字符串的长度，检索时不需要处理。\nCHAR 更适合存储长度较短或者长度都差不多的字符串，例如 Bcrypt 算法、MD5 算法加密后的密码、身份证号码。VARCHAR 类型适合存储长度不确定或者差异较大的字符串，例如用户昵称、文章标题等。\nCHAR(M) 和 VARCHAR(M) 的 M 都代表能够保存的字符数的最大值，无论是字母、数字还是中文，每个都只占用一个字符。\n1.2.3 VARCHAR(100) 和 VARCHAR(10)的区别 # VARCHAR(100)和 VARCHAR(10)都是变长类型，表示能存储最多 100 个字符和 10 个字符。因此，VARCHAR (100) 可以满足更大范围的字符存储需求，有更好的业务拓展性。而 VARCHAR(10)存储超过 10 个字符时，就需要修改表结构才可以。\n虽说 VARCHAR(100)和 VARCHAR(10)能存储的字符范围不同，但二者存储相同的字符串，所占用磁盘的存储空间其实是一样的，这也是很多人容易误解的一点。\n不过，VARCHAR(100) 会消耗更多的内存。这是因为 VARCHAR 类型在内存中操作时，通常会分配固定大小的内存块来保存值，即使用字符类型中定义的长度。例如在进行排序的时候，VARCHAR(100)是按照 100 这个长度来进行的，也就会消耗更多内存。\n1.2.4 DECIMAL 和 FLOAT/DOUBLE的区别 # DECIMAL 和 FLOAT 的区别是：DECIMAL 是定点数，FLOAT/DOUBLE 是浮点数。DECIMAL 可以存储精确的小数值，FLOAT/DOUBLE 只能存储近似的小数值。\nDECIMAL 用于存储具有精度要求的小数，例如与货币相关的数据，可以避免浮点数带来的精度损失。\n在 Java 中，MySQL 的 DECIMAL 类型对应的是 Java 类 java.math.BigDecimal。\n1.2.5 为什么不推荐使用 TEXT 和 BLOB # TEXT 类型类似于 CHAR（0-255 字节）和 VARCHAR（0-65,535 字节），但可以存储更长的字符串，即长文本数据，例如博客内容。\n类型 可存储大小 用途 TINYTEXT 0-255 字节 一般文本字符串 TEXT 0-65,535 字节 长文本字符串 MEDIUMTEXT 0-16,772,150 字节 较大文本数据 LONGTEXT 0-4,294,967,295 字节 极大文本数据 BLOB 类型主要用于存储二进制大对象，例如图片、音视频等文件。\n类型 可存储大小 用途 TINYBLOB 0-255 字节 短文本二进制字符串 BLOB 0-65KB 二进制字符串 MEDIUMBLOB 0-16MB 二进制形式的长文本数据 LONGBLOB 0-4GB 二进制形式的极大文本数据 在日常开发中，很少使用 TEXT 类型，但偶尔会用到，而 BLOB 类型则基本不常用。如果预期长度范围可以通过 VARCHAR 来满足，建议避免使用 TEXT。\n数据库规范通常不推荐使用 BLOB 和 TEXT 类型，这两种类型具有一些缺点和限制，例如：\n不能有默认值。 在使用临时表时无法使用内存临时表，只能在磁盘上创建临时表（《高性能 MySQL》书中有提到）。 检索效率较低。 不能直接创建索引，需要指定前缀长度。 可能会消耗大量的网络和 IO 带宽。 可能导致表上的 DML 操作变慢。 …… 1.2.6 DATETIME和TIMESTAMP的区别 # DATETIME 类型没有时区信息，TIMESTAMP 和时区有关。\nTIMESTAMP 只需要使用 4 个字节的存储空间，但是 DATETIME 需要耗费 8 个字节的存储空间。但是，这样同样造成了一个问题，Timestamp 表示的时间范围更小。\nDATETIME：1000-01-01 00:00:00 ~ 9999-12-31 23:59:59 Timestamp：1970-01-01 00:00:01 ~ 2037-12-31 23:59:59 关于两者的详细对比，请参考我写的MySQL 时间类型数据存储建议。\n1.2.7 NULL和“” 的区别 # NULL 跟 ''(空字符串)是两个完全不一样的值，区别如下：\nNULL 代表一个不确定的值,就算是两个 NULL,它俩也不一定相等。例如，SELECT NULL=NULL的结果为 false，但是在我们使用DISTINCT,GROUP BY,ORDER BY时,NULL又被认为是相等的。 ''的长度是 0，是不占用空间的，而NULL 是需要占用空间的。 NULL 会影响聚合函数的结果。例如，SUM、AVG、MIN、MAX 等聚合函数会忽略 NULL 值。 COUNT 的处理方式取决于参数的类型。如果参数是 *(COUNT(*))，则会统计所有的记录数，包括 NULL 值；如果参数是某个字段名(COUNT(列名))，则会忽略 NULL 值，只统计非空值的个数。 查询 NULL 值时，必须使用 IS NULL 或 IS NOT NULLl 来判断，而不能使用 =、!=、 \u0026lt;、\u0026gt; 之类的比较运算符。而''是可以使用这些比较运算符的。 看了上面的介绍之后，相信你对另外一个高频面试题：“为什么 MySQL 不建议使用 NULL 作为列默认值？”也有了答案。\n1.2.8 Boolean类型如何表示 # MySQL 中没有专门的布尔类型，而是用 TINYINT(1) 类型来表示布尔值。TINYINT(1) 类型可以存储 0 或 1，分别对应 false 或 true。\n1.3 MySQL基础架构 # 建议配合 SQL 语句在 MySQL 中的执行过程 这篇文章来理解 MySQL 基础架构。另外，“一个 SQL 语句在 MySQL 中的执行流程”也是面试中比较常问的一个问题。\n下图是 MySQL 的一个简要架构图，从下图你可以很清晰的看到客户端的一条 SQL 语句在 MySQL 内部是如何执行的。\n从上图可以看出， MySQL 主要由下面几部分构成：\n连接器： 身份认证和权限相关(登录 MySQL 的时候)。 查询缓存： 执行查询语句的时候，会先查询缓存（MySQL 8.0 版本后移除，因为这个功能不太实用）。 分析器： 没有命中缓存的话，SQL 语句就会经过分析器，分析器说白了就是要先看你的 SQL 语句要干嘛，再检查你的 SQL 语句语法是否正确。 优化器： 按照 MySQL 认为最优的方案去执行。 执行器： 执行语句，然后从存储引擎返回数据。 执行语句之前会先判断是否有权限，如果没有权限的话，就会报错。 插件式存储引擎：主要负责数据的存储和读取，采用的是插件式架构，支持 InnoDB、MyISAM、Memory 等多种存储引擎。 1.4 MySQL存储引擎 # MySQL 核心在于存储引擎，想要深入学习 MySQL，必定要深入研究 MySQL 存储引擎。\n1.4.1 MySQL 支持哪些存储引擎？默认使用哪个？ # MySQL 支持多种存储引擎，你可以通过 SHOW ENGINES 命令来查看 MySQL 支持的所有存储引擎。\nMySQL 提供的所有存储引擎\n从上图我们可以查看出， MySQL 当前默认的存储引擎是 InnoDB。并且，所有的存储引擎中只有 InnoDB 是事务性存储引擎，也就是说只有 InnoDB 支持事务。\n我这里使用的 MySQL 版本是 8.x，不同的 MySQL 版本之间可能会有差别。\nMySQL 5.5.5 之前，MyISAM 是 MySQL 的默认存储引擎。5.5.5 版本之后，InnoDB 是 MySQL 的默认存储引擎。\n你可以通过 SELECT VERSION() 命令查看你的 MySQL 版本。\nmysql\u0026gt; SELECT VERSION(); +-----------+ | VERSION() | +-----------+ | 8.0.27 | +-----------+ 1 row in set (0.00 sec) 你也可以通过 SHOW VARIABLES LIKE '%storage_engine%' 命令直接查看 MySQL 当前默认的存储引擎。\nmysql\u0026gt; SHOW VARIABLES LIKE \u0026#39;%storage_engine%\u0026#39;; +---------------------------------+-----------+ | Variable_name | Value | +---------------------------------+-----------+ | default_storage_engine | InnoDB | | default_tmp_storage_engine | InnoDB | | disabled_storage_engines | | | internal_tmp_mem_storage_engine | TempTable | +---------------------------------+-----------+ 4 rows in set (0.00 sec) 如果你想要深入了解每个存储引擎以及它们之间的区别，推荐你去阅读以下 MySQL 官方文档对应的介绍(面试不会问这么细，了解即可)：\nInnoDB 存储引擎详细介绍：https://dev.mysql.com/doc/refman/8.0/en/innodb-storage-engine.html 。 其他存储引擎详细介绍：https://dev.mysql.com/doc/refman/8.0/en/storage-engines.html 。 1.4.2 MySQL存储引擎架构 # MySQL 存储引擎采用的是 插件式架构 ，支持多种存储引擎，我们甚至可以为不同的数据库表设置不同的存储引擎以适应不同场景的需要。存储引擎是基于表的，而不是数据库。\n下图展示了具有可插拔存储引擎的 MySQL 架构（）：\nMySQL architecture diagram showing connectors, interfaces, pluggable storage engines, the file system with files and logs.\n你还可以根据 MySQL 定义的存储引擎实现标准接口来编写一个属于自己的存储引擎。这些非官方提供的存储引擎可以称为第三方存储引擎，区别于官方存储引擎。像目前最常用的 InnoDB 其实刚开始就是一个第三方存储引擎，后面由于过于优秀，其被 Oracle 直接收购了。\nMySQL 官方文档也有介绍到如何编写一个自定义存储引擎，地址：https://dev.mysql.com/doc/internals/en/custom-engine.html 。\n1.4.3 MyISAM 和 InnoDB的区别 # MySQL 5.5 之前，MyISAM 引擎是 MySQL 的默认存储引擎，可谓是风光一时。\n虽然，MyISAM 的性能还行，各种特性也还不错（比如全文索引、压缩、空间函数等）。但是，MyISAM 不支持事务和行级锁，而且最大的缺陷就是崩溃后无法安全恢复。\nMySQL 5.5 版本之后，InnoDB 是 MySQL 的默认存储引擎。\n言归正传！咱们下面还是来简单对比一下两者：\n1、是否支持行级锁\nMyISAM 只有表级锁(table-level locking)，而 InnoDB 支持行级锁(row-level locking)和表级锁,默认为行级锁。\n也就说，MyISAM 一锁就是锁住了整张表，这在并发写的情况下是多么滴憨憨啊！这也是为什么 InnoDB 在并发写的时候，性能更牛皮了！\n2、是否支持事务\nMyISAM 不提供事务支持。\nInnoDB 提供事务支持，实现了 SQL 标准定义了四个隔离级别，具有提交(commit)和回滚(rollback)事务的能力。并且，InnoDB 默认使用的 REPEATABLE-READ（可重读）隔离级别是可以解决幻读问题发生的（基于 MVCC 和 Next-Key Lock）。\n关于 MySQL 事务的详细介绍，可以看看我写的这篇文章：MySQL 事务隔离级别详解。\n3、是否支持外键\nMyISAM 不支持，而 InnoDB 支持。\n外键对于维护数据一致性非常有帮助，但是对性能有一定的损耗。因此，通常情况下，我们是不建议在实际生产项目中使用外键的，在业务代码中进行约束即可！\n阿里的《Java 开发手册》也是明确规定禁止使用外键的。\n不过，在代码中进行约束的话，对程序员的能力要求更高，具体是否要采用外键还是要根据你的项目实际情况而定。\n总结：一般我们也是不建议在数据库层面使用外键的，应用层面可以解决。不过，这样会对数据的一致性造成威胁。具体要不要使用外键还是要根据你的项目来决定。\n4、是否支持数据库异常崩溃后的安全恢复\nMyISAM 不支持，而 InnoDB 支持。\n使用 InnoDB 的数据库在异常崩溃后，数据库重新启动的时候会保证数据库恢复到崩溃前的状态。这个恢复的过程依赖于 redo log 。\n5、是否支持 MVCC\nMyISAM 不支持，而 InnoDB 支持。\n讲真，这个对比有点废话，毕竟 MyISAM 连行级锁都不支持。MVCC 可以看作是行级锁的一个升级，可以有效减少加锁操作，提高性能。\n6、索引实现不一样。\n虽然 MyISAM 引擎和 InnoDB 引擎都是使用 B+Tree 作为索引结构，但是两者的实现方式不太一样。\nInnoDB 引擎中，其数据文件本身就是索引文件。相比 MyISAM，索引文件和数据文件是分离的，其表数据文件本身就是按 B+Tree 组织的一个索引结构，树的叶节点 data 域保存了完整的数据记录。\n详细区别，推荐你看看我写的这篇文章：MySQL 索引详解。\n7、性能有差别。\nInnoDB 的性能比 MyISAM 更强大，不管是在读写混合模式下还是只读模式下，随着 CPU 核数的增加，InnoDB 的读写能力呈线性增长。MyISAM 因为读写不能并发，它的处理能力跟核数没关系。\nInnoDB 和 MyISAM 性能对比\n8、数据缓存策略和机制实现不同。\nInnoDB 使用缓冲池（Buffer Pool）缓存数据页和索引页，MyISAM 使用键缓存（Key Cache）仅缓存索引页而不缓存数据页。\n总结：\nInnoDB 支持行级别的锁粒度，MyISAM 不支持，只支持表级别的锁粒度。 MyISAM 不提供事务支持。InnoDB 提供事务支持，实现了 SQL 标准定义了四个隔离级别。 MyISAM 不支持外键，而 InnoDB 支持。 MyISAM 不支持 MVCC，而 InnoDB 支持。 虽然 MyISAM 引擎和 InnoDB 引擎都是使用 B+Tree 作为索引结构，但是两者的实现方式不太一样。 MyISAM 不支持数据库异常崩溃后的安全恢复，而 InnoDB 支持。 InnoDB 的性能比 MyISAM 更强大。 最后，再分享一张图片给你，这张图片详细对比了常见的几种 MySQL 存储引擎。\n1.4.4 MyISAM和InnoDB如何选择 # 大多数时候我们使用的都是 InnoDB 存储引擎，在某些读密集的情况下，使用 MyISAM 也是合适的。不过，前提是你的项目不介意 MyISAM 不支持事务、崩溃恢复等缺点（可是~我们一般都会介意啊）。\n《MySQL 高性能》上面有一句话这样写到:\n不要轻易相信“MyISAM 比 InnoDB 快”之类的经验之谈，这个结论往往不是绝对的。在很多我们已知场景中，InnoDB 的速度都可以让 MyISAM 望尘莫及，尤其是用到了聚簇索引，或者需要访问的数据都可以放入内存的应用。\n因此，对于咱们日常开发的业务系统来说，你几乎找不到什么理由使用 MyISAM 了，老老实实用默认的 InnoDB 就可以了！\n1.6 MySQL查询缓存 # MySQL 查询缓存是查询结果缓存。执行查询语句的时候，会先查询缓存，如果缓存中有对应的查询结果，就会直接返回。\nmy.cnf 加入以下配置，重启 MySQL 开启查询缓存\nquery_cache_type=1 query_cache_size=600000 MySQL 执行以下命令也可以开启查询缓存\nset global query_cache_type=1; set global query_cache_size=600000; 查询缓存会在同样的查询条件和数据情况下，直接返回缓存中的结果。但需要注意的是，查询缓存的匹配条件非常严格，任何细微的差异都会导致缓存无法命中。这里的查询条件包括查询语句本身、当前使用的数据库、以及其他可能影响结果的因素，如客户端协议版本号等。\n查询缓存不命中的情况：\n任何两个查询在任何字符上的不同都会导致缓存不命中。 如果查询中包含任何用户自定义函数、存储函数、用户变量、临时表、MySQL 库中的系统表，其查询结果也不会被缓存。 缓存建立之后，MySQL 的查询缓存系统会跟踪查询中涉及的每张表，如果这些表（数据或结构）发生变化，那么和这张表相关的所有缓存数据都将失效。 缓存虽然能够提升数据库的查询性能，但是缓存同时也带来了额外的开销，每次查询后都要做一次缓存操作，失效后还要销毁。 因此，开启查询缓存要谨慎，尤其对于写密集的应用来说更是如此。如果开启，要注意合理控制缓存空间大小，一般来说其大小设置为几十 MB 比较合适。此外，还可以通过 sql_cache 和 sql_no_cache 来控制某个查询语句是否需要缓存：\nSELECT sql_no_cache COUNT(*) FROM usr; MySQL 5.6 开始，查询缓存已默认禁用。MySQL 8.0 开始，已经不再支持查询缓存了（具体可以参考这篇文章：MySQL 8.0: Retiring Support for the Query Cache）。\n1.7 MySQL日志 # MySQL 日志常见的面试题有：\nMySQL 中常见的日志有哪些？ 慢查询日志有什么用？ binlog 主要记录了什么？ redo log 如何保证事务的持久性？ 页修改之后为什么不直接刷盘呢？ binlog 和 redolog 有什么区别？ undo log 如何保证事务的原子性？ …… 1.8 MySQL事务 # 1.8.1 何谓事务？ # 我们设想一个场景，这个场景中我们需要插入多条相关联的数据到数据库，不幸的是，这个过程可能会遇到下面这些问题：\n数据库中途突然因为某些原因挂掉了。 客户端突然因为网络原因连接不上数据库了。 并发访问数据库时，多个线程同时写入数据库，覆盖了彼此的更改。 …… 上面的任何一个问题都可能会导致数据的不一致性。为了保证数据的一致性，系统必须能够处理这些问题。事务就是我们抽象出来简化这些问题的首选机制。事务的概念起源于数据库，目前，已经成为一个比较广泛的概念。\n何为事务？ 一言蔽之，事务是逻辑上的一组操作，要么都执行，要么都不执行。\n事务的特性是ACID，即原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）、持久性（Durability）。\n事务最经典也经常被拿出来说例子就是转账了。假如小明要给小红转账 1000 元，这个转账会涉及到两个关键操作，这两个操作必须都成功或者都失败。\n将小明的余额减少 1000 元 将小红的余额增加 1000 元。 事务会把这两个操作就可以看成逻辑上的一个整体，这个整体包含的操作要么都成功，要么都要失败。这样就不会出现小明余额减少而小红的余额却并没有增加的情况。\n1.8.2 何谓数据库事务 # 大多数情况下，我们在谈论事务的时候，如果没有特指分布式事务，往往指的就是数据库事务。\n数据库事务在我们日常开发中接触的最多了。如果你的项目属于单体架构的话，你接触到的往往就是数据库事务了。\nMYSQL中有两种方式进行事务的操作：\n自动提交事务：即执行一条sql语句提交一次事务。（默认MySQL的事务是自动提交） 手动提交事务：先开启，再提交 事务操作有关的SQL语句：\nSQL语句 描述 start transaction; / begin ; 开启手动控制事务 commit; 提交事务 rollback; 回滚事务 手动提交事务使用步骤：\n第1种情况：开启事务 =\u0026gt; 执行SQL语句 =\u0026gt; 成功 =\u0026gt; 提交事务 第2种情况：开启事务 =\u0026gt; 执行SQL语句 =\u0026gt; 失败 =\u0026gt; 回滚事务 那数据库事务有什么作用呢？\n简单来说，数据库事务可以保证多个对数据库的操作（也就是 SQL 语句）构成一个逻辑上的整体。构成这个逻辑上的整体的这些数据库操作遵循：要么全部执行成功,要么全部不执行 。\n# 开启一个事务 START TRANSACTION; # 多条 SQL 语句 SQL1,SQL2... ## 提交事务 COMMIT; 另外，关系型数据库（例如：MySQL、SQL Server、Oracle 等）事务都有 ACID 特性：\n原子性（Atomicity）：事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用； 一致性（Consistency）：执行事务前后，数据保持一致，例如转账业务中，无论事务是否成功，转账者和收款人的总额应该是不变的； 隔离性（Isolation）：并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的； 持久性（Durability）：一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。 🌈 这里要额外补充一点：只有保证了事务的持久性、原子性、隔离性之后，一致性才能得到保障。也就是说 A、I、D 是手段，C 是目的！ 想必大家也和我一样，被 ACID 这个概念被误导了很久! 我也是看周志明老师的公开课《周志明的软件架构课》才搞清楚的（多看好书！！！）。\n另外，DDIA 也就是 《Designing Data-Intensive Application（数据密集型应用系统设计）》 的作者在他的这本书中如是说：\nAtomicity, isolation, and durability are properties of the database, whereas consis‐ tency (in the ACID sense) is a property of the application. The application may rely on the database’s atomicity and isolation properties in order to achieve consistency, but it’s not up to the database alone.\n翻译过来的意思是：原子性，隔离性和持久性是数据库的属性，而一致性（在 ACID 意义上）是应用程序的属性。应用可能依赖数据库的原子性和隔离属性来实现一致性，但这并不仅取决于数据库。因此，字母 C 不属于 ACID 。\n《Designing Data-Intensive Application（数据密集型应用系统设计）》这本书强推一波，值得读很多遍！豆瓣有接近 90% 的人看了这本书之后给了五星好评。另外，中文翻译版本已经在 GitHub 开源，地址：https://github.com/Vonng/ddia 。\n1.8.3 并发事务带来的问题 # 在典型的应用程序中，多个事务并发运行，经常会操作相同的数据来完成各自的任务（多个用户对同一数据进行操作）。并发虽然是必须的，但可能会导致以下的问题。\n1.8.3.1 脏读（Dirty read） # 一个事务读取数据并且对数据进行了修改，这个修改对其他事务来说是可见的，即使当前事务没有提交。这时另外一个事务读取了这个还未提交的数据，但第一个事务突然回滚，导致数据并没有被提交到数据库，那第二个事务读取到的就是脏数据，这也就是脏读的由来。\n例如：事务 1 读取某表中的数据 A=20，事务 1 修改 A=A-1，事务 2 读取到 A = 19,事务 1 回滚导致对 A 的修改并未提交到数据库， A 的值还是 20。\n1.8.3.2 丢失修改（Lost to modify） # 在一个事务读取一个数据时，另外一个事务也访问了该数据，那么在第一个事务中修改了这个数据后，第二个事务也修改了这个数据。这样第一个事务内的修改结果就被丢失，因此称为丢失修改。\n例如：事务 1 读取某表中的数据 A=20，事务 2 也读取 A=20，事务 1 先修改 A=A-1，事务 2 后来也修改 A=A-1，最终结果 A=19，事务 1 的修改被丢失。\n1.8.3.3 不可重复读（Unrepeatable read） # 指在一个事务内多次读同一数据。在这个事务还没有结束时，另一个事务也访问该数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改导致第一个事务两次读取的数据可能不太一样。这就发生了在一个事务内两次读到的数据是不一样的情况，因此称为不可重复读。\n例如：事务 1 读取某表中的数据 A=20，事务 2 也读取 A=20，事务 1 修改 A=A-1，事务 2 再次读取 A =19，此时读取的结果和第一次读取的结果不同。\n1.8.3.4 幻读（Phantom read） # 幻读与不可重复读类似。它发生在一个事务读取了几行数据，接着另一个并发事务插入了一些数据时。在随后的查询中，第一个事务就会发现多了一些原本不存在的记录，就好像发生了幻觉一样，所以称为幻读。\n例如：事务 2 读取某个范围的数据，事务 1 在这个范围插入了新的数据，事务 2 再次读取这个范围的数据发现相比于第一次读取的结果多了新的数据。\n1.8.4 不可重复读和幻读有什么区别 # 不可重复读的重点是内容修改或者记录减少比如多次读取一条记录发现其中某些记录的值被修改； 幻读的重点在于记录新增比如多次执行同一条查询语句（DQL）时，发现查到的记录增加了。 幻读其实可以看作是不可重复读的一种特殊情况，单独把幻读区分出来的原因主要是解决幻读和不可重复读的方案不一样。\n举个例子：执行 delete 和 update 操作的时候，可以直接对记录加锁，保证事务安全。而执行 insert 操作的时候，由于记录锁（Record Lock）只能锁住已经存在的记录，为了避免插入新记录，需要依赖间隙锁（Gap Lock）。也就是说执行 insert 操作的时候需要依赖 Next-Key Lock（Record Lock+Gap Lock） 进行加锁来保证不出现幻读。\n如何解决并发事务的问题 # 解决这些问题的方法是使用事务隔离。MySQL支持四种隔离级别：\n未提交读（READ UNCOMMITTED）：解决不了所有问题。 读已提交（READ COMMITTED）：能解决脏读，但不能解决不可重复读和幻读。 可重复读（REPEATABLE READ）：能解决脏读和不可重复读，但不能解决幻读，这也是MySQL的默认隔离级别。 串行化（SERIALIZABLE）：可以解决所有问题，但性能较低。 1.8.5 并发事务的控制方式 # MySQL 中并发事务的控制方式无非就两种：锁 和 MVCC。锁可以看作是悲观控制的模式，多版本并发控制（MVCC，Multiversion concurrency control）可以看作是乐观控制的模式。\n锁 控制方式下会通过锁来显式控制共享资源而不是通过调度手段，MySQL 中主要是通过 读写锁 来实现并发控制。\n共享锁（S 锁）：又称读锁，事务在读取记录的时候获取共享锁，允许多个事务同时获取（锁兼容）。 排他锁（X 锁）：又称写锁/独占锁，事务在修改记录的时候获取排他锁，不允许多个事务同时获取。如果一个记录已经被加了排他锁，那其他事务不能再对这条记录加任何类型的锁（锁不兼容）。 读写锁可以做到读读并行，但是无法做到写读、写写并行。另外，根据根据锁粒度的不同，又被分为 表级锁(table-level locking) 和 行级锁(row-level locking) 。InnoDB 不光支持表级锁，还支持行级锁，默认为行级锁。行级锁的粒度更小，仅对相关的记录上锁即可（对一行或者多行记录加锁），所以对于并发写入操作来说， InnoDB 的性能更高。不论是表级锁还是行级锁，都存在共享锁（Share Lock，S 锁）和排他锁（Exclusive Lock，X 锁）这两类。\nMVCC 是多版本并发控制方法，即对一份数据会存储多个版本，通过事务的可见性来保证事务能看到自己应该看到的版本。通常会有一个全局的版本分配器来为每一行数据设置版本号，版本号是唯一的。\nMVCC 在 MySQL 中实现所依赖的手段主要是: 隐藏字段、read view、undo log。\nundo log : undo log 用于记录某行数据的多个版本的数据。 read view 和 隐藏字段 : 用来判断当前版本数据的可见性。 关于 InnoDB 对 MVCC 的具体实现可以看这篇文章：InnoDB 存储引擎对 MVCC 的实现 。\n1.8.6 不可重复读和幻读有什么区别 # 不可重复读的重点是内容修改或者记录减少比如多次读取一条记录发现其中某些记录的值被修改； 幻读的重点在于记录新增比如多次执行同一条查询语句（DQL）时，发现查到的记录增加了。 幻读其实可以看作是不可重复读的一种特殊情况，单独把幻读区分出来的原因主要是解决幻读和不可重复读的方案不一样。\n举个例子：执行 delete 和 update 操作的时候，可以直接对记录加锁，保证事务安全。而执行 insert 操作的时候，由于记录锁（Record Lock）只能锁住已经存在的记录，为了避免插入新记录，需要依赖间隙锁（Gap Lock）。也就是说执行 insert 操作的时候需要依赖 Next-Key Lock（Record Lock+Gap Lock） 进行加锁来保证不出现幻读。\n1.8.7 并发事务的控制方式 # MySQL 中并发事务的控制方式无非就两种：锁 和 MVCC。锁可以看作是悲观控制的模式，多版本并发控制（MVCC，Multiversion concurrency control）可以看作是乐观控制的模式。\n锁 控制方式下会通过锁来显式控制共享资源而不是通过调度手段，MySQL 中主要是通过 读写锁 来实现并发控制。\n共享锁（S 锁）：又称读锁，事务在读取记录的时候获取共享锁，允许多个事务同时获取（锁兼容）。 排他锁（X 锁）：又称写锁/独占锁，事务在修改记录的时候获取排他锁，不允许多个事务同时获取。如果一个记录已经被加了排他锁，那其他事务不能再对这条记录加任何类型的锁（锁不兼容）。 读写锁可以做到读读并行，但是无法做到写读、写写并行。另外，根据根据锁粒度的不同，又被分为 表级锁(table-level locking) 和 行级锁(row-level locking) 。InnoDB 不光支持表级锁，还支持行级锁，默认为行级锁。行级锁的粒度更小，仅对相关的记录上锁即可（对一行或者多行记录加锁），所以对于并发写入操作来说， InnoDB 的性能更高。不论是表级锁还是行级锁，都存在共享锁（Share Lock，S 锁）和排他锁（Exclusive Lock，X 锁）这两类。\nMVCC 是多版本并发控制方法，即对一份数据会存储多个版本，通过事务的可见性来保证事务能看到自己应该看到的版本。通常会有一个全局的版本分配器来为每一行数据设置版本号，版本号是唯一的。\nMVCC 在 MySQL 中实现所依赖的手段主要是: 隐藏字段、read view、undo log。\nundo log : undo log 用于记录某行数据的多个版本的数据。 read view 和 隐藏字段 : 用来判断当前版本数据的可见性。 关于 InnoDB 对 MVCC 的具体实现可以看这篇文章：InnoDB 存储引擎对 MVCC 的实现 。\n1.8.8 SQL标准定义了哪些事务隔离级别 # SQL 标准定义了四个隔离级别：\nREAD-UNCOMMITTED(读取未提交) ：最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读。 READ-COMMITTED(读取已提交) ：允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生。 REPEATABLE-READ(可重复读) ：对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。 SERIALIZABLE(可串行化) ：最高的隔离级别，完全服从 ACID 的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。 隔离级别 脏读 不可重复读 幻读 READ-UNCOMMITTED √ √ √ READ-COMMITTED × √ √ REPEATABLE-READ × × √ SERIALIZABLE × × × 1.8.9 MySQL 的隔离级别是基于锁实现的吗？ # MySQL 的隔离级别基于锁和 MVCC 机制共同实现的。\nSERIALIZABLE 隔离级别是通过锁来实现的，READ-COMMITTED 和 REPEATABLE-READ 隔离级别是基于 MVCC 实现的。不过， SERIALIZABLE 之外的其他隔离级别可能也需要用到锁机制，就比如 REPEATABLE-READ 在当前读情况下需要使用加锁读来保证不会出现幻读。\n1.8.10 MySQL的默认隔离级别 # MySQL InnoDB 存储引擎的默认支持的隔离级别是 REPEATABLE-READ（可重读）。我们可以通过SELECT @@tx_isolation;命令来查看，MySQL 8.0 该命令改为SELECT @@transaction_isolation;\nmysql\u0026gt; SELECT @@tx_isolation; +-----------------+ | @@tx_isolation | +-----------------+ | REPEATABLE-READ | +-----------------+ 关于 MySQL 事务隔离级别的详细介绍，可以看看我写的这篇文章：MySQL 事务隔离级别详解。\n1.9 MySQL锁 # 锁是一种常见的并发事务的控制方式。\n1.9.1 表级锁和行级锁 # MyISAM 仅仅支持表级锁(table-level locking)，一锁就锁整张表，这在并发写的情况下性非常差。InnoDB 不光支持表级锁(table-level locking)，还支持行级锁(row-level locking)，默认为行级锁。\n行级锁的粒度更小，仅对相关的记录上锁即可（对一行或者多行记录加锁），所以对于并发写入操作来说， InnoDB 的性能更高。\n表级锁和行级锁对比：\n表级锁： MySQL 中锁定粒度最大的一种锁（全局锁除外），是针对非索引字段加的锁，对当前操作的整张表加锁，实现简单，资源消耗也比较少，加锁快，不会出现死锁。不过，触发锁冲突的概率最高，高并发下效率极低。表级锁和存储引擎无关，MyISAM 和 InnoDB 引擎都支持表级锁。 行级锁： MySQL 中锁定粒度最小的一种锁，是 针对索引字段加的锁 ，只针对当前操作的行记录进行加锁。 行级锁能大大减少数据库操作的冲突。其加锁粒度最小，并发度高，但加锁的开销也最大，加锁慢，会出现死锁。行级锁和存储引擎有关，是在存储引擎层面实现的。 1.9.2 行级锁的使用注意事项 # InnoDB 的行锁是针对索引字段加的锁，表级锁是针对非索引字段加的锁。当我们执行 UPDATE、DELETE 语句时，如果 WHERE条件中字段没有命中唯一索引或者索引失效的话，就会导致扫描全表对表中的所有行记录进行加锁。这个在我们日常工作开发中经常会遇到，一定要多多注意！！！\n不过，很多时候即使用了索引也有可能会走全表扫描，这是因为 MySQL 优化器的原因。\n1.9.3 InnoDB有哪几类行锁？ # InnoDB 行锁是通过对索引数据页上的记录加锁实现的，MySQL InnoDB 支持三种行锁定方式：\n记录锁（Record Lock）：也被称为记录锁，属于单个行记录上的锁。 间隙锁（Gap Lock）：锁定一个范围，不包括记录本身。 临键锁（Next-Key Lock）：Record Lock+Gap Lock，锁定一个范围，包含记录本身，主要目的是为了解决幻读问题（MySQL 事务部分提到过）。记录锁只能锁住已经存在的记录，为了避免插入新记录，需要依赖间隙锁。 在 InnoDB 默认的隔离级别 REPEATABLE-READ 下，行锁默认使用的是 Next-Key Lock。但是，如果操作的索引是唯一索引或主键，InnoDB 会对 Next-Key Lock 进行优化，将其降级为 Record Lock，即仅锁住索引本身，而不是范围。\n一些大厂面试中可能会问到 Next-Key Lock 的加锁范围，这里推荐一篇文章：MySQL next-key lock 加锁范围是什么？ - 程序员小航 - 2021 。\n1.9.4 共享锁和排他锁 # 不论是表级锁还是行级锁，都存在共享锁（Share Lock，S 锁）和排他锁（Exclusive Lock，X 锁）这两类：\n共享锁（S 锁）：又称读锁，事务在读取记录的时候获取共享锁，允许多个事务同时获取（锁兼容）。 排他锁（X 锁）：又称写锁/独占锁，事务在修改记录的时候获取排他锁，不允许多个事务同时获取。如果一个记录已经被加了排他锁，那其他事务不能再对这条事务加任何类型的锁（锁不兼容）。 排他锁与任何的锁都不兼容，共享锁仅和共享锁兼容。\nS 锁 X 锁 S 锁 不冲突 冲突 X 锁 冲突 冲突 由于 MVCC 的存在，对于一般的 SELECT 语句，InnoDB 不会加任何锁。不过， 你可以通过以下语句显式加共享锁或排他锁。\n# 共享锁 可以在 MySQL 5.7 和 MySQL 8.0 中使用 SELECT ... LOCK IN SHARE MODE; # 共享锁 可以在 MySQL 8.0 中使用 SELECT ... FOR SHARE; # 排他锁 SELECT ... FOR UPDATE; 1.9.5 意向锁 # 如果需要用到表锁的话，如何判断表中的记录没有行锁呢，一行一行遍历肯定是不行，性能太差。我们需要用到一个叫做意向锁的东东来快速判断是否可以对某个表使用表锁。\n意向锁是表级锁，共有两种：\n意向共享锁（Intention Shared Lock，IS 锁）：事务有意向对表中的某些记录加共享锁（S 锁），加共享锁前必须先取得该表的 IS 锁。 意向排他锁（Intention Exclusive Lock，IX 锁）：事务有意向对表中的某些记录加排他锁（X 锁），加排他锁之前必须先取得该表的 IX 锁。 意向锁是由数据引擎自己维护的，用户无法手动操作意向锁，在为数据行加共享/排他锁之前，InnoDB 会先获取该数据行所在在数据表的对应意向锁。\n意向锁之间是互相兼容的。\nIS 锁 IX 锁 IS 锁 兼容 兼容 IX 锁 兼容 兼容 意向锁和共享锁和排它锁互斥（这里指的是表级别的共享锁和排他锁，意向锁不会与行级的共享锁和排他锁互斥）。\nIS 锁 IX 锁 S 锁 兼容 互斥 X 锁 互斥 互斥 《MySQL 技术内幕 InnoDB 存储引擎》这本书对应的描述应该是笔误了。\n1.9.6 当前读和快照读 # 快照读（一致性非锁定读）就是单纯的 SELECT 语句，但不包括下面这两类 SELECT 语句：\nSELECT ... FOR UPDATE # 共享锁 可以在 MySQL 5.7 和 MySQL 8.0 中使用 SELECT ... LOCK IN SHARE MODE; # 共享锁 可以在 MySQL 8.0 中使用 SELECT ... FOR SHARE; 快照即记录的历史版本，每行记录可能存在多个历史版本（多版本技术）。\n快照读的情况下，如果读取的记录正在执行 UPDATE/DELETE 操作，读取操作不会因此去等待记录上 X 锁的释放，而是会去读取行的一个快照。\n只有在事务隔离级别 RC(读取已提交) 和 RR（可重读）下，InnoDB 才会使用一致性非锁定读：\n在 RC 级别下，对于快照数据，一致性非锁定读总是读取被锁定行的最新一份快照数据。 在 RR 级别下，对于快照数据，一致性非锁定读总是读取本事务开始时的行数据版本。 快照读比较适合对于数据一致性要求不是特别高且追求极致性能的业务场景。\n当前读 （一致性锁定读）就是给行记录加 X 锁或 S 锁。\n当前读的一些常见 SQL 语句类型如下：\n# 对读的记录加一个X锁 SELECT...FOR UPDATE # 对读的记录加一个S锁 SELECT...LOCK IN SHARE MODE # 对读的记录加一个S锁 SELECT...FOR SHARE # 对修改的记录加一个X锁 INSERT... UPDATE... DELETE... 1.9.7 自增锁 # 不太重要的一个知识点，简单了解即可。\n关系型数据库设计表的时候，通常会有一列作为自增主键。InnoDB 中的自增主键会涉及一种比较特殊的表级锁— 自增锁（AUTO-INC Locks） 。\nCREATE TABLE `sequence_id` ( `id` BIGINT(20) UNSIGNED NOT NULL AUTO_INCREMENT, `stub` CHAR(10) NOT NULL DEFAULT \u0026#39;\u0026#39;, PRIMARY KEY (`id`), UNIQUE KEY `stub` (`stub`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; 更准确点来说，不仅仅是自增主键，AUTO_INCREMENT的列都会涉及到自增锁，毕竟非主键也可以设置自增长。\n如果一个事务正在插入数据到有自增列的表时，会先获取自增锁，拿不到就可能会被阻塞住。这里的阻塞行为只是自增锁行为的其中一种，可以理解为自增锁就是一个接口，其具体的实现有多种。具体的配置项为 innodb_autoinc_lock_mode （MySQL 5.1.22 引入），可以选择的值如下：\ninnodb_autoinc_lock_mode 介绍 0 传统模式 1 连续模式（MySQL 8.0 之前默认） 2 交错模式(MySQL 8.0 之后默认) 交错模式下，所有的“INSERT-LIKE”语句（所有的插入语句，包括：INSERT、REPLACE、INSERT…SELECT、REPLACE…SELECT、LOAD DATA等）都不使用表级锁，使用的是轻量级互斥锁实现，多条插入语句可以并发执行，速度更快，扩展性也更好。\n不过，如果你的 MySQL 数据库有主从同步需求并且 Binlog 存储格式为 Statement 的话，不要将 InnoDB 自增锁模式设置为交叉模式，不然会有数据不一致性问题。这是因为并发情况下插入语句的执行顺序就无法得到保障。\n如果 MySQL 采用的格式为 Statement ，那么 MySQL 的主从同步实际上同步的就是一条一条的 SQL 语句。\n最后，再推荐一篇文章：为什么 MySQL 的自增主键不单调也不连续\n1.10 MySQL性能优化 # 关于 MySQL 性能优化的建议总结，请看这篇文章：MySQL 高性能优化规范建议总结 。\nMySQL中定位慢查询\n嗯，我们当时在做压力测试时发现有些接口响应时间非常慢，超过了2秒。因为我们的系统部署了运维监控系统Skywalking，在它的报表展示中可以看到哪个接口慢，并且能分析出接口中哪部分耗时较多，包括具体的SQL执行时间，这样就能定位到出现问题的SQL。\n如果没有这种监控系统，MySQL本身也提供了慢查询日志功能。可以在MySQL的系统配置文件中开启慢查询日志，并设置SQL执行时间超过多少就记录到日志文件，比如我们之前项目设置的是2秒，超过这个时间的SQL就会记录在日志文件中，我们就可以在那里找到执行慢的SQL。\nSQL语句执行的慢该如何分析\n如果一条SQL执行很慢，我们通常会使用MySQL的EXPLAIN命令来分析这条SQL的执行情况。通过key和key_len可以检查是否命中了索引，如果已经添加了索引，也可以判断索引是否有效。通过type字段可以查看SQL是否有优化空间，比如是否存在全索引扫描或全表扫描。通过extra建议可以判断是否出现回表情况，如果出现，可以尝试添加索引或修改返回字段来优化。\n1.10.1 能用MySQL直接存储文件（比如图片） # 可以是可以，直接存储文件对应的二进制数据即可。不过，还是建议不要在数据库中存储文件，会严重影响数据库性能，消耗过多存储空间。\n可以选择使用云服务厂商提供的开箱即用的文件存储服务，成熟稳定，价格也比较低。\n也可以选择自建文件存储服务，实现起来也不难，基于 FastDFS、MinIO（推荐） 等开源项目就可以实现分布式文件服务。\n数据库只存储文件地址信息，文件由文件存储服务负责存储。\n相关阅读：Spring Boot 整合 MinIO 实现分布式文件服务 。\n1.10.2 MySQL如何存储IP地址 # 可以将 IP 地址转换成整形数据存储，性能更好，占用空间也更小。\nMySQL 提供了两个方法来处理 ip 地址\nINET_ATON()：把 ip 转为无符号整型 (4-8 位) INET_NTOA() :把整型的 ip 转为地址 插入数据前，先用 INET_ATON() 把 ip 地址转为整型，显示数据时，使用 INET_NTOA() 把整型的 ip 地址转为地址显示即可。\n1.10.3 有哪些常见的SQL优化手段 # //todo\n1.10.4 如何分析SQL性能 # 我们可以使用 EXPLAIN 命令来分析 SQL 的 执行计划 。执行计划是指一条 SQL 语句在经过 MySQL 查询优化器的优化会后，具体的执行方式。\nEXPLAIN 并不会真的去执行相关的语句，而是通过 查询优化器 对语句进行分析，找出最优的查询方案，并显示对应的信息。\nEXPLAIN 适用于 SELECT, DELETE, INSERT, REPLACE, 和 UPDATE语句，我们一般分析 SELECT 查询较多。\n我们这里简单来演示一下 EXPLAIN 的使用。\nEXPLAIN 的输出格式如下：\nmysql\u0026gt; EXPLAIN SELECT `score`,`name` FROM `cus_order` ORDER BY `score` DESC; +----+-------------+-----------+------------+------+---------------+------+---------+------+--------+----------+----------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+-----------+------------+------+---------------+------+---------+------+--------+----------+----------------+ | 1 | SIMPLE | cus_order | NULL | ALL | NULL | NULL | NULL | NULL | 997572 | 100.00 | Using filesort | +----+-------------+-----------+------------+------+---------------+------+---------+------+--------+----------+----------------+ 1 row in set, 1 warning (0.00 sec) 各个字段的含义如下：\n列名 含义 id SELECT 查询的序列标识符 select_type SELECT 关键字对应的查询类型 table 用到的表名 partitions 匹配的分区，对于未分区的表，值为 NULL type 表的访问方法 possible_keys 可能用到的索引 key 实际用到的索引 key_len 所选索引的长度 ref 当使用索引等值查询时，与索引作比较的列或常量 rows 预计要读取的行数 filtered 按表条件过滤后，留存的记录数的百分比 Extra 附加信息 篇幅问题，我这里只是简单介绍了一下 MySQL 执行计划，详细介绍请看：SQL 的执行计划这篇文章。\n","date":"22 March 2025","externalUrl":null,"permalink":"/posts/1742633078455-mysql%E5%9F%BA%E7%A1%80/","section":"Posts","summary":"","title":"MySQL基础","type":"posts"},{"content":"an example to get you started\nMySQL操作 # SQL通用语法\n1、SQL语句可以单行或多行书写，以分号结尾。\n2、SQL语句可以使用空格/缩进来增强语句的可读性。\n3、MySQL数据库的SQL语句不区分大小写。\n4、注释：\n单行注释：\u0026ndash; 注释内容 或 # 注释内容(MySQL特有) 多行注释： /* 注释内容 */ 以上就是SQL语句的通用语法，这些通用语法大家目前先有一个直观的认识，我们后面在讲解每一类SQL语句的时候，还会再来强调通用语法。\n1.1 数据库操作 # 我们在进行数据库设计，需要使用到刚才所介绍SQL分类中的DDL语句。\nDDL英文全称是Data Definition Language(数据定义语言)，用来定义数据库对象(数据库、表)。\nDDL中数据库的常见操作：查询、创建、使用、删除。\n1.1.1 查询数据库 # 查询所有数据库：\nshow databases; 命令行中执行效果如下：\n查询当前数据库：\nselect database(); 命令行中执行效果如果：\n我们要操作某一个数据库，必须要切换到对应的数据库中。\n通过指令：select database() ，就可以查询到当前所处的数据库\n1.1.2 创建数据库 # 语法：\ncreate database [ if not exists ] 数据库名; 案例： 创建一个itcast数据库。\ncreate database itcast; 命令行执行效果如下：\n注意：在同一个数据库服务器中，不能创建两个名称相同的数据库，否则将会报错。\n可以使用if not exists来避免这个问题 -- 数据库不存在,则创建该数据库；如果存在则不创建 create database if not extists itcast; 命令行执行效果如下：\n1.1.3 使用数据库 # 语法：\nuse 数据库名 ; 我们要操作某一个数据库下的表时，就需要通过该指令，切换到对应的数据库下，否则不能操作。\n案例：切换到itcast数据\nuse itcast; 命令执行效果如下：\n1.1.4 删除数据库 # 语法：\ndrop database [ if exists ] 数据库名 ; 如果删除一个不存在的数据库，将会报错。\n可以加上参数 if exists ，如果数据库存在，再执行删除，否则不执行删除。\n案例：删除itcast数据库\ndrop database if exists itcast; -- itcast数据库存在时删除 命令执行效果如下：\n说明：上述语法中的database，也可以替换成 schema\n如：create schema db01; 如：show schemas; 1.2 使用 # 1.2.1 连接数据库 # 1、打开IDEA自带的Database\n2、配置MySQL\n3、输入相关信息\n4、下载MySQL连接驱动\n5、测试数据库连接\n6、保存配置\n默认情况下，连接上了MySQL数据库之后， 数据库并没有全部展示出来。 需要选择要展示哪些数据库。具体操作如下：\n1.2.2 操作数据库 # 建数据库：**\n有了图形化界面工具后，就可以方便的使用图形化工具：创建数据库，创建表、修改表等DDL操作。\n其实工具底层也是通过DDL语句操作的数据库，只不过这些SQL语句是图形化界面工具帮我们自动完成的。\n查看所有数据库：\n1.3 表操作 # 学习完了DDL语句当中关于数据库的操作之后，接下来我们继续学习DDL语句当中关于表结构的操作。\n关于表结构的操作也是包含四个部分：创建表、查询表、修改表、删除表。\n1.3.1 创建 # 1.3.1 创建 # 1.3.1.1 语法 # create table 表名( 字段1 字段1类型 [约束] [comment 字段1注释 ], 字段2 字段2类型 [约束] [comment 字段2注释 ], ...... 字段n 字段n类型 [约束] [comment 字段n注释 ] ) [ comment 表注释 ] ; 注意： [ ] 中的内容为可选参数； 最后一个字段后面没有逗号\n案例：创建tb_user表\n对应的结构如下： 建表语句： create table tb_user ( id int comment \u0026#39;ID,唯一标识\u0026#39;, # id是一行数据的唯一标识（不能重复） username varchar(20) comment \u0026#39;用户名\u0026#39;, name varchar(10) comment \u0026#39;姓名\u0026#39;, age int comment \u0026#39;年龄\u0026#39;, gender char(1) comment \u0026#39;性别\u0026#39; ) comment \u0026#39;用户表\u0026#39;; 数据表创建完成，接下来我们还需要测试一下是否可以往这张表结构当中来存储数据。\n双击打开tb_user表结构，大家会发现里面没有数据：\n添加数据：\n此时我们再插入一条数据：\n我们之前提到过：id字段是一行数据的唯一标识，不能有重复值。但是现在数据表中有两个相同的id值，这是为什么呢？\n其实我们现在创建表结构的时候， id这个字段我们只加了一个备注信息说明它是一个唯一标识，但是在数据库层面呢，并没有去限制字段存储的数据。所以id这个字段没有起到唯一标识的作用。 想要限制字段所存储的数据，就需要用到数据库中的约束。\n1.3.1.2 约束 # 概念：所谓约束就是作用在表中字段上的规则，用于限制存储在表中的数据。\n作用：就是来保证数据库当中数据的正确性、有效性和完整性。（后面的学习会验证这些）\n在MySQL数据库当中，提供了以下5种约束：\n约束 描述 关键字 非空约束 限制该字段值不能为null not null 唯一约束 保证字段的所有数据都是唯一、不重复的 unique 主键约束 主键是一行数据的唯一标识，要求非空且唯一 primary key 默认约束 保存数据时，如果未指定该字段值，则采用默认值 default 外键约束 让两张表的数据建立连接，保证数据的一致性和完整性 foreign key 注意：约束是作用于表中字段上的，可以在创建表/修改表的时候添加约束。\n案例：创建tb_user表\n对应的结构如下： 在上述的表结构中:\nid 是一行数据的唯一标识\nusername 用户名字段是非空且唯一的\nname 姓名字段是不允许存储空值的\ngender 性别字段是有默认值，默认为男\n建表语句： create table tb_user ( id int primary key comment \u0026#39;ID,唯一标识\u0026#39;, username varchar(20) not null unique comment \u0026#39;用户名\u0026#39;, name varchar(10) not null comment \u0026#39;姓名\u0026#39;, age int comment \u0026#39;年龄\u0026#39;, gender char(1) default \u0026#39;男\u0026#39; comment \u0026#39;性别\u0026#39; ) comment \u0026#39;用户表\u0026#39;; 数据表创建完成，接下来测试一下表中字段上的约束是否生效\n大家有没有发现一个问题：id字段下存储的值，如果由我们自己来维护会比较麻烦(必须保证值的唯一性)。MySQL数据库为了解决这个问题，给我们提供了一个关键字：auto_increment（自动增长）\n主键自增：auto_increment\n每次插入新的行记录时，数据库自动生成id字段(主键)下的值 具有auto_increment的数据列是一个正数序列开始增长(从1开始自增) create table tb_user ( id int primary key auto_increment comment \u0026#39;ID,唯一标识\u0026#39;, #主键自动增长 username varchar(20) not null unique comment \u0026#39;用户名\u0026#39;, name varchar(10) not null comment \u0026#39;姓名\u0026#39;, age int comment \u0026#39;年龄\u0026#39;, gender char(1) default \u0026#39;男\u0026#39; comment \u0026#39;性别\u0026#39; ) comment \u0026#39;用户表\u0026#39;; 测试：主键自增\n1.3.1.3 数据类型 # 在上面建表语句中，我们在指定字段的数据类型时，用到了int 、varchar、char，那么在MySQL中除了以上的数据类型，还有哪些常见的数据类型呢？ 接下来,我们就来详细介绍一下MySQL的数据类型。\nMySQL中的数据类型有很多，主要分为三类：数值类型、字符串类型、日期时间类型。\n数值类型\n类型 大小 有符号(SIGNED)范围 无符号(UNSIGNED)范围 描述 TINYINT 1byte (-128，127) (0，255) 小整数值 SMALLINT 2bytes (-32768，32767) (0，65535) 大整数值 MEDIUMINT 3bytes (-8388608，8388607) (0，16777215) 大整数值 INT/INTEGER 4bytes (-2147483648，2147483647) (0，4294967295) 大整数值 BIGINT 8bytes (-2^63，2^63-1) (0，2^64-1) 极大整数值 FLOAT 4bytes (-3.402823466 E+38，3.402823466351 E+38) 0 和 (1.175494351 E-38，3.402823466 E+38) 单精度浮点数值 DOUBLE 8bytes (-1.7976931348623157 E+308，1.7976931348623157 E+308) 0 和 (2.2250738585072014 E-308，1.7976931348623157 E+308) 双精度浮点数值 DECIMAL 依赖于M(精度)和D(标度)的值 依赖于M(精度)和D(标度)的值 小数值(精确定点数) 示例: 年龄字段 ---不会出现负数, 而且人的年龄不会太大 age tinyint unsigned 分数 ---总分100分, 最多出现一位小数 score double(4,1) 字符串类型\n类型 大小 描述 CHAR 0-255 bytes 定长字符串(需要指定长度) VARCHAR 0-65535 bytes 变长字符串(需要指定长度) TINYBLOB 0-255 bytes 不超过255个字符的二进制数据 TINYTEXT 0-255 bytes 短文本字符串 BLOB 0-65 535 bytes 二进制形式的长文本数据 TEXT 0-65 535 bytes 长文本数据 MEDIUMBLOB 0-16 777 215 bytes 二进制形式的中等长度文本数据 MEDIUMTEXT 0-16 777 215 bytes 中等长度文本数据 LONGBLOB 0-4 294 967 295 bytes 二进制形式的极大文本数据 LONGTEXT 0-4 294 967 295 bytes 极大文本数据 char 与 varchar 都可以描述字符串，char是定长字符串，指定长度多长，就占用多少个字符，和字段值的长度无关 。而varchar是变长字符串，指定的长度为最大占用长度 。相对来说，char的性能会更高些。\n示例： 用户名 username ---长度不定, 最长不会超过50 username varchar(50) 手机号 phone ---固定长度为11 phone char(11) 日期时间类型\n类型 大小 范围 格式 描述 DATE 3 1000-01-01 至 9999-12-31 YYYY-MM-DD 日期值 TIME 3 -838:59:59 至 838:59:59 HH:MM:SS 时间值或持续时间 YEAR 1 1901 至 2155 YYYY 年份值 DATETIME 8 1000-01-01 00:00:00 至 9999-12-31 23:59:59 YYYY-MM-DD HH:MM:SS 混合日期和时间值 TIMESTAMP 4 1970-01-01 00:00:01 至 2038-01-19 03:14:07 YYYY-MM-DD HH:MM:SS 混合日期和时间值，时间戳 示例: 生日字段 birthday ---生日只需要年月日 birthday date 创建时间 createtime --- 需要精确到时分秒 createtime datetime 1.3.2 查询 # 关于表结构的查询操作，工作中一般都是直接基于图形化界面操作。\n查询当前数据库所有表\nshow tables; 查看指定表结构\ndesc 表名 ;#可以查看指定表的字段、字段的类型、是否可以为NULL、是否存在默认值等信息 查询指定表的建表语句\nshow create table 表名 ; 1.3.3 修改 # 关于表结构的修改操作，工作中一般都是直接基于图形化界面操作。\n添加字段\nalter table 表名 add 字段名 类型(长度) [comment 注释] [约束]; 案例： 为tb_emp表添加字段qq，字段类型为 varchar(11)\nalter table tb_emp add qq varchar(11) comment \u0026#39;QQ号码\u0026#39;; 图形化操作：添加字段\n修改数据类型\nalter table 表名 modify 字段名 新数据类型(长度); alter table 表名 change 旧字段名 新字段名 类型(长度) [comment 注释] [约束]; 案例：修改qq字段的字段类型，将其长度由11修改为13\nalter table tb_emp modify qq varchar(13) comment \u0026#39;QQ号码\u0026#39;; 案例：修改qq字段名为 qq_num，字段类型varchar(13)\nalter table tb_emp change qq qq_num varchar(13) comment \u0026#39;QQ号码\u0026#39;; 图形化操作：修改数据类型和字段名\n删除字段\nalter table 表名 drop 字段名; 案例：删除tb_emp表中的qq_num字段\nalter table tb_emp drop qq_num; 图形化操作：删除字段\n修改表名\nrename table 表名 to 新表名; 案例：将当前的tb_emp表的表名修改为emp\nrename table tb_emp to emp; 图形化操作：修改表名\n1.3.4 删除 # 关于表结构的删除操作，工作中一般都是直接基于图形化界面操作。\n删除表语法：\ndrop table [ if exists ] 表名; if exists ：只有表名存在时才会删除该表，表名不存在，则不执行删除操作(如果不加该参数项，删除一张不存在的表，执行将会报错)。\n案例：如果tb_emp表存在，则删除tb_emp表\ndrop table if exists tb_emp; -- 在删除表时，表中的全部数据也会被删除。 图形化操作：删除表\n1.4 数据库操作-DML # DML英文全称是Data Manipulation Language(数据操作语言)，用来对数据库中表的数据记录进行增、删、改操作。\n添加数据（INSERT） 修改数据（UPDATE） 删除数据（DELETE） 1.4.1 增加(insert) # insert语法：\n向指定字段添加数据\ninsert into 表名 (字段名1, 字段名2) values (值1, 值2); 全部字段添加数据\ninsert into 表名 values (值1, 值2, ...); 批量添加数据（指定字段）\ninsert into 表名 (字段名1, 字段名2) values (值1, 值2), (值1, 值2); 批量添加数据（全部字段）\ninsert into 表名 values (值1, 值2, ...), (值1, 值2, ...); 案例1：向tb_emp表的username、name、gender字段插入数据\n-- 因为设计表时create_time, update_time两个字段不能为NULL，所以也做为要插入的字段 insert into tb_emp(username, name, gender, create_time, update_time) values (\u0026#39;wuji\u0026#39;, \u0026#39;张无忌\u0026#39;, 1, now(), now()); 案例2：向tb_emp表的所有字段插入数据\ninsert into tb_emp(id, username, password, name, gender, image, job, entrydate, create_time, update_time) values (null, \u0026#39;zhirou\u0026#39;, \u0026#39;123\u0026#39;, \u0026#39;周芷若\u0026#39;, 2, \u0026#39;1.jpg\u0026#39;, 1, \u0026#39;2010-01-01\u0026#39;, now(), now()); 案例3：批量向tb_emp表的username、name、gender字段插入数据\ninsert into tb_emp(username, name, gender, create_time, update_time) values (\u0026#39;weifuwang\u0026#39;, \u0026#39;韦一笑\u0026#39;, 1, now(), now()), (\u0026#39;fengzi\u0026#39;, \u0026#39;张三疯\u0026#39;, 1, now(), now()); 图形化操作：双击tb_emp表查看数据\nInsert操作的注意事项：\n插入数据时，指定的字段顺序需要与值的顺序是一一对应的。\n字符串和日期型数据应该包含在引号中。\n插入的数据大小，应该在字段的规定范围内。\n1.4.2 修改(update) # update语法：\nupdate 表名 set 字段名1 = 值1 , 字段名2 = 值2 , .... [where 条件] ; 案例1：将tb_emp表中id为1的员工，姓名name字段更新为\u0026rsquo;张三'\nupdate tb_emp set name=\u0026#39;张三\u0026#39;,update_time=now() where id=1; 案例2：将tb_emp表的所有员工入职日期更新为'2010-01-01'\nupdate tb_emp set entrydate=\u0026#39;2010-01-01\u0026#39;,update_time=now(); 注意事项:\n修改语句的条件可以有，也可以没有，如果没有条件，则会修改整张表的所有数据。\n在修改数据时，一般需要同时修改公共字段update_time，将其修改为当前操作时间。\n1.4.3 删除(delete) # delete语法：\ndelete from 表名 [where 条件] ; 案例1：删除tb_emp表中id为1的员工\ndelete from tb_emp where id = 1; 案例2：删除tb_emp表中所有员工\ndelete from tb_emp; 注意事项:\n​\t• DELETE 语句的条件可以有，也可以没有，如果没有条件，则会删除整张表的所有数据。\n​\t• DELETE 语句不能删除某一个字段的值(可以使用UPDATE，将该字段值置为NULL即可)。\n​\t• 当进行删除全部数据操作时，会提示询问是否确认删除所有数据，直接点击Execute即可。\n1.5 数据库操作-DQL # 1.5.1 介绍 # DQL英文全称是Data Query Language(数据查询语言)，用来查询数据库表中的记录。\n查询关键字：SELECT\n查询操作是所有SQL语句当中最为常见，也是最为重要的操作。在一个正常的业务系统中，查询操作的使用频次是要远高于增删改操作的。当我们打开某个网站或APP所看到的展示信息，都是通过从数据库中查询得到的，而在这个查询过程中，还会涉及到条件、排序、分页等操作。\n1.5.2 语法 # DQL查询语句，语法结构如下：\nSELECT 字段列表 FROM 表名列表 WHERE 条件列表 GROUP BY 分组字段列表 HAVING 分组后条件列表 ORDER BY 排序字段列表 LIMIT 分页参数 1.5.3 基本查询 # 在基本查询的DQL语句中，不带任何的查询条件，语法如下：\n查询多个字段\nselect 字段1, 字段2, 字段3 from 表名; 查询所有字段（通配符）\nselect * from 表名; 设置别名\nselect 字段1 [ as 别名1 ] , 字段2 [ as 别名2 ] from 表名; 去除重复记录\nselect distinct 字段列表 from 表名; 案例1：查询指定字段 name，entrydate并返回\nselect name,entrydate from tb_emp; 案例2：查询返回所有字段\nselect * from tb_emp; *号代表查询所有字段，在实际开发中尽量少用（不直观、影响效率）\n案例3：查询所有员工的 name,entrydate，并起别名(姓名、入职日期)\n-- 方式1： select name AS 姓名, entrydate AS 入职日期 from tb_emp; -- 方式2： 别名中有特殊字符时，使用\u0026#39;\u0026#39;或\u0026#34;\u0026#34;包含 select name AS \u0026#39;姓 名\u0026#39;, entrydate AS \u0026#39;入职日期\u0026#39; from tb_emp; -- 方式3： select name AS \u0026#34;姓名\u0026#34;, entrydate AS \u0026#34;入职日期\u0026#34; from tb_emp; 案例4：查询已有的员工关联了哪几种职位(不要重复)\nselect distinct job from tb_emp; 1.5.4 条件查询 # 语法：\nselect 字段列表 from 表名 where 条件列表 ; -- 条件列表：意味着可以有多个条件 学习条件查询就是学习条件的构建方式，而在SQL语句当中构造条件的运算符分为两类：\n比较运算符 逻辑运算符 常用的比较运算符如下:\n比较运算符 功能 \u0026gt; 大于 \u0026gt;= 大于等于 \u0026lt; 小于 \u0026lt;= 小于等于 = 等于 \u0026lt;\u0026gt; 或 != 不等于 between \u0026hellip; and \u0026hellip; 在某个范围之内(含最小、最大值) in(\u0026hellip;) 在in之后的列表中的值，多选一 like 占位符 模糊匹配(_匹配单个字符, %匹配任意个字符) is null 是null 常用的逻辑运算符如下:\n逻辑运算符 功能 and 或 \u0026amp;\u0026amp; 并且 (多个条件同时成立) or 或 || 或者 (多个条件任意一个成立) not 或 ! 非 , 不是 案例1：查询 姓名 为 杨逍 的员工\nselect id, username, password, name, gender, image, job, entrydate, create_time, update_time from tb_emp where name = \u0026#39;杨逍\u0026#39;; -- 字符串使用\u0026#39;\u0026#39;或\u0026#34;\u0026#34;包含 案例2：查询 id小于等于5 的员工信息\nselect id, username, password, name, gender, image, job, entrydate, create_time, update_time from tb_emp where id \u0026lt;=5; 案例3：查询 没有分配职位 的员工信息\nselect id, username, password, name, gender, image, job, entrydate, create_time, update_time from tb_emp where job is null ; 注意：查询为NULL的数据时，不能使用 = null\n案例4：查询 有职位 的员工信息\nselect id, username, password, name, gender, image, job, entrydate, create_time, update_time from tb_emp where job is not null ; 案例5：查询 密码不等于 \u0026lsquo;123456\u0026rsquo; 的员工信息\n-- 方式1： select id, username, password, name, gender, image, job, entrydate, create_time, update_time from tb_emp where password \u0026lt;\u0026gt; \u0026#39;123456\u0026#39;; -- 方式2： select id, username, password, name, gender, image, job, entrydate, create_time, update_time from tb_emp where password != \u0026#39;123456\u0026#39;; 案例6：查询 入职日期 在 \u0026lsquo;2000-01-01\u0026rsquo; (包含) 到 \u0026lsquo;2010-01-01\u0026rsquo;(包含) 之间的员工信息\n-- 方式1： select id, username, password, name, gender, image, job, entrydate, create_time, update_time from tb_emp where entrydate\u0026gt;=\u0026#39;2000-01-01\u0026#39; and entrydate\u0026lt;=\u0026#39;2010-01-01\u0026#39;; -- 方式2： between...and select id, username, password, name, gender, image, job, entrydate, create_time, update_time from tb_emp where entrydate between \u0026#39;2000-01-01\u0026#39; and \u0026#39;2010-01-01\u0026#39;; 案例7：查询 入职时间 在 \u0026lsquo;2000-01-01\u0026rsquo; (包含) 到 \u0026lsquo;2010-01-01\u0026rsquo;(包含) 之间 且 性别为女 的员工信息\nselect id, username, password, name, gender, image, job, entrydate, create_time, update_time from tb_emp where entrydate between \u0026#39;2000-01-01\u0026#39; and \u0026#39;2010-01-01\u0026#39; and gender = 2; 案例8：查询 职位是 2 (讲师), 3 (学工主管), 4 (教研主管) 的员工信息\n-- 方式1：使用or连接多个条件 select id, username, password, name, gender, image, job, entrydate, create_time, update_time from tb_emp where job=2 or job=3 or job=4; -- 方式2：in关键字 select id, username, password, name, gender, image, job, entrydate, create_time, update_time from tb_emp where job in (2,3,4); 案例9：查询 姓名 为两个字的员工信息\nselect id, username, password, name, gender, image, job, entrydate, create_time, update_time from tb_emp where name like \u0026#39;__\u0026#39;; # 通配符 \u0026#34;_\u0026#34; 代表任意1个字符 案例10：查询 姓 \u0026lsquo;张\u0026rsquo; 的员工信息\nselect id, username, password, name, gender, image, job, entrydate, create_time, update_time from tb_emp where name like \u0026#39;张%\u0026#39;; # 通配符 \u0026#34;%\u0026#34; 代表任意个字符（0个 ~ 多个） 1.5.5 聚合函数 # 之前我们做的查询都是横向查询，就是根据条件一行一行的进行判断，而使用聚合函数查询就是纵向查询，它是对一列的值进行计算，然后返回一个结果值。（将一列数据作为一个整体，进行纵向计算）\n语法：\nselect 聚合函数(字段列表) from 表名 ; 注意 : 聚合函数会忽略空值，对NULL值不作为统计。\n常用聚合函数：\n函数 功能 count 统计数量 max 最大值 min 最小值 avg 平均值 sum 求和 count ：按照列去统计有多少行数据。\n在根据指定的列统计的时候，如果这一列中有null的行，该行不会被统计在其中。 sum ：计算指定列的数值和，如果不是数值类型，那么计算结果为0\nmax ：计算指定列的最大值\nmin ：计算指定列的最小值\navg ：计算指定列的平均值\n案例1：统计该企业员工数量\n# count(字段) select count(id) from tb_emp;-- 结果：29 select count(job) from tb_emp;-- 结果：28 （聚合函数对NULL值不做计算） # count(常量) select count(0) from tb_emp; select count(\u0026#39;A\u0026#39;) from tb_emp; # count(*) 推荐此写法（MySQL底层进行了优化） select count(*) from tb_emp; 案例2：统计该企业最早入职的员工\nselect min(entrydate) from tb_emp; 案例3：统计该企业最迟入职的员工\nselect max(entrydate) from tb_emp; 案例4：统计该企业员工 ID 的平均值\nselect avg(id) from tb_emp; 案例5：统计该企业员工的 ID 之和\nselect sum(id) from tb_emp; 1.5.6 分组查询 # 分组： 按照某一列或者某几列，把相同的数据进行合并输出。\n分组其实就是按列进行分类(指定列下相同的数据归为一类)，然后可以对分类完的数据进行合并计算。\n分组查询通常会使用聚合函数进行计算。\n语法：\nselect 字段列表 from 表名 [where 条件] group by 分组字段名 [having 分组后过滤条件]; 案例1：根据性别分组 , 统计男性和女性员工的数量\nselect gender, count(*) from tb_emp group by gender; -- 按照gender字段进行分组（gender字段下相同的数据归为一组） 案例2：查询入职时间在 \u0026lsquo;2015-01-01\u0026rsquo; (包含) 以前的员工 , 并对结果根据职位分组 , 获取员工数量大于等于2的职位\nselect job, count(*) from tb_emp where entrydate \u0026lt;= \u0026#39;2015-01-01\u0026#39; -- 分组前条件 group by job -- 按照job字段分组 having count(*) \u0026gt;= 2; -- 分组后条件 注意事项:\n​\t• 分组之后，查询的字段一般为聚合函数和分组字段，查询其他字段无任何意义\n​\t• 执行顺序：where \u0026gt; 聚合函数 \u0026gt; having\nwhere与having区别（面试题）\n执行时机不同：where是分组之前进行过滤，不满足where条件，不参与分组；而having是分组之后对结果进行过滤。 判断条件不同：where不能对聚合函数进行判断，而having可以。 1.5.7 排序查询 # 排序在日常开发中是非常常见的一个操作，有升序排序，也有降序排序。\n语法：\nselect 字段列表 from 表名 [where 条件列表] [group by 分组字段 ] order by 字段1 排序方式1 , 字段2 排序方式2 … ; 排序方式：\nASC ：升序（默认值）\nDESC：降序\n案例1：根据入职时间, 对员工进行升序排序\nselect id, username, password, name, gender, image, job, entrydate, create_time, update_time from tb_emp order by entrydate ASC; -- 按照entrydate字段下的数据进行升序排序 select id, username, password, name, gender, image, job, entrydate, create_time, update_time from tb_emp order by entrydate; -- 默认就是ASC（升序） 注意事项：如果是升序, 可以不指定排序方式ASC\n案例2：根据入职时间，对员工进行降序排序\nselect id, username, password, name, gender, image, job, entrydate, create_time, update_time from tb_emp order by entrydate DESC; -- 按照entrydate字段下的数据进行降序排序 案例3：根据入职时间对公司的员工进行升序排序，入职时间相同，再按照更新时间进行降序排序\nselect id, username, password, name, gender, image, job, entrydate, create_time, update_time from tb_emp order by entrydate ASC , update_time DESC; 注意事项：如果是多字段排序，当第一个字段值相同时，才会根据第二个字段进行排序\n1.5.8 分页查询 # 分页操作在业务系统开发时，也是非常常见的一个功能，日常我们在网站中看到的各种各样的分页条，后台也都需要借助于数据库的分页操作。\n分页查询语法：\nselect 字段列表 from 表名 limit 起始索引, 查询记录数 ; 案例1：从起始索引0开始查询员工数据, 每页展示5条记录\nselect id, username, password, name, gender, image, job, entrydate, create_time, update_time from tb_emp limit 0 , 5; -- 从索引0开始，向后取5条记录 案例2：查询 第1页 员工数据, 每页展示5条记录\nselect id, username, password, name, gender, image, job, entrydate, create_time, update_time from tb_emp limit 5; -- 如果查询的是第1页数据，起始索引可以省略，直接简写为：limit 条数 案例3：查询 第2页 员工数据, 每页展示5条记录\nselect id, username, password, name, gender, image, job, entrydate, create_time, update_time from tb_emp limit 5 , 5; -- 从索引5开始，向后取5条记录 案例4：查询 第3页 员工数据, 每页展示5条记录\nselect id, username, password, name, gender, image, job, entrydate, create_time, update_time from tb_emp limit 10 , 5; -- 从索引10开始，向后取5条记录 注意事项:\n起始索引从0开始。 计算公式 ： 起始索引 = （查询页码 - 1）* 每页显示记录数\n分页查询是数据库的方言，不同的数据库有不同的实现，MySQL中是LIMIT\n如果查询的是第一页数据，起始索引可以省略，直接简写为 limit 条数\n1.5.9 回表查询 # 回表查询是指通过二级索引找到对应的主键值，然后再通过主键值查询聚簇索引中对应的整行数据的过程。\n1.6 多表设计 # 关于单表的操作(单表的设计、单表的增删改查)我们就已经学习完了。接下来我们就要来学习多表的操作，首先来学习多表的设计。\n项目开发中，在进行数据库表结构设计时，会根据业务需求及业务模块之间的关系，分析并设计表结构，由于业务之间相互关联，所以各个表结构之间也存在着各种联系，基本上分为三种：\n一对多(多对一)\n多对多\n一对一\n1.6.1 一对多 # 1.6.1.1 表设计 # 需求：根据页面原型及需求文档 ，完成部门及员工的表结构设计\n员工管理页面原型：（前面已完成tb_emp表结构设计） 部门管理页面原型： 经过上述分析，现已明确的部门表结构：\n业务字段 ： 部门名称 基础字段 ： id(主键)、创建时间、修改时间 部门表 - SQL语句：\n# 建议：创建新的数据库（多表设计存放在新数据库下） create database db03; use db03; -- 部门表 create table tb_dept ( id int unsigned primary key auto_increment comment \u0026#39;主键ID\u0026#39;, name varchar(10) not null unique comment \u0026#39;部门名称\u0026#39;, create_time datetime not null comment \u0026#39;创建时间\u0026#39;, update_time datetime not null comment \u0026#39;修改时间\u0026#39; ) comment \u0026#39;部门表\u0026#39;; 部门表创建好之后，我们还需要再修改下员工表。为什么要修改员工表呢？是因为我们之前设计员工表(单表)的时候，并没有考虑员工的归属部门。\n员工表：添加归属部门字段\n-- 员工表 create table tb_emp ( id int unsigned primary key auto_increment comment \u0026#39;ID\u0026#39;, username varchar(20) not null unique comment \u0026#39;用户名\u0026#39;, password varchar(32) default \u0026#39;123456\u0026#39; comment \u0026#39;密码\u0026#39;, name varchar(10) not null comment \u0026#39;姓名\u0026#39;, gender tinyint unsigned not null comment \u0026#39;性别, 说明: 1 男, 2 女\u0026#39;, image varchar(300) comment \u0026#39;图像\u0026#39;, job tinyint unsigned comment \u0026#39;职位, 说明: 1 班主任,2 讲师, 3 学工主管, 4 教研主管\u0026#39;, entrydate date comment \u0026#39;入职时间\u0026#39;, dept_id int unsigned comment \u0026#39;部门ID\u0026#39;, -- 员工的归属部门 create_time datetime not null comment \u0026#39;创建时间\u0026#39;, update_time datetime not null comment \u0026#39;修改时间\u0026#39; ) comment \u0026#39;员工表\u0026#39;; 测试数据：\n-- 部门表测试数据 insert into tb_dept (id, name, create_time, update_time) values (1,\u0026#39;学工部\u0026#39;,now(),now()), (2,\u0026#39;教研部\u0026#39;,now(),now()), (3,\u0026#39;咨询部\u0026#39;,now(),now()), (4,\u0026#39;就业部\u0026#39;,now(),now()), (5,\u0026#39;人事部\u0026#39;,now(),now()); -- 员工表测试数据 INSERT INTO tb_emp (id, username, password, name, gender, image, job, entrydate,dept_id, create_time, update_time) VALUES (1,\u0026#39;jinyong\u0026#39;,\u0026#39;123456\u0026#39;,\u0026#39;金庸\u0026#39;,1,\u0026#39;1.jpg\u0026#39;,4,\u0026#39;2000-01-01\u0026#39;,2,now(),now()), (2,\u0026#39;zhangwuji\u0026#39;,\u0026#39;123456\u0026#39;,\u0026#39;张无忌\u0026#39;,1,\u0026#39;2.jpg\u0026#39;,2,\u0026#39;2015-01-01\u0026#39;,2,now(),now()), (3,\u0026#39;yangxiao\u0026#39;,\u0026#39;123456\u0026#39;,\u0026#39;杨逍\u0026#39;,1,\u0026#39;3.jpg\u0026#39;,2,\u0026#39;2008-05-01\u0026#39;,2,now(),now()), (4,\u0026#39;weiyixiao\u0026#39;,\u0026#39;123456\u0026#39;,\u0026#39;韦一笑\u0026#39;,1,\u0026#39;4.jpg\u0026#39;,2,\u0026#39;2007-01-01\u0026#39;,2,now(),now()), (5,\u0026#39;changyuchun\u0026#39;,\u0026#39;123456\u0026#39;,\u0026#39;常遇春\u0026#39;,1,\u0026#39;5.jpg\u0026#39;,2,\u0026#39;2012-12-05\u0026#39;,2,now(),now()), (6,\u0026#39;xiaozhao\u0026#39;,\u0026#39;123456\u0026#39;,\u0026#39;小昭\u0026#39;,2,\u0026#39;6.jpg\u0026#39;,3,\u0026#39;2013-09-05\u0026#39;,1,now(),now()), (7,\u0026#39;jixiaofu\u0026#39;,\u0026#39;123456\u0026#39;,\u0026#39;纪晓芙\u0026#39;,2,\u0026#39;7.jpg\u0026#39;,1,\u0026#39;2005-08-01\u0026#39;,1,now(),now()), (8,\u0026#39;zhouzhiruo\u0026#39;,\u0026#39;123456\u0026#39;,\u0026#39;周芷若\u0026#39;,2,\u0026#39;8.jpg\u0026#39;,1,\u0026#39;2014-11-09\u0026#39;,1,now(),now()), (9,\u0026#39;dingminjun\u0026#39;,\u0026#39;123456\u0026#39;,\u0026#39;丁敏君\u0026#39;,2,\u0026#39;9.jpg\u0026#39;,1,\u0026#39;2011-03-11\u0026#39;,1,now(),now()), (10,\u0026#39;zhaomin\u0026#39;,\u0026#39;123456\u0026#39;,\u0026#39;赵敏\u0026#39;,2,\u0026#39;10.jpg\u0026#39;,1,\u0026#39;2013-09-05\u0026#39;,1,now(),now()), (11,\u0026#39;luzhangke\u0026#39;,\u0026#39;123456\u0026#39;,\u0026#39;鹿杖客\u0026#39;,1,\u0026#39;11.jpg\u0026#39;,1,\u0026#39;2007-02-01\u0026#39;,1,now(),now()), (12,\u0026#39;hebiweng\u0026#39;,\u0026#39;123456\u0026#39;,\u0026#39;鹤笔翁\u0026#39;,1,\u0026#39;12.jpg\u0026#39;,1,\u0026#39;2008-08-18\u0026#39;,1,now(),now()), (13,\u0026#39;fangdongbai\u0026#39;,\u0026#39;123456\u0026#39;,\u0026#39;方东白\u0026#39;,1,\u0026#39;13.jpg\u0026#39;,2,\u0026#39;2012-11-01\u0026#39;,2,now(),now()), (14,\u0026#39;zhangsanfeng\u0026#39;,\u0026#39;123456\u0026#39;,\u0026#39;张三丰\u0026#39;,1,\u0026#39;14.jpg\u0026#39;,2,\u0026#39;2002-08-01\u0026#39;,2,now(),now()), (15,\u0026#39;yulianzhou\u0026#39;,\u0026#39;123456\u0026#39;,\u0026#39;俞莲舟\u0026#39;,1,\u0026#39;15.jpg\u0026#39;,2,\u0026#39;2011-05-01\u0026#39;,2,now(),now()), (16,\u0026#39;songyuanqiao\u0026#39;,\u0026#39;123456\u0026#39;,\u0026#39;宋远桥\u0026#39;,1,\u0026#39;16.jpg\u0026#39;,2,\u0026#39;2010-01-01\u0026#39;,2,now(),now()), (17,\u0026#39;chenyouliang\u0026#39;,\u0026#39;123456\u0026#39;,\u0026#39;陈友谅\u0026#39;,1,\u0026#39;17.jpg\u0026#39;,NULL,\u0026#39;2015-03-21\u0026#39;,NULL,now(),now()); 员工表 - 部门表之间的关系：\n一对多关系实现：在数据库表中多的一方，添加字段，来关联属于一这方的主键。\n1.6.1.2 外键约束 # 问题\n表结构创建完毕后，我们看到两张表的数据分别为：\n现在员工表中有五个员工都归属于1号部门(学工部)，当删除了1号部门后，数据变为：\n1号部门被删除了，但是依然还有5个员工是属于1号部门的。 此时：就出现数据的不完整、不一致了。\n问题分析\n目前上述的两张表(员工表、部门表)，在数据库层面，并未建立关联，所以是无法保证数据的一致性和完整性的\n问题解决\n想解决上述的问题呢，我们就可以通过数据库中的 外键约束 来解决。\n外键约束：让两张表的数据建立连接，保证数据的一致性和完整性。\n对应的关键字：foreign key\n外键约束的语法：\n-- 创建表时指定 create table 表名( 字段名 数据类型, ... [constraint] [外键名称] foreign key (外键字段名) references 主表 (主表列名)\t); -- 建完表后，添加外键 alter table 表名 add constraint 外键名称 foreign key(外键字段名) references 主表(主表列名); 那接下来，我们就为员工表的dept_id 建立外键约束，来关联部门表的主键。\n方式1：通过SQL语句操作\n-- 修改表： 添加外键约束 alter table tb_emp add constraint fk_dept_id foreign key (dept_id) references tb_dept(id); 方式2：图形化界面操作\n当我们添加外键约束时，我们得保证当前数据库表中的数据是完整的。 所以，我们需要将之前删除掉的数据再添加回来。\n当我们添加了外键之后，再删除ID为1的部门，就会发现，此时数据库报错了，不允许删除。\n外键约束（foreign key）：保证了数据的完整性和一致性。\n物理外键和逻辑外键\n物理外键\n概念：使用foreign key定义外键关联另外一张表。 缺点： 影响增、删、改的效率（需要检查外键关系）。 仅用于单节点数据库，不适用与分布式、集群场景。 容易引发数据库的死锁问题，消耗性能。 逻辑外键\n概念：在业务层逻辑中，解决外键关联。 通过逻辑外键，就可以很方便的解决上述问题。 **在现在的企业开发中，很少会使用物理外键，都是使用逻辑外键。 甚至在一些数据库开发规范中，会明确指出禁止使用物理外键 foreign key **\n1.6.2 一对一 # 一对一关系表在实际开发中应用起来比较简单，通常是用来做单表的拆分，也就是将一张大表拆分成两张小表，将大表中的一些基础字段放在一张表当中，将其他的字段放在另外一张表当中，以此来提高数据的操作效率。\n一对一的应用场景： 用户表(基本信息+身份信息)\n基本信息：用户的ID、姓名、性别、手机号、学历 身份信息：民族、生日、身份证号、身份证签发机关，身份证的有效期(开始时间、结束时间) 如果在业务系统当中，对用户的基本信息查询频率特别的高，但是对于用户的身份信息查询频率很低，此时出于提高查询效率的考虑，我就可以将这张大表拆分成两张小表，第一张表存放的是用户的基本信息，而第二张表存放的就是用户的身份信息。他们两者之间一对一的关系，一个用户只能对应一个身份证，而一个身份证也只能关联一个用户。\n那么在数据库层面怎么去体现上述两者之间是一对一的关系呢？\n其实一对一我们可以看成一种特殊的一对多。一对多我们是怎么设计表关系的？是不是在多的一方添加外键。同样我们也可以通过外键来体现一对一之间的关系，我们只需要在任意一方来添加一个外键就可以了。\n一对一 ：在任意一方加入外键，关联另外一方的主键，并且设置外键为唯一的(UNIQUE)\nSQL脚本：\n-- 用户基本信息表 create table tb_user( id int unsigned primary key auto_increment comment \u0026#39;ID\u0026#39;, name varchar(10) not null comment \u0026#39;姓名\u0026#39;, gender tinyint unsigned not null comment \u0026#39;性别, 1 男 2 女\u0026#39;, phone char(11) comment \u0026#39;手机号\u0026#39;, degree varchar(10) comment \u0026#39;学历\u0026#39; ) comment \u0026#39;用户基本信息表\u0026#39;; -- 测试数据 insert into tb_user values (1,\u0026#39;白眉鹰王\u0026#39;,1,\u0026#39;18812340001\u0026#39;,\u0026#39;初中\u0026#39;), (2,\u0026#39;青翼蝠王\u0026#39;,1,\u0026#39;18812340002\u0026#39;,\u0026#39;大专\u0026#39;), (3,\u0026#39;金毛狮王\u0026#39;,1,\u0026#39;18812340003\u0026#39;,\u0026#39;初中\u0026#39;), (4,\u0026#39;紫衫龙王\u0026#39;,2,\u0026#39;18812340004\u0026#39;,\u0026#39;硕士\u0026#39;); -- 用户身份信息表 create table tb_user_card( id int unsigned primary key auto_increment comment \u0026#39;ID\u0026#39;, nationality varchar(10) not null comment \u0026#39;民族\u0026#39;, birthday date not null comment \u0026#39;生日\u0026#39;, idcard char(18) not null comment \u0026#39;身份证号\u0026#39;, issued varchar(20) not null comment \u0026#39;签发机关\u0026#39;, expire_begin date not null comment \u0026#39;有效期限-开始\u0026#39;, expire_end date comment \u0026#39;有效期限-结束\u0026#39;, user_id int unsigned not null unique comment \u0026#39;用户ID\u0026#39;, constraint fk_user_id foreign key (user_id) references tb_user(id) ) comment \u0026#39;用户身份信息表\u0026#39;; -- 测试数据 insert into tb_user_card values (1,\u0026#39;汉\u0026#39;,\u0026#39;1960-11-06\u0026#39;,\u0026#39;100000100000100001\u0026#39;,\u0026#39;朝阳区公安局\u0026#39;,\u0026#39;2000-06-10\u0026#39;,null,1), (2,\u0026#39;汉\u0026#39;,\u0026#39;1971-11-06\u0026#39;,\u0026#39;100000100000100002\u0026#39;,\u0026#39;静安区公安局\u0026#39;,\u0026#39;2005-06-10\u0026#39;,\u0026#39;2025-06-10\u0026#39;,2), (3,\u0026#39;汉\u0026#39;,\u0026#39;1963-11-06\u0026#39;,\u0026#39;100000100000100003\u0026#39;,\u0026#39;昌平区公安局\u0026#39;,\u0026#39;2006-06-10\u0026#39;,null,3), (4,\u0026#39;回\u0026#39;,\u0026#39;1980-11-06\u0026#39;,\u0026#39;100000100000100004\u0026#39;,\u0026#39;海淀区公安局\u0026#39;,\u0026#39;2008-06-10\u0026#39;,\u0026#39;2028-06-10\u0026#39;,4); 1.6.3 多对多 # 多对多的关系在开发中属于也比较常见的。比如：学生和老师的关系，一个学生可以有多个授课老师，一个授课老师也可以有多个学生。在比如：学生和课程的关系，一个学生可以选修多门课程，一个课程也可以供多个学生选修。\n案例：学生与课程的关系\n关系：一个学生可以选修多门课程，一门课程也可以供多个学生选择\n实现关系：建立第三张中间表，中间表至少包含两个外键，分别关联两方主键\nSQL脚本：\n-- 学生表 create table tb_student( id int auto_increment primary key comment \u0026#39;主键ID\u0026#39;, name varchar(10) comment \u0026#39;姓名\u0026#39;, no varchar(10) comment \u0026#39;学号\u0026#39; ) comment \u0026#39;学生表\u0026#39;; -- 学生表测试数据 insert into tb_student(name, no) values (\u0026#39;黛绮丝\u0026#39;, \u0026#39;2000100101\u0026#39;),(\u0026#39;谢逊\u0026#39;, \u0026#39;2000100102\u0026#39;),(\u0026#39;殷天正\u0026#39;, \u0026#39;2000100103\u0026#39;),(\u0026#39;韦一笑\u0026#39;, \u0026#39;2000100104\u0026#39;); -- 课程表 create table tb_course( id int auto_increment primary key comment \u0026#39;主键ID\u0026#39;, name varchar(10) comment \u0026#39;课程名称\u0026#39; ) comment \u0026#39;课程表\u0026#39;; -- 课程表测试数据 insert into tb_course (name) values (\u0026#39;Java\u0026#39;), (\u0026#39;PHP\u0026#39;), (\u0026#39;MySQL\u0026#39;) , (\u0026#39;Hadoop\u0026#39;); -- 学生课程表（中间表） create table tb_student_course( id int auto_increment comment \u0026#39;主键\u0026#39; primary key, student_id int not null comment \u0026#39;学生ID\u0026#39;, course_id int not null comment \u0026#39;课程ID\u0026#39;, constraint fk_courseid foreign key (course_id) references tb_course (id), constraint fk_studentid foreign key (student_id) references tb_student (id) )comment \u0026#39;学生课程中间表\u0026#39;; -- 学生课程表测试数据 insert into tb_student_course(student_id, course_id) values (1,1),(1,2),(1,3),(2,2),(2,3),(3,4); 多表查询 # 2.1 概述 # 2.1.1 数据准备 # SQL脚本：\n#建议：创建新的数据库 create database db04; use db04; -- 部门表 create table tb_dept ( id int unsigned primary key auto_increment comment \u0026#39;主键ID\u0026#39;, name varchar(10) not null unique comment \u0026#39;部门名称\u0026#39;, create_time datetime not null comment \u0026#39;创建时间\u0026#39;, update_time datetime not null comment \u0026#39;修改时间\u0026#39; ) comment \u0026#39;部门表\u0026#39;; -- 部门表测试 insert into tb_dept (id, name, create_time, update_time) values (1, \u0026#39;学工部\u0026#39;, now(), now()), (2, \u0026#39;教研部\u0026#39;, now(), now()), (3, \u0026#39;咨询部\u0026#39;, now(), now()), (4, \u0026#39;就业部\u0026#39;, now(), now()), (5, \u0026#39;人事部\u0026#39;, now(), now()); -- 员工表 create table tb_emp ( id int unsigned primary key auto_increment comment \u0026#39;ID\u0026#39;, username varchar(20) not null unique comment \u0026#39;用户名\u0026#39;, password varchar(32) default \u0026#39;123456\u0026#39; comment \u0026#39;密码\u0026#39;, name varchar(10) not null comment \u0026#39;姓名\u0026#39;, gender tinyint unsigned not null comment \u0026#39;性别, 说明: 1 男, 2 女\u0026#39;, image varchar(300) comment \u0026#39;图像\u0026#39;, job tinyint unsigned comment \u0026#39;职位, 说明: 1 班主任,2 讲师, 3 学工主管, 4 教研主管, 5 咨询师\u0026#39;, entrydate date comment \u0026#39;入职时间\u0026#39;, dept_id int unsigned comment \u0026#39;部门ID\u0026#39;, create_time datetime not null comment \u0026#39;创建时间\u0026#39;, update_time datetime not null comment \u0026#39;修改时间\u0026#39; ) comment \u0026#39;员工表\u0026#39;; -- 员工表测试数据 INSERT INTO tb_emp(id, username, password, name, gender, image, job, entrydate,dept_id, create_time, update_time) VALUES (1,\u0026#39;jinyong\u0026#39;,\u0026#39;123456\u0026#39;,\u0026#39;金庸\u0026#39;,1,\u0026#39;1.jpg\u0026#39;,4,\u0026#39;2000-01-01\u0026#39;,2,now(),now()), (2,\u0026#39;zhangwuji\u0026#39;,\u0026#39;123456\u0026#39;,\u0026#39;张无忌\u0026#39;,1,\u0026#39;2.jpg\u0026#39;,2,\u0026#39;2015-01-01\u0026#39;,2,now(),now()), (3,\u0026#39;yangxiao\u0026#39;,\u0026#39;123456\u0026#39;,\u0026#39;杨逍\u0026#39;,1,\u0026#39;3.jpg\u0026#39;,2,\u0026#39;2008-05-01\u0026#39;,2,now(),now()), (4,\u0026#39;weiyixiao\u0026#39;,\u0026#39;123456\u0026#39;,\u0026#39;韦一笑\u0026#39;,1,\u0026#39;4.jpg\u0026#39;,2,\u0026#39;2007-01-01\u0026#39;,2,now(),now()), (5,\u0026#39;changyuchun\u0026#39;,\u0026#39;123456\u0026#39;,\u0026#39;常遇春\u0026#39;,1,\u0026#39;5.jpg\u0026#39;,2,\u0026#39;2012-12-05\u0026#39;,2,now(),now()), (6,\u0026#39;xiaozhao\u0026#39;,\u0026#39;123456\u0026#39;,\u0026#39;小昭\u0026#39;,2,\u0026#39;6.jpg\u0026#39;,3,\u0026#39;2013-09-05\u0026#39;,1,now(),now()), (7,\u0026#39;jixiaofu\u0026#39;,\u0026#39;123456\u0026#39;,\u0026#39;纪晓芙\u0026#39;,2,\u0026#39;7.jpg\u0026#39;,1,\u0026#39;2005-08-01\u0026#39;,1,now(),now()), (8,\u0026#39;zhouzhiruo\u0026#39;,\u0026#39;123456\u0026#39;,\u0026#39;周芷若\u0026#39;,2,\u0026#39;8.jpg\u0026#39;,1,\u0026#39;2014-11-09\u0026#39;,1,now(),now()), (9,\u0026#39;dingminjun\u0026#39;,\u0026#39;123456\u0026#39;,\u0026#39;丁敏君\u0026#39;,2,\u0026#39;9.jpg\u0026#39;,1,\u0026#39;2011-03-11\u0026#39;,1,now(),now()), (10,\u0026#39;zhaomin\u0026#39;,\u0026#39;123456\u0026#39;,\u0026#39;赵敏\u0026#39;,2,\u0026#39;10.jpg\u0026#39;,1,\u0026#39;2013-09-05\u0026#39;,1,now(),now()), (11,\u0026#39;luzhangke\u0026#39;,\u0026#39;123456\u0026#39;,\u0026#39;鹿杖客\u0026#39;,1,\u0026#39;11.jpg\u0026#39;,5,\u0026#39;2007-02-01\u0026#39;,3,now(),now()), (12,\u0026#39;hebiweng\u0026#39;,\u0026#39;123456\u0026#39;,\u0026#39;鹤笔翁\u0026#39;,1,\u0026#39;12.jpg\u0026#39;,5,\u0026#39;2008-08-18\u0026#39;,3,now(),now()), (13,\u0026#39;fangdongbai\u0026#39;,\u0026#39;123456\u0026#39;,\u0026#39;方东白\u0026#39;,1,\u0026#39;13.jpg\u0026#39;,5,\u0026#39;2012-11-01\u0026#39;,3,now(),now()), (14,\u0026#39;zhangsanfeng\u0026#39;,\u0026#39;123456\u0026#39;,\u0026#39;张三丰\u0026#39;,1,\u0026#39;14.jpg\u0026#39;,2,\u0026#39;2002-08-01\u0026#39;,2,now(),now()), (15,\u0026#39;yulianzhou\u0026#39;,\u0026#39;123456\u0026#39;,\u0026#39;俞莲舟\u0026#39;,1,\u0026#39;15.jpg\u0026#39;,2,\u0026#39;2011-05-01\u0026#39;,2,now(),now()), (16,\u0026#39;songyuanqiao\u0026#39;,\u0026#39;123456\u0026#39;,\u0026#39;宋远桥\u0026#39;,1,\u0026#39;16.jpg\u0026#39;,2,\u0026#39;2007-01-01\u0026#39;,2,now(),now()), (17,\u0026#39;chenyouliang\u0026#39;,\u0026#39;123456\u0026#39;,\u0026#39;陈友谅\u0026#39;,1,\u0026#39;17.jpg\u0026#39;,NULL,\u0026#39;2015-03-21\u0026#39;,NULL,now(),now()); 2.1.2 介绍 # 多表查询：查询时从多张表中获取所需数据\n单表查询的SQL语句：select 字段列表 from 表名;\n那么要执行多表查询，只需要使用逗号分隔多张表即可，如： select 字段列表 from 表1, 表2;\n查询用户表和部门表中的数据：\nselect * from tb_emp , tb_dept; 此时,我们看到查询结果中包含了大量的结果集，总共85条记录，而这其实就是员工表所有的记录(17行)与部门表所有记录(5行)的所有组合情况，这种现象称之为笛卡尔积。\n笛卡尔积：笛卡尔乘积是指在数学中，两个集合(A集合和B集合)的所有组合情况。\n在多表查询时，需要消除无效的笛卡尔积，只保留表关联部分的数据\n在SQL语句中，如何去除无效的笛卡尔积呢？只需要给多表查询加上连接查询的条件即可。\nselect * from tb_emp , tb_dept where tb_emp.dept_id = tb_dept.id ; 由于id为17的员工，没有dept_id字段值，所以在多表查询时，根据连接查询的条件并没有查询到。\n2.1.3 分类 # 多表查询可以分为：\n连接查询\n内连接：相当于查询A、B交集部分数据 外连接\n左外连接：查询左表所有数据(包括两张表交集部分数据)\n右外连接：查询右表所有数据(包括两张表交集部分数据)\n子查询\n2.2 内连接 # 内连接查询：查询两表或多表中交集部分数据。\n内连接从语法上可以分为：\n隐式内连接\n显式内连接\n隐式内连接语法：\nselect 字段列表 from 表1 , 表2 where 条件 ... ; 显式内连接语法：\nselect 字段列表 from 表1 [ inner ] join 表2 on 连接条件 ... ; 案例：查询员工的姓名及所属的部门名称\n隐式内连接实现 select tb_emp.name , tb_dept.name -- 分别查询两张表中的数据 from tb_emp , tb_dept -- 关联两张表 where tb_emp.dept_id = tb_dept.id; -- 消除笛卡尔积 显式内连接实现 select tb_emp.name , tb_dept.name from tb_emp inner join tb_dept on tb_emp.dept_id = tb_dept.id; 多表查询时给表起别名：\ntableA as 别名1 , tableB as 别名2 ;\ntableA 别名1 , tableB 别名2 ;\n使用了别名的多表查询：\nselect emp.name , dept.name from tb_emp emp inner join tb_dept dept on emp.dept_id = dept.id; 注意事项:\n一旦为表起了别名，就不能再使用表名来指定对应的字段了，此时只能够使用别名来指定字段。\n2.3 外连接 # 外连接分为两种：左外连接 和 右外连接。\n左外连接语法结构：\nselect 字段列表 from 表1 left [ outer ] join 表2 on 连接条件 ... ; 左外连接相当于查询表1(左表)的所有数据，当然也包含表1和表2交集部分的数据。\n右外连接语法结构：\nselect 字段列表 from 表1 right [ outer ] join 表2 on 连接条件 ... ; 右外连接相当于查询表2(右表)的所有数据，当然也包含表1和表2交集部分的数据。\n案例：查询员工表中所有员工的姓名, 和对应的部门名称\n-- 左外连接：以left join关键字左边的表为主表，查询主表中所有数据，以及和主表匹配的右边表中的数据 select emp.name , dept.name from tb_emp AS emp left join tb_dept AS dept on emp.dept_id = dept.id; 案例：查询部门表中所有部门的名称, 和对应的员工名称\n-- 右外连接 select dept.name , emp.name from tb_emp AS emp right join tb_dept AS dept on emp.dept_id = dept.id; 注意事项：\n左外连接和右外连接是可以相互替换的，只需要调整连接查询时SQL语句中表的先后顺序就可以了。而我们在日常开发使用时，更偏向于左外连接。\n2.4 子查询 # 2.4.1 介绍 # SQL语句中嵌套select语句，称为嵌套查询，又称子查询。\nSELECT * FROM t1 WHERE column1 = ( SELECT column1 FROM t2 ... ); 子查询外部的语句可以是insert / update / delete / select 的任何一个，最常见的是 select。\n根据子查询结果的不同分为：\n标量子查询（子查询结果为单个值[一行一列]）\n列子查询（子查询结果为一列，但可以是多行）\n行子查询（子查询结果为一行，但可以是多列）\n表子查询（子查询结果为多行多列[相当于子查询结果是一张表]）\n子查询可以书写的位置：\nwhere之后 from之后 select之后 2.4.2 标量子查询 # 子查询返回的结果是单个值(数字、字符串、日期等)，最简单的形式，这种子查询称为标量子查询。\n常用的操作符： = \u0026lt;\u0026gt; \u0026gt; \u0026gt;= \u0026lt; \u0026lt;=\n案例1：查询\u0026quot;教研部\u0026quot;的所有员工信息\n可以将需求分解为两步：\n查询 \u0026ldquo;教研部\u0026rdquo; 部门ID 根据 \u0026ldquo;教研部\u0026rdquo; 部门ID，查询员工信息 -- 1.查询\u0026#34;教研部\u0026#34;部门ID select id from tb_dept where name = \u0026#39;教研部\u0026#39;; #查询结果：2 -- 2.根据\u0026#34;教研部\u0026#34;部门ID, 查询员工信息 select * from tb_emp where dept_id = 2; -- 合并出上两条SQL语句 select * from tb_emp where dept_id = (select id from tb_dept where name = \u0026#39;教研部\u0026#39;); 案例2：查询在 \u0026ldquo;方东白\u0026rdquo; 入职之后的员工信息\n可以将需求分解为两步：\n查询 方东白 的入职日期 查询 指定入职日期之后入职的员工信息 -- 1.查询\u0026#34;方东白\u0026#34;的入职日期 select entrydate from tb_emp where name = \u0026#39;方东白\u0026#39;; #查询结果：2012-11-01 -- 2.查询指定入职日期之后入职的员工信息 select * from tb_emp where entrydate \u0026gt; \u0026#39;2012-11-01\u0026#39;; -- 合并以上两条SQL语句 select * from tb_emp where entrydate \u0026gt; (select entrydate from tb_emp where name = \u0026#39;方东白\u0026#39;); 2.4.3 列子查询 # 子查询返回的结果是一列(可以是多行)，这种子查询称为列子查询。\n常用的操作符：\n操作符 描述 IN 在指定的集合范围之内，多选一 NOT IN 不在指定的集合范围之内 案例：查询\u0026quot;教研部\u0026quot;和\u0026quot;咨询部\u0026quot;的所有员工信息\n分解为以下两步：\n查询 \u0026ldquo;销售部\u0026rdquo; 和 \u0026ldquo;市场部\u0026rdquo; 的部门ID 根据部门ID, 查询员工信息 -- 1.查询\u0026#34;销售部\u0026#34;和\u0026#34;市场部\u0026#34;的部门ID select id from tb_dept where name = \u0026#39;教研部\u0026#39; or name = \u0026#39;咨询部\u0026#39;; #查询结果：3,2 -- 2.根据部门ID, 查询员工信息 select * from tb_emp where dept_id in (3,2); -- 合并以上两条SQL语句 select * from tb_emp where dept_id in (select id from tb_dept where name = \u0026#39;教研部\u0026#39; or name = \u0026#39;咨询部\u0026#39;); 2.4.4 行子查询 # 子查询返回的结果是一行(可以是多列)，这种子查询称为行子查询。\n常用的操作符：= 、\u0026lt;\u0026gt; 、IN 、NOT IN\n案例：查询与\u0026quot;韦一笑\u0026quot;的入职日期及职位都相同的员工信息\n可以拆解为两步进行：\n查询 \u0026ldquo;韦一笑\u0026rdquo; 的入职日期 及 职位 查询与\u0026quot;韦一笑\u0026quot;的入职日期及职位相同的员工信息 -- 查询\u0026#34;韦一笑\u0026#34;的入职日期 及 职位 select entrydate , job from tb_emp where name = \u0026#39;韦一笑\u0026#39;; #查询结果： 2007-01-01 , 2 -- 查询与\u0026#34;韦一笑\u0026#34;的入职日期及职位相同的员工信息 select * from tb_emp where (entrydate,job) = (\u0026#39;2007-01-01\u0026#39;,2); -- 合并以上两条SQL语句 select * from tb_emp where (entrydate,job) = (select entrydate , job from tb_emp where name = \u0026#39;韦一笑\u0026#39;); 2.4.5 表子查询 # 子查询返回的结果是多行多列，常作为临时表，这种子查询称为表子查询。\n案例：查询入职日期是 \u0026ldquo;2006-01-01\u0026rdquo; 之后的员工信息 , 及其部门信息\n分解为两步执行：\n查询入职日期是 \u0026ldquo;2006-01-01\u0026rdquo; 之后的员工信息 基于查询到的员工信息，在查询对应的部门信息 select * from emp where entrydate \u0026gt; \u0026#39;2006-01-01\u0026#39;; select e.*, d.* from (select * from emp where entrydate \u0026gt; \u0026#39;2006-01-01\u0026#39;) e left join dept d on e.dept_id = d.id ; ","date":"22 March 2025","externalUrl":null,"permalink":"/posts/1742633132219-mysql%E6%93%8D%E4%BD%9C/","section":"Posts","summary":"","title":"MySQL操作","type":"posts"},{"content":"an example to get you started\nMySQL高性能优化规范建议总结 # 1.1 数据库命名规范 # 所有数据库对象名称必须使用小写字母并用下划线分割 所有数据库对象名称禁止使用 MySQL 保留关键字（如果表名中包含关键字查询时，需要将其用单引号括起来） 数据库对象的命名要能做到见名识意，并且最后不要超过 32 个字符 临时库表必须以 tmp_ 为前缀并以日期为后缀，备份表必须以 bak_ 为前缀并以日期 (时间戳) 为后缀 所有存储相同数据的列名和列类型必须一致（一般作为关联列，如果查询时关联列类型不一致会自动进行数据类型隐式转换，会造成列上的索引失效，导致查询效率降低） 1.2 数据库基本设计规范 # 1.2.1 所有表必须使用InnoDB存储引擎 # 没有特殊要求（即 InnoDB 无法满足的功能如：列存储，存储空间数据等）的情况下，所有表必须使用 InnoDB 存储引擎（MySQL5.5 之前默认使用 Myisam，5.6 以后默认的为 InnoDB）。\nInnoDB 支持事务，支持行级锁，更好的恢复性，高并发下性能更好。\n1.2.2 数据库和表的字符集统一使用UTF8 # 兼容性更好，统一字符集可以避免由于字符集转换产生的乱码，不同的字符集进行比较前需要进行转换会造成索引失效，如果数据库中有存储 emoji 表情的需要，字符集需要采用 utf8mb4 字符集。\n推荐阅读一下我写的这篇文章：MySQL 字符集详解 。\n1.2.3 所有表和字段都需要添加注释 # 使用 comment 从句添加表和列的备注，从一开始就进行数据字典的维护\n1.2.4 尽量控制单表数据量的大小，建议控制在500万以内 # 500 万并不是 MySQL 数据库的限制，过大会造成修改表结构，备份，恢复都会有很大的问题。\n可以用历史数据归档（应用于日志数据），分库分表（应用于业务数据）等手段来控制数据量大小\n1.2.5 谨慎使用MySQL分区表 # 分区表在物理上表现为多个文件，在逻辑上表现为一个表；\n谨慎选择分区键，跨分区查询效率可能更低；\n建议采用物理分表的方式管理大数据。\n1.2.6 经常一起使用的列放到一个表中 # 避免更多的关联操作。\n1.2.7 禁止在表中建立预留字段 # 预留字段的命名很难做到见名识义。 预留字段无法确认存储的数据类型，所以无法选择合适的类型。 对预留字段类型的修改，会对表进行锁定。 1.2.8 禁止在数据库中存储文件（比如图片）这类大的二进制数据 # 在数据库中存储文件会严重影响数据库性能，消耗过多存储空间。\n文件（比如图片）这类大的二进制数据通常存储于文件服务器，数据库只存储文件地址信息。\n1.2.9 不要被数据库范式所束缚 # 一般来说，设计关系数据库时需要满足第三范式，但为了满足第三范式，我们可能会拆分出多张表。而在进行查询时需要对多张表进行关联查询，有时为了提高查询效率，会降低范式的要求，在表中保存一定的冗余信息，也叫做反范式。但要注意反范式一定要适度。\n1.2.10 禁止在线上做数据库压力测试 # 1.2.11 禁止从开发环境、测试环境直接连接生产环境数据库 # 安全隐患极大，要对生产环境抱有敬畏之心！\n1.3 数据库字段设计规范 # 1.3.1 优先选择符合存储需要的最小的数据类型 # 存储字节越小，占用也就空间越小，性能也越好。\na.某些字符串可以转换成数字类型存储比如可以将 IP 地址转换成整型数据。\n数字是连续的，性能更好，占用空间也更小。\nMySQL 提供了两个方法来处理 ip 地址\nINET_ATON()：把 ip 转为无符号整型 (4-8 位) INET_NTOA() :把整型的 ip 转为地址 插入数据前，先用 INET_ATON() 把 ip 地址转为整型，显示数据时，使用 INET_NTOA() 把整型的 ip 地址转为地址显示即可。\nb.对于非负型的数据 (如自增 ID,整型 IP，年龄) 来说,要优先使用无符号整型来存储。\n无符号相对于有符号可以多出一倍的存储空间\nSIGNED INT -2147483648~2147483647 UNSIGNED INT 0~4294967295 c.小数值类型（比如年龄、状态表示如 0/1）优先使用 TINYINT 类型。\n1.3.2 避免使用 TEXT,BLOB 数据类型，最常见的 TEXT 类型可以存储 64k 的数据 # a. 建议把 BLOB 或是 TEXT 列分离到单独的扩展表中。\nMySQL 内存临时表不支持 TEXT、BLOB 这样的大数据类型，如果查询中包含这样的数据，在排序等操作时，就不能使用内存临时表，必须使用磁盘临时表进行。而且对于这种数据，MySQL 还是要进行二次查询，会使 sql 性能变得很差，但是不是说一定不能使用这样的数据类型。\n如果一定要使用，建议把 BLOB 或是 TEXT 列分离到单独的扩展表中，查询时一定不要使用 select *而只需要取出必要的列，不需要 TEXT 列的数据时不要对该列进行查询。\n2、TEXT 或 BLOB 类型只能使用前缀索引\n因为 MySQL 对索引字段长度是有限制的，所以 TEXT 类型只能使用前缀索引，并且 TEXT 列上是不能有默认值的\n1.3.3 避免使用ENUM类型 # 修改 ENUM 值需要使用 ALTER 语句； ENUM 类型的 ORDER BY 操作效率低，需要额外操作； ENUM 数据类型存在一些限制比如建议不要使用数值作为 ENUM 的枚举值。 相关阅读：是否推荐使用 MySQL 的 enum 类型？ - 架构文摘 - 知乎 。\n1.3.4 尽可能把所有列定义为NOT NULL # 除非有特别的原因使用 NULL 值，应该总是让字段保持 NOT NULL。\n索引 NULL 列需要额外的空间来保存，所以要占用更多的空间； 进行比较和计算时要对 NULL 值做特别的处理。 相关阅读：技术分享 | MySQL 默认值选型（是空，还是 NULL） 。\n1.3.5 一定不要使用字符串存储日期 # 对于日期类型来说， 一定不要用字符串存储日期。可以考虑 DATETIME、TIMESTAMP 和 数值型时间戳。\n这三种种方式都有各自的优势，根据实际场景选择最合适的才是王道。下面再对这三种方式做一个简单的对比，以供大家实际开发中选择正确的存放时间的数据类型：\n类型 存储空间 日期格式 日期范围 是否带时区信息 DATETIME 5~8 字节 YYYY-MM-DD hh:mm:ss[.fraction] 1000-01-01 00:00:00[.000000] ～ 9999-12-31 23:59:59[.999999] 否 TIMESTAMP 4~7 字节 YYYY-MM-DD hh:mm:ss[.fraction] 1970-01-01 00:00:01[.000000] ～ 2038-01-19 03:14:07[.999999] 是 数值型时间戳 4 字节 全数字如 1578707612 1970-01-01 00:00:01 之后的时间 否 MySQL 时间类型选择的详细介绍请看这篇：MySQL 时间类型数据存储建议。\n1.3.6 同财务相关的金额类数据必须使用decimal类型 # 非精准浮点：float,double 精准浮点：decimal decimal 类型为精准浮点数，在计算时不会丢失精度。占用空间由定义的宽度决定，每 4 个字节可以存储 9 位数字，并且小数点要占用一个字节。并且，decimal 可用于存储比 bigint 更大的整型数据\n不过， 由于 decimal 需要额外的空间和计算开销，应该尽量只在需要对数据进行精确计算时才使用 decimal 。\n1.3.7 单表不要包含过多字段 # 如果一个表包含过多字段的话，可以考虑将其分解成多个表，必要时增加中间表进行关联。\n1.4 索引设计规范 # 1.4.1 限制每张表上的索引数量，建议单张表索引不超过5个 # 索引并不是越多越好！索引可以提高效率同样可以降低效率。\n索引可以增加查询效率，但同样也会降低插入和更新的效率，甚至有些情况下会降低查询效率。\n因为 MySQL 优化器在选择如何优化查询时，会根据统一信息，对每一个可以用到的索引来进行评估，以生成出一个最好的执行计划，如果同时有很多个索引都可以用于查询，就会增加 MySQL 优化器生成执行计划的时间，同样会降低查询性能。\n1.4.2 禁止使用全文索引 # 全文索引不适用于 OLTP 场景。\n1.4.3 禁止给表中的每一列都建立单独的索引 # 5.6 版本之前，一个 sql 只能使用到一个表中的一个索引，5.6 以后，虽然有了合并索引的优化方式，但是还是远远没有使用一个联合索引的查询方式好。\n1.4.4 每个InnoDB表必须有个主键 # InnoDB 是一种索引组织表：数据的存储的逻辑顺序和索引的顺序是相同的。每个表都可以有多个索引，但是表的存储顺序只能有一种。\nInnoDB 是按照主键索引的顺序来组织表的\n不要使用更新频繁的列作为主键，不使用多列主键（相当于联合索引） 不要使用 UUID,MD5,HASH,字符串列作为主键（无法保证数据的顺序增长） 主键建议使用自增 ID 值 1.4.5 常见索引列建议 # 出现在 SELECT、UPDATE、DELETE 语句的 WHERE 从句中的列 包含在 ORDER BY、GROUP BY、DISTINCT 中的字段 并不要将符合 1 和 2 中的字段的列都建立一个索引， 通常将 1、2 中的字段建立联合索引效果更好 多表 join 的关联列 1.4.6 如何选择索引列的顺序 # 建立索引的目的是：希望通过索引进行数据查找，减少随机 IO，增加查询性能 ，索引能过滤出越少的数据，则从磁盘中读入的数据也就越少。\n区分度最高的放在联合索引的最左侧（区分度=列中不同值的数量/列的总行数） 尽量把字段长度小的列放在联合索引的最左侧（因为字段长度越小，一页能存储的数据量越大，IO 性能也就越好） 使用最频繁的列放到联合索引的左侧（这样可以比较少的建立一些索引） 1.4.7 避免建立冗余索引和重复索引（增加了查询优化器生成执行计划的时间） # 重复索引示例：primary key(id)、index(id)、unique index(id) 冗余索引示例：index(a,b,c)、index(a,b)、index(a) 1.4.8 对于频繁的查询优先考虑使用覆盖索引 # 覆盖索引：就是包含了所有查询字段 (where,select,order by,group by 包含的字段) 的索引\n覆盖索引的好处：\n避免 InnoDB 表进行索引的二次查询，也就是回表操作: InnoDB 是以聚集索引的顺序来存储的，对于 InnoDB 来说，二级索引在叶子节点中所保存的是行的主键信息，如果是用二级索引查询数据的话，在查找到相应的键值后，还要通过主键进行二次查询才能获取我们真实所需要的数据。而在覆盖索引中，二级索引的键值中可以获取所有的数据，避免了对主键的二次查询（回表），减少了 IO 操作，提升了查询效率。 可以把随机 IO 变成顺序 IO 加快查询效率: 由于覆盖索引是按键值的顺序存储的，对于 IO 密集型的范围查找来说，对比随机从磁盘读取每一行的数据 IO 要少的多，因此利用覆盖索引在访问时也可以把磁盘的随机读取的 IO 转变成索引查找的顺序 IO。 1.4.9 索引SET规范 # 尽量避免使用外键约束\n不建议使用外键约束（foreign key），但一定要在表与表之间的关联键上建立索引 外键可用于保证数据的参照完整性，但建议在业务端实现 外键会影响父表和子表的写操作从而降低性能 1.5 数据库SQL开发规范 # 1.5.1 尽量不在数据库做运算，复杂运算需移到业务应用里完成 # 尽量不在数据库做运算，复杂运算需移到业务应用里完成。这样可以避免数据库的负担过重，影响数据库的性能和稳定性。数据库的主要作用是存储和管理数据，而不是处理数据。\n1.5.2 优化对性能影响较大的SQL语句 # 要找到最需要优化的 SQL 语句。要么是使用最频繁的语句，要么是优化后提高最明显的语句，可以通过查询 MySQL 的慢查询日志来发现需要进行优化的 SQL 语句。\n1.5.3 充分利用表上已经存在的索引 # 避免使用双%号的查询条件。如：a like '%123%'，（如果无前置%,只有后置%，是可以用到列上的索引的）\n一个 SQL 只能利用到复合索引中的一列进行范围查询。如：有 a,b,c 列的联合索引，在查询条件中有 a 列的范围查询，则在 b,c 列上的索引将不会被用到。\n在定义联合索引时，如果 a 列要用到范围查找的话，就要把 a 列放到联合索引的右侧，使用 left join 或 not exists 来优化 not in 操作，因为 not in 也通常会使用索引失效。\n1.5.4 禁止使用SELECT * 必须使用SELECT \u0026lt;字段列表\u0026gt;查询 # SELECT * 会消耗更多的 CPU。 SELECT * 无用字段增加网络带宽资源消耗，增加数据传输时间，尤其是大字段（如 varchar、blob、text）。 SELECT * 无法使用 MySQL 优化器覆盖索引的优化（基于 MySQL 优化器的“覆盖索引”策略又是速度极快，效率极高，业界极为推荐的查询优化方式） SELECT \u0026lt;字段列表\u0026gt; 可减少表结构变更带来的影响、 1.5.5 禁止使用不含字段列表的INSERT语句 # 如：\ninsert into t values (\u0026#39;a\u0026#39;,\u0026#39;b\u0026#39;,\u0026#39;c\u0026#39;); 应使用：\ninsert into t(c1,c2,c3) values (\u0026#39;a\u0026#39;,\u0026#39;b\u0026#39;,\u0026#39;c\u0026#39;); 1.5.6 建议使用预编译语句进行数据库操作 # 预编译语句可以重复使用这些计划，减少 SQL 编译所需要的时间，还可以解决动态 SQL 所带来的 SQL 注入的问题。 只传参数，比传递 SQL 语句更高效。 相同语句可以一次解析，多次使用，提高处理效率。 1.5.7 避免数据类型的隐式转换 # 隐式转换会导致索引失效如:\nselect name,phone from customer where id = \u0026#39;111\u0026#39;; 详细解读可以看：MySQL 中的隐式转换造成的索引失效 这篇文章。\n1.5.8 避免使用子查询，可以把子查询优化为 join 操作 # 通常子查询在 in 子句中，且子查询中为简单 SQL(不包含 union、group by、order by、limit 从句) 时,才可以把子查询转化为关联查询进行优化。\n子查询性能差的原因： 子查询的结果集无法使用索引，通常子查询的结果集会被存储到临时表中，不论是内存临时表还是磁盘临时表都不会存在索引，所以查询性能会受到一定的影响。特别是对于返回结果集比较大的子查询，其对查询性能的影响也就越大。由于子查询会产生大量的临时表也没有索引，所以会消耗过多的 CPU 和 IO 资源，产生大量的慢查询。\n1.5.9 避免使用JOIN关联太多的表 # 对于 MySQL 来说，是存在关联缓存的，缓存的大小可以由 join_buffer_size 参数进行设置。\n在 MySQL 中，对于同一个 SQL 多关联（join）一个表，就会多分配一个关联缓存，如果在一个 SQL 中关联的表越多，所占用的内存也就越大。\n如果程序中大量的使用了多表关联的操作，同时 join_buffer_size 设置的也不合理的情况下，就容易造成服务器内存溢出的情况，就会影响到服务器数据库性能的稳定性。\n同时对于关联操作来说，会产生临时表操作，影响查询效率，MySQL 最多允许关联 61 个表，建议不超过 5 个。\n1.5.10 减少同数据库的交互次数 # 数据库更适合处理批量操作，合并多个相同的操作到一起，可以提高处理效率。\n1.5.11 对应同一列进行or判断时，使用in代替or # in 的值不要超过 500 个，in 操作可以更有效的利用索引，or 大多数情况下很少能利用到索引。\n1.5.12 禁止使用order by rand()进行随机排序 # order by rand() 会把表中所有符合条件的数据装载到内存中，然后在内存中对所有数据根据随机生成的值进行排序，并且可能会对每一行都生成一个随机值，如果满足条件的数据集非常大，就会消耗大量的 CPU 和 IO 及内存资源。\n推荐在程序中获取一个随机值，然后从数据库中获取数据的方式。\n1.5.13 WHERE从句中禁止队列进行函数转换和计算 # 对列进行函数转换或计算时会导致无法使用索引\n不推荐：\nwhere date(create_time)=\u0026#39;20190101\u0026#39; 推荐：\nwhere create_time \u0026gt;= \u0026#39;20190101\u0026#39; and create_time \u0026lt; \u0026#39;20190102\u0026#39; 1.5.14 在明显不会有重复值时使用UNION ALL 而不是 UNION # UNION 会把两个结果集的所有数据放到临时表中后再进行去重操作 UNION ALL 不会再对结果集进行去重操作 1.5.15 拆分复杂的大SQL为多个小SQL # 大 SQL 逻辑上比较复杂，需要占用大量 CPU 进行计算的 SQL MySQL 中，一个 SQL 只能使用一个 CPU 进行计算 SQL 拆分后可以通过并行执行来提高处理效率 1.5.16 程序连接不同的数据库使用不同的账号，禁止跨库查询 # 为数据库迁移和分库分表留出余地 降低业务耦合度 避免权限过大而产生的安全风险 1.5.17 SQL的优化经验 # SQL优化可以从以下几个方面考虑：\n建表时选择合适的字段类型。 使用索引，遵循创建索引的原则。 编写高效的SQL语句，比如避免使用SELECT *，尽量使用UNION ALL代替UNION，以及在表关联时使用INNER JOIN。 采用主从复制和读写分离提高性能。 在数据量大时考虑分库分表。 1.6 数据库操作行为规范 # 1.6.1 超100万行的批量写（UPDATE,DEETE,INSERT）操作，要分批次多次进行操作 # 大批量操作可能会造成严重的主从延迟\n主从环境中,大批量操作可能会造成严重的主从延迟，大批量的写操作一般都需要执行一定长的时间，而只有当主库上执行完成后，才会在其他从库上执行，所以会造成主库与从库长时间的延迟情况\nbinlog 日志为 row 格式时会产生大量的日志\n大批量写操作会产生大量日志，特别是对于 row 格式二进制数据而言，由于在 row 格式中会记录每一行数据的修改，我们一次修改的数据越多，产生的日志量也就会越多，日志的传输和恢复所需要的时间也就越长，这也是造成主从延迟的一个原因\n避免产生大事务操作\n大批量修改数据，一定是在一个事务中进行的，这就会造成表中大批量数据进行锁定，从而导致大量的阻塞，阻塞会对 MySQL 的性能产生非常大的影响。\n特别是长时间的阻塞会占满所有数据库的可用连接，这会使生产环境中的其他应用无法连接到数据库，因此一定要注意大批量写操作要进行分批\n1.6.2 对于大表使用pt-online-schema-change修改表结构 # 避免大表修改产生的主从延迟 避免在对表字段进行修改时进行锁表 对大表数据结构的修改一定要谨慎，会造成严重的锁表操作，尤其是生产环境，是不能容忍的。\npt-online-schema-change 它会首先建立一个与原表结构相同的新表，并且在新表上进行表结构的修改，然后再把原表中的数据复制到新表中，并在原表中增加一些触发器。把原表中新增的数据也复制到新表中，在行所有数据复制完成之后，把新表命名成原表，并把原来的表删除掉。把原来一个 DDL 操作，分解成多个小的批次进行。\n1.6.3 禁止为程序使用的账号赋予super权限 # 当达到最大连接数限制时，还运行 1 个有 super 权限的用户连接 super 权限只能留给 DBA 处理问题的账号使用 1.6.4 对于程序连接数据库账号，遵循权限最小原则 # 程序使用数据库账号只能在一个 DB 下使用，不准跨库 程序使用的账号原则上不准有 drop 权限 1.7 MySQL主从同步的原理 # MySQL主从复制的核心是二进制日志（Binlog）。步骤如下：\n主库在事务提交时记录数据变更到Binlog。 从库读取主库的Binlog并写入中继日志（Relay Log）。 从库重做中继日志中的事件，反映到自己的数据中。 ","date":"22 March 2025","externalUrl":null,"permalink":"/posts/1742633110072-mysql%E9%AB%98%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E8%A7%84%E8%8C%83%E5%BB%BA%E8%AE%AE/","section":"Posts","summary":"","title":"MySQL高性能优化规范建议","type":"posts"},{"content":" SQL语法基础知识总结 # 1.1 基本概念 # 1.1.1 数据库术语 # 数据库（database） - 保存有组织的数据的容器（通常是一个文件或一组文件）。 数据表（table） - 某种特定类型数据的结构化清单。 模式（schema） - 关于数据库和表的布局及特性的信息。模式定义了数据在表中如何存储，包含存储什么样的数据，数据如何分解，各部分信息如何命名等信息。数据库和表都有模式。 列（column） - 表中的一个字段。所有表都是由一个或多个列组成的。 行（row） - 表中的一个记录。 主键（primary key） - 一列（或一组列），其值能够唯一标识表中每一行。 1.1.2 SQL 语法 # SQL（Structured Query Language)，标准 SQL 由 ANSI 标准委员会管理，从而称为 ANSI SQL。各个 DBMS 都有自己的实现，如 PL/SQL、Transact-SQL 等。\n1.1.2.1 SQL 语法结构 # SQL 语法结构包括：\n子句 - 是语句和查询的组成成分。（在某些情况下，这些都是可选的。） 表达式 - 可以产生任何标量值，或由列和行的数据库表 谓词 - 给需要评估的 SQL 三值逻辑（3VL）（true/false/unknown）或布尔真值指定条件，并限制语句和查询的效果，或改变程序流程。 查询 - 基于特定条件检索数据。这是 SQL 的一个重要组成部分。 语句 - 可以持久地影响纲要和数据，也可以控制数据库事务、程序流程、连接、会话或诊断。 1.1.2.2 SQL 语法要点 # SQL 语句不区分大小写，但是数据库表名、列名和值是否区分，依赖于具体的 DBMS 以及配置。例如：SELECT 与 select、Select 是相同的。 多条 SQL 语句必须以分号（;）分隔。 处理 SQL 语句时，所有空格都被忽略。 SQL 语句可以写成一行，也可以分写为多行。\n-- 一行 SQL 语句 UPDATE user SET username=\u0026#39;robot\u0026#39;, password=\u0026#39;robot\u0026#39; WHERE username = \u0026#39;root\u0026#39;; -- 多行 SQL 语句 UPDATE user SET username=\u0026#39;robot\u0026#39;, password=\u0026#39;robot\u0026#39; WHERE username = \u0026#39;root\u0026#39;; SQL 支持三种注释：\n## 注释1 -- 注释2 /* 注释3 */ 1.1.3 SQL 分类 # 1.1.3.1 数据定义语言（DDL） # 数据定义语言（Data Definition Language，DDL）是 SQL 语言集中负责数据结构定义与数据库对象定义的语言。\nDDL 的主要功能是定义数据库对象。\nDDL 的核心指令是 CREATE、ALTER、DROP。\n1.1.3.2 数据操纵语言（DML） # 数据操纵语言（Data Manipulation Language, DML）是用于数据库操作，对数据库其中的对象和数据运行访问工作的编程语句。\nDML 的主要功能是 访问数据，因此其语法都是以读写数据库为主。\nDML 的核心指令是 INSERT、UPDATE、DELETE、SELECT。这四个指令合称 CRUD(Create, Read, Update, Delete)，即增删改查。\n1.1.3.3 事务控制语言（TCL） # 事务控制语言 (Transaction Control Language, TCL) 用于管理数据库中的事务。这些用于管理由 DML 语句所做的更改。它还允许将语句分组为逻辑事务。\nTCL 的核心指令是 COMMIT、ROLLBACK。\n1.1.3.4 数据控制语言（DCL） # 数据控制语言 (Data Control Language, DCL) 是一种可对数据访问权进行控制的指令，它可以控制特定用户账户对数据表、查看表、预存程序、用户自定义函数等数据库对象的控制权。\nDCL 的核心指令是 GRANT、REVOKE。\nDCL 以控制用户的访问权限为主，因此其指令作法并不复杂，可利用 DCL 控制的权限有：CONNECT、SELECT、INSERT、UPDATE、DELETE、EXECUTE、USAGE、REFERENCES。\n根据不同的 DBMS 以及不同的安全性实体，其支持的权限控制也有所不同。\n我们先来介绍 DML 语句用法。 DML 的主要功能是读写数据库实现增删改查。\n1.2 增删改查 # 增删改查，又称为 CRUD，数据库基本操作中的基本操作。\n1.2.1 插入数据 # INSERT INTO 语句用于向表中插入新记录。\n插入完整的行\n# 插入一行 INSERT INTO user VALUES (10, \u0026#39;root\u0026#39;, \u0026#39;root\u0026#39;, \u0026#39;xxxx@163.com\u0026#39;); # 插入多行 INSERT INTO user VALUES (10, \u0026#39;root\u0026#39;, \u0026#39;root\u0026#39;, \u0026#39;xxxx@163.com\u0026#39;), (12, \u0026#39;user1\u0026#39;, \u0026#39;user1\u0026#39;, \u0026#39;xxxx@163.com\u0026#39;), (18, \u0026#39;user2\u0026#39;, \u0026#39;user2\u0026#39;, \u0026#39;xxxx@163.com\u0026#39;); 插入行的一部分\nINSERT INTO user(username, password, email) VALUES (\u0026#39;admin\u0026#39;, \u0026#39;admin\u0026#39;, \u0026#39;xxxx@163.com\u0026#39;); 插入查询出来的数据\nINSERT INTO user(username) SELECT name FROM account; 1.2.2 更新数据 # UPDATE 语句用于更新表中的记录。\nUPDATE user SET username=\u0026#39;robot\u0026#39;, password=\u0026#39;robot\u0026#39; WHERE username = \u0026#39;root\u0026#39;; 1.2.3 删除数据 # DELETE 语句用于删除表中的记录。 TRUNCATE TABLE 可以清空表，也就是删除所有行。说明：TRUNCATE 语句不属于 DML 语法而是 DDL 语法。 删除表中的指定数据\nDELETE FROM user WHERE username = \u0026#39;robot\u0026#39;; 清空表中的数据\nTRUNCATE TABLE user; #truncate table user; 1.2.4 查询数据 # SELECT 语句用于从数据库中查询数据。\nDISTINCT 用于返回唯一不同的值。它作用于所有列，也就是说所有列的值都相同才算相同。\nLIMIT 限制返回的行数。可以有两个参数，第一个参数为起始行，从 0 开始；第二个参数为返回的总行数。\nASC：升序（默认） DESC：降序 查询单列\nSELECT prod_name FROM products; 查询多列\nSELECT prod_id, prod_name, prod_price FROM products; 查询所有列\nSELECT * FROM products; 查询不同的值\nSELECT DISTINCT vend_id FROM products; 限制查询结果\n-- 返回前 5 行 SELECT * FROM mytable LIMIT 5; SELECT * FROM mytable LIMIT 0, 5; -- 返回第 3 ~ 5 行 SELECT * FROM mytable LIMIT 2, 3; 1.3 排序 # order by 用于对结果集按照一个列或者多个列进行排序。默认按照升序对记录进行排序，如果需要按照降序对记录进行排序，可以使用 desc 关键字。\norder by 对多列排序的时候，先排序的列放前面，后排序的列放后面。并且，不同的列可以有不同的排序规则。\nSELECT * FROM products ORDER BY prod_price DESC, prod_name ASC; 1.4 分组 # group by：\ngroup by 子句将记录分组到汇总行中。 group by 为每个组返回一个记录。 group by 通常还涉及聚合count，max，sum，avg 等。 group by 可以按一列或多列进行分组。 group by 按分组字段进行排序后，order by 可以以汇总字段来进行排序。 分组\nSELECT cust_name, COUNT(cust_address) AS addr_num FROM Customers GROUP BY cust_name; 分组后排序\nSELECT cust_name, COUNT(cust_address) AS addr_num FROM Customers GROUP BY cust_name ORDER BY cust_name DESC; having：\nhaving 用于对汇总的 group by 结果进行过滤。 having 一般都是和 group by 连用。 where 和 having 可以在相同的查询中。 使用 WHERE 和 HAVING 过滤数据\nSELECT cust_name, COUNT(*) AS NumberOfOrders FROM Customers WHERE cust_email IS NOT NULL GROUP BY cust_name HAVING COUNT(*) \u0026gt; 1; having vs where：\nwhere：过滤过滤指定的行，后面不能加聚合函数（分组函数）。where 在group by 前。 having：过滤分组，一般都是和 group by 连用，不能单独使用。having 在 group by 之后。 1.5 子查询 # 子查询是嵌套在较大查询中的 SQL 查询，也称内部查询或内部选择，包含子查询的语句也称为外部查询或外部选择。简单来说，子查询就是指将一个 select 查询（子查询）的结果作为另一个 SQL 语句（主查询）的数据来源或者判断条件。\n子查询可以嵌入 SELECT、INSERT、UPDATE 和 DELETE 语句中，也可以和 =、\u0026lt;、\u0026gt;、IN、BETWEEN、EXISTS 等运算符一起使用。\n子查询常用在 WHERE 子句和 FROM 子句后边：\n当用于 WHERE 子句时，根据不同的运算符，子查询可以返回单行单列、多行单列、单行多列数据。子查询就是要返回能够作为 WHERE 子句查询条件的值。 当用于 FROM 子句时，一般返回多行多列数据，相当于返回一张临时表，这样才符合 FROM 后面是表的规则。这种做法能够实现多表联合查询。 注意：MYSQL 数据库从 4.1 版本才开始支持子查询，早期版本是不支持的。\n用于 WHERE 子句的子查询的基本语法如下：\nselect column_name [, column_name ] from table1 [, table2 ] where column_name operator (select column_name [, column_name ] from table1 [, table2 ] [where]) 子查询需要放在括号( )内。 operator 表示用于 where 子句的运算符。 用于 FROM 子句的子查询的基本语法如下：\nselect column_name [, column_name ] from (select column_name [, column_name ] from table1 [, table2 ] [where]) as temp_table_name where condition 用于 FROM 的子查询返回的结果相当于一张临时表，所以需要使用 AS 关键字为该临时表起一个名字。\n子查询的子查询\nSELECT cust_name, cust_contact FROM customers WHERE cust_id IN (SELECT cust_id FROM orders WHERE order_num IN (SELECT order_num FROM orderitems WHERE prod_id = \u0026#39;RGAN01\u0026#39;)); 内部查询首先在其父查询之前执行，以便可以将内部查询的结果传递给外部查询。执行过程可以参考下图：\n1.5.1 WHERE # WHERE 子句用于过滤记录，即缩小访问数据的范围。 WHERE 后跟一个返回 true 或 false 的条件。 WHERE 可以与 SELECT，UPDATE 和 DELETE 一起使用。 可以在 WHERE 子句中使用的操作符。 运算符 描述 = 等于 \u0026lt;\u0026gt; 不等于。注释：在 SQL 的一些版本中，该操作符可被写成 != \u0026gt; 大于 \u0026lt; 小于 \u0026gt;= 大于等于 \u0026lt;= 小于等于 BETWEEN 在某个范围内 LIKE 搜索某种模式 IN 指定针对某个列的多个可能值 SELECT 语句中的 WHERE 子句\nSELECT * FROM Customers WHERE cust_name = \u0026#39;Kids Place\u0026#39;; UPDATE 语句中的 WHERE 子句\nUPDATE Customers SET cust_name = \u0026#39;Jack Jones\u0026#39; WHERE cust_name = \u0026#39;Kids Place\u0026#39;; DELETE 语句中的 WHERE 子句\nDELETE FROM Customers WHERE cust_name = \u0026#39;Kids Place\u0026#39;; 1.5.2 IN 和 BETWEEN # IN 操作符在 WHERE 子句中使用，作用是在指定的几个特定值中任选一个值。 BETWEEN 操作符在 WHERE 子句中使用，作用是选取介于某个范围内的值。 IN 示例\nSELECT * FROM products WHERE vend_id IN (\u0026#39;DLL01\u0026#39;, \u0026#39;BRS01\u0026#39;); BETWEEN 示例\nSELECT * FROM products WHERE prod_price BETWEEN 3 AND 5; 1.5.3 AND、OR、NOT # AND、OR、NOT 是用于对过滤条件的逻辑处理指令。 AND 优先级高于 OR，为了明确处理顺序，可以使用 ()。 AND 操作符表示左右条件都要满足。 OR 操作符表示左右条件满足任意一个即可。 NOT 操作符用于否定一个条件。 AND 示例\nSELECT prod_id, prod_name, prod_price FROM products WHERE vend_id = \u0026#39;DLL01\u0026#39; AND prod_price \u0026lt;= 4; OR 示例\nSELECT prod_id, prod_name, prod_price FROM products WHERE vend_id = \u0026#39;DLL01\u0026#39; OR vend_id = \u0026#39;BRS01\u0026#39;; NOT 示例\nSELECT * FROM products WHERE prod_price NOT BETWEEN 3 AND 5; 1.5.4 LIKE # LIKE 操作符在 WHERE 子句中使用，作用是确定字符串是否匹配模式。 只有字段是文本值时才使用 LIKE。 LIKE 支持两个通配符匹配选项：% 和 _。 不要滥用通配符，通配符位于开头处匹配会非常慢。 % 表示任何字符出现任意次数。 _ 表示任何字符出现一次。 % 示例\nSELECT prod_id, prod_name, prod_price FROM products WHERE prod_name LIKE \u0026#39;%bean bag%\u0026#39;; _ 示例\nSELECT prod_id, prod_name, prod_price FROM products WHERE prod_name LIKE \u0026#39;__ inch teddy bear\u0026#39;; 1.6 连接 # JOIN 是“连接”的意思，顾名思义，SQL JOIN 子句用于将两个或者多个表联合起来进行查询。\n连接表时需要在每个表中选择一个字段，并对这些字段的值进行比较，值相同的两条记录将合并为一条。连接表的本质就是将不同表的记录合并起来，形成一张新表。当然，这张新表只是临时的，它仅存在于本次查询期间。\n使用 JOIN 连接两个表的基本语法如下：\nselect table1.column1, table2.column2... from table1 join table2 on table1.common_column1 = table2.common_column2; table1.common_column1 = table2.common_column2 是连接条件，只有满足此条件的记录才会合并为一行。您可以使用多个运算符来连接表，例如 =、\u0026gt;、\u0026lt;、\u0026lt;\u0026gt;、\u0026lt;=、\u0026gt;=、!=、between、like 或者 not，但是最常见的是使用 =。\n当两个表中有同名的字段时，为了帮助数据库引擎区分是哪个表的字段，在书写同名字段名时需要加上表名。当然，如果书写的字段名在两个表中是唯一的，也可以不使用以上格式，只写字段名即可。\n另外，如果两张表的关联字段名相同，也可以使用 USING子句来代替 ON，举个例子：\n# join....on select c.cust_name, o.order_num from Customers c inner join Orders o on c.cust_id = o.cust_id order by c.cust_name; # 如果两张表的关联字段名相同，也可以使用USING子句：join....using() select c.cust_name, o.order_num from Customers c inner join Orders o using(cust_id) order by c.cust_name; ON 和 WHERE 的区别：\n连接表时，SQL 会根据连接条件生成一张新的临时表。ON 就是连接条件，它决定临时表的生成。 WHERE 是在临时表生成以后，再对临时表中的数据进行过滤，生成最终的结果集，这个时候已经没有 JOIN-ON 了。 所以总结来说就是：SQL 先根据 ON 生成一张临时表，然后再根据 WHERE 对临时表进行筛选。\nSQL 允许在 JOIN 左边加上一些修饰性的关键词，从而形成不同类型的连接，如下表所示：\n连接类型 说明 INNER JOIN 内连接 （默认连接方式）只有当两个表都存在满足条件的记录时才会返回行。 LEFT JOIN / LEFT OUTER JOIN 左(外)连接 返回左表中的所有行，即使右表中没有满足条件的行也是如此。 RIGHT JOIN / RIGHT OUTER JOIN 右(外)连接 返回右表中的所有行，即使左表中没有满足条件的行也是如此。 FULL JOIN / FULL OUTER JOIN 全(外)连接 只要其中有一个表存在满足条件的记录，就返回行。 SELF JOIN 将一个表连接到自身，就像该表是两个表一样。为了区分两个表，在 SQL 语句中需要至少重命名一个表。 CROSS JOIN 交叉连接，从两个或者多个连接表中返回记录集的笛卡尔积。 下图展示了 LEFT JOIN、RIGHT JOIN、INNER JOIN、OUTER JOIN 相关的 7 种用法。\n如果不加任何修饰词，只写 JOIN，那么默认为 INNER JOIN\n对于 INNER JOIN 来说，还有一种隐式的写法，称为 “隐式内连接”，也就是没有 INNER JOIN 关键字，使用 WHERE 语句实现内连接的功能\n# 隐式内连接 select c.cust_name, o.order_num from Customers c, Orders o where c.cust_id = o.cust_id order by c.cust_name; # 显式内连接 select c.cust_name, o.order_num from Customers c inner join Orders o using(cust_id) order by c.cust_name; 1.7 组合 # UNION 运算符将两个或更多查询的结果组合起来，并生成一个结果集，其中包含来自 UNION 中参与查询的提取行。\nUNION 基本规则：\n所有查询的列数和列顺序必须相同。 每个查询中涉及表的列的数据类型必须相同或兼容。 通常返回的列名取自第一个查询。 默认地，UNION 操作符选取不同的值。如果允许重复的值，请使用 UNION ALL。\nSELECT column_name(s) FROM table1 UNION ALL SELECT column_name(s) FROM table2; UNION 结果集中的列名总是等于 UNION 中第一个 SELECT 语句中的列名。\nJOIN vs UNION：\nJOIN 中连接表的列可能不同，但在 UNION 中，所有查询的列数和列顺序必须相同。 UNION 将查询之后的行放在一起（垂直放置），但 JOIN 将查询之后的列放在一起（水平放置），即它构成一个笛卡尔积。 1.8 函数 # 不同数据库的函数往往各不相同，因此不可移植。本节主要以 MySQL 的函数为例。\n1.8.1 文本处理 # 函数 说明 LEFT()、RIGHT() 左边或者右边的字符 LOWER()、UPPER() 转换为小写或者大写 LTRIM()、RTRIM() 去除左边或者右边的空格 LENGTH() 长度，以字节为单位 SOUNDEX() 转换为语音值 其中， SOUNDEX() 可以将一个字符串转换为描述其语音表示的字母数字模式。\nSELECT * FROM mytable WHERE SOUNDEX(col1) = SOUNDEX(\u0026#39;apple\u0026#39;) 1.8.2 日期和时间处理 # 日期格式：YYYY-MM-DD 时间格式：HH:MM:SS 函 数 说 明 AddDate() 增加一个日期（天、周等） AddTime() 增加一个时间（时、分等） CurDate() 返回当前日期 CurTime() 返回当前时间 Date() 返回日期时间的日期部分 DateDiff() 计算两个日期之差 Date_Add() 高度灵活的日期运算函数 Date_Format() 返回一个格式化的日期或时间串 Day() 返回一个日期的天数部分 DayOfWeek() 对于一个日期，返回对应的星期几 Hour() 返回一个时间的小时部分 Minute() 返回一个时间的分钟部分 Month() 返回一个日期的月份部分 Now() 返回当前日期和时间 Second() 返回一个时间的秒部分 Time() 返回一个日期时间的时间部分 Year() 返回一个日期的年份部分 1.8.3 数值处理 # 函数 说明 SIN() 正弦 COS() 余弦 TAN() 正切 ABS() 绝对值 SQRT() 平方根 MOD() 余数 EXP() 指数 PI() 圆周率 RAND() 随机数 1.8.4 汇总 # 函 数 说 明 AVG() 返回某列的平均值 COUNT() 返回某列的行数 MAX() 返回某列的最大值 MIN() 返回某列的最小值 SUM() 返回某列值之和 AVG() 会忽略 NULL 行。\n使用 DISTINCT 可以让汇总函数值汇总不同的值。\nSELECT AVG(DISTINCT col1) AS avg_col FROM mytable 接下来，我们来介绍 DDL 语句用法。DDL 的主要功能是定义数据库对象（如：数据库、数据表、视图、索引等）\n1.9 数据定义 # 1.9.1 数据库（DATABASE） # 1.9.1.1 创建数据库 # CREATE DATABASE test; 1.9.1.2 删除数据库 # DROP DATABASE test; 1.9.1.3 选择数据库 # USE test; 1.9.2数据表（TABLE） # 1.9.2.1 创建数据表 # 普通创建\nCREATE TABLE user ( id int(10) unsigned NOT NULL COMMENT \u0026#39;Id\u0026#39;, username varchar(64) NOT NULL DEFAULT \u0026#39;default\u0026#39; COMMENT \u0026#39;用户名\u0026#39;, password varchar(64) NOT NULL DEFAULT \u0026#39;default\u0026#39; COMMENT \u0026#39;密码\u0026#39;, email varchar(64) NOT NULL DEFAULT \u0026#39;default\u0026#39; COMMENT \u0026#39;邮箱\u0026#39; ) COMMENT=\u0026#39;用户表\u0026#39;; 根据已有的表创建新表\nCREATE TABLE vip_user AS SELECT * FROM user; 1.9.2.2 删除数据表 # DROP TABLE user; 1.9.2.3 修改数据表 # 添加列\nALTER TABLE user ADD age int(3); 删除列\nALTER TABLE user DROP COLUMN age; 修改列\nALTER TABLE `user` MODIFY COLUMN age tinyint; #modify column 添加主键\nALTER TABLE user ADD PRIMARY KEY (id); 删除主键\nALTER TABLE user DROP PRIMARY KEY; 1.9.3 视图（VIEW） # 定义：\n视图是基于 SQL 语句的结果集的可视化的表。 视图是虚拟的表，本身不包含数据，也就不能对其进行索引操作。对视图的操作和对普通表的操作一样。 作用：\n简化复杂的 SQL 操作，比如复杂的联结； 只使用实际表的一部分数据； 通过只给用户访问视图的权限，保证数据的安全性； 更改数据格式和表示。 1.9.3.1 创建视图 # CREATE VIEW top_10_user_view AS SELECT id, username FROM user WHERE id \u0026lt; 10; 1.9.3.2 删除视图 # DROP VIEW top_10_user_view; 1.9.4 索引（INDEX） # 索引是一种用于快速查询和检索数据的数据结构，其本质可以看成是一种排序好的数据结构。\n索引的作用就相当于书的目录。打个比方: 我们在查字典的时候，如果没有目录，那我们就只能一页一页的去找我们需要查的那个字，速度很慢。如果有目录了，我们只需要先去目录里查找字的位置，然后直接翻到那一页就行了。\n优点：\n使用索引可以大大加快 数据的检索速度（大大减少检索的数据量）, 这也是创建索引的最主要的原因。 通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性。 缺点：\n创建索引和维护索引需要耗费许多时间。当对表中的数据进行增删改的时候，如果数据有索引，那么索引也需要动态的修改，会降低 SQL 执行效率。 索引需要使用物理文件存储，也会耗费一定空间。 但是，使用索引一定能提高查询性能吗?\n大多数情况下，索引查询都是比全表扫描要快的。但是如果数据库的数据量不大，那么使用索引也不一定能够带来很大提升。\n关于索引的详细介绍，请看我写的 MySQL 索引详解 这篇文章。\n1.9.4.1 创建索引 # CREATE INDEX user_index ON user (id); 1.9.4.2 添加索引 # ALTER table user ADD INDEX user_index(id) 1.9.4.3 创建唯一索引 # CREATE UNIQUE INDEX user_index ON user (id); 1.9.4.4 删除索引 # ALTER TABLE user DROP INDEX user_index; 1.9.5 约束 # SQL 约束用于规定表中的数据规则。\n如果存在违反约束的数据行为，行为会被约束终止。\n约束可以在创建表时规定（通过 CREATE TABLE 语句），或者在表创建之后规定（通过 ALTER TABLE 语句）。\n约束类型：\nNOT NULL - 指示某列不能存储 NULL 值。 UNIQUE - 保证某列的每行必须有唯一的值。 PRIMARY KEY - NOT NULL 和 UNIQUE 的结合。确保某列（或两个列多个列的结合）有唯一标识，有助于更容易更快速地找到表中的一个特定的记录。 FOREIGN KEY - 保证一个表中的数据匹配另一个表中的值的参照完整性。 CHECK - 保证列中的值符合指定的条件。 DEFAULT - 规定没有给列赋值时的默认值。 创建表时使用约束条件：\nCREATE TABLE Users ( Id INT(10) UNSIGNED NOT NULL AUTO_INCREMENT COMMENT \u0026#39;自增Id\u0026#39;, Username VARCHAR(64) NOT NULL UNIQUE DEFAULT \u0026#39;default\u0026#39; COMMENT \u0026#39;用户名\u0026#39;, Password VARCHAR(64) NOT NULL DEFAULT \u0026#39;default\u0026#39; COMMENT \u0026#39;密码\u0026#39;, Email VARCHAR(64) NOT NULL DEFAULT \u0026#39;default\u0026#39; COMMENT \u0026#39;邮箱地址\u0026#39;, Enabled TINYINT(4) DEFAULT NULL COMMENT \u0026#39;是否有效\u0026#39;, PRIMARY KEY (Id) ) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8mb4 COMMENT=\u0026#39;用户表\u0026#39;; 接下来，我们来介绍 TCL 语句用法。TCL 的主要功能是管理数据库中的事务。\n1.10 事务处理 # 不能回退 SELECT 语句，回退 SELECT 语句也没意义；也不能回退 CREATE 和 DROP 语句。\nMySQL 默认是隐式提交，每执行一条语句就把这条语句当成一个事务然后进行提交。当出现 START TRANSACTION 语句时，会关闭隐式提交；当 COMMIT 或 ROLLBACK 语句执行后，事务会自动关闭，重新恢复隐式提交。\n通过 set autocommit=0 可以取消自动提交，直到 set autocommit=1 才会提交；autocommit 标记是针对每个连接而不是针对服务器的。\n指令：\nSTART TRANSACTION - 指令用于标记事务的起始点。 SAVEPOINT - 指令用于创建保留点。 ROLLBACK TO - 指令用于回滚到指定的保留点；如果没有设置保留点，则回退到 START TRANSACTION 语句处。 COMMIT - 提交事务。 -- 开始事务 START TRANSACTION; -- 插入操作 A INSERT INTO `user` VALUES (1, \u0026#39;root1\u0026#39;, \u0026#39;root1\u0026#39;, \u0026#39;xxxx@163.com\u0026#39;); -- 创建保留点 updateA SAVEPOINT updateA; -- 插入操作 B INSERT INTO `user` VALUES (2, \u0026#39;root2\u0026#39;, \u0026#39;root2\u0026#39;, \u0026#39;xxxx@163.com\u0026#39;); -- 回滚到保留点 updateA ROLLBACK TO updateA; -- 提交事务，只有操作 A 生效 COMMIT; 接下来，我们来介绍 DCL 语句用法。DCL 的主要功能是控制用户的访问权限。\n1.11 权限控制 # 要授予用户帐户权限，可以用GRANT命令。要撤销用户的权限，可以用REVOKE命令。这里以 MySQL 为例，介绍权限控制实际应用。\nGRANT授予权限语法：\nGRANT privilege,[privilege],.. ON privilege_level TO user [IDENTIFIED BY password] [REQUIRE tsl_option] [WITH [GRANT_OPTION | resource_option]]; 简单解释一下：\n在GRANT关键字后指定一个或多个权限。如果授予用户多个权限，则每个权限由逗号分隔。 ON privilege_level 确定权限应用级别。MySQL 支持 global（*.*），database（database.*），table（database.table）和列级别。如果使用列权限级别，则必须在每个权限之后指定一个或逗号分隔列的列表。 user 是要授予权限的用户。如果用户已存在，则GRANT语句将修改其权限。否则，GRANT语句将创建一个新用户。可选子句IDENTIFIED BY允许您为用户设置新的密码。 REQUIRE tsl_option指定用户是否必须通过 SSL，X059 等安全连接连接到数据库服务器。 可选 WITH GRANT OPTION 子句允许您授予其他用户或从其他用户中删除您拥有的权限。此外，您可以使用WITH子句分配 MySQL 数据库服务器的资源，例如，设置用户每小时可以使用的连接数或语句数。这在 MySQL 共享托管等共享环境中非常有用。 REVOKE 撤销权限语法：\nREVOKE privilege_type [(column_list)] [, priv_type [(column_list)]]... ON [object_type] privilege_level FROM user [, user]... 简单解释一下：\n在 REVOKE 关键字后面指定要从用户撤消的权限列表。您需要用逗号分隔权限。 指定在 ON 子句中撤销特权的特权级别。 指定要撤消 FROM 子句中的权限的用户帐户。 GRANT 和 REVOKE 可在几个层次上控制访问权限：\n整个服务器，使用 GRANT ALL 和 REVOKE ALL； 整个数据库，使用 ON database.*； 特定的表，使用 ON database.table； 特定的列； 特定的存储过程。 新创建的账户没有任何权限。账户用 username@host 的形式定义，username@% 使用的是默认主机名。MySQL 的账户信息保存在 mysql 这个数据库中。\nUSE mysql; SELECT user FROM user; 下表说明了可用于GRANT和REVOKE语句的所有允许权限：\n特权 说明 级别 全局 数据库 表 列 程序 代理 ALL [PRIVILEGES] 授予除 GRANT OPTION 之外的指定访问级别的所有权限 ALTER 允许用户使用 ALTER TABLE 语句 X X X ALTER ROUTINE 允许用户更改或删除存储的例程 X X X CREATE 允许用户创建数据库和表 X X X CREATE ROUTINE 允许用户创建存储的例程 X X CREATE TABLESPACE 允许用户创建，更改或删除表空间和日志文件组 X CREATE TEMPORARY TABLES 允许用户使用 CREATE TEMPORARY TABLE 创建临时表 X X CREATE USER 允许用户使用 CREATE USER，DROP USER，RENAME USER 和 REVOKE ALL PRIVILEGES 语句。 X CREATE VIEW 允许用户创建或修改视图。 X X X DELETE 允许用户使用 DELETE X X X DROP 允许用户删除数据库，表和视图 X X X EVENT 启用事件计划程序的事件使用。 X X EXECUTE 允许用户执行存储的例程 X X X FILE 允许用户读取数据库目录中的任何文件。 X GRANT OPTION 允许用户拥有授予或撤消其他帐户权限的权限。 X X X X X INDEX 允许用户创建或删除索引。 X X X INSERT 允许用户使用 INSERT 语句 X X X X LOCK TABLES 允许用户对具有 SELECT 权限的表使用 LOCK TABLES X X PROCESS 允许用户使用 SHOW PROCESSLIST 语句查看所有进程。 X PROXY 启用用户代理。 REFERENCES 允许用户创建外键 X X X X RELOAD 允许用户使用 FLUSH 操作 X REPLICATION CLIENT 允许用户查询以查看主服务器或从属服务器的位置 X REPLICATION SLAVE 允许用户使用复制从属从主服务器读取二进制日志事件。 X SELECT 允许用户使用 SELECT 语句 X X X X SHOW DATABASES 允许用户显示所有数据库 X SHOW VIEW 允许用户使用 SHOW CREATE VIEW 语句 X X X SHUTDOWN 允许用户使用 mysqladmin shutdown 命令 X SUPER 允许用户使用其他管理操作，例如 CHANGE MASTER TO，KILL，PURGE BINARY LOGS，SET GLOBAL 和 mysqladmin 命令 X TRIGGER 允许用户使用 TRIGGER 操作。 X X X UPDATE 允许用户使用 UPDATE 语句 X X X X USAGE 相当于“没有特权” 1.11.1 创建账户 # CREATE USER myuser IDENTIFIED BY \u0026#39;mypassword\u0026#39;; 1.11.2 修改账户名 # UPDATE user SET user=\u0026#39;newuser\u0026#39; WHERE user=\u0026#39;myuser\u0026#39;; FLUSH PRIVILEGES; 1.11.3 删除账户 # DROP USER myuser; 1.11.4 查看权限 # SHOW GRANTS FOR myuser; 1.11.5 授予权限 # GRANT SELECT, INSERT ON *.* TO myuser; 1.11.6 删除权限 # REVOKE SELECT, INSERT ON *.* FROM myuser; 1.11.7 更改密码 # SET PASSWORD FOR myuser = \u0026#39;mypass\u0026#39;; 1.12 存储过程 # 存储过程可以看成是对一系列 SQL 操作的批处理。存储过程可以由触发器，其他存储过程以及 Java， Python，PHP 等应用程序调用。\n使用存储过程的好处：\n代码封装，保证了一定的安全性； 代码复用； 由于是预先编译，因此具有很高的性能。 创建存储过程：\n命令行中创建存储过程需要自定义分隔符，因为命令行是以 ; 为结束符，而存储过程中也包含了分号，因此会错误把这部分分号当成是结束符，造成语法错误。 包含 in、out 和 inout 三种参数。 给变量赋值都需要用 select into 语句。 每次只能给一个变量赋值，不支持集合的操作。 需要注意的是：阿里巴巴《Java 开发手册》强制禁止使用存储过程。因为存储过程难以调试和扩展，更没有移植性。\n至于到底要不要在项目中使用，还是要看项目实际需求，权衡好利弊即可！\n1.12.1 创建存储过程 # DROP PROCEDURE IF EXISTS `proc_adder`; DELIMITER ;; CREATE DEFINER=`root`@`localhost` PROCEDURE `proc_adder`(IN a int, IN b int, OUT sum int) BEGIN DECLARE c int; if a is null then set a = 0; end if; if b is null then set b = 0; end if; set sum = a + b; END ;; DELIMITER ; 1.12.2 使用存储过程 # set @b=5; call proc_adder(2,@b,@s); select @s as sum; 1.13 游标 # 游标（cursor）是一个存储在 DBMS 服务器上的数据库查询，它不是一条 SELECT 语句，而是被该语句检索出来的结果集。\n在存储过程中使用游标可以对一个结果集进行移动遍历。\n游标主要用于交互式应用，其中用户需要滚动屏幕上的数据，并对数据进行浏览或做出更改。\n使用游标的几个明确步骤：\n在使用游标前，必须声明(定义)它。这个过程实际上没有检索数据， 它只是定义要使用的 SELECT 语句和游标选项。\n一旦声明，就必须打开游标以供使用。这个过程用前面定义的 SELECT 语句把数据实际检索出来。\n对于填有数据的游标，根据需要取出(检索)各行。\n在结束游标使用时，必须关闭游标，可能的话，释放游标(有赖于具\n体的 DBMS)。\nDELIMITER $ CREATE PROCEDURE getTotal() BEGIN DECLARE total INT; -- 创建接收游标数据的变量 DECLARE sid INT; DECLARE sname VARCHAR(10); -- 创建总数变量 DECLARE sage INT; -- 创建结束标志变量 DECLARE done INT DEFAULT false; -- 创建游标 DECLARE cur CURSOR FOR SELECT id,name,age from cursor_table where age\u0026gt;30; -- 指定游标循环结束时的返回值 DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = true; SET total = 0; OPEN cur; FETCH cur INTO sid, sname, sage; WHILE(NOT done) DO SET total = total + 1; FETCH cur INTO sid, sname, sage; END WHILE; CLOSE cur; SELECT total; END $ DELIMITER ; -- 调用存储过程 call getTotal(); 1.14 触发器 # 触发器是一种与表操作有关的数据库对象，当触发器所在表上出现指定事件时，将调用该对象，即表的操作事件触发表上的触发器的执行。\n我们可以使用触发器来进行审计跟踪，把修改记录到另外一张表中。\n使用触发器的优点：\nSQL 触发器提供了另一种检查数据完整性的方法。 SQL 触发器可以捕获数据库层中业务逻辑中的错误。 SQL 触发器提供了另一种运行计划任务的方法。通过使用 SQL 触发器，您不必等待运行计划任务，因为在对表中的数据进行更改之前或之后会自动调用触发器。 SQL 触发器对于审计表中数据的更改非常有用。 使用触发器的缺点：\nSQL 触发器只能提供扩展验证，并且不能替换所有验证。必须在应用程序层中完成一些简单的验证。例如，您可以使用 JavaScript 在客户端验证用户的输入，或者使用服务器端脚本语言（如 JSP，PHP，ASP.NET，Perl）在服务器端验证用户的输入。 从客户端应用程序调用和执行 SQL 触发器是不可见的，因此很难弄清楚数据库层中发生了什么。 SQL 触发器可能会增加数据库服务器的开销。 MySQL 不允许在触发器中使用 CALL 语句 ，也就是不能调用存储过程。\n注意：在 MySQL 中，分号 ; 是语句结束的标识符，遇到分号表示该段语句已经结束，MySQL 可以开始执行了。因此，解释器遇到触发器执行动作中的分号后就开始执行，然后会报错，因为没有找到和 BEGIN 匹配的 END。\n这时就会用到 DELIMITER 命令（DELIMITER 是定界符，分隔符的意思）。它是一条命令，不需要语句结束标识，语法为：DELIMITER new_delimiter。new_delimiter 可以设为 1 个或多个长度的符号，默认的是分号 ;，我们可以把它修改为其他符号，如 $ - DELIMITER $ 。在这之后的语句，以分号结束，解释器不会有什么反应，只有遇到了 $，才认为是语句结束。注意，使用完之后，我们还应该记得把它给修改回来。\n在 MySQL 5.7.2 版之前，可以为每个表定义最多六个触发器。\nBEFORE INSERT - 在将数据插入表格之前激活。 AFTER INSERT - 将数据插入表格后激活。 BEFORE UPDATE - 在更新表中的数据之前激活。 AFTER UPDATE - 更新表中的数据后激活。 BEFORE DELETE - 在从表中删除数据之前激活。 AFTER DELETE - 从表中删除数据后激活。 但是，从 MySQL 版本 5.7.2+开始，可以为同一触发事件和操作时间定义多个触发器。\nNEW 和 OLD：\nMySQL 中定义了 NEW 和 OLD 关键字，用来表示触发器的所在表中，触发了触发器的那一行数据。 在 INSERT 型触发器中，NEW 用来表示将要（BEFORE）或已经（AFTER）插入的新数据； 在 UPDATE 型触发器中，OLD 用来表示将要或已经被修改的原数据，NEW 用来表示将要或已经修改为的新数据； 在 DELETE 型触发器中，OLD 用来表示将要或已经被删除的原数据； 使用方法：NEW.columnName （columnName 为相应数据表某一列名） 1.14.1 创建触发器 # 提示：为了理解触发器的要点，有必要先了解一下创建触发器的指令。\nCREATE TRIGGER 指令用于创建触发器。\n语法：\nCREATE TRIGGER trigger_name trigger_time trigger_event ON table_name FOR EACH ROW BEGIN trigger_statements END; 说明：\ntrigger_name：触发器名 trigger_time : 触发器的触发时机。取值为 BEFORE 或 AFTER。 trigger_event : 触发器的监听事件。取值为 INSERT、UPDATE 或 DELETE。 table_name : 触发器的监听目标。指定在哪张表上建立触发器。 FOR EACH ROW: 行级监视，Mysql 固定写法，其他 DBMS 不同。 trigger_statements: 触发器执行动作。是一条或多条 SQL 语句的列表，列表内的每条语句都必须用分号 ; 来结尾。 当触发器的触发条件满足时，将会执行 BEGIN 和 END 之间的触发器执行动作。\n示例：\nDELIMITER $ CREATE TRIGGER `trigger_insert_user` AFTER INSERT ON `user` FOR EACH ROW BEGIN INSERT INTO `user_history`(user_id, operate_type, operate_time) VALUES (NEW.id, \u0026#39;add a user\u0026#39;, now()); END $ DELIMITER ; 1.14.2 查看触发器 # SHOW TRIGGERS; 1.14.3 删除触发器 # DROP TRIGGER IF EXISTS trigger_insert_user; ","date":"22 March 2025","externalUrl":null,"permalink":"/posts/1742632552154-sql%E8%AF%AD%E6%B3%95%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/","section":"Posts","summary":"","title":"SQL语法基础知识总结","type":"posts"},{"content":"","date":"18 March 2025","externalUrl":null,"permalink":"/tags/java/","section":"Tags","summary":"","title":"Java","type":"tags"},{"content":"an example to get you started\nAQS # 1.1 AQS # **AQS（AbstractQueuedSynchronizer）是Java并发编程中的一个重要组件，它是一个抽象类，提供了线程同步的底层实现机制。**AQS的作用是实现线程的同步和互斥操作，它提供了两种主要的锁机制，分别是排他锁和共享锁。 排他锁也称为独占锁，在多个线程竞争同一共享资源时，同一时刻只允许一个线程访问该共享资源，即多个线程中只有一个线程获得锁资源。在AQS中，排他锁是通过内置的同步状态来实现的。当同步状态为0时，表示锁是未被获取的；当同步状态大于0时，表示锁已经被获取且被占用；当同步状态小于0时，表示锁已经被获取但是处于等待状态。 **共享锁允许多个线程同时获得锁资源，但是在同一时刻只有一个线程可以获取到锁的拥有权，其他线程需要等待该线程释放锁。**在AQS中，共享锁的实现与排他锁类似，也是通过内置的同步状态来实现的。 AQS通过一个内置的FIFO（先进先出）等待队列来实现线程的排队和调度。当线程需要获取锁资源时，如果锁已经被其他线程获取，则该线程会被加入到等待队列中等待。当锁被释放时，等待队列中的第一个线程会获得锁资源并继续执行。 在实现AQS时，需要继承自AQS类并实现其抽象方法。其中比较重要的方法包括：tryAcquire()和tryRelease()方法，用于实现锁的获取和释放；acquire()和release()方法，用于实现阻塞和唤醒操作；isHeldExclusively()方法，用于判断是否是排他锁。 总之，AQS是Java并发编程中的重要组件之一，它提供了线程同步的底层实现机制。在使用AQS时，需要根据具体的应用场景选择合适的锁机制来实现线程的同步和互斥操作。\nAQS 的全称为 AbstractQueuedSynchronizer ，翻译过来的意思就是抽象队列同步器。这个类在 java.util.concurrent.locks 包下面。\nAQS 就是一个抽象类，主要用来构建锁和同步器。\npublic abstract class AbstractQueuedSynchronizer extends AbstractOwnableSynchronizer implements java.io.Serializable { } AQS 为构建锁和同步器提供了一些通用功能的实现，因此，使用 AQS 能简单且高效地构造出应用广泛的大量的同步器，比如我们提到的 ReentrantLock，Semaphore，其他的诸如 ReentrantReadWriteLock，SynchronousQueue等等皆是基于 AQS 的。\n1.2 AQS的原理 # AQS 核心思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制 AQS 是用 CLH 队列锁 实现的，即将暂时获取不到锁的线程加入到队列中。\n**CLH(Craig,Landin,and Hagersten) 队列是一个虚拟的双向队列（虚拟的双向队列即不存在队列实例，仅存在结点之间的关联关系）。**AQS 是将每条请求共享资源的线程封装成一个 CLH 锁队列的一个结点（Node）来实现锁的分配。在 CLH 同步队列中，一个节点表示一个线程，它保存着线程的引用（thread）、 当前节点在队列中的状态（waitStatus）、前驱节点（prev）、后继节点（next）。\nCLH 队列结构如下图所示：\nAQS(AbstractQueuedSynchronizer)的核心原理图（图源Java 并发之 AQS 详解）如下：\nAQS 使用 int 成员变量 state 表示同步状态，通过内置的 线程等待队列 来完成获取资源线程的排队工作。\nstate 变量由 volatile 修饰，用于展示当前临界资源的获锁情况。\n// 共享变量，使用volatile修饰保证线程可见性 private volatile int state; 另外，状态信息 state 可以通过 protected 类型的getState()、setState()和compareAndSetState() 进行操作。并且，这几个方法都是 final 修饰的，在子类中无法被重写。\n//返回同步状态的当前值 protected final int getState() { return state; } // 设置同步状态的值 protected final void setState(int newState) { state = newState; } //原子地（CAS操作）将同步状态值设置为给定值update如果当前同步状态的值等于expect（期望值） protected final boolean compareAndSetState(int expect, int update) { return unsafe.compareAndSwapInt(this, stateOffset, expect, update); } 以 ReentrantLock 为例，state 初始值为 0，表示未锁定状态。A 线程 lock() 时，会调用 tryAcquire() 独占该锁并将 state+1 。此后，其他线程再 tryAcquire() 时就会失败，直到 A 线程 unlock() 到 state=0（即释放锁）为止，其它线程才有机会获取该锁。当然，释放锁之前，A 线程自己是可以重复获取此锁的（state 会累加），这就是可重入的概念。但要注意，获取多少次就要释放多少次，这样才能保证 state 是能回到零态的。\n再以 CountDownLatch 以例，任务分为 N 个子线程去执行，state 也初始化为 N（注意 N 要与线程个数一致）。这 N 个子线程是并行执行的，每个子线程执行完后countDown() 一次，state 会 CAS(Compare and Swap) 减 1。等到所有子线程都执行完后(即 state=0 )，会 unpark() 主调用线程，然后主调用线程就会从 await() 函数返回，继续后余动作。\n1.3 Semaphore # synchronized 和 ReentrantLock 都是一次只允许一个线程访问某个资源，而Semaphore(信号量)可以用来控制同时访问特定资源的线程数量。\nSemaphore 的使用简单，我们这里假设有 N(N\u0026gt;5) 个线程来获取 Semaphore 中的共享资源，下面的代码表示同一时刻 N 个线程中只有 5 个线程能获取到共享资源，其他线程都会阻塞，只有获取到共享资源的线程才能执行。等到有线程释放了共享资源，其他阻塞的线程才能获取到。\n// 初始共享资源数量 final Semaphore semaphore = new Semaphore(5); // 获取1个许可 semaphore.acquire(); // 释放1个许可 semaphore.release(); 当初始的资源个数为 1 的时候，Semaphore 退化为排他锁。\nSemaphore 有两种模式：。\n公平模式： 调用 acquire() 方法的顺序就是获取许可证的顺序，遵循 FIFO； 非公平模式： 抢占式的。 Semaphore 对应的两个构造方法如下：\npublic Semaphore(int permits) { sync = new NonfairSync(permits); } public Semaphore(int permits, boolean fair) { sync = fair ? new FairSync(permits) : new NonfairSync(permits); } 这两个构造方法，都必须提供许可的数量，第二个构造方法可以指定是公平模式还是非公平模式，默认非公平模式。\nSemaphore 通常用于那些资源有明确访问数量限制的场景比如限流（仅限于单机模式，实际项目中推荐使用 Redis +Lua 来做限流）。\n1.4 Semaphore的原理 # Semaphore 是共享锁的一种实现，它默认构造 AQS 的 state 值为 permits，你可以将 permits 的值理解为许可证的数量，只有拿到许可证的线程才能执行。\n调用semaphore.acquire() ，线程尝试获取许可证，如果 state \u0026gt;= 0 的话，则表示可以获取成功。如果获取成功的话，使用 CAS 操作去修改 state 的值 state=state-1。如果 state\u0026lt;0 的话，则表示许可证数量不足。此时会创建一个 Node 节点加入阻塞队列，挂起当前线程。\n/** * 获取1个许可证 */ public void acquire() throws InterruptedException { sync.acquireSharedInterruptibly(1); } /** * 共享模式下获取许可证，获取成功则返回，失败则加入阻塞队列，挂起线程 */ public final void acquireSharedInterruptibly(int arg) throws InterruptedException { if (Thread.interrupted()) throw new InterruptedException(); // 尝试获取许可证，arg为获取许可证个数，当可用许可证数减当前获取的许可证数结果小于0,则创建一个节点加入阻塞队列，挂起当前线程。 if (tryAcquireShared(arg) \u0026lt; 0) doAcquireSharedInterruptibly(arg); } 调用semaphore.release(); ，线程尝试释放许可证，并使用 CAS 操作去修改 state 的值 state=state+1。释放许可证成功之后，同时会唤醒同步队列中的一个线程。被唤醒的线程会重新尝试去修改 state 的值 state=state-1 ，如果 state\u0026gt;=0 则获取令牌成功，否则重新进入阻塞队列，挂起线程。\n// 释放一个许可证 public void release() { sync.releaseShared(1); } // 释放共享锁，同时会唤醒同步队列中的一个线程。 public final boolean releaseShared(int arg) { //释放共享锁 if (tryReleaseShared(arg)) { //唤醒同步队列中的一个线程 doReleaseShared(); return true; } return false; } 1.5 CountDownLatch # CountDownLatch是Java中用于多线程协作的辅助类，它可以让一个或多个线程等待其他线程完成某个任务后再继续执行。 CountDownLatch通过一个计数器来实现，计数器的初始值可以设置为等待的线程数量。每个线程在完成任务后都会调用countDown()方法来减少计数器的值。当计数器的值减至0时，等待在CountDownLatch上的线程就会被唤醒，可以继续执行后续的操作。 CountDownLatch的主要作用是协调多个线程的执行顺序，使得某个线程（或多个线程）必须等待其他线程完成后才能继续执行。它常用于以下场景：\n主线程等待多个子线程完成任务：主线程可以使用await()方法等待所有子线程完成，然后进行结果的汇总或其他操作。 多个线程等待外部事件的发生：多个线程可以同时等待某个共同的事件发生，比如等待某个资源准备就绪或者等待某个信号的触发。 控制并发任务的同时开始：在某些并发场景中，需要等待所有线程都准备就绪后才能同时开始执行任务，CountDownLatch提供了一种便捷的方式来实现这一需求。 需要注意的是，CountDownLatch的计数器是不能被重置的，也就是说它是一次性的。一旦计数器减至0，它将无法再次使用。如果需要多次使用可重置的计数器，则可以考虑使用CyclicBarrier。\nCountDownLatch 允许 count 个线程阻塞在一个地方，直至所有线程的任务都执行完毕。\nCountDownLatch 是一次性的，计数器的值只能在构造方法中初始化一次，之后没有任何机制再次对其设置值，当 CountDownLatch 使用完毕后，它不能再次被使用。\nCountDownLatch 的作用就是 允许 count 个线程阻塞在一个地方，直至所有线程的任务都执行完毕。\n1.6 CountDownLatch的原理 # CountDownLatch 是共享锁的一种实现,它默认构造 AQS 的 state 值为 count。当线程使用 countDown() 方法时,其实使用了tryReleaseShared方法以 CAS 的操作来减少 state,直至 state 为 0 。当调用 await() 方法的时候，如果 state 不为 0，那就证明任务还没有执行完毕，await() 方法就会一直阻塞，也就是说 await() 方法之后的语句不会被执行。直到count 个线程调用了countDown()使 state 值被减为 0，或者调用await()的线程被中断，该线程才会从阻塞中被唤醒，await() 方法之后的语句得到执行。\n1.7 CyclicBarrier # CyclicBarrier是Java中的一个多线程协作工具，它可以让多个线程在一个屏障点等待，并在所有线程都到达后一起继续执行。与CountDownLatch不同，CyclicBarrier可以重复使用，并且可以指定屏障点后执行的额外动作。\nCyclicBarrier的主要特点有三个。\n它可以重复使用，这意味着当所有线程都到达屏障点后，屏障会自动重置，可以用来处理多次需要等待的任务。 CyclicBarrier可以协调多个线程同时开始执行，这在分阶段任务和并发游戏等场景中非常有用。 CyclicBarrier提供了可选的动作，在所有线程到达屏障点时执行，可以实现额外的逻辑。 需要注意的是，在创建CyclicBarrier时需要指定参与线程的数量。一旦所有参与线程都到达屏障点后，CyclicBarrier解除阻塞，所有线程可以继续执行后续操作。\nCyclicBarrier 和 CountDownLatch 非常类似，它也可以实现线程间的技术等待，但是它的功能比 CountDownLatch 更加复杂和强大。主要应用场景和 CountDownLatch 类似。\nCountDownLatch 的实现是基于 AQS 的，而 CycliBarrier 是基于 ReentrantLock(ReentrantLock 也属于 AQS 同步器)和 Condition 的。\nCyclicBarrier 的字面意思是可循环使用（Cyclic）的屏障（Barrier）。它要做的事情是：让一组线程到达一个屏障（也可以叫同步点）时被阻塞，直到最后一个线程到达屏障时，屏障才会开门，所有被屏障拦截的线程才会继续干活。\n1.8 CyclicBarrier的原理 # CyclicBarrier 内部通过一个 count 变量作为计数器，count 的初始值为 parties 属性的初始化值，每当一个线程到了栅栏这里了，那么就将计数器减 1。如果 count 值为 0 了，表示这是这一代最后一个线程到达栅栏，就尝试执行我们构造方法中输入的任务。\n//每次拦截的线程数 private final int parties; //计数器 private int count; 下面我们结合源码来简单看看。\n1、CyclicBarrier 默认的构造方法是 CyclicBarrier(int parties)，其参数表示屏障拦截的线程数量，每个线程调用 await() 方法告诉 CyclicBarrier 我已经到达了屏障，然后当前线程被阻塞。\npublic CyclicBarrier(int parties) { this(parties, null); } public CyclicBarrier(int parties, Runnable barrierAction) { if (parties \u0026lt;= 0) throw new IllegalArgumentException(); this.parties = parties; this.count = parties; this.barrierCommand = barrierAction; } 其中，parties 就代表了有拦截的线程的数量，当拦截的线程数量达到这个值的时候就打开栅栏，让所有线程通过。\n2、当调用 CyclicBarrier 对象调用 await() 方法时，实际上调用的是 dowait(false, 0L)方法。 await() 方法就像树立起一个栅栏的行为一样，将线程挡住了，当拦住的线程数量达到 parties 的值时，栅栏才会打开，线程才得以通过执行。\npublic int await() throws InterruptedException, BrokenBarrierException { try { return dowait(false, 0L); } catch (TimeoutException toe) { throw new Error(toe); // cannot happen } } dowait(false, 0L)方法源码分析如下：\n// 当线程数量或者请求数量达到 count 时 await 之后的方法才会被执行。上面的示例中 count 的值就为 5。 private int count; /** * Main barrier code, covering the various policies. */ private int dowait(boolean timed, long nanos) throws InterruptedException, BrokenBarrierException, TimeoutException { final ReentrantLock lock = this.lock; // 锁住 lock.lock(); try { final Generation g = generation; if (g.broken) throw new BrokenBarrierException(); // 如果线程中断了，抛出异常 if (Thread.interrupted()) { breakBarrier(); throw new InterruptedException(); } // cout减1 int index = --count; // 当 count 数量减为 0 之后说明最后一个线程已经到达栅栏了，也就是达到了可以执行await 方法之后的条件 if (index == 0) { // tripped boolean ranAction = false; try { final Runnable command = barrierCommand; if (command != null) command.run(); ranAction = true; // 将 count 重置为 parties 属性的初始化值 // 唤醒之前等待的线程 // 下一波执行开始 nextGeneration(); return 0; } finally { if (!ranAction) breakBarrier(); } } // loop until tripped, broken, interrupted, or timed out for (;;) { try { if (!timed) trip.await(); else if (nanos \u0026gt; 0L) nanos = trip.awaitNanos(nanos); } catch (InterruptedException ie) { if (g == generation \u0026amp;\u0026amp; ! g.broken) { breakBarrier(); throw ie; } else { // We\u0026#39;re about to finish waiting even if we had not // been interrupted, so this interrupt is deemed to // \u0026#34;belong\u0026#34; to subsequent execution. Thread.currentThread().interrupt(); } } if (g.broken) throw new BrokenBarrierException(); if (g != generation) return index; if (timed \u0026amp;\u0026amp; nanos \u0026lt;= 0L) { breakBarrier(); throw new TimeoutException(); } } } finally { lock.unlock(); } } 父子线程共享传递数据 # 在Java中，父线程和子线程之间共享或传递数据可以通过多种方式实现，具体可以根据需求选择以下几种常用的方法：\n使用ThreadLocal ThreadLocal是一种特殊的Java对象，它为每个线程提供了独立的变量副本。通过ThreadLocal可以实现线程范围内的变量隔离，但不直接用于父子线程数据共享。不过，父线程可以在线程启动之前将数据放到ThreadLocal，子线程可以读取到这些数据。\npublic class ThreadLocalExample { // 创建一个ThreadLocal对象 private static final ThreadLocal\u0026lt;String\u0026gt; threadLocal = ThreadLocal.withInitial(() -\u0026gt; \u0026#34;Initial Value\u0026#34;); public static void main(String[] args) { // 设置ThreadLocal的值 threadLocal.set(\u0026#34;Shared Data\u0026#34;); // 子线程 Thread childThread = new Thread(() -\u0026gt; { System.out.println(\u0026#34;Child Thread: \u0026#34; + threadLocal.get()); }); // 启动子线程 childThread.start(); } } 使用 Concurrent Collections Java提供了一些线程安全的集合类，如ConcurrentHashMap、CopyOnWriteArrayList等，可以安全并发地访问和修改，适用于需要较多线程共享数据的场景。\nimport java.util.concurrent.ConcurrentHashMap; import java.util.Map; public class ConcurrentCollectionExample { public static void main(String[] args) { Map\u0026lt;String, String\u0026gt; sharedMap = new ConcurrentHashMap\u0026lt;\u0026gt;(); sharedMap.put(\u0026#34;key\u0026#34;, \u0026#34;value from parent\u0026#34;); // 子线程 Thread childThread = new Thread(() -\u0026gt; { // 等待父线程设置完值 while (!sharedMap.containsKey(\u0026#34;key\u0026#34;)) { // active waiting } System.out.println(\u0026#34;Child read from map: \u0026#34; + sharedMap.get(\u0026#34;key\u0026#34;)); }); childThread.start(); } } 使用消息队列 在复杂的多线程环境下，使用Java的阻塞队列（如BlockingQueue）可以在父子线程之间传递数据，并控制线程的执行顺序。\nimport java.util.concurrent.ArrayBlockingQueue; import java.util.concurrent.BlockingQueue; public class BlockingQueueExample { public static void main(String[] args) { BlockingQueue\u0026lt;Integer\u0026gt; queue = new ArrayBlockingQueue\u0026lt;\u0026gt;(5); for (int i = 0; i \u0026lt; 5; i++) { queue.put(i); System.out.println(\u0026#34;Parent put: \u0026#34; + i); } // 子线程 Thread childThread = new Thread(() -\u0026gt; { try { for (int i = 0; i \u0026lt; 5; i++) { Integer value = queue.take(); System.out.println(\u0026#34;Child take: \u0026#34; + value); } } catch (InterruptedException e) { Thread.currentThread().interrupt(); } }); childThread.start(); } } 2.1 生产者消费者 # 概述\n生产者消费者模式是一个十分经典的多线程协作的模式，弄懂生产者消费者问题能够让我们对多线程编程的理解更加深刻。\n所谓生产者消费者问题，实际上主要是包含了两类线程：\n​\t一类是生产者线程用于生产数据\n​\t一类是消费者线程用于消费数据\n为了解耦生产者和消费者的关系，通常会采用共享的数据区域，就像是一个仓库\n生产者生产数据之后直接放置在共享数据区中，并不需要关心消费者的行为\n消费者只需要从共享数据区中去获取数据，并不需要关心生产者的行为\nObject类的等待和唤醒方法\n方法名 说明 void wait() 导致当前线程等待，直到另一个线程调用该对象的 notify()方法或 notifyAll()方法 void notify() 唤醒正在等待对象监视器的单个线程 void notifyAll() 唤醒正在等待对象监视器的所有线程 阻塞队列基本使用：\n阻塞队列继承结构 常见BlockingQueue:\nArrayBlockingQueue: 底层是数组,有界\nLinkedBlockingQueue: 底层是链表,无界.但不是真正的无界,最大为int的最大值\nBlockingQueue的核心方法:\nput(anObject): 将参数放入队列,如果放不进去会阻塞\ntake(): 取出第一个数据,取不到会阻塞\n","date":"18 March 2025","externalUrl":null,"permalink":"/posts/1742270631218-java-aqs/","section":"Posts","summary":"","title":"java AQS","type":"posts"},{"content":" ThreadLocal # ThreadLocal是Java中的一个类，用于在多线程环境下实现线程局部变量存储。它提供了一种让每个线程都拥有独立变量副本的机制，从而避免了多线程之间相互干扰和竞争的问题。 在多线程编程中，共享变量的访问往往需要考虑线程安全性和数据隔离问题。ThreadLocal通过为每个线程创建独立的变量副本来解决这些问题。每个线程可以独立地对自己的变量副本进行操作，而不会影响其他线程的副本。 ThreadLocal的核心思想是以\u0026quot;线程\u0026quot;为作用域，在每个线程内部维护一个变量副本。它使用Thread对象作为Key，在内部的数据结构中查找对应的变量副本。当通过ThreadLocal的get()方法获取变量时，实际上是根据当前线程获取其对应的变量副本；当通过set()方法设置变量时，实际上是将该值与当前线程关联，并存储在内部的数据结构中。 使用ThreadLocal时需要注意以下几点：\n内存泄漏：在使用完ThreadLocal后，应及时调用remove()方法清理与当前线程相关的变量副本，避免长时间持有引用导致内存泄漏。 线程安全性：ThreadLocal本身并不解决多线程并发访问共享变量的问题，需要额外的同步机制来保证线程安全性。 数据隔离：ThreadLocal适用于多线程环境下需要保持变量独立性的场景，可以避免使用传统的同步方式对共享变量进行操作，提高并发性能。 ThreadLocal常见的应用场景包括线程池、Web开发中的请求上下文信息管理、数据库连接管理和日志记录等。通过合理使用ThreadLocal，可以简化多线程编程，并提高程序的性能和可维护性。\nThreadLocal是Java中所提供的线程本地存储机制，可以利用该机制将数据缓存在某个线程内部，该线程可以在任意时刻、任意方法中获取缓存的数据 ThreadLocal底层是通过ThreadLocalMap来实现的，每个Thread对象（注意不是ThreadLocal对象）中都存在一个ThreadLocalMap，Map的key为ThreadLocal对象，Map的value为需要缓存的值 如果在线程池中使用ThreadLocal会造成内存泄漏，因为当ThreadLocal对象使用完之后，应该要把设置的key，value，也就是Entry对象进行回收，但线程池中的线程不会回收，而线程对象是通过强引用指向ThreadLocalMap，ThreadLocalMap也是通过强引用指向Entry对象，线程不被回收，Entry对象也就不会被回收，从而出现内存泄漏，解决办法是，在使用了ThreadLocal对象之后，手动调用ThreadLocal的remove方法，手动清楚Entry对象 ThreadLocal经典的应用场景就是连接管理（一个线程持有一个连接，该连接对象可以在不同的方法之间进行传递，线程之间不共享同一个连接） 1.1 ThreadLocal有什么用？ # 通常情况下，我们创建的变量是可以被任何一个线程访问并修改的。如果想实现每一个线程都有自己的专属本地变量该如何解决呢？\nJDK 中自带的ThreadLocal类正是为了解决这样的问题。 **ThreadLocal类主要解决的就是让每个线程绑定自己的值，可以将ThreadLocal类形象的比喻成存放数据的盒子，盒子中可以存储每个线程的私有数据。\n如果你创建了一个ThreadLocal变量，那么访问这个变量的每个线程都会有这个变量的本地副本，这也是ThreadLocal变量名的由来。他们可以使用 get() 和 set() 方法来获取默认值或将其值更改为当前线程所存的副本的值，从而避免了线程安全问题。\n再举个简单的例子：两个人去宝屋收集宝物，这两个共用一个袋子的话肯定会产生争执，但是给他们两个人每个人分配一个袋子的话就不会出现这样的问题。如果把这两个人比作线程的话，那么 ThreadLocal 就是用来避免这两个线程竞争的。\n用户会话管理：在Web应用中，可以用来存储每个用户的会话信息。 数据库连接管理：为每个线程提供独立的数据库连接，避免多线程竞争同一个连接。 线程上下文信息：存储线程的环境信息，比如请求ID、用户认证信息等。 1.2 如何使用ThreadLocal？ # 相信看了上面的解释，大家已经搞懂 ThreadLocal 类是个什么东西了。下面简单演示一下如何在项目中实际使用 ThreadLocal 。\nimport java.text.SimpleDateFormat; import java.util.Random; public class ThreadLocalExample implements Runnable{ // SimpleDateFormat 不是线程安全的，所以每个线程都要有自己独立的副本 private static final ThreadLocal\u0026lt;SimpleDateFormat\u0026gt; formatter = ThreadLocal.withInitial(() -\u0026gt; new SimpleDateFormat(\u0026#34;yyyyMMdd HHmm\u0026#34;)); public static void main(String[] args) throws InterruptedException { ThreadLocalExample obj = new ThreadLocalExample(); for(int i=0 ; i\u0026lt;10; i++){ Thread t = new Thread(obj, \u0026#34;\u0026#34;+i); Thread.sleep(new Random().nextInt(1000)); t.start(); } } @Override public void run() { System.out.println(\u0026#34;Thread Name= \u0026#34;+Thread.currentThread().getName()+\u0026#34; default Formatter = \u0026#34;+formatter.get().toPattern()); try { Thread.sleep(new Random().nextInt(1000)); } catch (InterruptedException e) { e.printStackTrace(); } //formatter pattern is changed here by thread, but it won\u0026#39;t reflect to other threads formatter.set(new SimpleDateFormat()); System.out.println(\u0026#34;Thread Name= \u0026#34;+Thread.currentThread().getName()+\u0026#34; formatter = \u0026#34;+formatter.get().toPattern()); } } 输出结果 :\nThread Name= 0 default Formatter = yyyyMMdd HHmm Thread Name= 0 formatter = yy-M-d ah:mm Thread Name= 1 default Formatter = yyyyMMdd HHmm Thread Name= 2 default Formatter = yyyyMMdd HHmm Thread Name= 1 formatter = yy-M-d ah:mm Thread Name= 3 default Formatter = yyyyMMdd HHmm Thread Name= 2 formatter = yy-M-d ah:mm Thread Name= 4 default Formatter = yyyyMMdd HHmm Thread Name= 3 formatter = yy-M-d ah:mm Thread Name= 4 formatter = yy-M-d ah:mm Thread Name= 5 default Formatter = yyyyMMdd HHmm Thread Name= 5 formatter = yy-M-d ah:mm Thread Name= 6 default Formatter = yyyyMMdd HHmm Thread Name= 6 formatter = yy-M-d ah:mm Thread Name= 7 default Formatter = yyyyMMdd HHmm Thread Name= 7 formatter = yy-M-d ah:mm Thread Name= 8 default Formatter = yyyyMMdd HHmm Thread Name= 9 default Formatter = yyyyMMdd HHmm Thread Name= 8 formatter = yy-M-d ah:mm Thread Name= 9 formatter = yy-M-d ah:mm 从输出中可以看出，虽然 Thread-0 已经改变了 formatter 的值，但 Thread-1 默认格式化值与初始化值相同，其他线程也一样。\n上面用于创建 ThreadLocal 变量的那段代码用到了 Java8 的知识，它等于下面这段代码，如果你写了下面这段代码的话，IDEA 会提示你转换为 Java8 的格式(IDEA 真的不错！)。因为 ThreadLocal 类在 Java 8 中扩展，使用一个新的方法withInitial()，将 Supplier 功能接口作为参数。\nprivate static final ThreadLocal\u0026lt;SimpleDateFormat\u0026gt; formatter = new ThreadLocal\u0026lt;SimpleDateFormat\u0026gt;(){ @Override protected SimpleDateFormat initialValue(){ return new SimpleDateFormat(\u0026#34;yyyyMMdd HHmm\u0026#34;); } }; 1.3 ThreadLocal 原理 # 从 Thread类源代码入手。\npublic class Thread implements Runnable { //...... //与此线程有关的ThreadLocal值。由ThreadLocal类维护 ThreadLocal.ThreadLocalMap threadLocals = null; //与此线程有关的InheritableThreadLocal值。由InheritableThreadLocal类维护 ThreadLocal.ThreadLocalMap inheritableThreadLocals = null; //...... } 从上面Thread类 源代码可以看出Thread 类中有一个 threadLocals 和 一个 inheritableThreadLocals 变量，它们都是 ThreadLocalMap 类型的变量,我们可以把 ThreadLocalMap 理解为ThreadLocal 类实现的定制化的 HashMap。默认情况下这两个变量都是 null，只有当前线程调用 ThreadLocal 类的 set或get方法时才创建它们，实际上调用这两个方法的时候，我们调用的是ThreadLocalMap类对应的 get()、set()方法。\nThreadLocal类的set()方法:\npublic void set(T value) { //获取当前请求的线程 Thread t = Thread.currentThread(); //取出 Thread 类内部的 threadLocals 变量(哈希表结构) ThreadLocalMap map = getMap(t); if (map != null) // 将需要存储的值放入到这个哈希表中 map.set(this, value); else createMap(t, value); } ThreadLocalMap getMap(Thread t) { return t.threadLocals; } 通过上面这些内容，我们足以通过猜测得出结论：最终的变量是放在了当前线程的 ThreadLocalMap 中，并不是存在 ThreadLocal 上，ThreadLocal 可以理解为只是ThreadLocalMap的封装，传递了变量值。 ThrealLocal 类中可以通过Thread.currentThread()获取到当前线程对象后，直接通过getMap(Thread t)可以访问到该线程的ThreadLocalMap对象。\n每个Thread中都具备一个ThreadLocalMap，而ThreadLocalMap可以存储以ThreadLocal为 key ，Object 对象为 value 的键值对。\nThreadLocalMap(ThreadLocal\u0026lt;?\u0026gt; firstKey, Object firstValue) { //...... } 比如我们在同一个线程中声明了两个 ThreadLocal 对象的话， Thread内部都是使用仅有的那个ThreadLocalMap 存放数据的，ThreadLocalMap的 key 就是 ThreadLocal对象，value 就是 ThreadLocal 对象调用set方法设置的值。\nThreadLocal 数据结构如下图所示：\nThreadLocalMap是ThreadLocal的静态内部类。\n1.4 ThreadLocal内存泄露问题 # ThreadLocalMap 中使用的 key 为 ThreadLocal 的弱引用，而 value 是强引用。所以，如果 ThreadLocal 没有被外部强引用的情况下，在垃圾回收的时候，key 会被清理掉，而 value 不会被清理掉。\n这样一来，ThreadLocalMap 中就会出现 key 为 null 的 Entry。假如我们不做任何措施的话，value 永远无法被 GC 回收，这个时候就可能会产生内存泄露。ThreadLocalMap 实现中已经考虑了这种情况，在调用 set()、get()、remove() 方法的时候，会清理掉 key 为 null 的记录。使用完 ThreadLocal方法后最好手动调用remove()方法\nstatic class Entry extends WeakReference\u0026lt;ThreadLocal\u0026lt;?\u0026gt;\u0026gt; { /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal\u0026lt;?\u0026gt; k, Object v) { super(k); value = v; } } 弱引用介绍：\n如果一个对象只具有弱引用，那就类似于可有可无的生活用品。弱引用与软引用的区别在于：只具有弱引用的对象拥有更短暂的生命周期。在垃圾回收器线程扫描它 所管辖的内存区域的过程中，一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。不过，由于垃圾回收器是一个优先级很低的线程， 因此不一定会很快发现那些只具有弱引用的对象。\n弱引用可以和一个引用队列（ReferenceQueue）联合使用，如果弱引用所引用的对象被垃圾回收，Java 虚拟机就会把这个弱引用加入到与之关联的引用队列中。\n1.4.1 ThreadLocal如何防止内存泄漏 # ThreadLocal 变量的内存泄漏问题主要是由于 ThreadLocalMap 中的 Entry 没有被及时清理导致的。ThreadLocalMap 是 ThreadLocal 的底层数据结构，它用于存储每个线程独立的变量副本。\n要防止 ThreadLocal 内存泄漏，可以考虑以下方法：\n使用完 ThreadLocal 后及时调用 remove() 方法\n在不再需要使用 ThreadLocal 存储的数据时，手动调用 ThreadLocal.remove() 方法将该数据从当前线程的 ThreadLocalMap 中清除。这样可以确保 ThreadLocalMap 不会持有对对象的引用，从而帮助垃圾回收器正常回收不再需要的对象。 javaCopy code ThreadLocal\u0026lt;Object\u0026gt; threadLocal = new ThreadLocal\u0026lt;\u0026gt;(); // 存储数据 threadLocal.set(someData); // 使用完毕后清除 threadLocal.remove(); 使用 try-with-resources 或 try-finally 块\n如果你的 ThreadLocal 变量在需要清理的资源管理上下文中使用，可以使用 try-with-resources（自动清理）或 try-finally（手动清理）块来确保及时清理。 javaCopy code try (ThreadLocalResource resource = new ThreadLocalResource()) { // 使用 ThreadLocalResource } // 或者使用 try-finally ThreadLocalResource resource = new ThreadLocalResource(); try { // 使用 ThreadLocalResource } finally { resource.close(); // 在 close 方法中清理 ThreadLocal 变量 } 使用InheritableThreadLocal\n如果需要在子线程中访问父线程的 ThreadLocal 变量，并且确保在子线程中正确清理，可以考虑使用 InheritableThreadLocal。这个类允许子线程继承父线程的 ThreadLocal 变量，并在子线程完成后自动清理。 javaCopy code ThreadLocal\u0026lt;String\u0026gt; threadLocal = new InheritableThreadLocal\u0026lt;\u0026gt;(); threadLocal.set(\u0026#34;Hello, Parent Thread\u0026#34;); Runnable childTask = () -\u0026gt; { String value = threadLocal.get(); // 子线程可以访问父线程的 ThreadLocal 变量 // ... }; Thread childThread = new Thread(childTask); childThread.start(); 1.5 ThreadLocal的应用场景 # ThreadLocal是Java中的一个类，它提供了一种在多线程环境下实现线程局部变量存储的机制。 它的应用场景包括线程池、Web开发中的请求上下文信息管理、数据库连接管理和日志记录等等。 在线程池中，可以使用ThreadLocal为每个线程维护独立的上下文信息，避免线程间互相干扰。 在Web开发中，可以使用ThreadLocal存储当前请求的上下文信息，避免参数传递的复杂性。 在数据库连接管理中，ThreadLocal可以为每个线程保持独立的数据库连接，提高并发性能。 在日志记录中，ThreadLocal可以将日志记录与当前线程关联起来，方便追踪和排查问题。 此外，ThreadLocal还可以用于在线程之间传递全局的上下文信息。 在使用ThreadLocal时需要注意内存泄漏问题和线程安全性，及时清理不再需要的变量副本，并采取适当的同步措施保证线程安全。通过合理使用ThreadLocal，可以简化多线程编程，提高程序的性能和可维护性。\n线程池 # 2.1 线程池 # 顾名思义，线程池就是管理一系列线程的资源池。当有任务要处理时，直接从线程池中获取线程来处理，处理完之后线程并不会立即被销毁，而是等待下一个任务。\n线程池也是可以看做成一个池子，在该池子中存储很多个线程。\n系统创建一个线程的成本是比较高的，因为它涉及到与操作系统交互，当程序中需要创建大量生存期很短暂的线程时，频繁的创建和销毁线程对系统的资源消耗有可能大于业务处理是对系统资源的消耗，这样就有点\u0026quot;舍本逐末\u0026quot;了。针对这一种情况，为了提高性能，我们就可以采用线程池。线程池在启动的时，会创建大量空闲线程，当我们向线程池提交任务的时，线程池就会启动一个线程来执行该任务。等待任务执行完毕以后，线程并不会死亡，而是再次返回到线程池中称为空闲状态。等待下一次任务的执行。\n线程池的设计思路 :\n准备一个任务容器 一次性启动多个(2个)消费者线程 刚开始任务容器是空的，所以线程都在wait 直到一个外部线程向这个任务容器中扔了一个\u0026quot;任务\u0026quot;，就会有一个消费者线程被唤醒 这个消费者线程取出\u0026quot;任务\u0026quot;，并且执行这个任务，执行完毕后，继续等待下一次任务的到来 线程池有五种状态，分别为：\nRUNNING 会接收新任务并且会处理队列中的任务 SHUTDOWN 不会接收新任务并且会处理队列中的任务，任务处理完后会中断所有线程 STOP 不会接收新任务并且不会处理队列中的任务，并且会直接中断所有线程 TIDYING 所有线程都停止了之后，线程池的状态就会转为TIDYING，一旦达到此状态，就会调用线程池的terminated() TERMINATED terminated()执行完之后就会转变为TERMINATED 这五种状态并不能任意转换，只会有以下几种转换情况：\n转变前 转变后 转变条件 RUNNING SHUTDOWN 手动调用shutdown()触发，或者线程池对象GC时会调用finalize()从而调用shutdown() RUNNING STOP 手动调用shutdownNow()触发 SHUTDOWN STOP 手动先调用shutdown()紧着调用shutdownNow()触发 SHUTDOWN TIDYING 线程池所有线程都停止后自动触发 STOP TIDYING 线程池所有线程都停止后自动触发 TIDYING TERMINATED 线程池自动调用terminated()后触发 2.1.1 为什么要用线程池？ # 池化技术想必大家已经屡见不鲜了，线程池、数据库连接池、HTTP 连接池等等都是对这个思想的应用。池化技术的思想主要是为了减少每次获取资源的消耗，提高对资源的利用率。\n线程池提供了一种限制和管理资源（包括执行一个任务）的方式。 每个线程池还维护一些基本统计信息，例如已完成任务的数量。\n这里借用《Java 并发编程的艺术》提到的来说一下使用线程池的好处：\n降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。 提高响应速度。当任务到达时，任务可以不需要等到线程创建就能立即执行。 提高线程的可管理性。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。 2.2 如何创建线程池？ # 方式一：通过ThreadPoolExecutor构造函数来创建（推荐）。\n方式二：通过 Executor 框架的工具类 Executors 来创建。\nExecutors工具类提供的创建线程池的方法如下图所示：\n概述 : JDK对线程池也进行了相关的实现，在真实企业开发中我们也很少去自定义线程池，而是使用JDK中自带的线程池。\n我们可以使用Executors中所提供的静态方法来创建线程池static ExecutorService newCachedThreadPool() 创建一个默认的线程池static newFixedThreadPool(int nThreads) 创建一个指定最多线程数量的线程池\n可以看出，通过Executors工具类可以创建多种类型的线程池，包括：\nFixedThreadPool：固定线程数量的线程池。该线程池中的线程数量始终不变。当有一个新的任务提交时，线程池中若有空闲线程，则立即执行。若没有，则新的任务会被暂存在一个任务队列中，待有线程空闲时，便处理在任务队列中的任务。\nSingleThreadExecutor： 只有一个线程的线程池。若多余一个任务被提交到该线程池，任务会被保存在一个任务队列中，待线程空闲，按先入先出的顺序执行队列中的任务。\nCachedThreadPool： 可根据实际情况调整线程数量的线程池。线程池的线程数量不确定，但若有空闲线程可以复用，则会优先使用可复用的线程。若所有线程均在工作，又有新的任务提交，则会创建新的线程处理任务。所有线程在当前任务执行完毕后，将返回线程池进行复用。\nScheduledThreadPool：给定的延迟后运行任务或者定期执行任务的线程池。\n2.2.1 为什么不推荐使用内置线程池？ # 在《阿里巴巴 Java 开发手册》“并发处理”这一章节，明确指出线程资源必须通过线程池提供，不允许在应用中自行显式创建线程。\n为什么呢？\n使用线程池的好处是减少在创建和销毁线程上所消耗的时间以及系统资源开销，解决资源不足的问题。如果不使用线程池，有可能会造成系统创建大量同类线程而导致消耗完内存或者“过度切换”的问题。\n另外，《阿里巴巴 Java 开发手册》中强制线程池不允许使用 Executors 去创建，而是通过 ThreadPoolExecutor 构造函数的方式，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险\nExecutors 返回线程池对象的弊端如下：\nFixedThreadPool 和 SingleThreadExecutor:使用的是有界阻塞队列是 LinkedBlockingQueue ，其任务队列的最大长度为 Integer.MAX_VALUE ，可能堆积大量的请求，从而导致 OOM。 CachedThreadPool:使用的是同步队列 SynchronousQueue, 允许创建的线程数量为 Integer.MAX_VALUE ，如果任务数量过多且执行速度较慢，可能会创建大量的线程，从而导致 OOM。 ScheduledThreadPool 和 SingleThreadScheduledExecutor :使用的无界的延迟阻塞队列 DelayedWorkQueue ，任务队列最大长度为 Integer.MAX_VALUE ，可能堆积大量的请求，从而导致 OOM。 // 有界队列 LinkedBlockingQueue public static ExecutorService newFixedThreadPool(int nThreads) { return new ThreadPoolExecutor(nThreads, nThreads,0L, TimeUnit.MILLISECONDS,new LinkedBlockingQueue\u0026lt;Runnable\u0026gt;()); } // 无界队列 LinkedBlockingQueue public static ExecutorService newSingleThreadExecutor() { return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1,0L, TimeUnit.MILLISECONDS,new LinkedBlockingQueue\u0026lt;Runnable\u0026gt;())); } // 同步队列 SynchronousQueue，没有容量，最大线程数是 Integer.MAX_VALUE` public static ExecutorService newCachedThreadPool() { return new ThreadPoolExecutor(0, Integer.MAX_VALUE,60L, TimeUnit.SECONDS,new SynchronousQueue\u0026lt;Runnable\u0026gt;()); } // DelayedWorkQueue（延迟阻塞队列） public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) { return new ScheduledThreadPoolExecutor(corePoolSize); } public ScheduledThreadPoolExecutor(int corePoolSize) { super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue()); } 2.3 线程池常见参数 # /** * 用给定的初始参数创建一个新的ThreadPoolExecutor。 */ public ThreadPoolExecutor(int corePoolSize,//线程池的核心线程数量 int maximumPoolSize,//线程池的最大线程数 long keepAliveTime,//当线程数大于核心线程数时，多余的空闲线程存活的最长时间 TimeUnit unit,//时间单位 BlockingQueue\u0026lt;Runnable\u0026gt; workQueue,//任务队列，用来储存等待执行任务的队列 ThreadFactory threadFactory,//线程工厂，用来创建线程，一般默认即可 RejectedExecutionHandler handler//拒绝策略，当提交的任务过多而不能及时处理时，我们可以定制策略来处理任务 ) { if (corePoolSize \u0026lt; 0 || maximumPoolSize \u0026lt;= 0 || maximumPoolSize \u0026lt; corePoolSize || keepAliveTime \u0026lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler; } ThreadPoolExecutor 3 个最重要的参数：\ncorePoolSize : 任务队列未达到队列容量时，最大可以同时运行的线程数量。 maximumPoolSize : 任务队列中存放的任务达到队列容量的时候，当前可以同时运行的线程数量变为最大线程数。 workQueue: 新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到的话，新任务就会被存放在队列中。 ThreadPoolExecutor其他常见参数 :\nkeepAliveTime:当线程池中的线程数量大于 corePoolSize ，即有非核心线程（线程池中核心线程以外的线程）时，这些非核心线程空闲后不会立即销毁，而是会等待，直到等待的时间超过了 keepAliveTime才会被回收销毁。 unit : keepAliveTime 参数的时间单位。 threadFactory :executor 创建新线程的时候会用到。 handler :拒绝策略（后面会单独详细介绍一下）。 下面这张图可以加深你对线程池中各个参数的相互关系的理解（图片来源：《Java 性能调优实战》）：\n2.4 线程池的核心线程会被回收吗？ # ThreadPoolExecutor 默认不会回收核心线程，即使它们已经空闲了。这是为了减少创建线程的开销，因为核心线程通常是要长期保持活跃的。但是，如果线程池是被用于周期性使用的场景，且频率不高（周期之间有明显的空闲时间），可以考虑将 allowCoreThreadTimeOut(boolean value) 方法的参数设置为 true，这样就会回收空闲（时间间隔由 keepAliveTime 指定）的核心线程了。\nThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor(4, 6, 6, TimeUnit.SECONDS, new SynchronousQueue\u0026lt;\u0026gt;()); threadPoolExecutor.allowCoreThreadTimeOut(true); 2.5 线程池的拒绝策略 # 如果当前同时运行的线程数量达到最大线程数量并且队列也已经被放满了任务时，ThreadPoolExecutor 定义一些策略:\nThreadPoolExecutor.AbortPolicy：抛出 RejectedExecutionException来拒绝新任务的处理。 ThreadPoolExecutor.CallerRunsPolicy：调用执行自己的线程运行任务，也就是直接在调用execute方法的线程中运行(run)被拒绝的任务，如果执行程序已关闭，则会丢弃该任务。因此这种策略会降低对于新任务提交速度，影响程序的整体性能。如果你的应用程序可以承受此延迟并且你要求任何一个任务请求都要被执行的话，你可以选择这个策略。 ThreadPoolExecutor.DiscardPolicy：不处理新任务，直接丢弃掉。 ThreadPoolExecutor.DiscardOldestPolicy：此策略将丢弃最早的未处理的任务请求。 举个例子：Spring 通过 ThreadPoolTaskExecutor 或者我们直接通过 ThreadPoolExecutor 的构造函数创建线程池的时候，当我们不指定 RejectedExecutionHandler 拒绝策略来配置线程池的时候，默认使用的是 AbortPolicy。在这种拒绝策略下，如果队列满了，ThreadPoolExecutor 将抛出 RejectedExecutionException 异常来拒绝新来的任务 ，这代表你将丢失对这个任务的处理。如果不想丢弃任务的话，可以使用CallerRunsPolicy。CallerRunsPolicy 和其他的几个策略不同，它既不会抛弃任务，也不会抛出异常，而是将任务回退给调用者，使用调用者的线程来执行任务。\npublic static class CallerRunsPolicy implements RejectedExecutionHandler { public CallerRunsPolicy() { } public void rejectedExecution(Runnable r, ThreadPoolExecutor e) { if (!e.isShutdown()) { // 直接主线程执行，而不是线程池中的线程执行 r.run(); } } } 2.5.1 如果不允许丢弃任务，应该选择哪个拒绝策略？ # 根据上面对线程池拒绝策略的介绍，相信大家很容易能够得出答案是：CallerRunsPolicy 。\n这里我们再来结合CallerRunsPolicy 的源码来看看：\npublic static class CallerRunsPolicy implements RejectedExecutionHandler { public CallerRunsPolicy() { } public void rejectedExecution(Runnable r, ThreadPoolExecutor e) { //只要当前程序没有关闭，就用执行execute方法的线程执行该任务 if (!e.isShutdown()) { r.run(); } } } 从源码可以看出，只要当前程序不关闭就会使用执行execute方法的线程执行该任务。\n2.5.2 CallerRunsPolicy拒绝策略有什么风险？如何解决？ # 我们上面也提到了：如果想要保证任何一个任务请求都要被执行的话，那选择 CallerRunsPolicy 拒绝策略更合适一些。\n不过，如果走到CallerRunsPolicy的任务是个非常耗时的任务，且处理提交任务的线程是主线程，可能会导致主线程阻塞，影响程序的正常运行。\n这里简单举一个例子，该线程池限定了最大线程数为 2，阻塞队列大小为 1(这意味着第 4 个任务就会走到拒绝策略)，ThreadUtil为 Hutool 提供的工具类：\npublic class ThreadPoolTest { private static final Logger log = LoggerFactory.getLogger(ThreadPoolTest.class); public static void main(String[] args) { // 创建一个线程池，核心线程数为1，最大线程数为2 // 当线程数大于核心线程数时，多余的空闲线程存活的最长时间为60秒， // 任务队列为容量为1的ArrayBlockingQueue，饱和策略为CallerRunsPolicy。 ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor(1, 2, 60, TimeUnit.SECONDS, new ArrayBlockingQueue\u0026lt;\u0026gt;(1), new ThreadPoolExecutor.CallerRunsPolicy()); // 提交第一个任务，由核心线程执行 threadPoolExecutor.execute(() -\u0026gt; { log.info(\u0026#34;核心线程执行第一个任务\u0026#34;); ThreadUtil.sleep(1, TimeUnit.MINUTES); }); // 提交第二个任务，由于核心线程被占用，任务将进入队列等待 threadPoolExecutor.execute(() -\u0026gt; { log.info(\u0026#34;非核心线程处理入队的第二个任务\u0026#34;); ThreadUtil.sleep(1, TimeUnit.MINUTES); }); // 提交第三个任务，由于核心线程被占用且队列已满，创建非核心线程处理 threadPoolExecutor.execute(() -\u0026gt; { log.info(\u0026#34;非核心线程处理第三个任务\u0026#34;); ThreadUtil.sleep(1, TimeUnit.MINUTES); }); // 提交第四个任务，由于核心线程和非核心线程都被占用，队列也满了，根据CallerRunsPolicy策略，任务将由提交任务的线程（即主线程）来执行 threadPoolExecutor.execute(() -\u0026gt; { log.info(\u0026#34;主线程处理第四个任务\u0026#34;); ThreadUtil.sleep(2, TimeUnit.MINUTES); }); // 提交第五个任务，主线程被第四个任务卡住，该任务必须等到主线程执行完才能提交 threadPoolExecutor.execute(() -\u0026gt; { log.info(\u0026#34;核心线程执行第五个任务\u0026#34;); }); // 关闭线程池 threadPoolExecutor.shutdown(); } } 输出：\n18:19:48.203 INFO [pool-1-thread-1] c.j.concurrent.ThreadPoolTest - 核心线程执行第一个任务 18:19:48.203 INFO [pool-1-thread-2] c.j.concurrent.ThreadPoolTest - 非核心线程处理第三个任务 18:19:48.203 INFO [main] c.j.concurrent.ThreadPoolTest - 主线程处理第四个任务 18:20:48.212 INFO [pool-1-thread-2] c.j.concurrent.ThreadPoolTest - 非核心线程处理入队的第二个任务 18:21:48.219 INFO [pool-1-thread-2] c.j.concurrent.ThreadPoolTest - 核心线程执行第五个任务 从输出结果可以看出，因为CallerRunsPolicy这个拒绝策略，导致耗时的任务用了主线程执行，导致线程池阻塞，进而导致后续任务无法及时执行，严重的情况下很可能导致 OOM。\n我们从问题的本质入手，调用者采用CallerRunsPolicy是希望所有的任务都能够被执行，暂时无法处理的任务又被保存在阻塞队列BlockingQueue中。这样的话，在内存允许的情况下，我们可以增加阻塞队列BlockingQueue的大小并调整堆内存以容纳更多的任务，确保任务能够被准确执行。\n为了充分利用 CPU，我们还可以调整线程池的maximumPoolSize （最大线程数）参数，这样可以提高任务处理速度，避免累计在 BlockingQueue的任务过多导致内存用完。\n如果服务器资源以达到可利用的极限，这就意味我们要在设计策略上改变线程池的调度了，我们都知道，导致主线程卡死的本质就是因为我们不希望任何一个任务被丢弃。换个思路，有没有办法既能保证任务不被丢弃且在服务器有余力时及时处理呢？\n这里提供的一种任务持久化的思路，这里所谓的任务持久化，包括但不限于:\n设计一张任务表将任务存储到 MySQL 数据库中。 Redis 缓存任务。 将任务提交到消息队列中。 这里以方案一为例，简单介绍一下实现逻辑：\n实现RejectedExecutionHandler接口自定义拒绝策略，自定义拒绝策略负责将线程池暂时无法处理（此时阻塞队列已满）的任务入库（保存到 MySQL 中）。注意：线程池暂时无法处理的任务会先被放在阻塞队列中，阻塞队列满了才会触发拒绝策略。 继承BlockingQueue实现一个混合式阻塞队列，该队列包含 JDK 自带的ArrayBlockingQueue。另外，该混合式阻塞队列需要修改取任务处理的逻辑，也就是重写take()方法，取任务时优先从数据库中读取最早的任务，数据库中无任务时再从 ArrayBlockingQueue中去取任务。 整个实现逻辑还是比较简单的，核心在于自定义拒绝策略和阻塞队列。如此一来，一旦我们的线程池中线程以达到满载时，我们就可以通过拒绝策略将最新任务持久化到 MySQL 数据库中，等到线程池有了有余力处理所有任务时，让其优先处理数据库中的任务以避免\u0026quot;饥饿\u0026quot;问题。\n当然，对于这个问题，我们也可以参考其他主流框架的做法，以 Netty 为例，它的拒绝策略则是直接创建一个线程池以外的线程处理这些任务，为了保证任务的实时处理，这种做法可能需要良好的硬件设备且临时创建的线程无法做到准确的监控：\nprivate static final class NewThreadRunsPolicy implements RejectedExecutionHandler { NewThreadRunsPolicy() { super(); } public void rejectedExecution(Runnable r, ThreadPoolExecutor executor) { try { //创建一个临时线程处理任务 final Thread t = new Thread(r, \u0026#34;Temporary task executor\u0026#34;); t.start(); } catch (Throwable e) { throw new RejectedExecutionException( \u0026#34;Failed to start a new thread\u0026#34;, e); } } } ActiveMQ 则是尝试在指定的时效内尽可能的争取将任务入队，以保证最大交付：\nnew RejectedExecutionHandler() { @Override public void rejectedExecution(final Runnable r, final ThreadPoolExecutor executor) { try { //限时阻塞等待，实现尽可能交付 executor.getQueue().offer(r, 60, TimeUnit.SECONDS); } catch (InterruptedException e) { throw new RejectedExecutionException(\u0026#34;Interrupted waiting for BrokerService.worker\u0026#34;); } throw new RejectedExecutionException(\u0026#34;Timed Out while attempting to enqueue Task.\u0026#34;); } }); 2.6 线程池常用的阻塞队列 # 阻塞队列（BlockingQueue）是一个支持线程安全的队列接口，它的实现类提供了在插入和移除元素时进行阻塞的功能。它可以自动管理生产者和消费者之间的同步，适用于多线程编程中需要安全和高效的数据共享场合。\n新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到的话，新任务就会被存放在队列中。\n不同的线程池会选用不同的阻塞队列，我们可以结合内置线程池来分析。\n容量为 Integer.MAX_VALUE 的 LinkedBlockingQueue（有界阻塞队列）：FixedThreadPool 和 SingleThreadExecutor 。FixedThreadPool最多只能创建核心线程数的线程（核心线程数和最大线程数相等），SingleThreadExecutor只能创建一个线程（核心线程数和最大线程数都是 1），二者的任务队列永远不会被放满。 SynchronousQueue（同步队列）：CachedThreadPool 。SynchronousQueue 没有容量，不存储元素，目的是保证对于提交的任务，如果有空闲线程，则使用空闲线程来处理；否则新建一个线程来处理任务。也就是说，CachedThreadPool 的最大线程数是 Integer.MAX_VALUE ，可以理解为线程数是可以无限扩展的，可能会创建大量线程，从而导致 OOM。 DelayedWorkQueue（延迟队列）：ScheduledThreadPool 和 SingleThreadScheduledExecutor 。DelayedWorkQueue 的内部元素并不是按照放入的时间排序，而是会按照延迟的时间长短对任务进行排序，内部采用的是“堆”的数据结构，可以保证每次出队的任务都是当前队列中执行时间最靠前的。DelayedWorkQueue 添加元素满了之后会自动扩容，增加原来容量的 50%，即永远不会阻塞，最大扩容可达 Integer.MAX_VALUE，所以最多只能创建核心线程数的线程。 ArrayBlockingQueue（有界阻塞队列）：底层由数组实现，容量一旦创建，就不能修改。 2.6.1 阻塞队列的应用场景 # 生产者-消费者模型： 在生产者-消费者模型中，生产者线程生成数据并放入队列，消费者线程从队列中取出数据进行处理。阻塞队列的自动阻塞机制使得它能够简单高效地实现生产者-消费者模型。 import java.util.concurrent.ArrayBlockingQueue; import java.util.concurrent.BlockingQueue; public class ProducerConsumerExample { public static void main(String[] args) { BlockingQueue\u0026lt;Integer\u0026gt; queue = new ArrayBlockingQueue\u0026lt;\u0026gt;(5); // 生产者线程 Thread producer = new Thread(() -\u0026gt; { try { for (int i = 0; i \u0026lt; 10; i++) { System.out.println(\u0026#34;Produced: \u0026#34; + i); queue.put(i); // 阻塞直到队列有空闲 } } catch (InterruptedException e) { Thread.currentThread().interrupt(); } }); // 消费者线程 Thread consumer = new Thread(() -\u0026gt; { try { for (int i = 0; i \u0026lt; 10; i++) { Integer value = queue.take(); // 阻塞直到队列有元素 System.out.println(\u0026#34;Consumed: \u0026#34; + value); } } catch (InterruptedException e) { Thread.currentThread().interrupt(); } }); producer.start(); consumer.start(); } } 线程池工作队列： 在Java的线程池实现中，阻塞队列常用来保存任务。例如，ThreadPoolExecutor使用阻塞队列来管理提交但未被执行的任务。 import java.util.concurrent.ArrayBlockingQueue; import java.util.concurrent.ThreadPoolExecutor; import java.util.concurrent.TimeUnit; public class ThreadPoolExample { public static void main(String[] args) { BlockingQueue\u0026lt;Runnable\u0026gt; queue = new ArrayBlockingQueue\u0026lt;\u0026gt;(10); ThreadPoolExecutor executor = new ThreadPoolExecutor( 2, // core thread pool size 4, // maximum thread pool size 1, // time to wait before resizing pool TimeUnit.SECONDS, queue ); for (int i = 0; i \u0026lt; 15; i++) { final int taskNum = i; executor.execute(() -\u0026gt; { System.out.println(\u0026#34;Executing task: \u0026#34; + taskNum); try { Thread.sleep(2000); // Simulating task } catch (InterruptedException e) { Thread.currentThread().interrupt(); } }); } executor.shutdown(); // Initiates an orderly shutdown } } 实时数据处理系统： 在需要处理实时流数据的系统中，阻塞队列可以用于在数据生成模块和数据处理模块之间传递数据，确保数据以正确的顺序被处理，并且不会因过快的生产速度导致数据丢失。 import java.util.concurrent.LinkedBlockingQueue; public class RealTimeDataProcessing { private static final int NUM_OF_DATA = 50; private static final LinkedBlockingQueue\u0026lt;String\u0026gt; dataQueue = new LinkedBlockingQueue\u0026lt;\u0026gt;(); public static void main(String[] args) { // 数据生产者线程 Thread producer = new Thread(() -\u0026gt; { for (int i = 0; i \u0026lt; NUM_OF_DATA; i++) { try { String data = \u0026#34;Data-\u0026#34; + i; dataQueue.put(data); System.out.println(\u0026#34;Produced: \u0026#34; + data); } catch (InterruptedException e) { Thread.currentThread().interrupt(); } } }); // 数据消费者线程 Thread consumer = new Thread(() -\u0026gt; { while (true) { try { String data = dataQueue.take(); System.out.println(\u0026#34;Processed: \u0026#34; + data); } catch (InterruptedException e) { Thread.currentThread().interrupt(); break; } } }); producer.start(); consumer.start(); } } 结论\n阻塞队列在多线程环境中提供了非常强大且灵活的工具来管理线程间的数据共享与通信。通过自动同步和阻塞，它能合理控制生产与消费节奏，避免死锁和数据丢失，是实现多线程程序的优秀工具。\n2.7 线程池处理任务的流程 # 如果当前运行的线程数小于核心线程数，那么就会新建一个线程来执行任务。 如果当前运行的线程数等于或大于核心线程数，但是小于最大线程数，那么就把该任务放入到任务队列里等待执行。 如果向任务队列投放任务失败（任务队列已经满了），但是当前运行的线程数是小于最大线程数的，就新建一个线程来执行任务。 如果当前运行的线程数已经等同于最大线程数了，新建线程将会使当前运行的线程超出最大线程数，那么当前任务会被拒绝，拒绝策略会调用RejectedExecutionHandler.rejectedExecution()方法。 再提一个有意思的小问题：线程池在提交任务前，可以提前创建线程吗？\n答案是可以的！ThreadPoolExecutor 提供了两个方法帮助我们在提交任务之前，完成核心线程的创建，从而实现线程池预热的效果：\nprestartCoreThread():启动一个线程，等待任务，如果已达到核心线程数，这个方法返回 false，否则返回 true； prestartAllCoreThreads():启动所有的核心线程，并返回启动成功的核心线程数。 2.8 线程池提交一个任务的流程 # 在使用execute()方法提交一个Runnable对象时 会先判断当前线程池中的线程数是否小于corePoolSize 如果小于，则创建新线程并执行Runnable 如果大于等于，则尝试将Runnable加入到workQueue中 如果workQueue没满，则将Runnable正常入队，等待执行 如果workQueue满了，则会入队失败，那么会尝试继续增加线程 如果当前线程池中的线程数是否小于maximumPoolSize 如果小于，则创建新线程并执行任务 如果大于等于，则执行拒绝策略，拒绝此Runnable 注意1：提交一个Runnable时，不管当前线程池中的线程是否空闲，只要数量小于核心线程数就会创建新线程。 注意2：ThreadPoolExecutor相当于是非公平的，比如队列满了之后提交的Runnable可能会比正在排队的Runnable先执行。\n2.9 线程池中线程异常后，销毁还是复用？ # 直接说结论，需要分两种情况：\n使用execute()提交任务：当任务通过execute()提交到线程池并在执行过程中抛出异常时，如果这个异常没有在任务内被捕获，那么该异常会导致当前线程终止，并且异常会被打印到控制台或日志文件中。线程池会检测到这种线程终止，并创建一个新线程来替换它，从而保持配置的线程数不变。 使用submit()提交任务：对于通过submit()提交的任务，如果在任务执行中发生异常，这个异常不会直接打印出来。相反，异常会被封装在由submit()返回的Future对象中。当调用Future.get()方法时，可以捕获到一个ExecutionException。在这种情况下，线程不会因为异常而终止，它会继续存在于线程池中，准备执行后续的任务。 简单来说：使用execute()时，未捕获异常导致线程终止，线程池创建新线程替代；使用submit()时，异常被封装在Future中，线程继续复用。\n这种设计允许submit()提供更灵活的错误处理机制，因为它允许调用者决定如何处理异常，而execute()则适用于那些不需要关注执行结果的场景。\n具体的源码分析可以参考这篇：线程池中线程异常后：销毁还是复用？ - 京东技术\n2.10 如何给线程池命名？ # 初始化线程池的时候需要显示命名（设置线程池名称前缀），有利于定位问题。\n默认情况下创建的线程名字类似 pool-1-thread-n 这样的，没有业务含义，不利于我们定位问题。\n给线程池里的线程命名通常有下面两种方式：\n1、利用 guava 的 ThreadFactoryBuilder\nThreadFactory threadFactory = new ThreadFactoryBuilder() .setNameFormat(threadNamePrefix + \u0026#34;-%d\u0026#34;) .setDaemon(true).build(); ExecutorService threadPool = new ThreadPoolExecutor(corePoolSize, maximumPoolSize, keepAliveTime, TimeUnit.MINUTES, workQueue, threadFactory); 2、自己实现 ThreadFactory。\nimport java.util.concurrent.ThreadFactory; import java.util.concurrent.atomic.AtomicInteger; /** * 线程工厂，它设置线程名称，有利于我们定位问题。 */ public final class NamingThreadFactory implements ThreadFactory { private final AtomicInteger threadNum = new AtomicInteger(); private final String name; /** * 创建一个带名字的线程池生产工厂 */ public NamingThreadFactory(String name) { this.name = name; } @Override public Thread newThread(Runnable r) { Thread t = new Thread(r); t.setName(name + \u0026#34; [#\u0026#34; + threadNum.incrementAndGet() + \u0026#34;]\u0026#34;); return t; } } 2.11 如何设定线程池的大小？ # 很多人甚至可能都会觉得把线程池配置过大一点比较好！我觉得这明显是有问题的。就拿我们生活中非常常见的一例子来说：并不是人多就能把事情做好，增加了沟通交流成本。你本来一件事情只需要 3 个人做，你硬是拉来了 6 个人，会提升做事效率嘛？我想并不会。 线程数量过多的影响也是和我们分配多少人做事情一样，对于多线程这个场景来说主要是增加了上下文切换成本。不清楚什么是上下文切换的话，可以看我下面的介绍。\n上下文切换：\n多线程编程中一般线程的个数都大于 CPU 核心的个数，而一个 CPU 核心在任意时刻只能被一个线程使用，为了让这些线程都能得到有效执行，CPU 采取的策略是为每个线程分配时间片并轮转的形式。当一个线程的时间片用完的时候就会重新处于就绪状态让给其他线程使用，这个过程就属于一次上下文切换。概括来说就是：当前任务在执行完 CPU 时间片切换到另一个任务之前会先保存自己的状态，以便下次再切换回这个任务时，可以再加载这个任务的状态。任务从保存到再加载的过程就是一次上下文切换。\n上下文切换通常是计算密集型的。也就是说，它需要相当可观的处理器时间，在每秒几十上百次的切换中，每次切换都需要纳秒量级的时间。所以，上下文切换对系统来说意味着消耗大量的 CPU 时间，事实上，可能是操作系统中时间消耗最大的操作。\nLinux 相比与其他操作系统（包括其他类 Unix 系统）有很多的优点，其中有一项就是，其上下文切换和模式切换的时间消耗非常少。\n类比于实现世界中的人类通过合作做某件事情，我们可以肯定的一点是线程池大小设置过大或者过小都会有问题，合适的才是最好。\n如果我们设置的线程池数量太小的话，如果同一时间有大量任务/请求需要处理，可能会导致大量的请求/任务在任务队列中排队等待执行，甚至会出现任务队列满了之后任务/请求无法处理的情况，或者大量任务堆积在任务队列导致 OOM。这样很明显是有问题的，CPU 根本没有得到充分利用。 如果我们设置线程数量太大，大量线程可能会同时在争取 CPU 资源，这样会导致大量的上下文切换，从而增加线程的执行时间，影响了整体执行效率。 有一个简单并且适用面比较广的公式：\nCPU 密集型任务(N+1)： 这种任务消耗的主要是 CPU 资源，可以将线程数设置为 N（CPU 核心数）+1。比 CPU 核心数多出来的一个线程是为了防止线程偶发的缺页中断，或者其它原因导致的任务暂停而带来的影响。一旦任务暂停，CPU 就会处于空闲状态，而在这种情况下多出来的一个线程就可以充分利用 CPU 的空闲时间。 I/O 密集型任务(2N)： 这种任务应用起来，系统会用大部分的时间来处理 I/O 交互，而线程在处理 I/O 的时间段内不会占用 CPU 来处理，这时就可以将 CPU 交出给其它线程使用。因此在 I/O 密集型任务的应用中，我们可以多配置一些线程，具体的计算方法是 2N。 如何判断是 CPU 密集任务还是 IO 密集任务？\nCPU 密集型简单理解就是利用 CPU 计算能力的任务比如你在内存中对大量数据进行排序。但凡涉及到网络读取，文件读取这类都是 IO 密集型，这类任务的特点是 CPU 计算耗费时间相比于等待 IO 操作完成的时间来说很少，大部分时间都花在了等待 IO 操作完成上。\n🌈 拓展一下（参见：issue#1737）：\n线程数更严谨的计算的方法应该是：最佳线程数 = N（CPU 核心数）∗（1+WT（线程等待时间）/ST（线程计算时间）），其中 WT（线程等待时间）=线程运行总时间 - ST（线程计算时间）。\n线程等待时间所占比例越高，需要越多线程。线程计算时间所占比例越高，需要越少线程。\n我们可以通过 JDK 自带的工具 VisualVM 来查看 WT/ST 比例。\nCPU 密集型任务的 WT/ST 接近或者等于 0，因此， 线程数可以设置为 N（CPU 核心数）∗（1+0）= N，和我们上面说的 N（CPU 核心数）+1 差不多。\nIO 密集型任务下，几乎全是线程等待时间，从理论上来说，你就可以将线程数设置为 2N（按道理来说，WT/ST 的结果应该比较大，这里选择 2N 的原因应该是为了避免创建过多线程吧）。\n公式也只是参考，具体还是要根据项目实际线上运行情况来动态调整。我在后面介绍的美团的线程池参数动态配置这种方案就非常不错，很实用！\n2.12 如何动态修改线程池的参数？ # 美团技术团队在《Java 线程池实现原理及其在美团业务中的实践》这篇文章中介绍到对线程池参数实现可自定义配置的思路和方法。\n美团技术团队的思路是主要对线程池的核心参数实现自定义可配置。这三个核心参数是：\ncorePoolSize : 核心线程数线程数定义了最小可以同时运行的线程数量。 maximumPoolSize : 当队列中存放的任务达到队列容量的时候，当前可以同时运行的线程数量变为最大线程数。 workQueue: 当新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到的话，新任务就会被存放在队列中。 为什么是这三个参数？\n我在Java 线程池详解 这篇文章中就说过这三个参数是 ThreadPoolExecutor 最重要的参数，它们基本决定了线程池对于任务的处理策略。\n如何支持参数动态配置？ 且看 ThreadPoolExecutor 提供的下面这些方法。\n格外需要注意的是corePoolSize， 程序运行期间的时候，我们调用 setCorePoolSize()这个方法的话，线程池会首先判断当前工作线程数是否大于corePoolSize，如果大于的话就会回收工作线程。\n另外，你也看到了上面并没有动态指定队列长度的方法，美团的方式是自定义了一个叫做 ResizableCapacityLinkedBlockIngQueue 的队列（主要就是把LinkedBlockingQueue的 capacity 字段的 final 关键字修饰给去掉了，让它变为可变的）。\n最终实现的可动态修改线程池参数效果如下。\n还没看够？推荐 why 神的如何设置线程池参数？美团给出了一个让面试官虎躯一震的回答。这篇文章，深度剖析，很不错哦！\n如果我们的项目也想要实现这种效果的话，可以借助现成的开源项目：\nHippo4j：异步线程池框架，支持线程池动态变更\u0026amp;监控\u0026amp;报警，无需修改代码轻松引入。支持多种使用模式，轻松引入，致力于提高系统运行保障能力。 Dynamic TP：轻量级动态线程池，内置监控告警功能，集成三方中间件线程池管理，基于主流配置中心（已支持 Nacos、Apollo，Zookeeper、Consul、Etcd，可通过 SPI 自定义实现）。 2.13 如何设计一个能够根据任务的优先级来执行的线程池？ # 这是一个常见的面试问题，本质其实还是在考察求职者对于线程池以及阻塞队列的掌握。\n我们上面也提到了，不同的线程池会选用不同的阻塞队列作为任务队列，比如FixedThreadPool 使用的是LinkedBlockingQueue（有界队列），默认构造器初始的队列长度为 Integer.MAX_VALUE ，由于队列永远不会被放满，因此FixedThreadPool最多只能创建核心线程数的线程。\n假如我们需要实现一个优先级任务线程池的话，那可以考虑使用 PriorityBlockingQueue （优先级阻塞队列）作为任务队列（ThreadPoolExecutor 的构造函数有一个 workQueue 参数可以传入任务队列）。\nPriorityBlockingQueue 是一个支持优先级的无界阻塞队列，可以看作是线程安全的 PriorityQueue，两者底层都是使用小顶堆形式的二叉堆，即值最小的元素优先出队。不过，PriorityQueue 不支持阻塞操作。\n要想让 PriorityBlockingQueue 实现对任务的排序，传入其中的任务必须是具备排序能力的，方式有两种：\n提交到线程池的任务实现 Comparable 接口，并重写 compareTo 方法来指定任务之间的优先级比较规则。 创建 PriorityBlockingQueue 时传入一个 Comparator 对象来指定任务之间的排序规则(推荐)。 不过，这存在一些风险和问题，比如：\nPriorityBlockingQueue 是无界的，可能堆积大量的请求，从而导致 OOM。 可能会导致饥饿问题，即低优先级的任务长时间得不到执行。 由于需要对队列中的元素进行排序操作以及保证线程安全（并发控制采用的是可重入锁 ReentrantLock），因此会降低性能。 对于 OOM 这个问题的解决比较简单粗暴，就是继承PriorityBlockingQueue 并重写一下 offer 方法(入队)的逻辑，当插入的元素数量超过指定值就返回 false 。\n饥饿问题这个可以通过优化设计来解决（比较麻烦），比如等待时间过长的任务会被移除并重新添加到队列中，但是优先级会被提升。\n对于性能方面的影响，是没办法避免的，毕竟需要对任务进行排序操作。并且，对于大部分业务场景来说，这点性能影响是可以接受的。\n2.14 判断线程池任务执行完成的方式 # Thread线程是否执行完成，我们可以调用join方法然后等待线程执行完成；那在使用线程池的时候，我们如何知道线程已经执行完成了？本文就带给大家五种判断的方式：\nisTerminated() 方式，在执行 shutdown() ，关闭线程池后，判断是否所有任务已经完成。\nThreadPoolExecutor 的 getCompletedTaskCount() 方法，判断完成任务数和全部任务数是否相等。\nCountDownLatch计数器，使用闭锁计数来判断是否全部完成。\n手动维护一个公共计数 ，原理和闭锁类似，就是更加灵活。\n使用submit向线程池提交任务，Future判断任务执行状态。\n2.14.1 isTerminated（） # 测试代码\npackage pool; import java.util.concurrent.LinkedBlockingQueue; import java.util.concurrent.ThreadPoolExecutor; import java.util.concurrent.TimeUnit; /** * @author 百里 */ public class BaiLiIsShutdownThreadPoolDemo { /** * 创建一个最大线程数15的线程池 */ public static ThreadPoolExecutor pool = new ThreadPoolExecutor( 10, 15, 0L, TimeUnit.MILLISECONDS, new ArrayBlockingQueue\u0026lt;\u0026gt;(10)); /** * 线程执行方法，随机等待0到10秒 */ private static void sleepMethod(int index){ try { long sleepTime = new Double(Math.random() * 10000).longValue(); Thread.sleep(sleepTime); System.out.println(\u0026#34;当前线程执行结束: \u0026#34; + index); } catch (InterruptedException e) { e.printStackTrace(); } } /** * 方法一：isTerminated * @param args * @throws InterruptedException */ public static void main(String[] args) throws InterruptedException { for (int i = 0; i \u0026lt; 10; i++) { int index = i; pool.execute(() -\u0026gt; sleepMethod(index)); } pool.shutdown(); while (!pool.isTerminated()){ Thread.sleep(1000); System.out.println(\u0026#34;还没停止。。。\u0026#34;); } System.out.println(\u0026#34;全部执行完毕\u0026#34;); } } 这里有两个主要方法：\nshutdown() ：对线程池进行有序关闭。调用该方法后，线程池将不再接受新的任务，但会继续执行已提交的任务。如果线程池已经处于关闭状态，则对该方法的调用没有额外的作用。 isTerminated() ：判断线程池中的所有任务是否在关闭后完成。只有在调用了shutdown()或shutdownNow()方法后，所有任务执行完毕，才会返回true。需要注意的是，在调用shutdown()之前调用isTerminated()方法始终返回false。 优缺点分析\n优点 ：操作简单。\n缺点 ：需要关闭线程池。并且日常使用是将线程池注入到Spring容器，然后各个组件中统一用同一个线程池，不能直接关闭线程池。\n2.14.2 getCompletedTaskCount（） # 测试代码\npackage pool; import java.util.concurrent.*; import java.util.concurrent.locks.Lock; import java.util.concurrent.locks.ReentrantLock; /** * @author 百里 */ public class BaiLiIsShutdownThreadPoolDemo { /** * 创建一个最大线程数15的线程池 */ public static ThreadPoolExecutor pool = new ThreadPoolExecutor( 10, 15, 0L, TimeUnit.MILLISECONDS, new ArrayBlockingQueue\u0026lt;\u0026gt;(10)); /** * 线程执行方法，随机等待0到10秒 */ private static void sleepMethod(int index){ try { long sleepTime = new Double(Math.random() * 10000).longValue(); Thread.sleep(sleepTime); System.out.println(\u0026#34;当前线程执行结束: \u0026#34; + index); } catch (InterruptedException e) { e.printStackTrace(); } } /** * 方法二：getCompletedTaskCount * @param args * @throws InterruptedException */ public static void main(String[] args) throws InterruptedException { for (int i = 0; i \u0026lt; 10; i++) { int index = i; pool.execute(() -\u0026gt; sleepMethod(index)); } //当线程池完成的线程数等于线程池中的总线程数 while (!(pool.getTaskCount() == pool.getCompletedTaskCount())) { System.out.println(\u0026#34;任务总数:\u0026#34; + pool.getTaskCount() + \u0026#34;； 已经完成任务数:\u0026#34; + pool.getCompletedTaskCount()); Thread.sleep(1000); System.out.println(\u0026#34;还没停止。。。\u0026#34;); } System.out.println(\u0026#34;全部执行完毕\u0026#34;); } } 主要两个方法：\ngetTaskCount() ：返回计划执行的任务总数。由于任务和线程的状态可能在计算过程中动态变化，返回的值只是一个近似值。这个方法返回的是线程池提交的任务总数，包括已经完成和正在执行中的任务。 getCompletedTaskCount() ：返回已经完成执行的任务的大致总数。由于任务和线程的状态可能在计算过程中动态改变，返回的值只是一个近似值，并且在连续的调用中不会减少。这个方法返回的是已经完成执行的任务数量，不包括正在执行中的任务。 优缺点分析\n优点 ：不必关闭线程池，避免了创建和销毁带来的损耗。 缺点 ：使用这种判断存在很大的限制条件；必须确定在循环判断过程中没有新的任务产生。 2.14.3 CountDownLatch # 测试代码\npackage pool; import java.util.concurrent.*; import java.util.concurrent.locks.Lock; import java.util.concurrent.locks.ReentrantLock; /** * @author 百里 */ public class BaiLiIsShutdownThreadPoolDemo { /** * 创建一个最大线程数15的线程池 */ public static ThreadPoolExecutor pool = new ThreadPoolExecutor( 10, 15, 0L, TimeUnit.MILLISECONDS, new ArrayBlockingQueue\u0026lt;\u0026gt;(10)); /** * 线程执行方法，随机等待0到10秒 */ private static void sleepMethod(int index){ try { long sleepTime = new Double(Math.random() * 10000).longValue(); Thread.sleep(sleepTime); System.out.println(\u0026#34;当前线程执行结束: \u0026#34; + index); } catch (InterruptedException e) { e.printStackTrace(); } } /** * 方法三：CountDownLatch * @throws Exception */ public static void main(String[] args) throws Exception { //计数器，判断线程是否执行结束 CountDownLatch taskLatch = new CountDownLatch(10); for (int i = 0; i \u0026lt; 10; i++) { int index = i; pool.execute(() -\u0026gt; { sleepMethod(index); taskLatch.countDown(); System.out.println(\u0026#34;当前计数器数量：\u0026#34; + taskLatch.getCount()); }); } //当前线程阻塞，等待计数器置为0 taskLatch.await(); System.out.println(\u0026#34;全部执行完毕\u0026#34;); } } 优缺点分析\n优点 ：代码优雅，不需要对线程池进行操作。 缺点 ：需要提前知道线程数量；性能较差；还需要在线程代码块内加上异常判断，否则在 countDown之前发生异常而没有处理，就会导致主线程永远阻塞在 await。 2.14.4 公共计数 # 测试代码\npackage pool; import java.util.concurrent.*; import java.util.concurrent.locks.Lock; import java.util.concurrent.locks.ReentrantLock; /** * @author 百里 */ public class BaiLiIsShutdownThreadPoolDemo { /** * 创建一个最大线程数15的线程池 */ public static ThreadPoolExecutor pool = new ThreadPoolExecutor( 10, 15, 0L, TimeUnit.MILLISECONDS, new ArrayBlockingQueue\u0026lt;\u0026gt;(10)); /** * 线程执行方法，随机等待0到10秒 */ private static void sleepMethod(int index){ try { long sleepTime = new Double(Math.random() * 10000).longValue(); Thread.sleep(sleepTime); System.out.println(\u0026#34;当前线程执行结束: \u0026#34; + index); } catch (InterruptedException e) { e.printStackTrace(); } } private static int taskNum = 0; //计数器 /** * 方法四：公共计数 * @throws Exception */ public static void main(String[] args) throws Exception { Lock lock = new ReentrantLock(); for (int i = 0; i \u0026lt; 10; i++) { int index = i; pool.execute(() -\u0026gt; { sleepMethod(index); lock.lock(); taskNum++; lock.unlock(); }); } while(taskNum \u0026lt; 10) { Thread.sleep(1000); System.out.println(\u0026#34;还没停止。。。当前完成任务数:\u0026#34; + taskNum); } System.out.println(\u0026#34;全部执行完毕\u0026#34;); } } 这种实现其实就是通过加锁计数，然后循环判断。\n优缺点分析\n优点 ：手动维护方式更加灵活，对于一些特殊场景可以手动处理。 缺点 ：和CountDownLatch相比，一样需要知道线程数目，但是代码实现比较麻烦。 2.14.5 Future # 测试代码\npackage pool; import java.util.concurrent.*; import java.util.concurrent.locks.Lock; import java.util.concurrent.locks.ReentrantLock; /** * @author 百里 */ public class BaiLiIsShutdownThreadPoolDemo { /** * 创建一个最大线程数15的线程池 */ public static ThreadPoolExecutor pool = new ThreadPoolExecutor( 10, 15, 0L, TimeUnit.MILLISECONDS, new ArrayBlockingQueue\u0026lt;\u0026gt;(10)); /** * 线程执行方法，随机等待0到10秒 */ private static void sleepMethod(int index){ try { long sleepTime = new Double(Math.random() * 10000).longValue(); Thread.sleep(sleepTime); System.out.println(\u0026#34;当前线程执行结束: \u0026#34; + index); } catch (InterruptedException e) { e.printStackTrace(); } } /** * 方法五：Future * @throws Exception */ public static void main(String[] args) throws Exception { Future future = pool.submit(() -\u0026gt; sleepMethod(1)); while (!future.isDone()){ Thread.sleep(1000); System.out.println(\u0026#34;还没停止。。。\u0026#34;); } System.out.println(\u0026#34;全部执行完毕\u0026#34;); } } 优缺点分析\n优点：使用简单，不需要关闭线程池。 缺点：每个提交给线程池的任务都会关联一个Future对象，这可能会引入额外的内存开销。如果需要处理大量的任务，可能会占用较多的内存。 2.15 线程池中线程复用原理 # 线程池的线程复用原理是指，将线程放入线程池中重复利用，**而不是每执行一个任务就创建一个新线程。**线程池会对线程进行封装，核心原理在于将线程的创建和管理与任务的执行分离。 线程池通过工作队列（WorkQueue）来存储待执行的任务，队列中可能有多个任务等待被执行。线程池中的线程数量是有限的，核心线程数通常是固定的，最大线程数可以设置，超过最大线程数后，任务会被拒绝。 当提交任务时，线程池首先会检查当前线程数是否小于核心线程数，如果是，则新建一个线程来执行任务；如果当前线程数已经达到核心线程数，但队列中没有正在执行的任务，则将任务放入队列中等待执行；如果队列已满，且线程池中的线程数量未达到最大线程数，则新建线程来执行任务；如果队列已满，且线程池中的线程数量达到最大线程数，则根据拒绝策略来处理无法执行的任务。 线程复用的关键是将任务的提交和线程的创建、管理、执行分离，通过线程池来统一管理和调度，减少了创建和销毁线程的开销，提高了系统的效率。同时，由于线程池的复用特性，可以有效控制并发度，避免大量线程的创建和销毁导致的系统负载过大。\n线程池中线程异常后：销毁还是复用？\n当一个线程池里面的线程异常后:\n当执行方式是execute时,当执行任务出现异常，内部会抛出异常，进而就会导致线程中断而被移除掉，并且会创建一个新的线程填充到线程池中。\n当执行方式是submit时, 内部会把异常捕获住且不会抛出，所以就不会把这个线程移除掉，也不会创建新的线程放入到线程池中。\n2.16 Fork/join框架 # Fork/Join框架是一个用于并行化执行任务的框架，它是Java 7引入的一个新特性，专门用于方便地利用多核CPU的性能优势，通过分治法的策略来将任务分解为更小的子任务，然后并行执行这些子任务，最后再合并子任务的结果。 Fork/Join框架的核心是ForkJoinPool，它是一种特殊的线程池，它使用工作窃取算法（Work-Stealing）来平衡负载，使得每个线程尽可能均匀地执行任务。ForkJoinPool中维护了一个任务队列（WorkQueue），当一个线程执行完一个任务时，它会尝试从队列中取出一个新的任务来执行。如果队列为空，它会尝试从其他线程的任务队列中“窃取”任务。这种工作窃取算法使得任务能够被高效地重新分配，从而最大限度地利用系统资源。 与传统的线程池相比，Fork/Join框架具有以下不同：\n自动并行化：Fork/Join框架可以自动将任务分解为多个子任务，并并行执行这些子任务。这是通过Fork/Join框架的分治法策略实现的。而传统的线程池则需要程序员手动地将任务分解为多个子任务，并且需要自行管理这些子任务的执行。 工作窃取算法：Fork/Join框架使用工作窃取算法来平衡负载，使得每个线程尽可能均匀地执行任务。这种算法可以有效地重新分配任务，从而最大限度地利用系统资源。而传统的线程池则没有这种算法，它只是简单地按照先来先服务的原则执行任务。 集成阻塞队列：Fork/Join框架集成了阻塞队列（BlockingQueue），这种队列可以在需要时自动阻塞线程，直到队列中有新的任务可供执行。这种集成使得Fork/Join框架可以更高效地管理任务队列。而传统的线程池则需要程序员自行管理任务队列，或者使用其他第三方库来实现阻塞队列的功能。 总之，Fork/Join框架是一种专门用于并行化执行任务的框架，它通过分治法策略和自动并行化功能，使得程序员可以更方便地利用多核CPU的性能优势。与传统的线程池相比，Fork/Join框架具有更高的效率和更方便的使用方式。\n2.17 线程池的底层工作原理 # 线程池是一种用于管理和重用线程的机制，其底层工作原理涉及线程的创建、调度、执行以及回收等关键过程。线程池的底层工作原理可以分为以下几个关键步骤：\n线程池的创建： 在使用线程池之前，需要首先创建一个线程池。通常，线程池会根据配置参数（如核心线程数、最大线程数、队列类型等）来初始化线程池的基本属性。 任务提交： 当有任务需要执行时，将任务提交给线程池。任务可以是Runnable或Callable对象，表示需要在一个独立线程中执行的工作单元。 线程分配： 线程池内部维护了一组工作线程，这些线程会被动态分配来执行任务。线程池首先会尝试将任务分配给核心线程，如果核心线程数没有达到上限，就创建一个新的核心线程来执行任务。如果核心线程已满，任务会被放入任务队列中等待执行。 任务执行： 分配给线程的任务会被执行。每个工作线程会不断地从任务队列中获取任务并执行它们。一旦任务执行完成，线程可以选择等待新任务或被回收，具体取决于线程池的配置和实现方式。 线程回收： 线程池内的线程可能会被回收，这可以是根据一些策略，如闲置时间超过一定阈值或线程数超过最大线程数等。回收的线程会释放资源，如内存和CPU，以便在需要时重新使用。 任务完成和结果返回： 任务执行完成后，可以将执行结果返回给调用者。如果任务是通过Callable提交的，线程池会返回Future对象，通过该对象可以获取任务的执行结果。 异常处理： 线程池通常会处理任务执行过程中抛出的异常，可以将异常信息记录下来或采取适当的措施，以确保线程池的稳定性。 总的来说，线程池的底层工作原理是通过管理一组工作线程、任务队列和任务分配策略来实现任务的调度和执行。这种机制可以提高线程的重用性、提高程序性能，并有效地控制线程的生命周期，使得线程池成为多线程编程中的重要工具。\n2.18 线程池中影响性能的参数 # 线程池的性能受到以下参数的影响：\n核心线程数（corePoolSize）： 这是线程池中一直保持活动状态的最小线程数量。核心线程在空闲时不会被销毁，除非启用了 allowCoreThreadTimeOut 选项。核心线程数的设置直接影响了线程池的基本并发度。 最大线程数（maximumPoolSize）： 当任务提交到线程池时，首先会尝试使用已有的空闲线程来处理，如果没有空闲线程则根据需要创建新线程。最大线程数限制了线程池可以创建的最大线程数量，过高的设置可能会导致资源消耗过多。 keepAliveTime 和 TimeUnit： 这两个参数用于控制空闲线程的存活时间。如果线程在空闲时间超过 keepAliveTime 指定的时间段，它将被终止并从线程池中移除。合理的设置可以降低线程池的维护成本。 工作队列（workQueue）： 工作队列用于存储等待执行的任务。不同类型的工作队列（如有界队列或无界队列）对线程池的性能有一定影响。有界队列可以避免无限制的任务积压，但可能导致任务丢失，而无界队列可能会占用更多的内存。 这些参数的合理配置取决于实际情况，包括任务的数量、性质以及可用资源等因素。通过正确选择和调整这些参数，可以优化线程池的性能，确保它能够高效地处理任务并避免资源浪费。\n2.19 优化线程池的性能 # 要优化线程池的性能，需要根据实际情况进行参数配置。以下是一些优化建议：\n根据应用场景和任务性质，合理设置核心线程数（corePoolSize）和最大线程数（maximumPoolSize）。如果任务主要是IO密集型的，核心线程数可以设置为CPU核心数的两倍左右，最大线程数可以设置为CPU核心数的四倍左右。如果任务是CPU密集型的，核心线程数可以适当减少，最大线程数也可以适当减少。 根据任务性质和实际需求，选择合适的任务队列（workQueue）。例如，如果任务是CPU密集型的，可以选择容量较大的有界队列，以减少线程的创建和销毁；如果任务是I/O密集型的，可以选择容量较小的无界队列，以避免队列过小导致的任务拒绝问题。 根据系统资源和任务性质，合理设置线程的存活时间（keepAliveTime）。如果系统资源充足且任务性质不紧张，可以适当增加线程存活时间，以减少线程的创建和销毁；如果系统资源有限或任务性质较为紧张，可以适当减少线程存活时间，以减少线程的空闲时间。 根据实际需求，自定义线程工厂（threadFactory）和任务拒绝策略（handler）。可以通过实现自己的线程工厂来设置线程的名称、优先级等属性，以提高线程池的可维护性。当任务队列已满且线程数达到最大值时，可以使用任务拒绝策略来处理无法执行的任务，例如抛出异常、记录日志或尝试重新提交等。 总之，在优化线程池性能时，需要根据实际情况进行参数配置，并选择合适的队列类型和任务拒绝策略。同时，还需要注意系统资源的利用和线程池的可维护性。\n线程池中有哪些常见的阻塞队列 # 难易程度：☆☆☆\n出现频率：☆☆☆\nworkQueue - 当没有空闲核心线程时，新来任务会加入到此队列排队，队列满会创建救急线程执行任务\n比较常见的有4个，用的最多是ArrayBlockingQueue和LinkedBlockingQueue\n1.ArrayBlockingQueue：基于数组结构的有界阻塞队列，FIFO。\n2.LinkedBlockingQueue：基于链表结构的有界阻塞队列，FIFO。\n3.DelayedWorkQueue ：是一个优先级队列，它可以保证每次出队的任务都是当前队列中执行时间最靠前的\n4.SynchronousQueue：不存储元素的阻塞队列，每个插入操作都必须等待一个移出操作。\nArrayBlockingQueue的LinkedBlockingQueue区别\nLinkedBlockingQueue ArrayBlockingQueue 默认无界，支持有界 强制有界 底层是链表 底层是数组 是懒惰的，创建节点的时候添加数据 提前初始化 Node 数组 入队会生成新 Node Node需要是提前创建好的 两把锁（头尾） 一把锁 左边是LinkedBlockingQueue加锁的方式，右边是ArrayBlockingQueue加锁的方式\nLinkedBlockingQueue读和写各有一把锁，性能相对较好 ArrayBlockingQueue只有一把锁，读和写公用，性能相对于LinkedBlockingQueue差一些 参考回答\nJdk中提供了很多阻塞队列，开发中常见的有两个：ArrayBlockingQueue和LinkedBlockingQueue\nArrayBlockingQueue和LinkedBlockingQueue是Java中两种常见的阻塞队列，它们在实现和使用上有一些关键的区别。\n首先，ArrayBlockingQueue是一个有界队列，它在创建时必须指定容量，并且这个容量不能改变。而LinkedBlockingQueue默认是无界的，但也可以在创建时指定最大容量，使其变为有界队列。\n其次，它们在内部数据结构上也有所不同。ArrayBlockingQueue是基于数组实现的，而LinkedBlockingQueue则是基于链表实现的。这意味着ArrayBlockingQueue在访问元素时可能会更快，因为它可以直接通过索引访问数组中的元素。而LinkedBlockingQueue则在添加和删除元素时可能更快，因为它不需要移动其他元素来填充空间。\n另外，它们在加锁机制上也有所不同。ArrayBlockingQueue使用一把锁来控制对队列的访问，这意味着读写操作都是互斥的。而LinkedBlockingQueue则使用两把锁，一把用于控制读操作，另一把用于控制写操作，这样可以提高并发性能。\n如何确定核心线程数 # 难易程度：☆☆☆☆\n出现频率：☆☆☆\n在设置核心线程数之前，需要先熟悉一些执行线程池执行任务的类型\nIO密集型任务 一般来说：文件读写、DB读写、网络请求等\n推荐：核心线程数大小设置为2N+1 （N为计算机的CPU核数）\nCPU密集型任务 一般来说：计算型代码、Bitmap转换、Gson转换等\n推荐：核心线程数大小设置为N+1 （N为计算机的CPU核数）\njava代码查看CPU核数\n参考回答\n① 高并发、任务执行时间短 \u0026ndash;\u0026gt;（ CPU核数+1 ），减少线程上下文的切换\n② 并发不高、任务执行时间长\nIO密集型的任务 \u0026ndash;\u0026gt; (CPU核数 * 2 + 1) 计算密集型任务 \u0026ndash;\u0026gt; （ CPU核数+1 ） ③ 并发高、业务执行时间长，解决这种类型任务的关键不在于线程池而在于整体架构的设计，看看这些业务里面某些数据是否能做缓存是第一步，增加服务器是第二步，至于线程池的设置，设置参考（2）\n线程池的种类有哪些 # 难易程度：☆☆☆\n出现频率：☆☆☆\n在java.util.concurrent.Executors类中提供了大量创建连接池的静态方法，常见就有四种\n创建使用固定线程数的线程池 核心线程数与最大线程数一样，没有救急线程 阻塞队列是LinkedBlockingQueue，最大容量为Integer.MAX_VALUE 适用场景：适用于任务量已知，相对耗时的任务 案例： public class FixedThreadPoolCase { static class FixedThreadDemo implements Runnable{ @Override public void run() { String name = Thread.currentThread().getName(); for (int i = 0; i \u0026lt; 2; i++) { System.out.println(name + \u0026#34;:\u0026#34; + i); } } } public static void main(String[] args) throws InterruptedException { //创建一个固定大小的线程池，核心线程数和最大线程数都是3 ExecutorService executorService = Executors.newFixedThreadPool(3); for (int i = 0; i \u0026lt; 5; i++) { executorService.submit(new FixedThreadDemo()); Thread.sleep(10); } executorService.shutdown(); } } 单线程化的线程池，它只会用唯一的工作线程来执行任 务，保证所有任务按照指定顺序(FIFO)执行 核心线程数和最大线程数都是1 阻塞队列是LinkedBlockingQueue，最大容量为Integer.MAX_VALUE 适用场景：适用于按照顺序执行的任务 案例： public class NewSingleThreadCase { static int count = 0; static class Demo implements Runnable { @Override public void run() { count++; System.out.println(Thread.currentThread().getName() + \u0026#34;:\u0026#34; + count); } } public static void main(String[] args) throws InterruptedException { //单个线程池，核心线程数和最大线程数都是1 ExecutorService exec = Executors.newSingleThreadExecutor(); for (int i = 0; i \u0026lt; 10; i++) { exec.execute(new Demo()); Thread.sleep(5); } exec.shutdown(); } } 可缓存线程池 核心线程数为0 最大线程数是Integer.MAX_VALUE 阻塞队列为SynchronousQueue:不存储元素的阻塞队列，每个插入操作都必须等待一个移出操作。 适用场景：适合任务数比较密集，但每个任务执行时间较短的情况 案例： public class CachedThreadPoolCase { static class Demo implements Runnable { @Override public void run() { String name = Thread.currentThread().getName(); try { //修改睡眠时间，模拟线程执行需要花费的时间 Thread.sleep(100); System.out.println(name + \u0026#34;执行完了\u0026#34;); } catch (InterruptedException e) { e.printStackTrace(); } } } public static void main(String[] args) throws InterruptedException { //创建一个缓存的线程，没有核心线程数，最大线程数为Integer.MAX_VALUE ExecutorService exec = Executors.newCachedThreadPool(); for (int i = 0; i \u0026lt; 10; i++) { exec.execute(new Demo()); Thread.sleep(1); } exec.shutdown(); } } 提供了“延迟”和“周期执行”功能的ThreadPoolExecutor。 适用场景：有定时和延迟执行的任务 案例： public class ScheduledThreadPoolCase { static class Task implements Runnable { @Override public void run() { try { String name = Thread.currentThread().getName(); System.out.println(name + \u0026#34;, 开始：\u0026#34; + new Date()); Thread.sleep(1000); System.out.println(name + \u0026#34;, 结束：\u0026#34; + new Date()); } catch (InterruptedException e) { e.printStackTrace(); } } } public static void main(String[] args) throws InterruptedException { //按照周期执行的线程池，核心线程数为2，最大线程数为Integer.MAX_VALUE ScheduledExecutorService scheduledThreadPool = Executors.newScheduledThreadPool(2); System.out.println(\u0026#34;程序开始：\u0026#34; + new Date()); /** * schedule 提交任务到线程池中 * 第一个参数：提交的任务 * 第二个参数：任务执行的延迟时间 * 第三个参数：时间单位 */ scheduledThreadPool.schedule(new Task(), 0, TimeUnit.SECONDS); scheduledThreadPool.schedule(new Task(), 1, TimeUnit.SECONDS); scheduledThreadPool.schedule(new Task(), 5, TimeUnit.SECONDS); Thread.sleep(5000); // 关闭线程池 scheduledThreadPool.shutdown(); } } 参考回答\n在jdk中默认提供了4中方式创建线程池\n第一个是：newCachedThreadPool创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回 收空闲线程，若无可回收，则新建线程。\n第二个是：newFixedThreadPool 创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列 中等待。\n第三个是：newScheduledThreadPool 创建一个定长线程池，支持定时及周期性任务执行。\n第四个是：newSingleThreadExecutor 创建一个单线程化的线程池，它只会用唯一的工作线程来执行任 务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。\n为什么不建议用Executors创建线程池 # 难易程度：☆☆☆\n出现频率：☆☆☆\n参考阿里开发手册《Java开发手册-嵩山版》\n参考回答\n其实这个事情在阿里提供的最新开发手册《Java开发手册-嵩山版》中也提到了\n主要原因是如果使用Executors创建线程池的话，它允许的请求队列默认长度是Integer.MAX_VALUE，这样的话，有可能导致堆积大量的请求，从而导致OOM（内存溢出）。\n所以，我们一般推荐使用ThreadPoolExecutor来创建线程池，这样可以明确规定线程池的参数，避免资源的耗尽。\nFuture # 3.1 Future # Future 类是异步思想的典型运用，主要用在一些需要执行耗时任务的场景，避免程序一直原地等待耗时任务执行完成，执行效率太低。具体来说是这样的：当我们执行某一耗时的任务时，可以将这个耗时任务交给一个子线程去异步执行，同时我们可以干点其他事情，不用傻傻等待耗时任务执行完成。等我们的事情干完后，我们再通过 Future 类获取到耗时任务的执行结果。这样一来，程序的执行效率就明显提高了。\n这其实就是多线程中经典的 Future 模式，你可以将其看作是一种设计模式，核心思想是异步调用，主要用在多线程领域，并非 Java 语言独有。\n在 Java 中，Future 类只是一个泛型接口，位于 java.util.concurrent 包下，其中定义了 5 个方法，主要包括下面这 4 个功能：\n取消任务； 判断任务是否被取消; 判断任务是否已经执行完成; 获取任务执行结果。 // V 代表了Future执行的任务返回值的类型 public interface Future\u0026lt;V\u0026gt; { // 取消任务执行 // 成功取消返回 true，否则返回 false boolean cancel(boolean mayInterruptIfRunning); // 判断任务是否被取消 boolean isCancelled(); // 判断任务是否已经执行完成 boolean isDone(); // 获取任务执行结果 V get() throws InterruptedException, ExecutionException; // 指定时间内没有返回计算结果就抛出 TimeOutException 异常 V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutExceptio } 简单理解就是：我有一个任务，提交给了 Future 来处理。任务执行期间我自己可以去做任何想做的事情。并且，在这期间我还可以取消任务以及获取任务的执行状态。一段时间之后，我就可以 Future 那里直接取出任务执行结果。\n3.2 Callable和Future # 我们可以通过 FutureTask 来理解 Callable 和 Future 之间的关系。\nFutureTask 提供了 Future 接口的基本实现，常用来封装 Callable 和 Runnable，具有取消任务、查看任务是否执行完成以及获取任务执行结果的方法。ExecutorService.submit() 方法返回的其实就是 Future 的实现类 FutureTask 。\n\u0026lt;T\u0026gt; Future\u0026lt;T\u0026gt; submit(Callable\u0026lt;T\u0026gt; task); Future\u0026lt;?\u0026gt; submit(Runnable task); FutureTask 不光实现了 Future接口，还实现了Runnable 接口，因此可以作为任务直接被线程执行。\n","date":"18 March 2025","externalUrl":null,"permalink":"/posts/1742270597263-java-threadlocal/","section":"Posts","summary":"","title":"java ThreadLocal","type":"posts"},{"content":" 多线程 # 多线程是指从软件或者硬件上实现多个线程并发执行的技术。\n具有多线程能力的计算机因有硬件支持而能够在同一时间执行多个线程，提升性能。\n1.1 并发与并行 # 并发与并行的区别\n并发：两个及两个以上的作业在同一 时间段 内执行，即多个指令在单个CPU上交替执行。 并行：两个及两个以上的作业在同一 时刻 执行，即多个指令在多个CPU上同时执行。 最关键的点是：是否是 同时 执行。\n并发针对单核 CPU 而言，它指的是 多个任务交替执行，每个任务都会在一段时间内执行一部分，然后切换到另一个任务，因为单核 CPU 一次只能执行一个任务。并发的目的是提高系统的响应性和吞吐量，允许多个任务在同一个处理器上共享时间片。 并行针对多核 CPU 而言，它指的是多个任务真正同时执行，每个任务都有自己的处理器核心，它们可以在同一时刻执行不同的指令。并行的目的是提高计算能力和性能，允许多个任务同时处理，以加快任务完成的速度。 单核 CPU 只能并发，无法并行；换句话说，并行只可能发生在多核 CPU 中。在多核 CPU 中，并发和并行通常会同时存在。多个任务可以在不同的核心上并行执行，并且每个任务内部可能也包含并发的逻辑，以处理不同的子任务。这样可以最大程度地提高系统的性能和响应性。\n同步和异步的区别\n同步：发出一个调用之后，在没有得到结果之前， 该调用就不可以返回，一直等待。 异步：调用在发出之后，不用等待返回结果，该调用直接返回。 1.1.1 并发中的可见性 # Java并发可见性指的是多线程并发访问共享变量时，对变量的更改能够被其他线程及时感知，即在一个线程修改变量后，其他线程能够立即看到这个变量的修改结果：\n当线程A读取变量i的值时，会从内存中读取数据，并缓存一份在CPU1内部的高速缓存中，然后线程1修改i，改为i=2，但是还没有回写到内存，此时线程B也来读取i，那么也会从内存读取，读到的i仍然为1，此时就出现了可见性问题。\n在Java中，可以volatile关键字来保证变量的可见性，对于加了volatile的变量，线程在读取该变量时会直接从内存中读取，再修改该变量时会同时修改CPU高速缓存和内存中的值。\n1.1.2 并发中的原子性 # Java并发原子性指的是在多线程并发的情况下，一段代码或操作要么完全执行成功，要么完全不执行，不出现执行一半被其他线程打断或干扰的情况。换句话说，就是对同一个变量的多个操作能够像原子操作一样，保证多线程环境下的数据一致性，避免出现数据竞争和脏数据等问题。\n由于CPU、内存、IO（磁盘、网络）之间的性能差距，为了能充分利用CPU，当线程执行IO操作时，线程会让出CPU，使得CPU去执行其他线程的指令，并且本身来说，为了达到线程并发执行的效果，CPU也会按固定时间片来切换执行不同线程。\n当我们执行i++这行代码时，底层其实对应的是三条指令：\n从内存中读取i的值 对i+1 写回i的值到CPU高速缓存 但是有可能执行线程A执行了第1条指令后，就发生了线程切换，线程A相当于暂停执行，此时如果有另外一个线程B也在执行i++，并且把3条执行都执行完了，那么线程B得到的结果是i=2，然后线程A又切换回来继续执行，最终导致线程A得到的i也为2，正常来说i应该等于3的，这就是原子性问题。\nJava中我们需要通过各种锁机制来保证原子性.\n1.1.3 并发中的有序性 # Java并发有序性指的是多个线程执行的指令和操作，按照开发者编写程序的顺序或者预定的顺序进行执行。多线程并发执行时，可能会发生指令的重排，导致程序的执行顺序与预期不一致，从而出现数据竞争和线程安全问题。\n编译器有时为了进行编译优化，会进行指令重排序，比如：\nnew Person(); 这行代码会分为三步：\n申请内存空间 在内存空间初始化Person对象相关的内容 返回内存空间地址 但是编译有可能会优化为：\n申请内存空间 返回内存空间地址 在内存空间初始化Person对象相关的内容 所以对于我们的单例模式实现：\npublic class Person { static Person instance; static Person getInstance(){ if (instance == null) { synchronized(Person.class) { if (instance == null) instance = new Person(); } } return instance; } } 就算了用DCL可能也会有问题，比如线程A拿到锁后，在new Person()时，第二步就返回了内存地址并赋值给了instance变量，此时线程B来执行getInstance()，直接就判断出了instance不为空，但是instance对于的对象其实是还没有初始化的，里面的成员变量可能为null。\n我们可以通过锁机制或者volatile来保证有序性。\n1.1.4 并发中的条件等待队列 # 当一个线程加到锁之后，可能并不能立马执行业务逻辑，得在满足某个条件后才能执行，比如对于阻塞队列而言，当我们要条件元素时，会先加锁，加到锁之后，会判断队列是否满了，如果队列满了则需要阻塞当前线程并等待队列有空位，这样当前线程会进入条件等待队列，同时有可能其他线程也会进入此条件等待队列，而一旦队列有元素出队了，那么会可以唤醒条件等待队列中的某一个线程了，使得该线程去执行它的入队操作。\n所以条件等待队列就是针对某一条件，如果线程在没有满足此条件下需要阻塞就可以加入到该条件等待队列进行等待。\n1.1.5 JAVA中用到的线程调度算法 # **在Java中，线程调度采用的是一种抢占式调度模型。**这就像在一个抢夺战中，有较高优先级的线程将首先占用CPU资源。如果线程具有相同的优先级，那么Java虚拟机会随机选择一个线程来执行，以保持公平竞争的原则。一旦一个线程获得了CPU，它将一直运行，直到自愿放弃CPU资源，或者由于某些情况（比如等待I/O操作、等待锁等）被迫放弃CPU，从而让其他线程有机会执行。 这种抢占式调度模型的目标是确保具有较高优先级的线程在争夺CPU资源时具有优势，但仍然让较低优先级的线程有机会执行，以避免它们被永远地忽略。Java的多线程调度机制有助于平衡线程之间的竞争和公平性，从而提高了多线程程序的响应速度和效率。\n1.1.6 不可变对象 # 不可变对象（Immutable object）是一种一旦创建后其状态就不能被修改的对象。在Java中，不可变对象包括String、基本类型的包装类（如Integer、Double等）等。 不可变对象对写并发有如下帮助：\n线程安全：不可变对象是线程安全的，因为它们不会被其他线程修改。因此，多个线程可以同时使用不可变对象，无需额外的同步措施。 减少锁竞争：由于不可变对象的状态不能被修改，因此不需要使用锁来保护对它的访问。这减少了锁竞争的可能性，从而提高了程序的性能。 缓存优化：由于不可变对象一旦创建后其状态就不能被修改，因此可以将它们用作缓存项。这是因为缓存项的值不会在缓存和使用之间发生改变，从而避免了因缓存项状态被修改而导致的缓存失效问题。 需要注意的是，虽然不可变对象有以上优点，但它们也有一些缺点。例如，创建新的不可变对象比创建可变对象需要更多的内存，因为每次状态改变都需要创建新的对象。因此，在设计并发应用时，应根据具体需求和性能要求来决定是否使用不可变对象。\n1.2 为什么要使用多线程 # 先从总体上来说：\n从计算机底层来说： 线程可以比作是轻量级的进程，是程序执行的最小单位,线程间的切换和调度的成本远远小于进程。另外，多核 CPU 时代意味着多个线程可以同时运行，这减少了线程上下文切换的开销。\n从当代互联网发展趋势来说： 现在的系统动不动就要求百万级甚至千万级的并发量，而多线程并发编程正是开发高并发系统的基础，利用好多线程机制可以大大提高系统整体的并发能力以及性能。\n再深入到计算机底层来探讨：\n单核时代：在单核时代多线程主要是为了提高单进程利用 CPU 和 IO 系统的效率。 假设只运行了一个 Java 进程的情况，当我们请求 IO 的时候，如果 Java 进程中只有一个线程，此线程被 IO 阻塞则整个进程被阻塞。CPU 和 IO 设备只有一个在运行，那么可以简单地说系统整体效率只有 50%。当使用多线程的时候，一个线程被 IO 阻塞，其他线程还可以继续使用 CPU。从而提高了 Java 进程利用系统资源的整体效率。\n多核时代: 多核时代多线程主要是为了提高进程利用多核 CPU 的能力。举个例子：假如我们要计算一个复杂的任务，我们只用一个线程的话，不论系统有几个 CPU 核心，都只会有一个 CPU 核心被利用到。而创建多个线程，这些线程可以被映射到底层多个 CPU 核心上执行，在任务中的多个线程没有资源竞争的情况下，任务执行的效率会有显著性的提高，约等于（单核时执行时间/CPU 核心数）。\n1.2.1 单核CPUI支持多线程吗？ # 单核 CPU 是支持 Java 多线程的。操作系统通过时间片轮转的方式，将 CPU 的时间分配给不同的线程。尽管单核 CPU 一次只能执行一个任务，但通过快速在多个线程之间切换，可以让用户感觉多个任务是同时进行的。\n这里顺带提一下 Java 使用的线程调度方式。\n操作系统主要通过两种线程调度方式来管理多线程的执行：\n抢占式调度（Preemptive Scheduling）：操作系统决定何时暂停当前正在运行的线程，并切换到另一个线程执行。这种切换通常是由系统时钟中断（时间片轮转）或其他高优先级事件（如 I/O 操作完成）触发的。这种方式存在上下文切换开销，但公平性和 CPU 资源利用率较好，不易阻塞。 协同式调度（Cooperative Scheduling）：线程执行完毕后，主动通知系统切换到另一个线程。这种方式可以减少上下文切换带来的性能开销，但公平性较差，容易阻塞。 Java 使用的线程调度是抢占式的。也就是说，JVM 本身不负责线程的调度，而是将线程的调度委托给操作系统。操作系统通常会基于线程优先级和时间片来调度线程的执行，高优先级的线程通常获得 CPU 时间片的机会更多。\n1.2.2 单核CPU上运行多个线程效率一定会高吗？ # 单核 CPU 同时运行多个线程的效率是否会高，取决于线程的类型和任务的性质。一般来说，有两种类型的线程：\nCPU 密集型：CPU 密集型的线程主要进行计算和逻辑处理，需要占用大量的 CPU 资源。 IO 密集型：IO 密集型的线程主要进行输入输出操作，如读写文件、网络通信等，需要等待 IO 设备的响应，而不占用太多的 CPU 资源。 在单核 CPU 上，同一时刻只能有一个线程在运行，其他线程需要等待 CPU 的时间片分配。如果线程是 CPU 密集型的，那么多个线程同时运行会导致频繁的线程切换，增加了系统的开销，降低了效率。如果线程是 IO 密集型的，那么多个线程同时运行可以利用 CPU 在等待 IO 时的空闲时间，提高了效率。\n因此，对于单核 CPU 来说，如果任务是 CPU 密集型的，那么开很多线程会影响效率；如果任务是 IO 密集型的，那么开很多线程会提高效率。当然，这里的“很多”也要适度，不能超过系统能够承受的上限。\n线程数设定成多少合适？\n计算密集型任务：建议线程数 = CPU核心数。例如，假设有8核CPU，可以启动8个线程来充分利用所有CPU资源。 I/O密集型任务：建议线程数稍高于核心数，通常采用的策略是线程数 = 核心数 * (1 + 线程等待时间/线程计算时间)。 1.2.3 使用多线程可能带来什么问题？ # 并发编程的目的就是为了能提高程序的执行效率进而提高程序的运行速度，但是并发编程并不总是能提高程序运行速度的，而且并发编程可能会遇到很多问题，比如：内存泄漏、死锁、线程不安全等等。\n1.2.4 如何理解线程安全和不安全？ # 线程安全和不安全是在多线程环境下对于同一份数据的访问是否能够保证其正确性和一致性的描述。\n线程安全指的是在多线程环境下，对于同一份数据，不管有多少个线程同时访问，都能保证这份数据的正确性和一致性。 线程不安全则表示在多线程环境下，对于同一份数据，多个线程同时访问时可能会导致数据混乱、错误或者丢失。 1.2.5 如何确保线程安全 # 确保线程安全可以通过多种方法和技术来实现。以下是一些常用的方法：\n**使用synchronized关键字：**synchronized关键字可以确保同一时刻只有一个线程可以执行某个代码块，从而避免了多个线程同时访问和修改共享资源的问题。 **使用Atomic类：**Java提供了多个原子类，如AtomicInteger、AtomicLong等，它们可以保证对基本数据类型的原子性操作，避免了使用synchronized关键字和volatile关键字的限制。 **使用ReentrantLock类：**ReentrantLock类是Java提供的一种可重入锁，与synchronized关键字类似，但它提供了更多的灵活性和功能。 **使用线程安全的数据结构：**Java提供了多种线程安全的数据结构，如ConcurrentHashMap、CopyOnWriteArrayList等，这些数据结构内部已经实现了线程安全，可以直接使用。 **使用线程池：**线程池可以避免创建和销毁线程的开销，并且可以有效地控制并发量，保证线程安全。 避免共享状态： 如果可能，尽量避免多个线程共享状态。将数据封装在线程内部，减少共享数据的需求。 使用线程安全的设计模式： 了解并应用线程安全的设计模式，如单例模式中的双重检查锁定等。 在实现线程安全时，还需要考虑其他问题，如避免死锁、合理地控制并发量等。同时，应该避免使用非线程安全的数据结构和方法，避免使用可能会引起竞态条件和数据不一致的操作。\n1.3 守护线程 # 相关方法\n方法名 说明 void setDaemon(boolean on) 将此线程标记为守护线程，当运行的线程都是守护线程时，Java虚拟机将退出 守护线程是在程序运行时在后台提供一种支持性的线程。与普通线程相比，守护线程有以下几个区别：\n终止条件：当所有用户线程结束时，守护线程会自动停止。换句话说，守护线程不会阻止程序的终止，即使它们还没有执行完任务。 生命周期：守护线程的生命周期与主线程或其他用户线程无关。当所有的非守护线程都结束时，JVM 将会退出并停止守护线程的执行。 线程优先级：守护线程的优先级默认与普通线程一样。优先级较高的守护线程也不能够保证在其他线程之前执行。 资源回收：守护线程通常被用于执行一些后台任务，例如垃圾回收、日志记录、定时任务等。当只剩下守护线程时，JVM 会自动退出并且不会等待守护线程执行完毕。 需要注意的是，守护线程与普通线程在编写代码时没有太大的区别。可以通过将线程的setDaemon(true)方法设置为 true，将普通线程转换为守护线程。 总结起来，守护线程在程序运行过程中提供了一种支持性的服务，会在所有的用户线程结束时自动停止。\n1.3.1 守护线程与本地线程的区别 # 守护线程，可以看作是为其他线程提供服务的辅助工具。它们通常执行一些后台任务，比如垃圾回收、定期检查、日志记录等。一个重要的特点是它们不会阻止JVM的退出。当所有的本地线程都执行完毕后，JVM会自动退出，不会等待守护线程。 本地线程，则是应用程序的主力军，执行着应用的核心逻辑。它们的存在会阻止JVM退出，因为只要还有本地线程在运行，JVM会继续工作。 至于如何创建它们，守护线程需要通过设置 setDaemon(true) 来告诉JVM它是守护线程。而本地线程则是默认的线程类型，不需要额外设置。\n1.4 懒汉模式和饿汉模式 # 懒汉模式和饿汉模式都是单例模式的实现方式，用于确保一个类只有一个实例存在。\n懒汉模式：在首次使用时才进行对象的初始化，延迟加载实例。它可以避免不必要的资源消耗，但在多线程环境下需要考虑线程安全和同步开销。 饿汉模式：在类加载时就进行对象的初始化，无论是否需要。它通过类加载机制保证线程安全性，而且获取实例的性能开销较小。但它没有延迟加载的特性，可能浪费一些资源。 选择懒汉模式还是饿汉模式取决于具体需求。如果需要延迟加载且对性能要求不高，可以选择懒汉模式。如果要通过类加载机制保证线程安全且对象创建成本较低，可以选择饿汉模式。也可以结合两种模式的优点，使用双重检查锁、静态内部类等方式实现单例模式，提高线程安全性和性能。\n1.5 线程优先级 # 线程调度\n两种调度方式\n分时调度模型：所有线程轮流使用 CPU 的使用权，平均分配每个线程占用 CPU 的时间片 抢占式调度模型：优先让优先级高的线程使用 CPU，如果线程的优先级相同，那么会随机选择一个，优先级高的线程获取的 CPU 时间片相对多一些 Java使用的是抢占式调度模型\n随机性\n假如计算机只有一个 CPU，那么 CPU 在某一个时刻只能执行一条指令，线程只有得到CPU时间片，也就是使用权，才可以执行指令。所以说多线程程序的执行是有随机性，因为谁抢到CPU的使用权是不一定的\n优先级相关方法\n方法名 说明 final int getPriority() 返回此线程的优先级 final void setPriority(int newPriority) 更改此线程的优先级线程默认优先级是5；线程优先级的范围是：1-10 1.5.1 有三个线程T1,T2,T3,如何保证顺序执行 # 确保三个线程 T1、T2、T3 按照指定顺序执行有多种方式。以下是其中一些常见的方式：\n使用 join() 方法： 可以在每个线程内部使用 join() 方法来等待前一个线程执行完成。具体操作是在线程 T2 的 run() 方法中调用 T1.join()，在线程 T3 的 run() 方法中调用 T2.join()。这样可以确保 T1 在 T2 之前执行，T2 在 T3 之前执行。 Thread T1 = new Thread(() -\u0026gt; { // 线程 T1 的任务 }); Thread T2 = new Thread(() -\u0026gt; { try { T1.join(); // 等待 T1 执行完成 } catch (InterruptedException e) { e.printStackTrace(); } // 线程 T2 的任务 }); Thread T3 = new Thread(() -\u0026gt; { try { T2.join(); // 等待 T2 执行完成 } catch (InterruptedException e) { e.printStackTrace(); } // 线程 T3 的任务 }); T1.start(); T2.start(); T3.start(); 使用 CountDownLatch： 可以使用 CountDownLatch 来控制线程的执行顺序。创建一个 CountDownLatch 对象，设置初始计数为 2，分别在 T1 和 T2 的线程内等待计数器减少到 0，然后释放 T3 线程，该方法也可用于保证线程同时执行。 CountDownLatch latch1 = new CountDownLatch(1); CountDownLatch latch2 = new CountDownLatch(1); Thread t1 = new Thread(() -\u0026gt; { System.out.println(\u0026#34;T1 running.\u0026#34;); latch1.countDown(); // T1 执行完后释放 latch1 }); Thread t2 = new Thread(() -\u0026gt; { try { latch1.await(); // 等待 latch1 的释放 System.out.println(\u0026#34;T2 running.\u0026#34;); latch2.countDown(); // T2 执行完后释放 latch2 } catch (InterruptedException e) { e.printStackTrace(); } }); Thread t3 = new Thread(() -\u0026gt; { try { latch2.await(); // 等待 latch2 的释放 System.out.println(\u0026#34;T3 running.\u0026#34;); } catch (InterruptedException e) { e.printStackTrace(); } }); t1.start(); t2.start(); t3.start(); 使用 LockSupport： 可以使用LockSupport的park和unpark来控制线程的执行顺序。 CountDownLatch latch1 = new CountDownLatch(1); CountDownLatch latch2 = new CountDownLatch(1); Thread t1 = new Thread(() -\u0026gt; { System.out.println(\u0026#34;T1 running.\u0026#34;); latch1.countDown(); // T1 执行完后释放 latch1 }); Thread t2 = new Thread(() -\u0026gt; { try { latch1.await(); // 等待 latch1 的释放 System.out.println(\u0026#34;T2 running.\u0026#34;); latch2.countDown(); // T2 执行完后释放 latch2 } catch (InterruptedException e) { e.printStackTrace(); } }); Thread t3 = new Thread(() -\u0026gt; { try { latch2.await(); // 等待 latch2 的释放 System.out.println(\u0026#34;T3 running.\u0026#34;); } catch (InterruptedException e) { e.printStackTrace(); } }); t1.start(); t2.start(); t3.start(); [!CAUTION]\n我们可以通过使用ReentrantLock以及3个Condition来实现三个线程有序交错进行。\n1.6 伪共享问题 # 伪共享（False Sharing）是多线程编程中的一个重要性能问题，尤其在多核处理器中尤为显著。了解如何因共享缓存行引起的无谓性能消耗，从而有效规避，是编写高效并发程序的关键。\n1.6.1 伪共享的核心概念 # 在现代处理器中，缓存行（Cache Line）是缓存的最小可分配单位，通常是64字节。当多个线程在不同CPU核心上操作缓存行中的不同变量时，如果这些变量位于同一个缓存行，修改其中一个变量会导致整个缓存行被标记为无效(cpu缓存一致性决定)。这种重复的缓存行无效化和重新加载的现象就是伪共享。 它的本质问题在于：虽然多个线程操作的是物理上不同的数据，但由于它们共享了同一个缓存行，造成不必要的缓存同步，导致性能下降。\n代码示例：\npublic class FalseSharingExample implements Runnable { // 定义线程数 public static int NUM_THREADS = 4; public static final long ITERATIONS = 5000000000L; // 每个线程的迭代次数 private final int arrayIndex; // 此线程操作的共享数据索引 private static ValuePadding[] values; // 用于存储共享数据 public FalseSharingExample(int arrayIndex) { this.arrayIndex = arrayIndex; } public static void main(final String[] args) throws InterruptedException { Thread[] threads = new Thread[NUM_THREADS]; // 初始化共享变量数组 values = new ValuePadding[NUM_THREADS]; for (int i = 0; i \u0026lt; values.length; i++) { values[i] = new ValuePadding(); } final long start = System.nanoTime(); for (int i = 0; i \u0026lt; threads.length; i++) { threads[i] = new Thread(new FalseSharingExample(i)); } for (Thread t : threads) { t.start(); } for (Thread t : threads) { t.join(); } System.out.println(\u0026#34;Duration = \u0026#34; + (System.nanoTime() - start)); } @Override public void run() { long i = ITERATIONS + 1; while (0 != --i) { // 更新当前线程对应的共享变量 values[arrayIndex].value = i; } } // 内部类，带有缓存行填充以避免伪共享 public static class ValuePadding { protected long p1, p2, p3, p4, p5, p6, p7; // 填充字段 public volatile long value = 0L; // 实际操作的变量 protected long p9, p10, p11, p12, p13, p14, p15; // 填充字段 } // @Contended注释的使用演示，如果使用该注解，需要加启动参数启用 -XX:-RestrictContended /* public static class ValueWithContended { @Contended public volatile long value = 0L; } */ } 代码的详细解释\nValuePadding 类的设计： 这里使用了ValuePadding类来存储每个线程要操作的共享变量value。 通过在value字段的前后添加几个填充字段（p1到p7和p9到p15），每个ValuePadding对象会占据多个缓存行，从而使value与相邻的对象实际分离至不同的缓存行。 这可以有效防止多个线程不必要地共享同一缓存行（即避免伪共享），从而提升程序的并发性能。 主程序的执行流程： 主线程启动了多个工作线程，每个线程负责增加自己的ValuePadding实例中的value。 每个线程访问和更新values数组中的一个ValuePadding实例，由于填充字段的存在，每个线程访问的value字段分布在不同缓存行上，尽可能减少缓存争用。 代码运行效率： 如果不采用填充策略，不同线程可能会因共享同一缓存行而导致频繁的缓存无效化和重新加载，造成性能的严重下降。 通过填充确保每个value字段在不同缓存行上，甚至在高并发下也能高效执行，从而减少伪共享。 1.6.2 总结 # 伪共享问题的解决尤其适合在性能敏感的大规模并发应用中。通过了解缓存行的基本原理并采取适当的填充策略，可以有效减少缓存行争用带来的性能开销，从而在不改变逻辑操作的前提下实现更佳的性能。注意，Java8还提供@Contended注解用于更高级的填充，但使用它需要相应的JVM参数配置支持。\n1.7 线程之间的通信 # 当我们处理线程通信时，通常有两种主要的实现方式，每种方式都有其独特的机制和优势： 共享内存： 这是一种常见的方式，多个线程可以访问同一个共享内存区域，通过读取和写入共享内存中的数据来进行通信和同步。在Java中，我们可以使用共享变量或共享数据结构来实现共享内存通信。例如，可以使用 volatile 关键字来确保共享变量的可见性，以及使用等待和通知机制，即 wait() 和 notify() 方法，来实现线程之间的协作。这种方式适用于需要高效共享数据的场景，但需要谨慎处理数据竞争和同步问题。 消息传递： 另一种方式是消息传递，多个线程之间通过消息队列、管道、信号量等机制来传递信息和同步状态。这种方式通常涉及线程之间的显式消息发送和接收操作，使线程能够协调它们的工作。例如，我们可以使用信号量机制，通过获取和释放许可证来控制线程的访问。又或者使用栅栏机制，通过等待所有线程达到栅栏点来同步它们的执行。此外，锁机制也是一种重要的消息传递方式，通过获取和释放锁来实现线程之间的互斥和同步。消息传递的优点在于可以实现更松散的耦合，线程之间不需要直接共享内存，从而减少了潜在的竞争条件。\n","date":"18 March 2025","externalUrl":null,"permalink":"/posts/1742270530770-java-%E5%A4%9A%E7%BA%BF%E7%A8%8B/","section":"Posts","summary":"","title":"java 多线程","type":"posts"},{"content":"an example to get you started\n并发编程 # 1.1 Java并发编程三大特性 # 原子性 可见性 有序性 1.1.1 原子性 # 一个线程在CPU中操作不可暂停，也不可中断，要不执行完成，要不不执行\n比如，如下代码能保证原子性吗？\n以上代码会出现超卖或者是一张票卖给同一个人，执行并不是原子性的\n解决方案：\n1.synchronized：同步加锁\n2.JUC里面的lock：加锁\n1.1.2 内存可见性 # 内存可见性：让一个线程对共享变量的修改对另一个线程可见\n比如，以下代码不能保证内存可见性\n解决方案：\nsynchronized volatile（推荐） LOCK 1.1.3 有序性 # 指令重排：处理器为了提高程序运行效率，可能会对输入代码进行优化，它不保证程序中各个语句的执行先后顺序同代码中的顺序一致，但是它会保证程序最终执行结果和代码顺序执行的结果是一致的\n还是之前的例子，如下代码：\n解决方案：\nvolatile 导致并发程序出现问题的根本原因是什么\n参考回答\nJava并发编程有三大核心特性，分别是原子性、可见性和有序性。\n首先，原子性指的是一个线程在CPU中的操作是不可暂停也不可中断的，要么执行完成，要么不执行。比如，一些简单的操作如赋值可能是原子的，但复合操作如自增就不是原子的。为了保证原子性，我们可以使用synchronized关键字或JUC里面的Lock来进行加锁。\n其次，可见性是指让一个线程对共享变量的修改对另一个线程可见。由于线程可能在自己的工作内存中缓存共享变量的副本，因此一个线程对共享变量的修改可能不会立即反映在其他线程的工作内存中。为了解决这个问题，我们可以使用synchronized关键字、volatile关键字或Lock来确保可见性。\n最后，有序性是指处理器为了提高程序运行效率，可能会对输入代码进行优化，导致程序中各个语句的执行先后顺序与代码中的顺序不一致。虽然处理器会保证程序最终执行结果与代码顺序执行的结果一致，但在某些情况下我们可能需要确保特定的执行顺序。为了解决这个问题，我们可以使用volatile关键字来禁止指令重排。\n死锁 # 2.1 线程死锁 # 线程死锁描述的是这样一种情况：多个线程同时被阻塞，它们中的一个或者全部都在等待某个资源被释放。由于线程被无限期地阻塞，因此程序不可能正常终止。\n如下图所示，线程 A 持有资源 2，线程 B 持有资源 1，他们同时都想申请对方的资源，所以这两个线程就会互相等待而进入死锁状态。\n产生死锁的四个必要条件：\n互斥条件：该资源任意一个时刻只由一个线程占用。\n请求与保持条件：一个线程因请求资源而阻塞时，对已获得的资源保持不放。\n不剥夺条件:线程已获得的资源在未使用完之前不能被其他线程强行剥夺，只有自己使用完毕后才释放资源。\n循环等待条件:若干线程之间形成一种头尾相接的循环等待资源关系。\n2.1.1 如何检测死锁？ # 使用jmap、jstack等命令查看 JVM 线程栈和堆内存的情况。如果有死锁，jstack 的输出中通常会有 Found one Java-level deadlock:的字样，后面会跟着死锁相关的线程信息。另外，实际项目中还可以搭配使用top、df、free等命令查看操作系统的基本情况，出现死锁可能会导致 CPU、内存等资源消耗过高。\n采用 VisualVM、JConsole 等工具进行排查。\n当程序出现了死锁现象，我们可以使用jdk自带的工具：jps和 jstack\n步骤如下：\n第一：查看运行的线程\n第二：使用jstack查看线程运行的情况，下图是截图的关键信息\n运行命令：jstack -l 46032\n其他解决工具，可视化工具\njconsole 用于对jvm的内存，线程，类 的监控，是一个基于 jmx 的 GUI 性能监控工具\n打开方式：java 安装目录 bin目录下 直接启动 jconsole.exe 就行\nVisualVM：故障处理工具 能够监控线程，内存情况，查看方法的CPU时间和内存中的对 象，已被GC的对象，反向查看分配的堆栈\n打开方式：java 安装目录 bin目录下 直接启动 jvisualvm.exe就行\n参考回答\n我们只需要通过jdk自动的工具就能搞定\n我们可以先通过jps来查看当前java程序运行的进程id\n然后通过jstack来查看这个进程id，就能展示出来死锁的问题，并且，可以定位代码的具体行号范围，我们再去找到对应的代码进行排查就行了。\n2.1.2 如何预防和避免线程死锁？ # 如何预防死锁？ 破坏死锁的产生的必要条件即可：\n破坏请求与保持条件：一次性申请所有的资源。 破坏不剥夺条件：占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源。 破坏循环等待条件：靠按序申请资源来预防。按某一顺序申请资源，释放资源则反序释放。破坏循环等待条件。 如何避免死锁？\n避免死锁就是在资源分配时，借助于算法（比如银行家算法）对资源分配进行计算评估，使其进入安全状态。\n安全状态 指的是系统能够按照某种线程推进顺序（P1、P2、P3……Pn）来为每个线程分配所需资源，直到满足每个线程对资源的最大需求，使每个线程都可顺利完成。称 \u0026lt;P1、P2、P3.....Pn\u0026gt; 序列为安全序列。\n2.2 死锁与活锁、饥饿的区别 # 死锁是指多个线程相互等待对方释放资源，导致它们都无法继续执行下去。这是一种静止状态，这种情况会导致所有线程都被永久性地阻塞，没有一个线程能够继续执行。就像交通堵塞一样，没有车辆能够前进。 活锁是指多个线程不断地改变自己的状态以回应对方，但最终无法取得进展，导致线程不断重试相同的操作，却无法成功。这是一种运行时状态，线程在持续地执行，但任务不会向前推进。活锁通常发生在线程在避免冲突时不断改变状态，但却没有成功，就像两个人在狭窄的道路上不断让对方走，却无法通过一样。 饥饿是指一个或多个线程或进程由于某种原因无法获得所需的资源或执行机会，因此无法适时地执行。这是一种动态问题，通常由资源分配不合理或线程优先级设置不当等原因导致。在饥饿中，线程不一定被永久性地阻塞，但是它们可能长时间无法获得所需的资源。就像一个人在繁忙的自助餐厅排队等待很长时间，但一直无法获得食物一样。\nvolatile关键字 # volatile是Java提供的一种轻量级的同步机制。Java 语言包含两种内在的同步机制：同步块（或方法）和 volatile 变量，相比于synchronized（synchronized通常称为重量级锁），volatile更轻量级，因为它不会引起线程上下文的切换和调度。但是volatile 变量的同步性较差（有时它更简单并且开销更低），而且其使用也更容易出错。\n3.1 如何保证变量的可见性？ # 在 Java 中，volatile 关键字可以保证变量的可见性，如果我们将变量声明为 volatile ，这就指示 JVM，这个变量是共享且不稳定的，每次使用它都到主存中进行读取。\nvolatile 关键字其实并非是 Java 语言特有的，在 C 语言里也有，它最原始的意义就是禁用 CPU 缓存。如果我们将一个变量使用 volatile 修饰，这就指示 编译器，这个变量是共享且不稳定的，每次使用它都到主存中进行读取。\nvolatile 关键字能保证数据的可见性，但不能保证数据的原子性。synchronized 关键字两者都能保证。\n3.2 如何禁止指令重排序？ # [!CAUTION]\n重排序：\n假设我们写了一个 Java 程序，包含一系列的语句，我们会默认期望这些语句的实际运行顺序和写的代码顺序一致。 但实际上，编译器、JVM 或者 CPU 都有可能出于优化等目的，对于实际指令执行的顺序进行调整，这就是重排序。 **重排序的好处：**提高指令执行速度\n重排序的三种情况：\n（1）编译器优化\n编译器（包括 JVM、JIT 编译器等）出于优化的目的，例如当前有了数据 a，把对 a 的操作放到一起效率会更高，避免读取 b 后又返回来重新读取 a 的时间开销，此时在编译的过程中会进行一定程度的重排。不过重排序并不意味着可以任意排序，它需要需要保证重排序后，不改变单线程内的语义，否则如果能任意排序的话，程序早就逻辑混乱了。 （2）CPU 重排序\nCPU 同样会有优化行为，这里的优化和编译器优化类似，都是通过乱序执行的技术来提高整体的执行效率。 所以即使之前编译器不发生重排，CPU 也可能进行重排，我们在开发中，一定要考虑到重排序带来的后果。 （3） 内存的“重排序”\n内存系统内不存在真正的重排序，但是内存会带来看上去和重排序一样的效果，所以这里的“重排序”打了双引号。 由于内存有缓存的存在，在 JMM 里表现为主存和本地内存，而主存和本地内存的内容可能不一致，所以这也会导致程序表现出乱序的行为。 举个例子，线程 1 修改了 a 的值，但是修改后没有来得及把新结果写回主存或者线程 2 没来得及读到最新的值，所以线程 2 看不到刚才线程 1 对 a 的修改，此时线程 2 看到的 a 还是等于初始值。但是线程 2 却可能看到线程 1 修改 a 之后的代码执行效果，表面上看起来像是发生了重顺序。 在 Java 中，volatile 关键字除了可以保证变量的可见性，还有一个重要的作用就是防止 JVM 的指令重排序。 如果我们将变量声明为 volatile ，在对这个变量进行读写操作的时候，会通过插入特定的 内存屏障 的方式来禁止指令重排序。\n在 Java 中，Unsafe 类提供了三个开箱即用的内存屏障相关的方法，屏蔽了操作系统底层的差异：\npublic native void loadFence(); public native void storeFence(); public native void fullFence(); 理论上来说，你通过这个三个方法也可以实现和volatile禁止重排序一样的效果，只是会麻烦一些。\n下面我以一个常见的面试题为例讲解一下 volatile 关键字禁止指令重排序的效果。\n面试中面试官经常会说：“单例模式了解吗？来给我手写一下！给我解释一下双重检验锁方式实现单例模式的原理呗！”\n[!CAUTION]\n单例模式：\n单例模式（Singleton Pattern）是 Java 中最简单的设计模式之一。这种类型的设计模式属于创建型模式，它提供了一种创建对象的最佳方式。\n这种模式涉及到一个单一的类，该类负责创建自己的对象，同时确保只有单个对象被创建。这个类提供了一种访问其唯一的对象的方式，可以直接访问，不需要实例化该类的对象。\n单例模式是一种创建型设计模式，它确保一个类只有一个实例，并提供了一个全局访问点来访问该实例。\n1、单例类只能有一个实例。 2、单例类必须自己创建自己的唯一实例。 3、单例类必须给所有其他对象提供这一实例。 双重校验锁(DCL)实现对象单例（线程安全）：\npublic class Singleton { private volatile static Singleton uniqueInstance; private Singleton() { } public static Singleton getUniqueInstance() { //先判断对象是否已经实例过，没有实例化过才进入加锁代码 if (uniqueInstance == null) { //类对象加锁 synchronized (Singleton.class) { //在同步块内再次检查实例是否已创建，防止多个线程通过第一次检查后仍然创建多个实例的情况 if (uniqueInstance == null) { //当且仅当实例未被创建时，初始化 uniqueInstance uniqueInstance = new Singleton(); } } } return uniqueInstance; } } uniqueInstance 采用 volatile 关键字修饰也是很有必要的， uniqueInstance = new Singleton(); 这段代码其实是分为三步执行：\n为 uniqueInstance 分配内存空间 初始化 uniqueInstance 将 uniqueInstance 指向分配的内存地址 但是由于 JVM 具有指令重排的特性，执行顺序有可能变成 1-\u0026gt;3-\u0026gt;2。指令重排在单线程环境下不会出现问题，但是在多线程环境下会导致一个线程获得还没有初始化的实例。例如，线程 T1 执行了 1 和 3，此时 T2 调用 getUniqueInstance() 后发现 uniqueInstance 不为空，因此返回 uniqueInstance，但此时 uniqueInstance 还未被初始化。\n3.3 volatile可以保证原子性吗？ # volatile 关键字能保证变量的可见性，但不能保证对变量的操作是原子性的。\n我们通过下面的代码即可证明：\npublic class VolatileAtomicityDemo { public volatile static int inc = 0; public void increase() { inc++; } public static void main(String[] args) throws InterruptedException { ExecutorService threadPool = Executors.newFixedThreadPool(5); VolatileAtomicityDemo volatileAtomicityDemo = new VolatileAtomicityDemo(); for (int i = 0; i \u0026lt; 5; i++) { threadPool.execute(() -\u0026gt; { for (int j = 0; j \u0026lt; 500; j++) { volatileAtomicityDemo.increase(); } }); } // 等待1.5秒，保证上面程序执行完成 Thread.sleep(1500); System.out.println(inc); threadPool.shutdown(); } } 正常情况下，运行上面的代码理应输出 2500。但你真正运行了上面的代码之后，你会发现每次输出结果都小于 2500。\n为什么会出现这种情况呢？不是说好了，volatile 可以保证变量的可见性嘛！\n也就是说，如果 volatile 能保证 inc++ 操作的原子性的话。每个线程中对 inc 变量自增完之后，其他线程可以立即看到修改后的值。5 个线程分别进行了 500 次操作，那么最终 inc 的值应该是 5*500=2500。\n很多人会误认为自增操作 inc++ 是原子性的，实际上，inc++ 其实是一个复合操作，包括三步:\n读取 inc 的值。 对 inc 加 1。 将 inc 的值写回内存。 volatile 是无法保证这三个操作是具有原子性的，有可能导致下面这种情况出现：\n线程 1 对 inc 进行读取操作之后，还未对其进行修改。线程 2 又读取了 inc的值并对其进行修改（+1），再将inc 的值写回内存。 线程 2 操作完毕后，线程 1 对 inc的值进行修改（+1），再将inc 的值写回内存。 这也就导致两个线程分别对 inc 进行了一次自增操作后，inc 实际上只增加了 1。\n其实，如果想要保证上面的代码运行正确也非常简单，利用 synchronized、Lock或者AtomicInteger都可以。\n使用 synchronized 改进：\npublic synchronized void increase() { inc++; } 使用 AtomicInteger 改进：\npublic AtomicInteger inc = new AtomicInteger(); public void increase() { inc.getAndIncrement(); } 使用 ReentrantLock 改进：\nLock lock = new ReentrantLock(); public void increase() { lock.lock(); try { inc++; } finally { lock.unlock(); } } ","date":"18 March 2025","externalUrl":null,"permalink":"/posts/1742270546243-java-%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/","section":"Posts","summary":"","title":"java 并发编程","type":"posts"},{"content":" 线程 # 1.1 线程和进程 # 1.1.1 进程 # ==进程是程序的一次执行过程==，是系统运行程序的基本单位，因此进程是动态的。系统运行一个程序即是一个进程从创建，运行到消亡的过程。\n进程的特性：\n独立性：进程是一个能独立运行的基本单位，同时也是系统分配资源和调度的独立单位 动态性：进程的实质是程序的一次执行过程，进程是动态产生，动态消亡的 并发性：任何进程都可以同其他进程一起并发执行 在java中，当我们启动main函数时其实就是启动了一个JVM的进程，而main函数所在的线程就是这个进程中的一个线程，也称主线程。\n1.1.2 线程 # ==线程（英语：thread）是操作系统能够进行运算调度的最小单位。==线程与进程相似，但线程是一个比进程更小的执行单位。一个进程在其执行的过程中可以产生多个线程。与进程不同的是同类的多个线程共享进程的堆和方法区资源，但每个线程有自己的程序计数器、虚拟机栈和本地方法栈，所以系统在产生一个线程，或是在各个线程之间做切换工作时，负担要比进程小得多，也正因为如此，线程也被称为轻量级进程。\n程序计数器：用于存放下一条指令所在单元的地址的地方。\n虚拟机栈：Java虚拟机栈(Java virtual Machine stack) ,早期也叫Java栈。每个线程在创建时都会创建一个虚拟机栈,其内部保存一个个的栈帧(stack Frame) ,对应着一次次的Java方法调用。一次方法的调用，就是栈帧入栈到出栈的过程\n本地方法栈：java虚拟机栈用于管理java方法的调用，而本地方法栈用于管理本地方法的调用\nJava 程序天生就是多线程程序，我们可以通过 JMX 来看看一个普通的 Java 程序有哪些线程，代码如下。\npublic class MultiThread { public static void main(String[] args) { // 获取 Java 线程管理 MXBean ThreadMXBean threadMXBean = ManagementFactory.getThreadMXBean(); // 不需要获取同步的 monitor 和 synchronizer 信息，仅获取线程和线程堆栈信息 ThreadInfo[] threadInfos = threadMXBean.dumpAllThreads(false, false); // 遍历线程信息，仅打印线程 ID 和线程名称信息 for (ThreadInfo threadInfo : threadInfos) { System.out.println(\u0026#34;[\u0026#34; + threadInfo.getThreadId() + \u0026#34;] \u0026#34; + threadInfo.getThreadName()); } } } 上述程序输出如下（输出内容可能不同，不用太纠结下面每个线程的作用，只用知道 main 线程执行 main 方法即可）：\n[5] Attach Listener //添加事件 [4] Signal Dispatcher // 分发处理给 JVM 信号的线程 [3] Finalizer //调用对象 finalize 方法的线程 [2] Reference Handler //清除 reference 线程 [1] main //main 线程,程序入口 从上面的输出内容可以看出：一个 Java 程序的运行是 main 线程和多个其他线程同时运行。\n1.1.3 Java线程与操作系统的线程 # JDK 1.2 之前，Java 线程是基于绿色线程（Green Threads）实现的，这是一种用户级线程（用户线程），也就是说 JVM 自己模拟了多线程的运行，而不依赖于操作系统。由于绿色线程和原生线程比起来在使用时有一些限制（比如绿色线程不能直接使用操作系统提供的功能如异步 I/O、只能在一个内核线程上运行无法利用多核），在 JDK 1.2 及以后，Java 线程改为基于原生线程（Native Threads）实现，也就是说 JVM 直接使用操作系统原生的内核级线程（内核线程）来实现 Java 线程，由操作系统内核进行线程的调度和管理。\n用户线程：由用户空间程序管理和调度的线程，运行在用户空间（专门给应用程序使用）。 内核线程：由操作系统内核管理和调度的线程，运行在内核空间（只有内核程序可以访问） 顺便简单总结一下用户线程和内核线程的区别和特点：用户线程创建和切换成本低，但不可以利用多核。内核态线程，创建和切换成本高，可以利用多核。\n一句话概括 Java 线程和操作系统线程的关系：现在的 Java 线程的本质其实就是操作系统的线程。\n线程模型是用户线程和内核线程之间的关联方式，常见的线程模型有这三种：\n一对一（一个用户线程对应一个内核线程） 多对一（多个用户线程映射到一个内核线程） 多对多（多个用户线程映射到多个内核线程） 在 Windows 和 Linux 等主流操作系统中，Java 线程采用的是一对一的线程模型，也就是一个 Java 线程对应一个系统内核线程。Solaris 系统是一个特例（Solaris 系统本身就支持多对多的线程模型），HotSpot VM 在 Solaris 上支持多对多和一对一。具体可以参考 : JVM 中的线程模型是用户级的么？。\n1.1.4 线程与进程的关系 # 下图是java内存区域，通过下图我们从JVM的角度来说一下线程和进程之间的关系。\n从上图可以看出：一个进程中可以有多个线程，多个线程共享进程的堆和方法区 (JDK1.8 之后的元空间)资源，但是每个线程有自己的程序计数器、虚拟机栈 和 本地方法栈。\n总结：线程是进程划分成的更小的运行单位。线程和进程最大的不同在于基本上各进程是独立的，而各线程则不一定，因为同一进程中的线程极有可能会相互影响。线程执行开销小，但不利于资源的管理和保护；而进程正相反。\n下面是该知识点的扩展内容：\n下面来思考这样一个问题：为什么程序计数器、虚拟机栈和本地方法栈是线程私有的呢？为什么堆和方法区是线程共享的呢？\n1.1.5 程序计数器 # 程序计数器主要有下面两个作用：\n字节码解释器通过改变程序计数器来依次读取指令，从而实现代码的流程控制，如：顺序执行、选择、循环、异常处理。\n在多线程的情况下，程序计数器用于记录当前线程执行的位置，从而当线程被切换回来的时候能够知道该线程上次运行到哪儿了。\n需要注意的是，如果执行的是 native 方法，那么程序计数器记录的是 undefined 地址，只有执行的是 Java 代码时程序计数器记录的才是下一条指令的地址。\n所以，程序计数器私有主要是为了线程切换后能恢复到正确的执行位置。\n1.1.6 虚拟机栈和本地方法栈 # 虚拟机栈： 每个 Java 方法在执行之前会创建一个栈帧用于存储局部变量表、操作数栈、常量池引用等信息。从方法调用直至执行完成的过程，就对应着一个栈帧在 Java 虚拟机栈中入栈和出栈的过程。\n本地方法栈： 和虚拟机栈所发挥的作用非常相似，区别是：虚拟机栈为虚拟机执行 Java 方法 （也就是字节码）服务，而本地方法栈则为虚拟机使用到的 Native 方法服务。 在 HotSpot 虚拟机中和 Java 虚拟机栈合二为一。\n所以，为了保证线程中的局部变量不被别的线程访问到，虚拟机栈和本地方法栈是线程私有的。\n1.1.7 堆和方法区 # 堆和方法区是所有线程共享的资源，其中堆是进程中最大的一块内存，主要用于存放新创建的对象 (几乎所有对象都在这里分配内存)，方法区主要用于存放已被加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。\n1.2 创建线程 # 一般来说，创建线程有很多中方式，例如继承Thread（/θred/）类、实现Runnable接口、实现Callable接口、使用线程池、使用CompletableFuture类等等。\n不过，这些方法其实并没有真正创建出线程。准确点来说，这些都属于是在java代码中使用多线程的方法。\n严格来说，Java就只有一种方式可以创建线程，那就是通过new Thread().start()创建。不管是哪种方式，最终还是依赖于new Thread().start()。\n大家都说 Java 有三种创建线程的方式！并发编程中的惊天骗局！。\n1.**继承Thread类：**创建一个继承自Thread类的子类，然后重写子类的run方法，将线程的任务逻辑放在run方法中。然后通过创建子类的对象并调用start方法来启动线程。示例代码如下：\njavaCopy code class MyThread extends Thread { public void run() { // 线程任务逻辑 } } // 创建并启动线程 MyThread myThread = new MyThread(); myThread.start(); 2.**实现Runnable/Callable接口：**创建一个类实现Runnable接口，并重写run方法，然后通过将实现了Runnable接口的对象传递给Thread类的构造函数来创建线程对象。示例代码如下：\njavaCopy code class MyRunnable implements Runnable { public void run() { // 线程任务逻辑 } } // 创建并启动线程 Thread thread = new Thread(new MyRunnable()); thread.start(); Callable接口如下：\npublic class MyCallable implements Callable\u0026lt;String\u0026gt; { @Override public String call() throws Exception { System.out.println(\u0026#34;MyCallable...call...\u0026#34;); return \u0026#34;OK\u0026#34;; } public static void main(String[] args) throws ExecutionException, InterruptedException { // 创建MyCallable对象 MyCallable mc = new MyCallable() ; // 创建F FutureTask\u0026lt;String\u0026gt; ft = new FutureTask\u0026lt;String\u0026gt;(mc) ; // 创建Thread对象 Thread t1 = new Thread(ft) ; Thread t2 = new Thread(ft) ; // 调用start方法启动线程 t1.start(); // 调用ft的get方法获取执行结果 String result = ft.get(); // 输出 System.out.println(result); } } runnable 和 callable 的区别：\nRunnable 接口run方法没有返回值；Callable接口call方法有返回值，是个泛型，和Future、FutureTask配合可以用来获取异步执行的结果 Callalbe接口支持返回执行结果，需要调用FutureTask.get()得到，此方法会阻塞主进程的继续往下执行，如果不调用不会阻塞。 Callable接口的call()方法允许抛出异常；而Runnable接口的run()方法的异常只能在内部消化，不能继续上抛 3.**使用匿名内部类：**可以使用匿名内部类来创建线程对象，这种方式通常用于简单的线程任务。示例代码如下：\njavaCopy code Thread thread = new Thread(new Runnable() { public void run() { // 线程任务逻辑 } }); thread.start(); 4.**使用Lambda表达式：**在Java 8及以后的版本中，可以使用Lambda表达式来创建线程对象，更加简洁。示例代码如下：\njavaCopy code Thread thread = new Thread(() -\u0026gt; { // 线程任务逻辑 }); thread.start(); 5.**使用线程池（Executor框架）：**可以使用Executor框架中的线程池来管理和执行线程。通过ExecutorService接口的实现类，例如ThreadPoolExecutor，可以提交任务并由线程池管理线程的生命周期。\njavaCopy code ExecutorService executorService = Executors.newFixedThreadPool(5); executorService.submit(() -\u0026gt; { // 线程任务逻辑 }); 启动线程为什么是start而不是run方法?\n调用 start() 方法会告诉jvm创建一个新的线程，并在这个新线程中执行与 run() 方法相关联的代码块。这个过程允许多个线程同时运行，每个线程都拥有独立的执行上下文，这意味着它们可以在不互相干扰的情况下执行任务。 与此不同，如果直接调用 run() 方法，它仅仅是一个普通的方法调用，不会创建新的线程。相反，它会在当前线程的上下文中执行 run() 方法中的代码。这将导致代码的顺序执行，没有并行性可言，因为它们都在同一个线程内执行。 这种区别非常重要，因为多线程编程的一个主要目标是实现并行性，从而提高程序的性能和响应能力。通过调用 start() 方法，可以利用多核处理器的优势，同时执行多个线程，以更有效地完成任务。而直接调用 run() 方法只是按照一般的方法顺序执行代码，无法发挥多线程的潜力。因此，使用 start() 方法来启动线程是实现并行性的关键。\n1.2.1 线程的生命周期和状态 # 当线程被创建并启动以后，它既不是一启动就进入了执行状态，也不是一直处于执行状态。线程对象在不同的时期有不同的状态。\nJava中的线程存在6种状态，每种线程状态的含义如下\n线程状态 具体含义 NEW 一个尚未启动的线程的状态。也称之为初始状态、开始状态。线程刚被创建，但是并未启动。还没调用start方法。MyThread t = new MyThread()只有线程象，没有线程特征。 RUNNABLE 当我们调用线程对象的start方法，那么此时线程对象进入了RUNNABLE状态。那么此时才是真正的在JVM进程中创建了一个线程，线程一经启动并不是立即得到执行，线程的运行与否要听令与CPU的调度，那么我们把这个中间状态称之为可执行状态(RUNNABLE)也就是说它具备执行的资格，但是并没有真正的执行起来而是在等待CPU的度。 BLOCKED 当一个线程试图获取一个对象锁，而该对象锁被其他的线程持有，则该线程进入Blocked状态；当该线程持有锁时，该线程将变成Runnable状态。 WAITING 一个正在等待的线程的状态。也称之为等待状态。造成线程等待的原因有两种，分别是调用Object.wait()、join()方法。处于等待状态的线程，正在等待其他线程去执行一个特定的操作。例如：因为wait()而等待的线程正在等待另一个线程去调用notify()或notifyAll()；一个因为join()而等待的线程正在等待另一个线程结束。 TIMED_WAITING 一个在限定时间内等待的线程的状态。也称之为限时等待状态。造成线程限时等待状态的原因有三种，分别是：Thread.sleep(long)，Object.wait(long)、join(long)。 TERMINATED 一个完全运行完成的线程的状态。也称之为终止状态、结束状态(terminated /ˈtɜːrməˌnet/ ) Java 线程在运行的生命周期中的指定时刻只可能处于下面 6 种不同状态的其中一个状态：\nNEW: 初始状态，线程被创建出来但没有被调用 start() 。 RUNNABLE: 运行状态，线程被调用了 start()等待运行的状态。 BLOCKED：阻塞状态，需要等待锁释放。 WAITING：等待状态，表示该线程需要等待其他线程做出一些特定动作（通知或中断）。 TIME_WAITING：超时等待状态，可以在指定的时间后自行返回而不是像 WAITING 那样一直等待。 TERMINATED：终止状态，表示该线程已经运行完毕。 **关于start调用：**底层源码在调用start()方法的时候会针对状态进行判断，如果不是NEW状态就会报线程状态的异常，也就是说如果调用了两次start()方法或者在线程执行完后再调用一次start()方法，都会产生异常。\n线程在生命周期中并不是固定处于某一个状态而是随着代码的执行在不同状态之间切换。\nJava 线程状态变迁图(图源：挑错 |《Java 并发编程的艺术》中关于线程状态的三处错误)：\n由上图可以看出：线程创建之后它将处于 NEW（新建） 状态，调用 start() 方法后开始运行，线程这时候处于 READY（可运行） 状态。可运行状态的线程获得了 CPU 时间片（timeslice）后就处于 RUNNING（运行） 状态。\n在操作系统层面，线程有 READY 和 RUNNING 状态；而在 JVM 层面，只能看到 RUNNABLE 状态（图源：HowToDoInJava：Java Thread Life Cycle and Thread States），所以 Java 系统一般将这两个状态统称为 RUNNABLE（运行中） 状态 。\n为什么 JVM 没有区分这两种状态呢？ （摘自：Java 线程运行怎么有第六种状态？ - Dawell 的回答 ） 现在的时分（time-sharing）多任务（multi-task）操作系统架构通常都是用所谓的“时间分片（time quantum or time slice）”方式进行抢占式（preemptive）轮转调度（round-robin 式）。这个时间分片通常是很小的，一个线程一次最多只能在 CPU 上运行比如 10-20ms 的时间（此时处于 running 状态），也即大概只有 0.01 秒这一量级，时间片用后就要被切换下来放入调度队列的末尾等待再次调度。（也即回到 ready 状态）。线程切换的如此之快，区分这两种状态就没什么意义了。\n当线程执行 wait()方法之后，线程进入 WAITING（等待） 状态。进入等待状态的线程需要依靠其他线程的通知才能够返回到运行状态。\nTIMED_WAITING(超时等待) 状态相当于在等待状态的基础上增加了超时限制，比如通过 sleep（long millis）方法或 wait（long millis）方法可以将线程置于 TIMED_WAITING 状态。当超时时间结束后，线程将会返回到 RUNNABLE 状态。\n当线程进入 synchronized 方法/块或者调用 wait 后（被 notify）重新进入 synchronized 方法/块，但是锁被其它线程占有，这个时候线程就会进入 BLOCKED（阻塞） 状态。\n线程在执行完了 run()方法之后将会进入到 TERMINATED（终止） 状态。\n关于进入WAITING状态的几种方法\n调用Object.wait()方法，该方法会使得当前线程进入等待状态，等待其他线程调用同一个对象的notify()或notifyAll()方法唤醒该线程。 调用Thread.join()方法，该方法会使得当前线程等待指定线程的结束，当指定线程结束时，当前线程将被唤醒。 调用LockSupport.park()方法，该方法会使得当前线程等待，直到获取LockSupport指定的许可或者线程被中断、调度。 在获取锁时，如果当前线程没有获取到锁，就会进入等待状态，等待其他线程释放锁。 等待I/O操作：当线程在执行期间遇到了需要等待I/O操作完成的情况，它会进入WAITING状态，直到I/O操作完成。 需要注意的是，当线程进入WAITING状态时，会释放所有的锁，并且不会占用CPU资源。如果线程长时间处于等待状态，可能会造成CPU的空闲，因此需要注意避免出现不必要的等待。\n相关阅读：线程的几种状态你真的了解么？\n1.2.2 线程上下文切换 # 线程在执行过程中会有自己的运行条件和状态（也称上下文），比如上文所说到过的程序计数器，栈信息等。当出现如下情况的时候，线程会从占用 CPU 状态中退出。\n主动让出 CPU，比如调用了 sleep(), wait() 等。\n时间片用完，因为操作系统要防止一个线程或者进程长时间占用 CPU 导致其他线程或者进程饿死。\n调用了阻塞类型的系统中断，比如请求 IO，线程被阻塞。\n被终止或结束运行\n这其中前三种都会发生线程切换，线程切换意味着需要保存当前线程的上下文，留待线程下次占用 CPU 的时候恢复现场。并加载下一个将要占用 CPU 的线程上下文。这就是所谓的 上下文切换。\n上下文切换是现代操作系统的基本功能，因其每次需要保存信息恢复信息，这将会占用 CPU，内存等系统资源进行处理，也就意味着效率会有一定损耗，如果频繁切换就会造成整体效率低下。\n1.2.3 Thread#sleep()方法和Object#wait()方法对比 # 共同点：两者都可以暂停线程的执行。\n区别：\nsleep() 方法没有释放锁，而 wait() 方法释放了锁 。 wait() 通常被用于线程间交互/通信，sleep()通常被用于暂停执行。 wait() 方法被调用后，线程不会自动苏醒，需要别的线程调用同一个对象上的 notify()或者 notifyAll() 方法。sleep()方法执行完成后，线程会自动苏醒，或者也可以使用 wait(long timeout) 超时后线程会自动苏醒。 sleep() 是 Thread 类的静态本地方法，wait() 则是 Object 类的本地方法。为什么这样设计呢？下一个问题就会聊到。 为什么wait()方法不定义在Thread中？\nwait() 是让获得对象锁的线程实现等待，会自动释放当前线程占有的对象锁。每个对象（Object）都拥有对象锁，既然要释放当前线程占有的对象锁并让其进入 WAITING 状态，自然是要操作对应的对象（Object）而非当前的线程（Thread）。\n类似的问题：为什么 sleep() 方法定义在 Thread 中？\n因为 sleep() 是让当前线程暂停执行，不涉及到对象类，也不需要获得对象锁。\n可以直接调用Thread类的run方法吗？\nnew 一个 Thread，线程进入了新建状态。调用 start()方法，会启动一个线程并使线程进入了就绪状态，当分配到时间片后就可以开始运行了。 start() 会执行线程的相应准备工作，然后自动执行 run() 方法的内容，这是真正的多线程工作。 但是，直接执行 run() 方法，会把 run() 方法当成一个 main 线程下的普通方法去执行，并不会在某个线程中执行它，所以这并不是多线程工作。\n总结：调用 start() 方法方可启动线程并使线程进入就绪状态，直接执行 run() 方法的话不会以多线程的方式执行。\n1.2.4 notify()和notifyAll()方法 # 在Java中，notify()和notifyAll()都属于Object类的方法，用于实现线程间的通信。 notify()方法用于唤醒在当前对象上等待的单个线程。如果有多个线程同时在某个对象上等待（通过调用该对象的wait()方法），则只会唤醒其中一个线程，并使其从等待状态变为可运行状态。具体是哪个线程被唤醒是不确定的，取决于线程调度器的实现。 notifyAll()方法用于唤醒在当前对象上等待的所有线程。如果有多个线程在某个对象上等待，调用notifyAll()方法后，所有等待的线程都会被唤醒并竞争该对象的锁。其中一个线程获得锁后继续执行，其他线程则继续等待。 需要注意的是，notify()和notifyAll()方法只能在同步代码块或同步方法内部调用，并且必须拥有与该对象关联的锁。否则会抛出IllegalMonitorStateException异常。\n1.2.4 线程调度器和时间分片 # 线程调度器（Thread Scheduler）是操作系统内核中的一个重要组件，负责分配并管理处理器时间片，控制多线程程序的执行顺序。当有多个线程同时运行时，线程调度器会在这些线程之间进行切换，使得每个线程都有机会使用 CPU 资源，并实现任务的并发执行。 时间分片（Time Slicing）是指将可用的 CPU 时间分配给可用的 Runnable 线程的过程。分配 CPU 时间可以基于线程优先级或者线程等待的时间。这样，每个线程运行一段时间后，会被暂停，然后调度器会选择下一个线程来执行。这种方式可以确保每个线程都能获得一定的运行时间，从而实现多任务并发执行。\n1.2.5 为什么wait和notify方法要在同步块中调用 # 当使用 wait() 和 notify() 方法时，需要将它们放在同步块内，这是因为：\n互斥性： 多线程环境下，我们希望在同一时刻只有一个线程能够执行 wait()、notify() 或 notifyAll() 方法。使用同步块（synchronized）提供了这种互斥性，避免多线程并发修改的问题。 上下文切换： 当一个线程调用 wait() 时，它会暂时放弃执行权并释放对象的锁。如果不在同步块内调用 wait()，线程可能在不合适的时机被唤醒，导致混乱。同步块内的 wait() 确保线程在正确的上下文中被唤醒，可以继续执行并获取锁。 安全性： 如果不在同步块内使用 wait()、notify() 或 notifyAll()，多个线程可能同时访问和修改同一个共享对象的状态，可能引发竞态条件，导致程序行为不确定。同步块（synchronized /ˈsɪŋkrənaɪzd/ ）可以确保对这些方法的访问是原子的，避免了潜在的并发问题。 简而言之，将 wait() 和 notify() 方法包裹在同步块内，有助于确保线程间的协同和同步工作正确，避免了多线程问题，提高了程序的可靠性和安全性。\n1.2.6 线程的 run()和 start()有什么区别？ # start(): 用来启动线程，通过该线程调用run方法执行run方法中所定义的逻辑代码。start方法只能被调用一次。\nrun(): 封装了要被线程执行的代码，可以被调用多次。\n1.3 终止线程 # 停止一个线程通常意味着在线程处理任务完成之前停掉正在做的操作，也就是放弃当前的操作。\n在Java中有以下3种方法可以中止正在运行的线程：\n使用退出标识，是线程正常退出，也就是当run()方法完成后线程终止。 使用stop()方法强行中止线程，但是不推荐使用这个方法，该方法已经被弃用。 使用interrupt*/ˌɪntəˈrʌpt/*方法终止线程。 1.3.1 使用标志位终止线程（推荐） # InterruptedException：对于阻塞操作，使用线程的中断机制。 标志位（Volatile）：对于正在执行的非阻塞任务，可以使用一个volatile类型的布尔标志。 在 run() 方法执行完毕后，该线程就中止了。但是在某些特殊的情况下，run() 方法会被一直执行；比如在服务端程序中可能会使用 while(true) { \u0026hellip; } 这样的循环结构来不断的接收来自客户端的请求。此时就可以用修改标志位的方式来结束 run() 方法。\npublic class ExitFlagTests { // volatile修饰符用来保证其它线程读取的总是该变量的最新的值 private volatile boolean exitFlag = false; // 退出标志 public void run() { while (!exitFlag) { // 执行线程的任务 System.out.println(\u0026#34;Thread is running...\u0026#34;); try { Thread.sleep(1000); // 模拟一些工作 } catch (InterruptedException e) { // 处理中断（如果需要） Thread.currentThread().interrupt(); // 重新设置中断状态 } } System.out.println(\u0026#34;Thread is stopping...\u0026#34;); } public void stop() { exitFlag = true; // 设置退出标志为true } public static void main(String[] args) throws InterruptedException { ExitFlagTests exit = new ExitFlagTests(); Thread thread = new Thread(exit::run); thread.start(); // 让线程运行一段时间 Thread.sleep(5000); // 请求线程停止 exit.stop(); } } 关于volatile\nvolatile是Java虚拟机提供的轻量级的同步机制，具有以下特点：\n保证可见性：volatile保证了多个线程对共享变量的操作是可见的。当一个线程修改了共享变量的值，其他线程会立即看到这个改变。 禁止指令重排：volatile通过禁止指令重排来保证顺序性。在多线程环境下，为了提高程序执行效率，编译器和处理器可能会对指令进行重新排序。但是，如果一个变量被volatile修饰，就禁止了指令重排，确保每个线程都能看到正确的操作顺序。 总的来说，volatile可以确保多个线程对共享变量的操作一致，避免了数据不一致的问题。但是它不能保证原子性，因此对于需要保证原子性的操作，还需要使用其他同步机制，如synchronized关键字或java.util.concurrent.atomic包中的原子类。\n1.3.2 使用stop()终止线程（不推荐） # Thread.stop()方法可以强行中止线程的执行。然而，这种方法是不安全的，因为它不保证线程资源的正确释放和清理，可能导致数据不一致和资源泄露等问题，因此已被官方弃用。\npublic class StopMethodTests extends Thread { public void run() { while (true) { System.out.println(\u0026#34;Thread is running...\u0026#34;); try { Thread.sleep(1000); } catch (InterruptedException e) { Thread.currentThread().interrupt(); } } } public static void main(String[] args) throws InterruptedException { StopMethodTests thread = new StopMethodTests(); thread.start(); // 让线程运行一段时间 Thread.sleep(5000); // 强行中止线程（不推荐） thread.stop(); } } 通过查看 JDK 的 API，我们会看到 java.lang.Thread 类型提供了一系列的方法如 start()、stop()、resume()、suspend()、destory()等方法来管理线程。但是除了 start() 之外，其它几个方法都被声名为已过时（deprecated）。 虽然 stop() 方法确实可以停止一个正在运行的线程，但是这个方法是不安全的，而且该方法已被弃用，最好不要使用它。 JDK 文档中还引入用一篇文章来解释了弃用这些方法的原因：《Why are Thread.stop, Thread.suspend and Thread.resume Deprecated?》 为什么弃用stop：\n调用 stop() 方法会立刻停止 run() 方法中剩余的全部工作，包括在 catch 或 finally 语句中的，并抛出ThreadDeath异常(通常情况下此异常不需要显示的捕获)，因此可能会导致一些清理性的工作的得不到完成，如文件，数据库等的关闭。 调用 stop() 方法会立即释放该线程所持有的所有的锁，导致数据得不到同步，出现数据不一致的问题。 1.3.3 使用interrupt()方法终止线程 # 现在我们知道了使用 stop() 方式停止线程是非常不安全的方式，那么我们应该使用什么方法来停止线程呢？答案就是使用 interrupt() 方法来中断线程。 需要明确的一点的是：interrupt() 方法并不像在 for 循环语句中使用 break 语句那样干脆，马上就停止循环。调用 interrupt() 方法仅仅是在当前线程中打一个停止的标记，并不是真的停止线程。 也就是说，线程中断并不会立即中止线程，而是通知目标线程，有人希望你中止。至于目标线程收到通知后会如何处理，则完全由目标线程自行决定。这一点很重要，如果中断后，线程立即无条件退出，那么我们又会遇到 stop() 方法的老问题。 事实上，如果一个线程不能被 interrupt，那么 stop 方法也不会起作用。 我们来看一个使用 interrupt() 的例子：\npublic class StopMethodTests extends Thread { public void run() { while (true) { System.out.println(\u0026#34;Thread is running...\u0026#34;); try { Thread.sleep(1000); } catch (InterruptedException e) { Thread.currentThread().interrupt(); } } } public static void main(String[] args) throws InterruptedException { StopMethodTests thread = new StopMethodTests(); thread.start(); // 让线程运行一段时间 Thread.sleep(5000); // 强行中止线程（不推荐） thread.stop(); } } i=199993 i=199994 i=199995 i=199996 i=199997 i=199998 i=199999 i=200000 从输出的结果我们会发现 interrupt 方法并没有停止线程 t 中的处理逻辑，也就是说即使 t 线程被设置为了中断状态，但是这个中断并不会起作用，那么该如何停止线程呢？ 这就需要使用到另外两个与线程中断有关的方法了：\npublic boolean Thread.isInterrupted() //判断是否被中断 public static boolean Thread.interrupted() //判断是否被中断，并清除当前中断状态 这两个方法使得当前线程能够感知到是否被中断了（通过检查标志位）。 所以如果希望线程 t 在中断后停止，就必须先判断是否被中断，并为它增加相应的中断处理代码：\n@Override public void run() { super.run(); for(int i = 0; i \u0026lt;= 200000; i++) { //判断是否被中断 if(Thread.currentThread().isInterrupted()){ //处理中断逻辑 break; } System.out.println(\u0026#34;i=\u0026#34; + i); } } 在上面这段代码中，我们增加了 Thread.isInterrupted() 来判断当前线程是否被中断了，如果是，则退出 for 循环，结束线程。 这种方式看起来与之前介绍的“使用标志位中止线程”非常类似，==但是在遇到 sleep() 或者 wait() 这样的操作，我们只能通过中断来处理了。== public static native void sleep(long millis) throws InterruptedException Thread.sleep() 方法会抛出一个 InterruptedException 异常，当线程被 sleep() 休眠时，如果被中断，这会就抛出这个异常。 （注意：Thread.sleep() 方法由于中断而抛出的异常，是会清除中断标记的。）\n","date":"18 March 2025","externalUrl":null,"permalink":"/posts/1742270512074-java-%E7%BA%BF%E7%A8%8B/","section":"Posts","summary":"","title":"java 线程","type":"posts"},{"content":" java锁机制 # 在多线程环境下，为了让多线程安全地访问和使用共享变量，必须引入锁机制。锁机制即当一个线程持有锁后，其他线程只能进行等待，直到持有锁的线程释放锁，再次重新竞争锁。\n乐观锁和悲观锁 # 1.1 什么是悲观锁? # 悲观锁总是假设最坏的情况，认为共享资源每次被访问的时候就会出现问题(比如共享数据被修改)，所以每次在获取资源操作的时候都会上锁，这样其他线程想拿到这个资源就会阻塞直到锁被上一个持有者释放。也就是说，共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程。\n像 Java 中synchronized和ReentrantLock等独占锁就是悲观锁思想的实现。\npublic void performSynchronisedTask() { synchronized (this) { // 需要同步的操作 } } private Lock lock = new ReentrantLock(); lock.lock(); try { // 需要同步的操作 } finally { lock.unlock(); } 高并发的场景下，激烈的锁竞争会造成线程阻塞，大量阻塞线程会导致系统的上下文切换，增加系统的性能开销。并且，悲观锁还可能会存在死锁问题，影响代码的正常运行。\n1.2 什么是乐观锁？ # 乐观锁总是假设最好的情况，认为共享资源每次被访问的时候不会出现问题，线程可以不停地执行，无需加锁也无需等待，只是在提交修改的时候去验证对应的资源（也就是数据）是否被其它线程修改了（具体方法可以使用版本号机制或 CAS 算法）。\n在 Java 中java.util.concurrent.atomic包下面的原子变量类（比如AtomicInteger、LongAdder）就是使用了乐观锁的一种实现方式 CAS 实现的。\n// LongAdder 在高并发场景下会比 AtomicInteger 和 AtomicLong 的性能更好 // 代价就是会消耗更多的内存空间（空间换时间） LongAdder sum = new LongAdder(); sum.increment(); 高并发的场景下，乐观锁相比悲观锁来说，不存在锁竞争造成线程阻塞，也不会有死锁的问题，在性能上往往会更胜一筹。但是，如果冲突频繁发生（写占比非常多的情况），会频繁失败和重试，这样同样会非常影响性能，导致 CPU 飙升。\n不过，大量失败重试的问题也是可以解决的，像我们前面提到的 LongAdder以空间换时间的方式就解决了这个问题。\n理论上来说：\n悲观锁通常多用于写比较多的情况（多写场景，竞争激烈），这样可以避免频繁失败和重试影响性能，悲观锁的开销是固定的。不过，如果乐观锁解决了频繁失败和重试这个问题的话（比如LongAdder），也是可以考虑使用乐观锁的，要视实际情况而定。\n乐观锁通常多用于写比较少的情况（多读场景，竞争较少），这样可以避免频繁加锁影响性能。不过，乐观锁主要针对的对象是单个共享变量（参考java.util.concurrent.atomic包下面的原子变量类）。\n1.3 如何实现乐观锁？ # 乐观锁一般会使用版本号机制或 CAS 算法实现，CAS 算法相对来说更多一些，这里需要格外注意。\n1.3.1 版本号机制 # 一般是在数据表中加上一个数据版本号 version 字段，表示数据被修改的次数。当数据被修改时，version 值会加一。当线程 A 要更新数据值时，在读取数据的同时也会读取 version 值，在提交更新时，若刚才读取到的 version 值为当前数据库中的 version 值相等时才更新，否则重试更新操作，直到更新成功。\n举一个简单的例子：假设数据库中帐户信息表中有一个 version 字段，当前值为 1 ；而当前帐户余额字段（ balance ）为 $100 。\n操作员 A 此时将其读出（ version=1 ），并从其帐户余额中扣除 $50（ $100-$50 ）。 在操作员 A 操作的过程中，操作员 B 也读入此用户信息（ version=1 ），并从其帐户余额中扣除 $20 （ $100-$20 ）。 操作员 A 完成了修改工作，将数据版本号（ version=1 ），连同帐户扣除后余额（ balance=$50 ），提交至数据库更新，此时由于提交数据版本等于数据库记录当前版本，数据被更新，数据库记录 version 更新为 2 。 操作员 B 完成了操作，也将版本号（ version=1 ）试图向数据库提交数据（ balance=$80 ），但此时比对数据库记录版本时发现，操作员 B 提交的数据版本号为 1 ，数据库记录当前版本也为 2 ，不满足 “ 提交版本必须等于当前版本才能执行更新 “ 的乐观锁策略，因此，操作员 B 的提交被驳回。 这样就避免了操作员 B 用基于 version=1 的旧数据修改的结果覆盖操作员 A 的操作结果的可能。\n1.3.2 CAS算法 # CAS 的全称是 Compare And Swap（比较与交换） ，用于实现乐观锁，被广泛应用于各大框架中。CAS 的思想很简单，就是用一个预期值和要更新的变量值进行比较，两值相等才会进行更新。\nCAS 是一个原子操作，底层依赖于一条 CPU 的原子指令。\n原子操作 即最小不可拆分的操作，也就是说操作一旦开始，就不能被打断，直到操作完成。\nCAS 涉及到三个操作数：\nV：要更新的变量值(Var) E：预期值(Expected) N：拟写入的新值(New) 当且仅当 V 的值等于 E 时，CAS 通过原子方式用新值 N 来更新 V 的值。如果不等，说明已经有其它线程更新了 V，则当前线程放弃更新。\n举一个简单的例子：线程 A 要修改变量 i 的值为 6，i 原值为 1（V = 1，E=1，N=6，假设不存在 ABA 问题）。\ni 与 1 进行比较，如果相等， 则说明没被其他线程修改，可以被设置为 6 。 i 与 1 进行比较，如果不相等，则说明被其他线程修改，当前线程放弃更新，CAS 操作失败。 当多个线程同时使用 CAS 操作一个变量时，只有一个会胜出，并成功更新，其余均会失败，但失败的线程并不会被挂起，仅是被告知失败，并且允许再次尝试，当然也允许失败的线程放弃操作。\nJava 语言并没有直接实现 CAS，CAS 相关的实现是通过 C++ 内联汇编的形式实现的（JNI 调用）。因此， CAS 的具体实现和操作系统以及 CPU 都有关系。\nsun.misc包下的Unsafe类提供了compareAndSwapObject、compareAndSwapInt、compareAndSwapLong方法来实现的对Object、int、long类型的 CAS 操作\n/** * CAS * @param o 包含要修改field的对象 * @param offset 对象中某field的偏移量 * @param expected 期望值 * @param update 更新值 * @return true | false */ public final native boolean compareAndSwapObject(Object o, long offset, Object expected, Object update); public final native boolean compareAndSwapInt(Object o, long offset, int expected,int update); public final native boolean compareAndSwapLong(Object o, long offset, long expected, long update); 关于 Unsafe 类：Java 魔法类 Unsafe 详解 - JavaGuide - 2022\n1.3.3 Java中CAS的实现 # 在 Java 中，实现 CAS（Compare-And-Swap, 比较并交换）操作的一个关键类是Unsafe。\nUnsafe类位于sun.misc包下，是一个提供低级别、不安全操作的类。由于其强大的功能和潜在的危险性，它通常用于 JVM 内部或一些需要极高性能和底层访问的库中，而不推荐普通开发者在应用程序中使用。关于 Unsafe类的详细介绍，可以阅读这篇文章：📌Java 魔法类 Unsafe 详解。\nsun.misc包下的Unsafe类提供了compareAndSwapObject、compareAndSwapInt、compareAndSwapLong方法来实现的对Object、int、long类型的 CAS 操作：\n/** * 以原子方式更新对象字段的值。 * * @param o 要操作的对象 * @param offset 对象字段的内存偏移量 * @param expected 期望的旧值 * @param x 要设置的新值 * @return 如果值被成功更新，则返回 true；否则返回 false */ boolean compareAndSwapObject(Object o, long offset, Object expected, Object x); /** * 以原子方式更新 int 类型的对象字段的值。 */ boolean compareAndSwapInt(Object o, long offset, int expected, int x); /** * 以原子方式更新 long 类型的对象字段的值。 */ boolean compareAndSwapLong(Object o, long offset, long expected, long x); Unsafe类中的 CAS 方法是native方法。native关键字表明这些方法是用本地代码（通常是 C 或 C++）实现的，而不是用 Java 实现的。这些方法直接调用底层的硬件指令来实现原子操作。也就是说，Java 语言并没有直接用 Java 实现 CAS，而是通过 C++ 内联汇编的形式实现的（通过 JNI 调用）。因此，CAS 的具体实现与操作系统以及 CPU 密切相关。\njava.util.concurrent.atomic 包提供了一些用于原子操作的类。这些类利用底层的原子指令，确保在多线程环境下的操作是线程安全的。\n关于这些 Atomic 原子类的介绍和使用，可以阅读这篇文章：Atomic 原子类总结。\nAtomicInteger是 Java 的原子类之一，主要用于对 int 类型的变量进行原子操作，它利用Unsafe类提供的低级别原子操作方法实现无锁的线程安全性。\n下面，我们通过解读AtomicInteger的核心源码（JDK1.8），来说明 Java 如何使用Unsafe类的方法来实现原子操作。\nAtomicInteger核心源码如下：\n// 获取 Unsafe 实例 private static final Unsafe unsafe = Unsafe.getUnsafe(); private static final long valueOffset; static { try { // 获取“value”字段在AtomicInteger类中的内存偏移量 valueOffset = unsafe.objectFieldOffset (AtomicInteger.class.getDeclaredField(\u0026#34;value\u0026#34;)); } catch (Exception ex) { throw new Error(ex); } } // 确保“value”字段的可见性 private volatile int value; // 如果当前值等于预期值，则原子地将值设置为newValue // 使用 Unsafe#compareAndSwapInt 方法进行CAS操作 public final boolean compareAndSet(int expect, int update) { return unsafe.compareAndSwapInt(this, valueOffset, expect, update); } // 原子地将当前值加 delta 并返回旧值 public final int getAndAdd(int delta) { return unsafe.getAndAddInt(this, valueOffset, delta); } // 原子地将当前值加 1 并返回加之前的值（旧值） // 使用 Unsafe#getAndAddInt 方法进行CAS操作。 public final int getAndIncrement() { return unsafe.getAndAddInt(this, valueOffset, 1); } // 原子地将当前值减 1 并返回减之前的值（旧值） public final int getAndDecrement() { return unsafe.getAndAddInt(this, valueOffset, -1); } Unsafe#getAndAddInt源码：\n// 原子地获取并增加整数值 public final int getAndAddInt(Object o, long offset, int delta) { int v; do { // 以 volatile 方式获取对象 o 在内存偏移量 offset 处的整数值 v = getIntVolatile(o, offset); } while (!compareAndSwapInt(o, offset, v, v + delta)); // 返回旧值 return v; } 可以看到，getAndAddInt 使用了 do-while 循环：在compareAndSwapInt操作失败时，会不断重试直到成功。也就是说，getAndAddInt方法会通过 compareAndSwapInt 方法来尝试更新 value 的值，如果更新失败（当前值在此期间被其他线程修改），它会重新获取当前值并再次尝试更新，直到操作成功。\n由于 CAS 操作可能会因为并发冲突而失败，因此通常会与while循环搭配使用，在失败后不断重试，直到操作成功。这就是 自旋锁机制 。\n1.3.4 CAS算法存在的问题 # ABA问题是CAS算法最常见的问题。\nABA问题\n如果一个变量 V 初次读取的时候是 A 值，并且在准备赋值的时候检查到它仍然是 A 值，那我们就能说明它的值没有被其他线程修改过了吗？很明显是不能的，因为在这段时间它的值可能被改为其他值，然后又改回 A，那 CAS 操作就会误认为它从来没有被修改过。这个问题被称为 CAS 操作的 \u0026ldquo;ABA\u0026quot;问题。\nABA 问题的解决思路是在变量前面追加上版本号或者时间戳。JDK 1.5 以后的 AtomicStampedReference 类就是用来解决 ABA 问题的，其中的 compareAndSet() 方法就是首先检查当前引用是否等于预期引用，并且当前标志是否等于预期标志，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值。\npublic boolean compareAndSet(V expectedReference, V newReference, int expectedStamp, int newStamp) { Pair\u0026lt;V\u0026gt; current = pair; return expectedReference == current.reference \u0026amp;\u0026amp; expectedStamp == current.stamp \u0026amp;\u0026amp; ((newReference == current.reference \u0026amp;\u0026amp; newStamp == current.stamp) || casPair(current, Pair.of(newReference, newStamp))); } 循环时间长开销大\nCAS 经常会用到自旋操作来进行重试，也就是不成功就一直循环执行直到成功。如果长时间不成功，会给 CPU 带来非常大的执行开销。\n如果 JVM 能够支持处理器提供的pause指令，那么自旋操作的效率将有所提升。pause指令有两个重要作用：\n延迟流水线执行指令：pause指令可以延迟指令的执行，从而减少 CPU 的资源消耗。具体的延迟时间取决于处理器的实现版本，在某些处理器上，延迟时间可能为零。 避免内存顺序冲突：在退出循环时，pause指令可以避免由于内存顺序冲突而导致的 CPU 流水线被清空，从而提高 CPU 的执行效率。 只能保证一个共享变量的原子操作\nCAS 操作仅能对单个共享变量有效。当需要操作多个共享变量时，CAS 就显得无能为力。不过，从 JDK 1.5 开始，Java 提供了AtomicReference类，这使得我们能够保证引用对象之间的原子性。通过将多个变量封装在一个对象中，我们可以使用AtomicReference来执行 CAS 操作。\n除了 AtomicReference 这种方式之外，还可以利用加锁来保证。\n1.4 synchronized关键字 # synchronized 底层使用的JVM级别中的Monitor 来决定当前线程是否获得了锁，如果某一个线程获得了锁，在没有释放锁之前，其他线程是不能或得到锁的。synchronized 属于悲观锁。\nsynchronized 因为需要依赖于JVM级别的Monitor ，相对性能也比较低。\nmonitor对象存在于每个Java对象的对象头中，synchronized 锁便是通过这种方式获取锁的，也是为什么Java中任意对象可以作为锁的原因\nmonitor内部维护了三个变量\nWaitSet：保存处于Waiting状态的线程 EntryList：保存处于Blocked状态的线程 Owner：持有锁的线程 只有一个线程获取到的标志就是在monitor中设置成功了Owner，一个monitor中只能有一个Owner\n在上锁的过程中，如果有其他线程也来抢锁，则进入EntryList 进行阻塞，当获得锁的线程执行完了，释放了锁，就会唤醒EntryList 中等待的线程竞争锁，竞争的时候是非公平的。\nsynchronized 是 Java 中的一个关键字，翻译成中文是同步的意思，主要解决的是多个线程之间访问资源的同步性，可以保证被它修饰的方法或者代码块在任意时刻只能有一个线程执行。\n在 Java 早期版本中，synchronized 属于 重量级锁，效率低下。这是因为监视器锁（monitor）是依赖于底层的操作系统的 Mutex Lock 来实现的，Java 的线程是映射到操作系统的原生线程之上的。如果要挂起或者唤醒一个线程，都需要操作系统帮忙完成，而操作系统实现线程之间的切换时需要从用户态转换到内核态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高。\n不过，在 Java 6 之后， synchronized 引入了大量的优化如自旋锁、适应性自旋锁、锁消除、锁粗化、偏向锁、轻量级锁等技术来减少锁操作的开销，这些优化让 synchronized 锁的效率提升了很多。因此， synchronized 还是可以在实际项目中使用的，像 JDK 源码、很多开源框架都大量使用了 synchronized 。\n关于偏向锁多补充一点：由于偏向锁增加了 JVM 的复杂性，同时也并没有为所有应用都带来性能提升。因此，在 JDK15 中，偏向锁被默认关闭（仍然可以使用 -XX:+UseBiasedLocking 启用偏向锁），在 JDK18 中，偏向锁已经被彻底废弃（无法通过命令行打开）。\n偏向锁：在锁对象的对象头中记录一下当前获取到该锁的线程ID，该线程下次如果又来获取该锁就可以直接获取到了 轻量级锁：由偏向锁升级而来，当一个线程获取到锁后，此时这把锁是偏向锁，此时如果有第二个线程来竞争锁，偏向锁就会升级为轻量级锁，之所以叫轻量级锁，是为了和重量级锁区分开来，轻量级锁底层是通过自旋来实现的，并不会阻塞线程 如果自旋次数过多仍然没有获取到锁，则会升级为重量级锁，重量级锁会导致线程阻塞 自旋锁：自旋锁就是线程在获取锁的过程中，不会去阻塞线程，也就无所谓唤醒线程，阻塞和唤醒这两个步骤都是需要操作系统去进行的，比较消耗时间，自旋锁是线程通过CAS获取预期的一个标记，如果没有获取到，则继续循环获取，如果获取到了则表示获取到了锁，这个过程线程一直在运行中，相对而言没有使用太多的操作系统资源，比较轻量。\nMonitor实现的锁属于重量级锁，你了解过锁升级吗？\nMonitor实现的锁属于重量级锁，里面涉及到了用户态和内核态的切换、进程的上下文切换，成本较高，性能比较低。 在JDK 1.6引入了两种新型锁机制：偏向锁和轻量级锁，它们的引入是为了解决在没有多线程竞争或基本没有竞争的场景下因使用传统锁机制带来的性能开销问题。 对象的内存结构 # 在HotSpot虚拟机中，对象在内存中存储的布局可分为3块区域：对象头（Header）、实例数据（Instance Data）和对齐填充\n我们需要重点分析MarkWord对象头\nMarkWord # hashcode：25位的对象标识Hash码 age：对象分代年龄占4位 biased_lock：偏向锁标识，占1位 ，0表示没有开始偏向锁，1表示开启了偏向锁 thread：持有偏向锁的线程ID，占23位 epoch：偏向时间戳，占2位 ptr_to_lock_record：轻量级锁状态下，指向栈中锁记录的指针，占30位 ptr_to_heavyweight_monitor：重量级锁状态下，指向对象监视器Monitor的指针，占30位 我们可以通过lock的标识，来判断是哪一种锁的等级\n后三位是001表示无锁 后三位是101表示偏向锁 后两位是00表示轻量级锁 后两位是10表示重量级锁 再说Monitor重量级锁 # 每个 Java 对象都可以关联一个 Monitor 对象，如果使用 synchronized 给对象上锁（重量级）之后，该对象头的Mark Word 中就被设置指向 Monitor 对象的指针\n简单说就是：每个对象的对象头都可以设置monoitor的指针，让对象与monitor产生关联\n轻量级锁 # 在很多的情况下，在Java程序运行时，同步块中的代码都是不存在竞争的，不同的线程交替的执行同步块中的代码。这种情况下，用重量级锁是没必要的。因此JVM引入了轻量级锁的概念。\nstatic final Object obj = new Object(); public static void method1() { synchronized (obj) { // 同步块 A method2(); } } public static void method2() { synchronized (obj) { // 同步块 B } } 加锁的流程\n1.在线程栈中创建一个Lock Record，将其obj字段指向锁对象。\n2.通过CAS指令将Lock Record的地址存储在对象头的mark word中（数据进行交换），如果对象处于无锁状态则修改成功，代表该线程获得了轻量级锁。\n3.如果是当前线程已经持有该锁了，代表这是一次锁重入。设置Lock Record第一部分为null，起到了一个重入计数器的作用。\n4.如果CAS修改失败，说明发生了竞争，需要膨胀为重量级锁。\n解锁过程\n1.遍历线程栈,找到所有obj字段等于当前锁对象的Lock Record。\n2.如果Lock Record的Mark Word为null，代表这是一次重入，将obj设置为null后continue。\n3.如果Lock Record的 Mark Word不为null，则利用CAS指令将对象头的mark word恢复成为无锁状态。如果失败则膨胀为重量级锁。\n偏向锁 # 轻量级锁在没有竞争时（就自己这个线程），每次重入仍然需要执行 CAS 操作。\nJava 6 中引入了偏向锁来做进一步优化：只有第一次使用 CAS 将线程 ID 设置到对象的 Mark Word 头，之后发现\n这个线程 ID 是自己的就表示没有竞争，不用重新 CAS。以后只要不发生竞争，这个对象就归该线程所有\nstatic final Object obj = new Object(); public static void m1() { synchronized (obj) { // 同步块 A m2(); } } public static void m2() { synchronized (obj) { // 同步块 B m3(); } } public static void m3() { synchronized (obj) { } } 加锁的流程\n1.在线程栈中创建一个Lock Record，将其obj字段指向锁对象。\n2.通过CAS指令将Lock Record的线程id存储在对象头的mark word中，同时也设置偏向锁的标识为101，如果对象处于无锁状态则修改成功，代表该线程获得了偏向锁。\n3.如果是当前线程已经持有该锁了，代表这是一次锁重入。设置Lock Record第一部分为null，起到了一个重入计数器的作用。与轻量级锁不同的时，这里不会再次进行cas操作，只是判断对象头中的线程id是否是自己，因为缺少了cas操作，性能相对轻量级锁更好一些\n解锁流程参考轻量级锁\n参考回答\nJava中的synchronized有偏向锁、轻量级锁、重量级锁三种形式，分别对应了锁只被一个线程持有、不同线程交替持有锁、多线程竞争锁三种情况。\n重量级锁：底层使用的Monitor实现，里面涉及到了用户态和内核态的切换、进程的上下文切换，成本较高，性能比较低。\n轻量级锁：线程加锁的时间是错开的（也就是没有竞争），可以使用轻量级锁来优化。轻量级修改了对象头的锁标志，相对重量级锁性能提升很多。每次修改都是CAS操作，保证原子性\n偏向锁：一段很长的时间内都只被一个线程使用锁，可以使用了偏向锁，在第一次获得锁时，会有一个CAS操作，之后该线程再获取锁，只需要判断mark word中是否是自己的线程id即可，而不是开销相对较大的CAS命令\n一旦锁发生了竞争，都会升级为重量级锁\n你谈谈 JMM（Java 内存模型） # 难易程度：☆☆☆\n出现频率：☆☆☆\nJMM(Java Memory Model)Java内存模型,是java虚拟机规范中所定义的一种内存模型。\nJava内存模型(Java Memory Model)描述了Java程序中各种变量(线程共享变量)的访问规则，以及在JVM中将变量存储到内存和从内存中读取变量这样的底层细节。\n特点：\n所有的共享变量都存储于主内存(计算机的RAM)这里所说的变量指的是实例变量和类变量。不包含局部变量，因为局部变量是线程私有的，因此不存在竞争问题。 每一个线程还存在自己的工作内存，线程的工作内存，保留了被线程使用的变量的工作副本。 线程对变量的所有的操作(读，写)都必须在工作内存中完成，而不能直接读写主内存中的变量，不同线程之间也不能直接访问对方工作内存中的变量，线程间变量的值的传递需要通过主内存完成。 参考回答\nJava内存模型是Java虚拟机规范中定义的一种非常重要的内存模型。它的主要作用是描述Java程序中线程共享变量的访问规则，以及这些变量在JVM中是如何被存储和读取的，涉及到一些底层的细节。\n这个模型有几个核心的特点。首先，所有的共享变量，包括实例变量和类变量，都被存储在主内存中，也就是计算机的RAM。需要注意的是，局部变量并不包含在内，因为它们是线程私有的，所以不存在竞争问题。\n其次，每个线程都有自己的工作内存，这里保留了线程所使用的变量的工作副本。这意味着，线程对变量的所有操作，无论是读还是写，都必须在自己的工作内存中完成，而不能直接读写主内存中的变量。\n最后，不同线程之间不能直接访问对方工作内存中的变量。如果线程间需要传递变量的值，那么这个过程必须通过主内存来完成。\n1.4.1 如何使用 synchronized？ # synchronized 关键字的使用方式主要有下面 3 种：\n修饰实例方法 修饰静态方法 修饰代码块 1. 修饰实例方法（锁当前对象实例）\n给当前对象实例加锁，进入同步代码前要获得 当前对象实例的锁 。\nsynchronized void method() { //业务代码 } 2. 修饰静态方法（锁当前类）\n给当前类加锁，会作用于类的所有对象实例 ，进入同步代码前要获得 当前 class 的锁。\n这是因为静态成员不属于任何一个实例对象，归整个类所有，不依赖于类的特定实例，被类的所有实例共享。\nsynchronized static void method() { //业务代码 } 静态 synchronized 方法和非静态 synchronized 方法之间的调用互斥么？不互斥！如果一个线程 A 调用一个实例对象的非静态 synchronized 方法，而线程 B 需要调用这个实例对象所属类的静态 synchronized 方法，是允许的，不会发生互斥现象，因为访问静态 synchronized 方法占用的锁是当前类的锁，而访问非静态 synchronized 方法占用的锁是当前实例对象锁。\n3. 修饰代码块（锁指定对象/类）\n对括号里指定的对象/类加锁：\nsynchronized(object) 表示进入同步代码库前要获得 给定对象的锁。 synchronized(类.class) 表示进入同步代码前要获得 给定 Class 的锁 synchronized(this) { //业务代码 } 总结\nsynchronized 关键字加到 static 静态方法和 synchronized(class) 代码块上都是是给 Class 类上锁；\nsynchronized 关键字加到实例方法上是给对象实例上锁；\n尽量不要使用 synchronized(String a) 因为 JVM 中，字符串常量池具有缓存功能。\n1.4.2 构造方法可以用 synchronized 修饰么？ # 构造方法不能使用 synchronized 关键字修饰。不过，可以在构造方法内部使用 synchronized 代码块。\n另外，构造方法本身是线程安全的，但如果在构造方法中涉及到共享资源的操作，就需要采取适当的同步措施来保证整个构造过程的线程安全。\n1.4.3 synchronized 底层原理 # synchronized 关键字底层原理属于 JVM 层面的东西。\nsynchronized 同步语句块的情况\npublic class SynchronizedDemo { public void method() { synchronized (this) { System.out.println(\u0026#34;synchronized 代码块\u0026#34;); } } } 通过 JDK 自带的 javap 命令查看 SynchronizedDemo 类的相关字节码信息：首先切换到类的对应目录执行 javac SynchronizedDemo.java 命令生成编译后的 .class 文件，然后执行javap -c -s -v -l SynchronizedDemo.class。\n从上面我们可以看出：synchronized 同步语句块的实现使用的是 monitorenter 和 monitorexit 指令，其中 monitorenter 指令指向同步代码块的开始位置，monitorexit 指令则指明同步代码块的结束位置。\n上面的字节码中包含一个 monitorenter 指令以及两个 monitorexit 指令，这是为了保证锁在同步代码块代码正常执行以及出现异常的这两种情况下都能被正确释放。\n当执行 monitorenter 指令时，线程试图获取锁也就是获取 对象监视器 monitor 的持有权。\n在 Java 虚拟机(HotSpot)中，Monitor 是基于 C++实现的，由ObjectMonitor实现的。每个对象中都内置了一个 ObjectMonitor对象。\n另外，wait/notify等方法也依赖于monitor对象，这就是为什么只有在同步的块或者方法中才能调用wait/notify等方法，否则会抛出java.lang.IllegalMonitorStateException的异常的原因。\n在执行monitorenter时，会尝试获取对象的锁，如果锁的计数器为 0 则表示锁可以被获取，获取后将锁计数器设为 1 也就是加 1。\n对象锁的的拥有者线程才可以执行 monitorexit 指令来释放锁。在执行 monitorexit 指令后，将锁计数器设为 0，表明锁被释放，其他线程可以尝试获取锁。\n如果获取对象锁失败，那当前线程就要阻塞等待，直到锁被另外一个线程释放为止。\nsynchronized 修饰方法的情况\npublic class SynchronizedDemo2 { public synchronized void method() { System.out.println(\u0026#34;synchronized 方法\u0026#34;); } } synchronized 修饰的方法并没有 monitorenter 指令和 monitorexit 指令，取而代之的是 ACC_SYNCHRONIZED 标识，该标识指明了该方法是一个同步方法。JVM 通过该 ACC_SYNCHRONIZED 访问标志来辨别一个方法是否声明为同步方法，从而执行相应的同步调用。\n如果是实例方法，JVM 会尝试获取实例对象的锁。如果是静态方法，JVM 会尝试获取当前 class 的锁。\n总结\nsynchronized 同步语句块的实现使用的是 monitorenter 和 monitorexit 指令，其中 monitorenter 指令指向同步代码块的开始位置，monitorexit 指令则指明同步代码块的结束位置。\nsynchronized 修饰的方法并没有 monitorenter 指令和 monitorexit 指令，取而代之的是 ACC_SYNCHRONIZED 标识，该标识指明了该方法是一个同步方法。\n不过两者的本质都是对对象监视器 monitor 的获取。\n相关推荐：Java 锁与线程的那些事 - 有赞技术团队 。\n🧗🏻 进阶一下：学有余力的小伙伴可以抽时间详细研究一下对象监视器 monitor。\n1.4.3.1 JDK1.6 之后的synchronized底层做了哪些优化？锁升级原理了解吗？ # 在 Java 6 之后， synchronized 引入了大量的优化如自旋锁、适应性自旋锁、锁消除、锁粗化、偏向锁、轻量级锁等技术来减少锁操作的开销，这些优化让 synchronized 锁的效率提升了很多（JDK18 中，偏向锁已经被彻底废弃，前面已经提到过了）。\n锁主要存在四种状态，依次是：无锁状态、偏向锁状态、轻量级锁状态、重量级锁状态，他们会随着竞争的激烈而逐渐升级。注意锁可以升级不可降级，这种策略是为了提高获得锁和释放锁的效率。\n偏向锁：偏向锁是指当一个线程获取到锁之后，会在对象头中记录下该线程的标识，下次再进入同步块时，无需进行额外的加锁操作，从而提高性能。\n轻量级锁：当多个线程对同一个锁进行争夺时，JVM会使用轻量级锁来避免传统的重量级锁带来的性能消耗。它采用自旋的方式，即不放弃CPU的执行时间，尝试快速获取锁，避免线程阻塞和上下文切换的开销。\n重量级锁：当多个线程对同一个锁进行强烈争夺时，JVM会升级为重量级锁，此时线程会进入阻塞状态，等待锁的释放。这种方式适用于竞争激烈的情况，但会带来较大的性能开销。\n自旋锁（Spin Lock）：自旋锁是一种非阻塞的锁机制，当线程无法立即获取锁时，它会持续检查锁是否被释放，直到获取到锁为止。自旋锁可以减少线程的上下文切换开销，但在锁持有时间较长的情况下，会浪费CPU资源。\n适应性自旋锁（Adaptive Spin Lock）：适应性自旋锁是一种结合了自旋锁和阻塞锁的锁机制。在刚开始时，线程会采用自旋的方式来等待锁的释放，但随着时间的推移，如果锁仍然没有被释放，线程会逐渐切换到阻塞状态，从而减少CPU资源的浪费.\n分段锁（Segmented Locking）：分段锁是一种针对共享资源过多的情况下的锁优化机制。它将共享资源分成多个段，每个线程只需要对其中一部分进行加锁和解锁操作，从而减少了锁的竞争和开销。\n锁粗化（Lock Coarsening）：锁粗化是一种针对长时间持有锁的场景的优化策略。如果一个线程在短时间内需要连续多次加锁和解锁，那么可以将这些加锁和解锁操作合并成一个较大的加锁和解锁操作，从而减少了加锁和解锁的次数，提高了效率。\n乐观锁（Optimistic Locking）：乐观锁是一种基于冲突检测的锁机制。它假设多个线程同时访问和修改同一个数据的概率较小，因此在读取数据时不会加锁，而是在提交修改时检测是否存在冲突。如果存在冲突，则进行回滚或重试操作。乐观锁适用于读操作较多的场景。\n锁优化技术是为了提高synchronized的并发性能，根据锁的竞争程度和持有时间的长短选择相应的锁状态，使得多个线程能够更高效地共享资源。\nsynchronized 锁升级是一个比较复杂的过程，面试也很少问到，如果你想要详细了解的话，可以看看这篇文章：浅析 synchronized 锁升级的原理与实现。\n1.4.3.2 synchronized 和 volatile 有什么区别？ # synchronized 关键字和 volatile 关键字是两个互补的存在，而不是对立的存在！\nvolatile 关键字是线程同步的轻量级实现，所以 volatile性能肯定比synchronized关键字要好 。但是 volatile 关键字只能用于变量而 synchronized 关键字可以修饰方法以及代码块 。 volatile 关键字能保证数据的可见性，但不能保证数据的原子性。synchronized 关键字两者都能保证。 volatile关键字主要用于解决变量在多个线程之间的可见性，而 synchronized 关键字解决的是多个线程之间访问资源的同步性。 1.4.4 线程同步 # 同步与异步关注的是消息通信机制。\n==所谓同步，就是在发出一个调用时，在没有得到结果之前，该调用就不返回。==但是一旦调用返回，就得到返回值了。换句话说，就是由调用者主动等待这个调用的结果。 ==而异步则是相反，调用在发出之后，这个调用就直接返回了，所以就没有返回结果。==换句话说，当一个异步过程调用发出后，调用者不会立刻得到结果。而是在调用发出之后，被调用者通过“状态”、“通知”、“回调”三种途径通知调用者。 可以使用哪一种途径依赖于被调用者的实现，除非被调用者提供多种选择，否则不受调用者控制。\n如果被调用者用状态来通知，那么调用者就需要每隔一定时间检查一次，效率就很低。 如果使用通知和回调的方式，效率则很高。因为被调用者几乎不需要做额外的操作。 举个例子：\n你打电话问书店老板有没有《高效演讲》这本书。\n如果是同步通信机制，书店老板会说，你稍等，”我查一下\u0026rdquo;，然后开始查啊查，等查好了（可能是5秒，也可能是一天）告诉你结果（返回结果）。\n而异步通信机制，书店老板直接告诉你我查一下啊，查好了打电话给你，然后直接挂电话了（不返回结果）。然后查好了，他会主动打电话给你。在这里老板通过“回电”这种方式来回调。\n线程的同步是为了保证多个线程按照特定的顺序、协调地访问共享资源，避免数据不一致和竞争条件等问题。 在Java中，常见的线程同步方式有以下几种：\n使用synchronized关键字：通过在方法或代码块前加上synchronized关键字，确保同一时间只有一个线程可以执行标记为同步的代码。这样可以避免多个线程同时访问共享资源造成的数据不一致问题。(实现原理： synchronized基于监视器锁（Monitor Lock）实现，底层依赖于操作系统的互斥锁（Mutex）。每个对象在Java中都与一个隐式的监视器相关联，使用synchronized时，线程需要获得对象的监视器锁，然后才能进入同步代码块。Java的对象有一个头（Object Header），其中包含一个Mark Word，用于存储锁的信息。锁有不同的状态，包括无锁状态、偏向锁、轻量级锁和重量级锁，JVM会根据竞争情况自动进行状态变换以优化性能。) 使用ReentrantLock类：它是一个**可重入锁**，通过调用lock()和unlock()方法获取和释放锁。与synchronized不同，ReentrantLock提供了更灵活的同步控制，例如可实现公平性和试锁等待时间。 使用wait()、notify()和notifyAll()方法：这些方法是Object类的方法，允许线程间进行协作和通信。通过调用wait()方法使线程进入等待状态，然后其他线程可以通过notify()或notifyAll()方法唤醒等待的线程。 使用CountDownLatch和CyclicBarrier：它们是并发工具类，用于线程之间的同步和等待。CountDownLatch可用于等待一组线程完成操作，而CyclicBarrier用于等待一组线程互相达到屏障位置。 选择适合的同步方式会根据具体需求和场景而定。在使用任何同步机制时，需要注意避免死锁和性能问题，合理设计同步范围和粒度。\n1.4.5 synchronized的实现原理 # synchronized是Java语言中最基本的线程同步机制，它通过互斥锁来控制线程对共享变量的访问。 具体实现原理如下：\nsynchronized的实现基础是对象内部的锁（也称为监视器锁或管程），每个锁关联着一个对象实例。 当synchronized作用于某个对象时，它就会尝试获取这个对象的锁，如果锁没有被其他线程占用，则当前线程获取到锁，并可以执行同步代码块；如果锁已经被其他线程占用，那么当前线程就会阻塞在同步块之外，直到获取到锁才能进入同步块。 synchronized还支持作用于类上，此时它锁住的是整个类，而不是类的某个实例。在这种情况下，由于只有一个锁存在，所以所有使用该类的线程都需要等待锁的释放。 在JVM内部，每个Java对象都有头信息，其中包含了对象的一些元信息和状态标志。synchronized通过修改头信息的状态标志来实现锁的获取和释放。 synchronized还支持可重入性，即在同一个线程中可以多次获取同一个锁，这样可以避免死锁问题。 Java虚拟机会通过锁升级的方式来提升synchronized的效率，比如偏向锁、轻量级锁和重量级锁等机制，使得在竞争不激烈的情况下，synchronized的性能可以达到与非同步代码相当的水平。 1.4.6 synchronized 可以锁字符串吗 # 使用synchronized 锁字符串，需要将字符串添加到字符串常量池中。日常使用中通过通过new对象的方式创建对象，再取对象的字段，因此需要使用intern把字符串放入常量池中，但是直接使用String的intern全部把字符串放入常量池会存在一些问题。显然在数据量很大的情况下，将所有字符串都放入常量池是不合理的，常量池大小依赖服务器内存，且只有等待fullGC，极端情况下会导致频繁fullGC。并且在数据量很大的情况下，将字符串放入常量会存在性能问题。 可以用google的guava包的interner类：\npublic class test{ private static Interner\u0026lt;String\u0026gt; lock = Interners.newWeakInterner(); public void test() { synchronized (lock.intern(id.toString())){ //do... } } } Interner是通过MapMaker构造ConcurrentMap来实现弱引用，ConcurrentMap用分段的方式保证安全。这里个人觉得比常量池的优点就在于这里是弱引用的方式，便于map的回收，常量池只能依赖于fullGC，这里的回收在不使用或内存不够用条件下即可被回收（Minor GC阶段）\nsynchronized可以锁存活于字符串常量池中的值，不能锁存活于堆栈中的字符串（字符串地址要相同） 可以使用String对象.intern() 将该字符串放入字符串常量池中，但是常量池的回收只能依赖于fullGC，故不推荐使用 推荐使用guava包下的interner类，使用弱引用的方式，在内存不足的时候自动进行垃圾回收\n1.4.7 可重入锁 # 可重入锁可以简单理解为一个可以重复获取的锁，就像拿钥匙开锁一样，你可以反复用同一把钥匙开锁。这种锁在同一线程内是安全的，因为它可以被同一线程多次获取，而不会产生不一致的状态。 举个例子，假设有一个线程A在执行一个方法，同时这个方法内部又调用另一个方法，那么线程A可以重复获取同一个锁，而不会出现死锁的情况。因为同一线程可以多次获取同一个锁，所以这种锁机制避免了死锁的发生。 但是需要注意，在使用可重入锁时，必须保证在释放锁之前已经获取了该锁，否则会导致死锁。同时还需要保证在获取锁的时候没有嵌套地获取其他锁，否则也会导致死锁。另外，还必须保证在获取锁的时候没有阻塞其他线程，否则同样会导致死锁。 总之，可重入锁是一种安全的锁机制，可以避免死锁的发生。但是在使用时需要注意以上几点，以确保程序的正确性和安全性。\n阻塞与非阻塞\n阻塞和非阻塞关注的是程序在等待调用结果（消息，返回值）时的状态。\n阻塞调用是指调用结果返回之前，当前线程会被挂起。调用线程只有在得到结果之后才会返回。 非阻塞调用指在不能立刻得到结果之前，该调用不会阻塞当前线程。 接着上面的例子：\n打电话问书店老板有没有《高效演讲》这本书，\n如果是阻塞式调用，你会一直把自己“挂起”，直到得到这本书有没有的结果。 如果是非阻塞式调用，你不管老板有没有告诉你，你自己先一边去玩了（先去干点别的，不用傻等）， 当然你也要偶尔过几分钟检查一下老板有没有返回结果。 同步代码块解决数据安全问题：\n安全问题出现的条件\n是多线程环境\n有共享数据\n有多条语句操作共享数据\n如何解决多线程安全问题呢?\n基本思想：让程序没有安全问题的环境 怎么实现呢?\n把多条语句操作共享数据的代码给锁起来，让任意时刻只能有一个线程执行即可\nJava提供了同步代码块的方式来解决\n同步代码块格式：\nsynchronized(任意对象) { 多条语句操作共享数据的代码 } synchronized(任意对象)：就相当于给代码加锁了，任意对象就可以看成是一把锁\n同步的好处和弊端\n好处：解决了多线程的数据安全问题\n弊端：当线程很多时，因为每个线程都会去判断同步上的锁，这是很耗费资源的，无形中会降低程序的运行效率\n同步方法解决数据安全问题：\n同步方法的格式\n同步方法：就是把synchronized关键字加到方法上\n修饰符 synchronized 返回值类型 方法名(方法参数) { 方法体； } 同步方法的锁对象是什么呢?\n​\tthis\n静态同步方法\n同步静态方法：就是把synchronized关键字加到静态方法上\n修饰符 static synchronized 返回值类型 方法名(方法参数) { 方法体； } 同步静态方法的锁对象是什么呢?\n​\t类名.class\n1.5 ReentrantLock # 1.5.1 ReentrantLock 是什么？ # ReentrantLock 实现了 Lock 接口，是一个可重入且独占式的锁，和 synchronized 关键字类似。不过，ReentrantLock 更灵活、更强大，增加了轮询、超时、中断、公平锁和非公平锁等高级功能。\npublic class ReentrantLock implements Lock, java.io.Serializable {} ReentrantLock 里面有一个内部类 Sync，Sync 继承 AQS（AbstractQueuedSynchronizer），添加锁和释放锁的大部分操作实际上都是在 Sync 中实现的。Sync 有公平锁 FairSync 和非公平锁 NonfairSync 两个子类。\nReentrantLock 默认使用非公平锁，也可以通过构造器来显式的指定使用公平锁。\n// 传入一个 boolean 值，true 时为公平锁，false 时为非公平锁 public ReentrantLock(boolean fair) { sync = fair ? new FairSync() : new NonfairSync(); } 从上面的内容可以看出， ReentrantLock 的底层就是由 AQS 来实现的。关于 AQS 的相关内容推荐阅读 AQS 详解 这篇文章。\n1.5.2 Sychronized和ReentrantLock的区别 # sychronized是一个关键字，ReentrantLock是一个类 sychronized会自动的加锁与释放锁，ReentrantLock需要程序员手动加锁与释放锁 sychronized的底层是JVM层面的锁，ReentrantLock是API层面的锁 sychronized是非公平锁，ReentrantLock可以选择公平锁或非公平锁 sychronized锁的是对象，锁信息保存在对象头中，ReentrantLock通过代码中int类型的state标识来标识锁的状态 sychronized底层有一个锁升级的过程 相似之处\n线程安全：两者都可以用于实现对临界区的保护，从而实现线程安全。 可重入性：两者都支持可重入性，允许一个线程多次获取同一把锁而不会发生死锁。 互斥锁：本质上都是互斥锁，确保在同一时刻只有一个线程能执行被同步的代码块。 区别\n灵活性： ○synchronized是Java语言的内置特性，使用简单，但功能有限。 ○ReentrantLock是一个类，提供了更高级的锁功能，例如：可中断的锁获取、超时获取锁、非阻塞尝试获取锁以及可实现更复杂的同步结构。 性能： ○在较低竞争时，synchronized会自动使用优化，比如锁消除和锁粗化，使得它的性能在某些情况下可能高于ReentrantLock。 ○ReentrantLock可能在高竞争下表现更好，因为它可以提供非公平和公平锁模式，公平模式会严格按照请求锁的顺序来分配锁。 实现的功能： ○ReentrantLock提供了更多控制功能，如lock()、unlock()方法，可在任何位置灵活调用。而synchronized在语法上是强制块结束时锁自动释放。 ○ReentrantLock提供tryLock()和lockInterruptibly()方法，以响应中断和超时。 条件变量： ○ReentrantLock具有与之关联的Condition对象，可以搭配lock来更细粒度的控制线程通信。 ○synchronized配合Object的wait()和notify()/notifyAll()来进行线程之间的通信，但不如Condition灵活。 适用场景\n**synchronized：**适用于简单的同步需求。由于其语法简单且嵌入在Java语言中，特别适合锁定范围与方法等价的情况。小规模、多线程竞争不高的情况下表现优异。适合开发者不想处理锁的复杂生命周期时使用。 **ReentrantLock：**适用于需要更高级的同步控制，或者锁定范围与方法不同时。特别是在需要公平锁、可中断锁操作、尝试获取带超时功能的锁，或者需要多个条件等待时，应选择ReentrantLock。当系统规模较大、线程数较多，且具有复杂同步需求的情境时表现突出。 1.5.2 公平锁和非公平锁 # 公平锁 : 锁被释放之后，先申请的线程先得到锁。性能较差一些，因为公平锁为了保证时间上的绝对顺序，上下文切换更频繁。\n非公平锁：锁被释放之后，后申请的线程可能会先获取到锁，是随机或者按照其他优先级排序的。性能更好，但可能会导致某些线程永远无法获取到锁。\n1.5.3 公平锁和非公平锁的底层实现 # 首先不管是公平锁和非公平锁，它们的底层实现都会使用AQS来进行排队，它们的区别在于：线程在使用lock()方法加锁时，如果是公平锁，会先检查AQS队列中是否存在线程在排队，如果有线程在排队，则当前线程也进行排队，如果是非公平锁，则不会去检查是否有线程在排队，而是直接竞争锁。\n不管是公平锁还是非公平锁，一旦没竞争到锁，都会进行排队，当锁释放时，都是唤醒排在最前面的线程，所以非公平锁只是体现在了线程加锁阶段，而没有体现在线程被唤醒阶段。\n另外，ReentrantLock是可重入锁，不管是公平锁还是非公平锁都是可重入的。\n非公平锁加锁：\nReentrantLock是Java中提供的一种可重入锁，它支持两种锁的模式：公平锁和非公平锁。这两种锁模式的底层实现略有不同：\n公平锁（Fair Lock）： 公平锁的特点是按照请求锁的顺序来分配锁，即先到先得。在ReentrantLock中，通过构造函数可以选择创建一个公平锁。公平锁的底层实现使用了一个FIFO队列（First-In-First-Out），即等待队列。当一个线程请求锁时，如果锁已经被其他线程持有，请求线程会被放入等待队列的末尾，按照请求的顺序等待锁的释放。当锁被释放时，等待队列中的第一个线程会被唤醒并获得锁。 非公平锁（Non-Fair Lock）： 非公平锁不考虑请求锁的顺序，它允许新的请求线程插队并尝试立即获取锁，而不管其他线程是否在等待。在ReentrantLock中，默认情况下创建的是非公平锁。非公平锁的底层实现中，有一个等待队列，但它不会严格按照请求的顺序来分配锁，而是根据线程竞争锁的情况来判断是否立即分配给新的请求线程。 底层实现中，无论是公平锁还是非公平锁，都使用了类似的同步器（Sync）来管理锁的状态和线程的竞争。不同之处在于如何处理等待队列中的线程，以及是否按照请求的顺序来分配锁。 需要注意的是，公平锁虽然遵循公平性原则，但在高并发情况下可能会引入较大的性能开销，因为每次都要维护一个有序的等待队列。而非公平锁则更加灵活，但可能导致某些线程一直获取不到锁。\n1.5.4 synchronized 和 ReentrantLock # 两者都是可重入锁\n可重入锁 也叫递归锁，指的是线程可以再次获取自己的内部锁。比如一个线程获得了某个对象的锁，此时这个对象锁还没有释放，当其再次想要获取这个对象的锁的时候还是可以获取的，如果是不可重入锁的话，就会造成死锁。\nJDK 提供的所有现成的 Lock 实现类，包括 synchronized 关键字锁都是可重入的。\n在下面的代码中，method1() 和 method2()都被 synchronized 关键字修饰，method1()调用了method2()。\npublic class SynchronizedDemo { public synchronized void method1() { System.out.println(\u0026#34;方法1\u0026#34;); method2(); } public synchronized void method2() { System.out.println(\u0026#34;方法2\u0026#34;); } } 由于 synchronized锁是可重入的，同一个线程在调用method1() 时可以直接获得当前对象的锁，执行 method2() 的时候可以再次获取这个对象的锁，不会产生死锁问题。假如synchronized是不可重入锁的话，由于该对象的锁已被当前线程所持有且无法释放，这就导致线程在执行 method2()时获取锁失败，会出现死锁问题。\nsynchronized依赖于JVM而ReentrantLock依赖于API\nsynchronized 是依赖于 JVM 实现的，前面我们也讲到了 虚拟机团队在 JDK1.6 为 synchronized 关键字进行了很多优化，但是这些优化都是在虚拟机层面实现的，并没有直接暴露给我们。\nReentrantLock 是 JDK 层面实现的（也就是 API 层面，需要 lock() 和 unlock() 方法配合 try/finally 语句块来完成），所以我们可以通过查看它的源代码，来看它是如何实现的。\nReentrantLock比synchronized增加了一些高级功能\n相比synchronized，ReentrantLock增加了一些高级功能。主要来说主要有三点：\n等待可中断 : ReentrantLock提供了一种能够中断等待锁的线程的机制，通过 lock.lockInterruptibly() 来实现这个机制。也就是说正在等待的线程可以选择放弃等待，改为处理其他事情。 可实现公平锁 : ReentrantLock可以指定是公平锁还是非公平锁。而synchronized只能是非公平锁。所谓的公平锁就是先等待的线程先获得锁。ReentrantLock默认情况是非公平的，可以通过 ReentrantLock类的ReentrantLock(boolean fair)构造方法来指定是否是公平的。 可实现选择性通知（锁可以绑定多个条件）: synchronized关键字与wait()和notify()/notifyAll()方法相结合可以实现等待/通知机制。ReentrantLock类当然也可以实现，但是需要借助于Condition接口与newCondition()方法。 如果你想使用上述功能，那么选择 ReentrantLock 是一个不错的选择。\n关于 Condition接口的补充：\nCondition是 JDK1.5 之后才有的，它具有很好的灵活性，比如可以实现多路通知功能也就是在一个Lock对象中可以创建多个Condition实例（即对象监视器），线程对象可以注册在指定的Condition中，从而可以有选择性的进行线程通知，在调度线程上更加灵活。 在使用notify()/notifyAll()方法进行通知时，被通知的线程是由 JVM 选择的，用ReentrantLock类结合Condition实例可以实现“选择性通知” ，这个功能非常重要，而且是 Condition 接口默认提供的。而synchronized关键字就相当于整个 Lock 对象中只有一个Condition实例，所有的线程都注册在它一个身上。如果执行notifyAll()方法的话就会通知所有处于等待状态的线程，这样会造成很大的效率问题。而Condition实例的signalAll()方法，只会唤醒注册在该Condition实例中的所有等待线程。\n1.5.5 可中断锁和不可中断锁 # 可中断锁：获取锁的过程中可以被中断，不需要一直等到获取锁之后 才能进行其他逻辑处理。ReentrantLock 就属于是可中断锁。\n不可中断锁：一旦线程申请了锁，就只能等到拿到锁以后才能进行其他的逻辑处理。 synchronized 就属于是不可中断锁。\n1.5.6 tryLock（）和 lock（）方法 # tryLock()表示尝试加锁，可能加到，也可能加不到，该方法不会阻塞线程，如果加到锁则返回true，没有加到则返回false lock()表示阻塞加锁，线程会阻塞直到加到锁，方法也没有返回值 1.6 ReentrantReadWriteLock # ReentrantReadWriteLock 在实际项目中使用的并不多，面试中也问的比较少，简单了解即可。JDK 1.8 引入了性能更好的读写锁 StampedLock 。\n1.6.1 ReentrantReadWriteLock 是什么？ # ReentrantReadWriteLock 实现了 ReadWriteLock ，是一个可重入的读写锁，既可以保证多个线程同时读的效率，同时又可以保证有写入操作时的线程安全。\npublic class ReentrantReadWriteLock implements ReadWriteLock, java.io.Serializable{ } public interface ReadWriteLock { Lock readLock(); Lock writeLock(); } 一般锁进行并发控制的规则：读读互斥、读写互斥、写写互斥。 读写锁进行并发控制的规则：读读不互斥、读写互斥、写写互斥（只有读读不互斥）。 ReentrantReadWriteLock 其实是两把锁，一把是 WriteLock (写锁)，一把是 ReadLock（读锁） 。读锁是共享锁，写锁是独占锁。读锁可以被同时读，可以同时被多个线程持有，而写锁最多只能同时被一个线程持有。\n和 ReentrantLock 一样，ReentrantReadWriteLock 底层也是基于 AQS 实现的。\nReentrantReadWriteLock 也支持公平锁和非公平锁，默认使用非公平锁，可以通过构造器来显示的指定。\n// 传入一个 boolean 值，true 时为公平锁，false 时为非公平锁 public ReentrantReadWriteLock(boolean fair) { sync = fair ? new FairSync() : new NonfairSync(); readerLock = new ReadLock(this); writerLock = new WriteLock(this); } ReentrantReadWriteLock 适合什么场景？\n由于 ReentrantReadWriteLock 既可以保证多个线程同时读的效率，同时又可以保证有写入操作时的线程安全。因此，在读多写少的情况下，使用 ReentrantReadWriteLock 能够明显提升系统性能。\n1.6.2 共享锁和独占锁有什么区别？ # 共享锁：一把锁可以被多个线程同时获得。 独占锁：一把锁只能被一个线程获得。 1.6.3 线程持有读锁还能获取写锁吗？ # 在线程持有读锁的情况下，该线程不能取得写锁(因为获取写锁的时候，如果发现当前的读锁被占用，就马上获取失败，不管读锁是不是被当前线程持有)。 在线程持有写锁的情况下，该线程可以继续获取读锁（获取读锁时如果发现写锁被占用，只有写锁没有被当前线程占用的情况才会获取失败）。 读写锁的源码分析，推荐阅读 聊聊 Java 的几把 JVM 级锁 - 阿里巴巴中间件 这篇文章，写的很不错。\n1.6.4 读锁为什么不能升级为写锁？ # 写锁可以降级为读锁，但是读锁却不能升级为写锁。这是因为读锁升级为写锁会引起线程的争夺，毕竟写锁属于是独占锁，这样的话，会影响性能。\n另外，还可能会有死锁问题发生。举个例子：假设两个线程的读锁都想升级写锁，则需要对方都释放自己锁，而双方都不释放，就会产生死锁。\n1.6.5 读写锁的应用场景 # ReadWriteLock 是 Java 提供的一种用于解决并发读写问题的锁机制，其主要目的在于提高在读多写少的场景下的并发性能。ReadWriteLock 允许多个线程同时读取共享资源，但是对写操作是独占的。这意味着在一个线程写入数据时，其他线程既不能读取也不能写入。\n应用场景\n缓存系统： 在缓存系统中，数据读取频率通常远高于数据写入，因此使用读写锁可以提高读取操作的并发性和效率。 配置管理： 系统配置或应用程序配置的数据通常在初始化后多为读取，只有在特殊情况下才会更新，因此适合使用读写锁。 文档编辑： 多人协同编辑文档时，可能会有许多人同时查看文档内容，只有少数人进行编辑，这种场合也可以使用读写锁。 游戏状态： 游戏服务器可能需要频繁读取玩家的状态，而状态更新相对较少，因此读写锁可以提高状态读取的性能。 关键点\n提升读取性能：ReadWriteLock 允许多个读取线程同时访问共享资源，从而提高了读取性能。 写锁独占：只有在没有其他线程读取或写入时，写锁才能获得，这保障了数据在写入时的一致性和安全性。 适用性：适用于读多写少场景，能显著提高系统在并发读取场景下的性能。 易于使用：ReadWriteLock 提供了清晰的语义分离（读与写），使得代码更具可读性和维护性。 1.7 StampedLock # StampedLock 面试中问的比较少，不是很重要，简单了解即可。\n1.7.1 StampedLock是什么？ # StampedLock 是 JDK 1.8 引入的性能更好的读写锁，不可重入且不支持条件变量 Condition。\n不同于一般的 Lock 类，StampedLock 并不是直接实现 Lock或 ReadWriteLock接口，而是基于 CLH 锁 独立实现的（AQS 也是基于这玩意）。\npublic class StampedLock implements java.io.Serializable { } StampedLock 提供了三种模式的读写控制模式：读锁、写锁和乐观读。\n写锁：独占锁，一把锁只能被一个线程获得。当一个线程获取写锁后，其他请求读锁和写锁的线程必须等待。类似于 ReentrantReadWriteLock 的写锁，不过这里的写锁是不可重入的。 读锁 （悲观读）：共享锁，没有线程获取写锁的情况下，多个线程可以同时持有读锁。如果己经有线程持有写锁，则其他线程请求获取该读锁会被阻塞。类似于 ReentrantReadWriteLock 的读锁，不过这里的读锁是不可重入的。 乐观读：允许多个线程获取乐观读以及读锁。同时允许一个写线程获取写锁。 另外，StampedLock 还支持这三种锁在一定条件下进行相互转换 。\nlong tryConvertToWriteLock(long stamp){} long tryConvertToReadLock(long stamp){} long tryConvertToOptimisticRead(long stamp){} StampedLock 在获取锁的时候会返回一个 long 型的数据戳，该数据戳用于稍后的锁释放参数，如果返回的数据戳为 0 则表示锁获取失败。当前线程持有了锁再次获取锁还是会返回一个新的数据戳，这也是StampedLock不可重入的原因。\n// 写锁 public long writeLock() { long s, next; // bypass acquireWrite in fully unlocked case only return ((((s = state) \u0026amp; ABITS) == 0L \u0026amp;\u0026amp; U.compareAndSwapLong(this, STATE, s, next = s + WBIT)) ? next : acquireWrite(false, 0L)); } // 读锁 public long readLock() { long s = state, next; // bypass acquireRead on common uncontended case return ((whead == wtail \u0026amp;\u0026amp; (s \u0026amp; ABITS) \u0026lt; RFULL \u0026amp;\u0026amp; U.compareAndSwapLong(this, STATE, s, next = s + RUNIT)) ? next : acquireRead(false, 0L)); } // 乐观读 public long tryOptimisticRead() { long s; return (((s = state) \u0026amp; WBIT) == 0L) ? (s \u0026amp; SBITS) : 0L; } 1.7.2 StampedLock 的性能为什么更好？ # 相比于传统读写锁多出来的乐观读是StampedLock比 ReadWriteLock 性能更好的关键原因。StampedLock 的乐观读允许一个写线程获取写锁，所以不会导致所有写线程阻塞，也就是当读多写少的时候，写线程有机会获取写锁，减少了线程饥饿的问题，吞吐量大大提高。\n1.7.3 StampedLock适合什么场景？ # 和 ReentrantReadWriteLock 一样，StampedLock 同样适合读多写少的业务场景，可以作为 ReentrantReadWriteLock的替代品，性能更好。\n不过，需要注意的是StampedLock不可重入，不支持条件变量 Condition，对中断操作支持也不友好（使用不当容易导致 CPU 飙升）。如果你需要用到 ReentrantLock 的一些高级性能，就不太建议使用 StampedLock 了。\n另外，StampedLock 性能虽好，但使用起来相对比较麻烦，一旦使用不当，就会出现生产问题。强烈建议你在使用StampedLock 之前，看看 StampedLock 官方文档中的案例。\n1.7.4 StampedLock的底层原理了解吗？ # StampedLock 不是直接实现 Lock或 ReadWriteLock接口，而是基于 CLH 锁 实现的（AQS 也是基于这玩意），CLH 锁是对自旋锁的一种改良，是一种隐式的链表队列。StampedLock 通过 CLH 队列进行线程的管理，通过同步状态值 state 来表示锁的状态和类型。\nStampedLock 的原理和 AQS 原理比较类似，这里就不详细介绍了，感兴趣的可以看看下面这两篇文章：\nAQS 详解 StampedLock 底层原理分析 如果你只是准备面试的话，建议多花点精力搞懂 AQS 原理即可，StampedLock 底层原理在面试中遇到的概率非常小。\n自旋锁 # 阻塞或唤醒一个Java进程，需要操作系统切换CPU状态来完成，这种状态转换需要耗费处理器时间。如果同步代码块中的内容过于简单，状态转换花费的时间有可能比用户代码执行的时间还长。\n在许多场景中，同步资源的锁定时间很短，为了这一小段时间去切换线程，线程挂起和恢复现场的时间花费可能会让系统得不偿失。如果物理机器有多个处理器，可以让两个或以上的线程并行执行，我们就可以让后面那个请求锁的线程不放弃CPU的执行时间，看看前面那个得到锁的线程是否会很快释放锁。\n而为了让当前线程“稍等一下”，我们就需要让当前线程进行自旋，如果自旋完成后，持有锁的线程已经释放了锁，当前线程就可以不进入阻塞状态而是直接获得同步资源，避免的线程切换的开销，这就是自旋锁。\n自旋锁与非自旋锁流程图\n自旋锁的缺陷\n自旋等待虽然避免了线程切换的开销，但它要占用处理器时间。如果锁被占用的时间很短，自旋的效果就很好。反之，如果所被占用的时间很长，自旋就是在白白浪费处理器时间。所以，自旋等待的时间必须要有限度，默认情况下是10次，也可以通过 -Xx:PreBloackSpin来更改。如果在自旋10次都没有获得锁，就应该挂起线程。\n自旋锁的实现原理\n自旋锁的实现原理同样也是CAS，AtomicInteger中调用unsafe进行自增操作源码中的do…while循环就是一个自旋操作，如果修改数值失败则通过循环来执行自旋，直到成功。\n自适应自旋锁\n自旋锁在Java1.6中改为默认开启，并引入了自适应的自旋锁。 自适应意味着自旋的次数不在固定，而是由前一次在同一个锁上的自旋时间和锁的拥有者的状态共同决定。 如果在同一个锁对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋也是很可能再次成功的，进而它将会允许线程自旋相对更长的时间。 如果对于某个锁，线程很少成功获得过，则会相应减少自旋的时间甚至直接进入阻塞的状态，避免浪费处理器资源。\n锁升级 # 1.8 无锁状态 # 程序不会有锁的竞争。那么这种情况我们不需要加锁，所以这种情况下对象锁状态为无锁。\n1.9 偏向锁 # 偏向锁，顾名思义，它会偏向于第一个访问锁的线程\n如果在运行过程中，同步锁只有一个线程访问，不存在多线程争用的情况，则线程是不需要触发同步的，这种情况下，就会给线程加一个偏向锁。线程第二次到达同步代码块时，会判断此时持有锁的线程是否就是自己，如果是则正常往下执行。由于之前没有释放锁，这里也就不需要重新加锁。如果自始至终使用锁的线程只有一个，很明显偏向锁几乎没有额外开销，性能极高。 如果在运行过程中，遇到了其他线程抢占锁，则持有偏向锁的线程会被挂起，JVM会消除它身上的偏向锁，将锁恢复到标准的轻量级锁。偏向锁通过消除资源无竞争情况下的同步原语，进一步提高了程序的运行性能。一旦有第二个线程加入锁竞争，偏向锁就升级为轻量级锁（自旋锁）。升级为轻量级锁的时候需要撤销偏向锁，撤销偏向锁的时候会导致STW(stop the word)操作； 锁竞争：如果多个线程轮流获取一个锁，但是每次获取锁的时候都很顺利，没有发生阻塞，那么就不存在锁竞争。只有当某线程尝试获取锁的时候，发现该锁已经被占用，只能等待其释放，这才发生了锁竞争。\n1.10 轻量级锁 # 在轻量级锁状态下继续锁竞争，如果成功就成功获取轻量级锁。否则进入锁膨胀阶段，没有抢到锁的线程将自旋，即不停地循环判断锁是否能够被成功获取。长时间的自旋操作是非常消耗资源的，一个线程持有锁，其他线程就只能在原地空耗CPU，执行不了任何有效的任务，这种现象叫做忙等（busy-waiting）。如果锁竞争情况严重，某个达到最大自旋次数的线程，会将轻量级锁升级为重量级锁。 轻量级锁不会自旋，另一个线程一旦CAS竞争轻量级锁失败，直接进入锁的膨胀。锁膨胀会有自旋操作，但最终在java层面看到的锁状态都会是重量级锁。所以，轻量级锁在加锁过程中是没有自旋的。自旋发生在轻量级锁膨胀为重量级锁的过程中。 相反，重量级锁在加锁的过程中，为了避免直接park线程，会有自适应自旋操作，来挽救线程被park。\n1.11 重量级锁 # 当后续线程尝试获取锁时，发现被占用的锁是重量级锁，则直接将自己挂起，等待将来被唤醒。在JDK1.6之前，synchronized直接加重量级锁，很明显现在得到了很好的优化。 重量级锁的特点：其他线程试图获取锁时，都会被阻塞，只有持有锁的线程释放锁之后才会唤醒这些线程。\n锁的优缺点对比\n锁 优点 缺点 适用场景 偏向锁 加锁和解锁不需要额外的消耗，和执行非同步方法比仅存在纳秒级的差距。 如果线程间存在锁竞争，会带来额外的锁撤销的消耗。 适用于只有一个线程访问同步块场景。 轻量级锁 竞争的线程不会阻塞，提高了程序的响应速度。 如果始终得不到锁竞争的线程使用自旋会消耗CPU。 追求响应时间。同步块执行速度非常快。 重量级锁 线程竞争不使用自旋，不会消耗CPU。 线程阻塞，响应时间缓慢。 追求吞吐量。同步块执行速度较长。 1.12 锁升级场景 # 场景1： 经常只有某一个线程来加锁。\n加锁过程：也许获取锁的经常为同一个线程，这种情况下为了避免加锁造成的性能开销，加偏向锁。 偏向锁的执行流程如下： 1、线程首先检查该对象头的线程ID是否为当前线程； 2、A：如果对象头的线程ID和当前线程ID一致，则直接执行代码；B：如果不是当前线程ID则使用CAS方式替换对象头中的线程ID，如果使用CAS替换不成功则说明有线程正在执行，存在锁的竞争，这时需要撤销偏向锁，升级为轻量级锁。 3、如果CAS替换成功，则把对象头的线程ID改为自己的线程ID，然后执行代码。 4、执行代码完成之后释放锁，把对象头的线程ID修改为空。 场景2： 有线程来参与锁的竞争，但是获取锁的冲突时间很短。\n当开始有锁的竞争了，那么偏向锁就会升级到轻量级锁； 线程获取锁出现冲突时，线程必须做出决定是继续在这里等，还是先去做其他事情，等会再来看看，而轻量级锁的采用了继续在这里等的方式。当发现有锁竞争，线程首先会使用自旋的方式循环在这里获取锁，因为使用自旋的方式非常消耗CPU。当一定时间内通过自旋的方式无法获取到锁的话，那么锁就开始升级为重量级锁了。 场景3： 有大量的线程参与锁的竞争，冲突性很高。\n当获取锁冲突多，时间越长的时候，线程肯定无法继续在这里死等了，所以只好先挂起，然后等前面获取锁的线程释放了锁之后，再开启下一轮的锁竞争，而这种形式就是我们的重量级锁。 ","date":"18 March 2025","externalUrl":null,"permalink":"/posts/1742270561314-java-%E9%94%81%E6%9C%BA%E5%88%B6/","section":"Posts","summary":"","title":"Java 锁机制","type":"posts"},{"content":"","date":"18 March 2025","externalUrl":null,"permalink":"/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/","section":"Tags","summary":"","title":"并发编程","type":"tags"},{"content":"","date":"13 March 2025","externalUrl":null,"permalink":"/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/","section":"Tags","summary":"","title":"计算机网络","type":"tags"},{"content":" 计算机网络总结 （上） # 1.1 计算机网络基础 # 计算机网络\n是指将地理位置不同的具有独立功能的多台计算机及其外部设备，通过通信线路连接起来，在网络操作系统，网络管理软件及网络通信协议的管理和协调下，实现资源共享和信息传递的计算机系统\n网络编程\n在网络通信协议下，不同计算机上运行的程序，可以进行数据传输\n1.1.2 网络编程三要素 # IP地址\n要想让网络中的计算机能够互相通信，必须为每台计算机指定一个标识号，通过这个标识号来指定要接收数据的计算机和识别发送的计算机，而IP地址就是这个标识号。也就是设备的标识\n端口\n网络的通信，本质上是两个应用程序的通信。每台计算机都有很多的应用程序，那么在网络通信时，如何区分这些应用程序呢？**如果说IP地址可以唯一标识网络中的设备，那么端口号就可以唯一标识设备中的应用程序了。**也就是应用程序的标识\n协议\n通过计算机网络可以使多台计算机实现连接，位于同一个网络中的计算机在进行连接和通信时需要遵守一定的规则，这就好比在道路中行驶的汽车一定要遵守交通规则一样。在计算机网络中，这些连接和通信的规则被称为网络通信协议，它对数据的传输格式、传输速率、传输步骤等做了统一规定，通信双方必须同时遵守才能完成数据交换。常见的协议有UDP协议和TCP协议\n1.1.3 IP地址 # IP地址：是网络中设备的唯一标识\nIP地址分为两大类 IPv4：**是给每个连接在网络上的主机分配一个32bit地址。按照TCP/IP规定，IP地址用二进制来表示，每个IP地址长32bit，也就是4个字节。**例如一个采用二进制形式的IP地址是“11000000 10101000 00000001 01000010”，这么长的地址，处理起来也太费劲了。为了方便使用，IP地址经常被写成十进制的形式，中间使用符号“.”分隔不同的字节。于是，上面的IP地址可以表示为“192.168.1.66”。IP地址的这种表示法叫做“点分十进制表示法”，这显然比1和0容易记忆得多 IPv6：由于互联网的蓬勃发展，IP地址的需求量愈来愈大，但是网络地址资源有限，使得IP的分配越发紧张。为了扩大地址空间，通过IPv6重新定义地址空间，采用128位地址长度，每16个字节一组，分成8组十六进制数，这样就解决了网络地址资源数量不够的问题 DOS常用命令： ipconfig：查看本机IP地址 ping IP地址：检查网络是否连通 特殊IP地址： 127.0.0.1：是回送地址，可以代表本机地址，一般用来测试使用 1.1.4 InetAddress # InetAddress：此类表示Internet协议（IP）地址\n相关方法 方法名 说明 static InetAddress getByName(String host) 确定主机名称的IP地址。主机名称可以是机器名称，也可以是IP地址 String getHostName() 获取此IP地址的主机名 String getHostAddress() 返回文本显示中的IP地址字符串 1.1.5 端口和协议 # 端口\n设备上应用程序的唯一标识 端口号\n用两个字节表示的整数，它的取值范围是0 ~ 65535。其中，0 ~ 1023之间的端口号用于一些知名的网络服务和应用，普通的应用程序需要使用1024以上的端口号。如果端口号被另外一个服务或应用所占用，会导致当前程序启动失败 协议\n计算机网络中，连接和通信的规则被称为网络通信协议 UDP协议\n用户数据报协议(User Datagram Protocol) **UDP是无连接通信协议，即在数据传输时，数据的发送端和接收端不建立逻辑连接。**简单来说，当一台计算机向另外一台计算机发送数据时，发送端不会确认接收端是否存在，就会发出数据，同样接收端在收到数据时，也不会向发送端反馈是否收到数据。 由于使用UDP协议消耗系统资源小，通信效率高，所以通常都会用于音频、视频和普通数据的传输 例如视频会议通常采用UDP协议，因为这种情况即使偶尔丢失一两个数据包，也不会对接收结果产生太大影响。但是在使用UDP协议传送数据时，由于UDP的面向无连接性，不能保证数据的完整性，因此在传输重要数据时不建议使用UDP协议 TCP协议\n传输控制协议 (Transmission Control Protocol)\nTCP协议是面向连接的通信协议，即传输数据之前，在发送端和接收端建立逻辑连接，然后再传输数据，它提供了两台计算机之间可靠无差错的数据传输。在TCP连接中必须要明确客户端与服务器端，由客户端向服务端发出连接请求，每次连接的创建都需要经过“三次握手”\n三次握手：TCP协议中，在发送数据的准备阶段，客户端与服务器之间的三次交互，以保证连接的可靠\n第一次握手，客户端向服务器端发出连接请求，等待服务器确认\n第二次握手，服务器端向客户端回送一个响应，通知客户端收到了连接请求\n第三次握手，客户端再次向服务器端发送确认信息，确认连接\n完成三次握手，连接建立后，客户端和服务器就可以开始进行数据传输了。由于这种面向连接的特性，TCP协议可以保证传输数据的安全，所以应用十分广泛。例如上传文件、下载文件、浏览网页等\n1.2 UDP通信程序 # 1.2.1 UDP发送数据 # Java中的UDP通信\nUDP协议是一种不可靠的网络协议，它在通信的两端各建立一个Socket对象，但是这两个Socket只是发送，接收数据的对象，因此对于基于UDP协议的通信双方而言，没有所谓的客户端和服务器的概念 Java提供了DatagramSocket类作为基于UDP协议的Socket 构造方法\n方法名 说明 DatagramSocket() 创建数据报套接字并将其绑定到本机地址上的任何可用端口 DatagramPacket(byte[] buf,int len,InetAddress add,int port) 创建数据包,发送长度为len的数据包到指定主机的指定端口 相关方法\n方法名 说明 void send(DatagramPacket p) 发送数据报包 void close() 关闭数据报套接字 void receive(DatagramPacket p) 从此套接字接受数据报包 发送数据的步骤\n创建发送端的Socket对象(DatagramSocket) 创建数据，并把数据打包 调用DatagramSocket对象的方法发送数据 关闭发送端 1.2.2UDP接收数据 # 接收数据的步骤\n创建接收端的Socket对象(DatagramSocket) 创建一个数据包，用于接收数据 调用DatagramSocket对象的方法接收数据 解析数据包，并把数据在控制台显示 关闭接收端 构造方法\n方法名 说明 DatagramPacket(byte[] buf, int len) 创建一个DatagramPacket用于接收长度为len的数据包 相关方法\n方法名 说明 byte[] getData() 返回数据缓冲区 int getLength() 返回要发送的数据的长度或接收的数据的长度 1.2.3UDP三种通讯方式 # 单播\n单播用于两个主机之间的端对端通信\n组播\n组播用于对一组特定的主机进行通信\n广播\n广播用于一个主机对整个局域网上所有主机上的数据通信\n1.2.4UDP组播实现 # 实现步骤\n发送端 创建发送端的Socket对象(DatagramSocket) 创建数据，并把数据打包(DatagramPacket) 调用DatagramSocket对象的方法发送数据(在单播中,这里是发给指定IP的电脑但是在组播当中,这里是发给组播地址) 释放资源 接收端 创建接收端Socket对象(MulticastSocket) 创建一个箱子,用于接收数据 把当前计算机绑定一个组播地址 将数据接收到箱子中 解析数据包,并打印数据 释放资源 1.2.5UDP广播实现 # 实现步骤\n发送端 创建发送端Socket对象(DatagramSocket) 创建存储数据的箱子,将广播地址封装进去 发送数据 释放资源 接收端 创建接收端的Socket对象(DatagramSocket) 创建一个数据包，用于接收数据 调用DatagramSocket对象的方法接收数据 解析数据包，并把数据在控制台显示 关闭接收端 1.3 TCP通信程序 # 1.3.1TCP发送数据 # Java中的TCP通信\nJava对基于TCP协议的的网络提供了良好的封装，使用Socket对象来代表两端的通信端口，并通过Socket产生IO流来进行网络通信。 Java为客户端提供了Socket类，为服务器端提供了ServerSocket类 构造方法\n方法名 说明 Socket(InetAddress address,int port) 创建流套接字并将其连接到指定IP指定端口号 Socket(String host, int port) 创建流套接字并将其连接到指定主机上的指定端口号 相关方法\n方法名 说明 InputStream getInputStream() 返回此套接字的输入流 OutputStream getOutputStream() 返回此套接字的输出流 1.3.2TCP接收数据 # 构造方法\n方法名 说明 ServletSocket(int port) 创建绑定到指定端口的服务器套接字 相关方法\n方法名 说明 Socket accept() 监听要连接到此的套接字并接受它 注意事项\naccept方法是阻塞的,作用就是等待客户端连接 客户端创建对象并连接服务器,此时是通过三次握手协议,保证跟服务器之间的连接 针对客户端来讲,是往外写的,所以是输出流 针对服务器来讲,是往里读的,所以是输入流 read方法也是阻塞的 客户端在关流的时候,还多了一个往服务器写结束标记的动作 最后一步断开连接,通过四次挥手协议保证连接终止 三次握手和四次挥手\n三次握手 四次挥手 1.4 网络分层模型 # 1.4.1 OSI 七层模型是什么？每一层的作用是什么？ # OSI 七层模型 是国际标准化组织提出的一个网络分层模型，其大体结构以及每一层提供的功能如下图所示：\n每一层都专注做一件事情，并且每一层都需要使用下一层提供的功能比如传输层需要使用网络层提供的路由和寻址功能，这样传输层才知道把数据传输到哪里去。\nOSI 的七层体系结构概念清楚，理论也很完整，但是它比较复杂而且不实用，而且有些功能在多个层中重复出现。\n上面这种图可能比较抽象，再来一个比较生动的图片。下面这个图片是我在国外的一个网站上看到的，非常赞！\n1.4.2 TCP/IP 四层模型是什么？每一层的作用是什么？ # TCP/IP 四层模型 是目前被广泛采用的一种模型,我们可以将 TCP / IP 模型看作是 OSI 七层模型的精简版本，由以下 4 层组成：\n应用层 传输层 网络层 网络接口层 需要注意的是，我们并不能将 TCP/IP 四层模型 和 OSI 七层模型完全精确地匹配起来，不过可以简单将两者对应起来，如下图所示：\n关于每一层作用的详细介绍，请看 OSI 和 TCP/IP 网络分层模型详解（基础） 这篇文章。\n1.4.3 为什么网络要分层？ # 说到分层，我们先从我们平时使用框架开发一个后台程序来说，我们往往会按照每一层做不同的事情的原则将系统分为三层（复杂的系统分层会更多）:\nRepository（数据库操作） Service（业务操作） Controller（前后端数据交互） 复杂的系统需要分层，因为每一层都需要专注于一类事情。网络分层的原因也是一样，每一层只专注于做一类事情。\n好了，再来说回：“为什么网络要分层？”。我觉得主要有 3 方面的原因：\n各层之间相互独立：各层之间相互独立，各层之间不需要关心其他层是如何实现的，只需要知道自己如何调用下层提供好的功能就可以了（可以简单理解为接口调用）。这个和我们对开发时系统进行分层是一个道理。 提高了灵活性和可替换性：每一层都可以使用最适合的技术来实现，你只需要保证你提供的功能以及暴露的接口的规则没有改变就行了。并且，每一层都可以根据需要进行修改或替换，而不会影响到整个网络的结构。这个和我们平时开发系统的时候要求的高内聚、低耦合的原则也是可以对应上的。 大问题化小：分层可以将复杂的网络问题分解为许多比较小的、界线比较清晰简单的小问题来处理和解决。这样使得复杂的计算机网络系统变得易于设计，实现和标准化。 这个和我们平时开发的时候，一般会将系统功能分解，然后将复杂的问题分解为容易理解的更小的问题是相对应的，这些较小的问题具有更好的边界（目标和接口）定义。 我想到了计算机世界非常非常有名的一句话，这里分享一下：\n计算机科学领域的任何问题都可以通过增加一个间接的中间层来解决，计算机整个体系从上到下都是按照严格的层次结构设计的。\n1.5 常见网络协议 # 1.5.1 应用层有哪些常见的协议？ # HTTP（Hypertext Transfer Protocol，超文本传输协议）：基于 TCP 协议，是一种用于传输超文本和多媒体内容的协议，主要是为 Web 浏览器与 Web 服务器之间的通信而设计的。当我们使用浏览器浏览网页的时候，我们网页就是通过 HTTP 请求进行加载的。 SMTP（Simple Mail Transfer Protocol，简单邮件发送协议）：基于 TCP 协议，是一种用于发送电子邮件的协议。注意 ⚠️：SMTP 协议只负责邮件的发送，而不是接收。要从邮件服务器接收邮件，需要使用 POP3 或 IMAP 协议。 POP3/IMAP（邮件接收协议）：基于 TCP 协议，两者都是负责邮件接收的协议。IMAP 协议是比 POP3 更新的协议，它在功能和性能上都更加强大。IMAP 支持邮件搜索、标记、分类、归档等高级功能，而且可以在多个设备之间同步邮件状态。几乎所有现代电子邮件客户端和服务器都支持 IMAP。 FTP（File Transfer Protocol，文件传输协议） : 基于 TCP 协议，是一种用于在计算机之间传输文件的协议，可以屏蔽操作系统和文件存储方式。注意 ⚠️：FTP 是一种不安全的协议，因为它在传输过程中不会对数据进行加密。建议在传输敏感数据时使用更安全的协议，如 SFTP。 Telnet（远程登陆协议）：基于 TCP 协议，用于通过一个终端登陆到其他服务器。Telnet 协议的最大缺点之一是所有数据（包括用户名和密码）均以明文形式发送，这有潜在的安全风险。这就是为什么如今很少使用 Telnet，而是使用一种称为 SSH 的非常安全的网络传输协议的主要原因。 SSH（Secure Shell Protocol，安全的网络传输协议）：基于 TCP 协议，通过加密和认证机制实现安全的访问和文件传输等业务 RTP（Real-time Transport Protocol，实时传输协议）：通常基于 UDP 协议，但也支持 TCP 协议。它提供了端到端的实时传输数据的功能，但不包含资源预留存、不保证实时传输质量，这些功能由 WebRTC 实现。 DNS（Domain Name System，域名管理系统）: 基于 UDP 协议，用于解决域名和 IP 地址的映射问题。 关于这些协议的详细介绍请看 应用层常见协议总结（应用层） 这篇文章。\n1.5.2 传输层有哪些常见的协议？ # TCP（Transmission Control Protocol，传输控制协议 ）：提供 面向连接 的，可靠 的数据传输服务。 UDP（User Datagram Protocol，用户数据协议）：提供 无连接 的，尽最大努力 的数据传输服务（不保证数据传输的可靠性），简单高效。 1.5.3 网络层有哪些常见的协议？ # IP（Internet Protocol，网际协议）：TCP/IP 协议中最重要的协议之一，属于网络层的协议，主要作用是定义数据包的格式、对数据包进行路由和寻址，以便它们可以跨网络传播并到达正确的目的地。目前 IP 协议主要分为两种，一种是过去的 IPv4，另一种是较新的 IPv6，目前这两种协议都在使用，但后者已经被提议来取代前者。 ARP（Address Resolution Protocol，地址解析协议）：ARP 协议解决的是网络层地址和链路层地址之间的转换问题。因为一个 IP 数据报在物理上传输的过程中，总是需要知道下一跳（物理上的下一个目的地）该去往何处，但 IP 地址属于逻辑地址，而 MAC 地址才是物理地址，ARP 协议解决了 IP 地址转 MAC 地址的一些问题。 ICMP（Internet Control Message Protocol，互联网控制报文协议）：一种用于传输网络状态和错误消息的协议，常用于网络诊断和故障排除。例如，Ping 工具就使用了 ICMP 协议来测试网络连通性。 NAT（Network Address Translation，网络地址转换协议）：NAT 协议的应用场景如同它的名称——网络地址转换，应用于内部网到外部网的地址转换过程中。具体地说，在一个小的子网（局域网，LAN）内，各主机使用的是同一个 LAN 下的 IP 地址，但在该 LAN 以外，在广域网（WAN）中，需要一个统一的 IP 地址来标识该 LAN 在整个 Internet 上的位置。 OSPF（Open Shortest Path First，开放式最短路径优先）：一种内部网关协议（Interior Gateway Protocol，IGP），也是广泛使用的一种动态路由协议，基于链路状态算法，考虑了链路的带宽、延迟等因素来选择最佳路径。 RIP(Routing Information Protocol，路由信息协议）：一种内部网关协议（Interior Gateway Protocol，IGP），也是一种动态路由协议，基于距离向量算法，使用固定的跳数作为度量标准，选择跳数最少的路径作为最佳路径。 BGP（Border Gateway Protocol，边界网关协议）：一种用来在路由选择域之间交换网络层可达性信息（Network Layer Reachability Information，NLRI）的路由选择协议，具有高度的灵活性和可扩展性。 1.6 HTTP # 1.6.1 从输入 URL 到页面展示到底发生了什么？（非常重要） # 类似的问题：打开一个网页，整个过程会使用哪些协议？\n先来看一张图（来源于《图解 HTTP》）：\n上图有一个错误需要注意：是 OSPF 不是 OPSF。 OSPF（Open Shortest Path First，ospf）开放最短路径优先协议, 是由 Internet 工程任务组开发的路由选择协议\n总体来说分为以下几个步骤:\n在浏览器中输入指定网页的 URL。 浏览器通过 DNS 协议，获取域名对应的 IP 地址。 浏览器根据 IP 地址和端口号，向目标服务器发起一个 TCP 连接请求。 浏览器在 TCP 连接上，向服务器发送一个 HTTP 请求报文，请求获取网页的内容。 服务器收到 HTTP 请求报文后，处理请求，并返回 HTTP 响应报文给浏览器。 浏览器收到 HTTP 响应报文后，解析响应体中的 HTML 代码，渲染网页的结构和样式，同时根据 HTML 中的其他资源的 URL（如图片、CSS、JS 等），再次发起 HTTP 请求，获取这些资源的内容，直到网页完全加载显示。 浏览器在不需要和服务器通信时，可以主动关闭 TCP 连接，或者等待服务器的关闭请求。 详细介绍可以查看这篇文章：访问网页的全过程（知识串联）（强烈推荐）。\n1.6.2 HTTP 状态码有哪些？ # HTTP 状态码用于描述 HTTP 请求的结果，比如 2xx 就代表请求被成功处理。\n关于 HTTP 状态码更详细的总结，可以看我写的这篇文章：HTTP 常见状态码总结（应用层）。\n1.6.3 HTTP Header 中常见的字段有哪些？ # 请求头字段名 说明 示例 Accept 能够接受的回应内容类型（Content-Types）。 Accept: text/plain Accept-Charset 能够接受的字符集 Accept-Charset: utf-8 Accept-Datetime 能够接受的按照时间来表示的版本 Accept-Datetime: Thu, 31 May 2007 20:35:00 GMT Accept-Encoding 能够接受的编码方式列表。参考 HTTP 压缩。 Accept-Encoding: gzip, deflate Accept-Language 能够接受的回应内容的自然语言列表。 Accept-Language: en-US Authorization 用于超文本传输协议的认证的认证信息 Authorization: Basic QWxhZGRpbjpvcGVuIHNlc2FtZQ== Cache-Control 用来指定在这次的请求/响应链中的所有缓存机制 都必须 遵守的指令 Cache-Control: no-cache Connection 该浏览器想要优先使用的连接类型 Connection: keep-alive Content-Length 以八位字节数组（8 位的字节）表示的请求体的长度 Content-Length: 348 Content-MD5 请求体的内容的二进制 MD5 散列值，以 Base64 编码的结果 Content-MD5: Q2hlY2sgSW50ZWdyaXR5IQ== Content-Type 请求体的多媒体类型（用于 POST 和 PUT 请求中） Content-Type: application/x-www-form-urlencoded Cookie 之前由服务器通过 Set-Cookie（下文详述）发送的一个超文本传输协议 Cookie Cookie: $Version=1; Skin=new; Date 发送该消息的日期和时间(按照 RFC 7231 中定义的\u0026quot;超文本传输协议日期\u0026quot;格式来发送) Date: Tue, 15 Nov 1994 08:12:31 GMT Expect 表明客户端要求服务器做出特定的行为 Expect: 100-continue From 发起此请求的用户的邮件地址 From: user@example.com Host 服务器的域名(用于虚拟主机)，以及服务器所监听的传输控制协议端口号。如果所请求的端口是对应的服务的标准端口，则端口号可被省略。 Host: en.wikipedia.org If-Match 仅当客户端提供的实体与服务器上对应的实体相匹配时，才进行对应的操作。主要作用是用于像 PUT 这样的方法中，仅当从用户上次更新某个资源以来，该资源未被修改的情况下，才更新该资源。 If-Match: \u0026ldquo;737060cd8c284d8af7ad3082f209582d\u0026rdquo; If-Modified-Since 允许服务器在请求的资源自指定的日期以来未被修改的情况下返回 304 Not Modified 状态码 If-Modified-Since: Sat, 29 Oct 1994 19:43:31 GMT If-None-Match 允许服务器在请求的资源的 ETag 未发生变化的情况下返回 304 Not Modified 状态码 If-None-Match: \u0026ldquo;737060cd8c284d8af7ad3082f209582d\u0026rdquo; If-Range 如果该实体未被修改过，则向我发送我所缺少的那一个或多个部分；否则，发送整个新的实体 If-Range: \u0026ldquo;737060cd8c284d8af7ad3082f209582d\u0026rdquo; If-Unmodified-Since 仅当该实体自某个特定时间以来未被修改的情况下，才发送回应。 If-Unmodified-Since: Sat, 29 Oct 1994 19:43:31 GMT Max-Forwards 限制该消息可被代理及网关转发的次数。 Max-Forwards: 10 Origin 发起一个针对跨来源资源共享的请求。 Origin: http://www.example-social-network.com Pragma 与具体的实现相关，这些字段可能在请求/回应链中的任何时候产生多种效果。 Pragma: no-cache Proxy-Authorization 用来向代理进行认证的认证信息。 Proxy-Authorization: Basic QWxhZGRpbjpvcGVuIHNlc2FtZQ== Range 仅请求某个实体的一部分。字节偏移以 0 开始。参见字节服务。 Range: bytes=500-999 Referer 表示浏览器所访问的前一个页面，正是那个页面上的某个链接将浏览器带到了当前所请求的这个页面。 Referer: http://en.wikipedia.org/wiki/Main_Page TE 浏览器预期接受的传输编码方式：可使用回应协议头 Transfer-Encoding 字段中的值； TE: trailers, deflate Upgrade 要求服务器升级到另一个协议。 Upgrade: HTTP/2.0, SHTTP/1.3, IRC/6.9, RTA/x11 User-Agent 浏览器的浏览器身份标识字符串 User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:12.0) Gecko/20100101 Firefox/21.0 Via 向服务器告知，这个请求是由哪些代理发出的。 Via: 1.0 fred, 1.1 example.com (Apache/1.1) Warning 一个一般性的警告，告知，在实体内容体中可能存在错误。 Warning: 199 Miscellaneous warning 1.6.4 HTTP 和 HTTPS 有什么区别？（重要） # 端口号：HTTP 默认是 80，HTTPS 默认是 443。 URL 前缀：HTTP 的 URL 前缀是 http://，HTTPS 的 URL 前缀是 https://。 安全性和资源消耗：HTTP 协议运行在 TCP 之上，所有传输的内容都是明文，客户端和服务器端都无法验证对方的身份。HTTPS 是运行在 SSL/TLS 之上的 HTTP 协议，SSL/TLS 运行在 TCP 之上。所有传输的内容都经过加密，加密采用对称加密，但对称加密的密钥用服务器方的证书进行了非对称加密。所以说，HTTP 安全性没有 HTTPS 高，但是 HTTPS 比 HTTP 耗费更多服务器资源。 SEO（搜索引擎优化）：搜索引擎通常会更青睐使用 HTTPS 协议的网站，因为 HTTPS 能够提供更高的安全性和用户隐私保护。使用 HTTPS 协议的网站在搜索结果中可能会被优先显示，从而对 SEO 产生影响。 关于 HTTP 和 HTTPS 更详细的对比总结，可以看我写的这篇文章：HTTP vs HTTPS（应用层） 。\n1.6.5 HTTP/1.0 和 HTTP/1.1 有什么区别？ # 连接方式 : HTTP/1.0 为短连接，HTTP/1.1 支持长连接。HTTP 协议的长连接和短连接，实质上是 TCP 协议的长连接和短连接。 状态响应码 : HTTP/1.1 中新加入了大量的状态码，光是错误响应状态码就新增了 24 种。比如说，100 (Continue)——在请求大资源前的预热请求，206 (Partial Content)——范围请求的标识码，409 (Conflict)——请求与当前资源的规定冲突，410 (Gone)——资源已被永久转移，而且没有任何已知的转发地址。 缓存机制 : 在 HTTP/1.0 中主要使用 Header 里的 If-Modified-Since,Expires 来做为缓存判断的标准，HTTP/1.1 则引入了更多的缓存控制策略例如 Entity tag，If-Unmodified-Since, If-Match, If-None-Match 等更多可供选择的缓存头来控制缓存策略。 带宽：HTTP/1.0 中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，HTTP/1.1 则在请求头引入了 range 头域，它允许只请求资源的某个部分，即返回码是 206（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。 Host 头（Host Header）处理 :HTTP/1.1 引入了 Host 头字段，允许在同一 IP 地址上托管多个域名，从而支持虚拟主机的功能。而 HTTP/1.0 没有 Host 头字段，无法实现虚拟主机。 关于 HTTP/1.0 和 HTTP/1.1 更详细的对比总结，可以看我写的这篇文章：HTTP/1.0 vs HTTP/1.1（应用层） 。\n1.6.6 HTTP/1.1 和 HTTP/2.0 有什么区别？ # 多路复用（Multiplexing）：HTTP/2.0 在同一连接上可以同时传输多个请求和响应（可以看作是 HTTP/1.1 中长链接的升级版本），互不干扰。HTTP/1.1 则使用串行方式，每个请求和响应都需要独立的连接，而浏览器为了控制资源会有 6-8 个 TCP 连接的限制。。这使得 HTTP/2.0 在处理多个请求时更加高效，减少了网络延迟和提高了性能。 二进制帧（Binary Frames）：HTTP/2.0 使用二进制帧进行数据传输，而 HTTP/1.1 则使用文本格式的报文。二进制帧更加紧凑和高效，减少了传输的数据量和带宽消耗。 头部压缩（Header Compression）：HTTP/1.1 支持Body压缩，Header不支持压缩。HTTP/2.0 支持对Header压缩，使用了专门为Header压缩而设计的 HPACK 算法，减少了网络开销。 服务器推送（Server Push）：HTTP/2.0 支持服务器推送，可以在客户端请求一个资源时，将其他相关资源一并推送给客户端，从而减少了客户端的请求次数和延迟。而 HTTP/1.1 需要客户端自己发送请求来获取相关资源。 HTTP/2.0 多路复用效果图（图源： HTTP/2 For Web Developers）：\n可以看到，HTTP/2.0 的多路复用使得不同的请求可以共用一个 TCP 连接，避免建立多个连接带来不必要的额外开销，而 HTTP/1.1 中的每个请求都会建立一个单独的连接\n1.6.7 HTTP/2.0 和 HTTP/3.0 有什么区别？ # 传输协议：HTTP/2.0 是基于 TCP 协议实现的，HTTP/3.0 新增了 QUIC（Quick UDP Internet Connections） 协议来实现可靠的传输，提供与 TLS/SSL 相当的安全性，具有较低的连接和传输延迟。你可以将 QUIC 看作是 UDP 的升级版本，在其基础上新增了很多功能比如加密、重传等等。HTTP/3.0 之前名为 HTTP-over-QUIC，从这个名字中我们也可以发现，HTTP/3 最大的改造就是使用了 QUIC。 连接建立：HTTP/2.0 需要经过经典的 TCP 三次握手过程（由于安全的 HTTPS 连接建立还需要 TLS 握手，共需要大约 3 个 RTT）。由于 QUIC 协议的特性（TLS 1.3，TLS 1.3 除了支持 1 个 RTT 的握手，还支持 0 个 RTT 的握手）连接建立仅需 0-RTT 或者 1-RTT。这意味着 QUIC 在最佳情况下不需要任何的额外往返时间就可以建立新连接。 头部压缩：HTTP/2.0 使用 HPACK 算法进行头部压缩，而 HTTP/3.0 使用更高效的 QPACK 头压缩算法。 队头阻塞：HTTP/2.0 多请求复用一个 TCP 连接，一旦发生丢包，就会阻塞住所有的 HTTP 请求。由于 QUIC 协议的特性，HTTP/3.0 在一定程度上解决了队头阻塞（Head-of-Line blocking, 简写：HOL blocking）问题，一个连接建立多个不同的数据流，这些数据流之间独立互不影响，某个数据流发生丢包了，其数据流不受影响（本质上是多路复用+轮询）。 连接迁移：HTTP/3.0 支持连接迁移，因为 QUIC 使用 64 位 ID 标识连接，只要 ID 不变就不会中断，网络环境改变时（如从 Wi-Fi 切换到移动数据）也能保持连接。而 TCP 连接是由（源 IP，源端口，目的 IP，目的端口）组成，这个四元组中一旦有一项值发生改变，这个连接也就不能用了。 错误恢复：HTTP/3.0 具有更好的错误恢复机制，当出现丢包、延迟等网络问题时，可以更快地进行恢复和重传。而 HTTP/2.0 则需要依赖于 TCP 的错误恢复机制。 安全性：在 HTTP/2.0 中，TLS 用于加密和认证整个 HTTP 会话，包括所有的 HTTP 头部和数据负载。TLS 的工作是在 TCP 层之上，它加密的是在 TCP 连接中传输的应用层的数据，并不会对 TCP 头部以及 TLS 记录层头部进行加密，所以在传输的过程中 TCP 头部可能会被攻击者篡改来干扰通信。而 HTTP/3.0 的 QUIC 对整个数据包（包括报文头和报文体）进行了加密与认证处理，保障安全性。 HTTP/1.0、HTTP/2.0 和 HTTP/3.0 的协议栈比较：\n下图是一个更详细的 HTTP/2.0 和 HTTP/3.0 对比图：\n从上图可以看出：\nHTTP/2.0：使用 TCP 作为传输协议、使用 HPACK 进行头部压缩、依赖 TLS 进行加密。 HTTP/3.0：使用基于 UDP 的 QUIC 协议、使用更高效的 QPACK 进行头部压缩、在 QUIC 中直接集成了 TLS。QUIC 协议具备连接迁移、拥塞控制与避免、流量控制等特性。 关于 HTTP/1.0 -\u0026gt; HTTP/3.0 更详细的演进介绍，推荐阅读HTTP1 到 HTTP3 的工程优化。\n1.6.8 HTTP 是不保存状态的协议, 如何保存用户状态? # HTTP 是一种不保存状态，即无状态（stateless）协议。也就是说 HTTP 协议自身不对请求和响应之间的通信状态进行保存。那么我们如何保存用户状态呢？Session 机制的存在就是为了解决这个问题，Session 的主要作用就是通过服务端记录用户的状态。典型的场景是购物车，当你要添加商品到购物车的时候，系统不知道是哪个用户操作的，因为 HTTP 协议是无状态的。服务端给特定的用户创建特定的 Session 之后就可以标识这个用户并且跟踪这个用户了（一般情况下，服务器会在一定时间内保存这个 Session，过了时间限制，就会销毁这个 Session）。\n在服务端保存 Session 的方法很多，最常用的就是内存和数据库(比如是使用内存数据库 redis 保存)。既然 Session 存放在服务器端，那么我们如何实现 Session 跟踪呢？大部分情况下，我们都是通过在 Cookie 中附加一个 Session ID 来方式来跟踪。\nCookie 被禁用怎么办?\n最常用的就是利用 URL 重写把 Session ID 直接附加在 URL 路径的后面。\n1.6.9 URI 和 URL 的区别是什么? # URI(Uniform Resource Identifier) 是统一资源标志符，可以唯一标识一个资源。 URL(Uniform Resource Locator) 是统一资源定位符，可以提供该资源的路径。它是一种具体的 URI，即 URL 可以用来标识一个资源，而且还指明了如何 locate 这个资源。 URI 的作用像身份证号一样，URL 的作用更像家庭住址一样。URL 是一种具体的 URI，它不仅唯一标识资源，而且还提供了定位该资源的信息。\n1.6.10 Cookie 和 Session 有什么区别？ # 准确点来说，这个问题属于认证授权的范畴，你可以在 认证授权基础概念详解 这篇文章中找到详细的答案。\n1.6.11 GET 和 POST 的区别 # 这个问题在知乎上被讨论的挺火热的，地址：https://www.zhihu.com/question/28586791 。\nGET 和 POST 是 HTTP 协议中两种常用的请求方法，它们在不同的场景和目的下有不同的特点和用法。一般来说，可以从以下几个方面来区分二者（重点搞清两者在语义上的区别即可）：\n语义（主要区别）：GET 通常用于获取或查询资源，而 POST 通常用于创建或修改资源。 幂等：GET 请求是幂等的，即多次重复执行不会改变资源的状态，而 POST 请求是不幂等的，即每次执行可能会产生不同的结果或影响资源的状态。 格式：GET 请求的参数通常放在 URL 中，形成查询字符串（querystring），而 POST 请求的参数通常放在请求体（body）中，可以有多种编码格式，如 application/x-www-form-urlencoded、multipart/form-data、application/json 等。GET 请求的 URL 长度受到浏览器和服务器的限制，而 POST 请求的 body 大小则没有明确的限制。不过，实际上 GET 请求也可以用 body 传输数据，只是并不推荐这样做，因为这样可能会导致一些兼容性或者语义上的问题。 缓存：由于 GET 请求是幂等的，它可以被浏览器或其他中间节点（如代理、网关）缓存起来，以提高性能和效率。而 POST 请求则不适合被缓存，因为它可能有副作用，每次执行可能需要实时的响应。 安全性：GET 请求和 POST 请求如果使用 HTTP 协议的话，那都不安全，因为 HTTP 协议本身是明文传输的，必须使用 HTTPS 协议来加密传输数据。另外，GET 请求相比 POST 请求更容易泄露敏感数据，因为 GET 请求的参数通常放在 URL 中。 再次提示，重点搞清两者在语义上的区别即可，实际使用过程中，也是通过语义来区分使用 GET 还是 POST。不过，也有一些项目所有的请求都用 POST，这个并不是固定的，项目组达成共识即可。\n1.7 WebSocket # 1.7.1 什么是 WebSocket? # WebSocket 是一种基于 TCP 连接的全双工通信协议，即客户端和服务器可以同时发送和接收数据。\nWebSocket 协议在 2008 年诞生，2011 年成为国际标准，几乎所有主流较新版本的浏览器都支持该协议。不过，WebSocket 不只能在基于浏览器的应用程序中使用，很多编程语言、框架和服务器都提供了 WebSocket 支持。\nWebSocket 协议本质上是应用层的协议，用于弥补 HTTP 协议在持久通信能力上的不足。客户端和服务器仅需一次握手，两者之间就直接可以创建持久性的连接，并进行双向数据传输。\n下面是 WebSocket 的常见应用场景：\n视频弹幕 实时消息推送，详见Web 实时消息推送详解这篇文章 实时游戏对战 多用户协同编辑 社交聊天 …… 1.7.2 WebSocket 和 HTTP 有什么区别？ # WebSocket 和 HTTP 两者都是基于 TCP 的应用层协议，都可以在网络中传输数据。\n下面是二者的主要区别：\nWebSocket 是一种双向实时通信协议，而 HTTP 是一种单向通信协议。并且，HTTP 协议下的通信只能由客户端发起，服务器无法主动通知客户端。 WebSocket 使用 ws:// 或 wss://（使用 SSL/TLS 加密后的协议，类似于 HTTP 和 HTTPS 的关系） 作为协议前缀，HTTP 使用 http:// 或 https:// 作为协议前缀。 WebSocket 可以支持扩展，用户可以扩展协议，实现部分自定义的子协议，如支持压缩、加密等。 WebSocket 通信数据格式比较轻量，用于协议控制的数据包头部相对较小，网络开销小，而 HTTP 通信每次都要携带完整的头部，网络开销较大（HTTP/2.0 使用二进制帧进行数据传输，还支持头部压缩，减少了网络开销）。 1.7.3 WebSocket 的工作过程是什么样的？ # WebSocket 的工作过程可以分为以下几个步骤：\n客户端向服务器发送一个 HTTP 请求，请求头中包含 Upgrade: websocket 和 Sec-WebSocket-Key 等字段，表示要求升级协议为 WebSocket； 服务器收到这个请求后，会进行升级协议的操作，如果支持 WebSocket，它将回复一个 HTTP 101 状态码，响应头中包含 ，Connection: Upgrade和 Sec-WebSocket-Accept: xxx 等字段、表示成功升级到 WebSocket 协议。 客户端和服务器之间建立了一个 WebSocket 连接，可以进行双向的数据传输。数据以帧（frames）的形式进行传送，WebSocket 的每条消息可能会被切分成多个数据帧（最小单位）。发送端会将消息切割成多个帧发送给接收端，接收端接收消息帧，并将关联的帧重新组装成完整的消息。 客户端或服务器可以主动发送一个关闭帧，表示要断开连接。另一方收到后，也会回复一个关闭帧，然后双方关闭 TCP 连接。 另外，建立 WebSocket 连接之后，通过心跳机制来保持 WebSocket 连接的稳定性和活跃性。\n1.7.4 SSE 与 WebSocket 有什么区别？ # 摘自Web 实时消息推送详解。\nSSE 与 WebSocket 作用相似，都可以建立服务端与浏览器之间的通信，实现服务端向客户端推送消息，但还是有些许不同：\nSSE 是基于 HTTP 协议的，它们不需要特殊的协议或服务器实现即可工作；WebSocket 需单独服务器来处理协议。 SSE 单向通信，只能由服务端向客户端单向通信；WebSocket 全双工通信，即通信的双方可以同时发送和接受信息。 SSE 实现简单开发成本低，无需引入其他组件；WebSocket 传输数据需做二次解析，开发门槛高一些。 SSE 默认支持断线重连；WebSocket 则需要自己实现。 SSE 只能传送文本消息，二进制数据需要经过编码后传送；WebSocket 默认支持传送二进制数据。 SSE 与 WebSocket 该如何选择？\nSSE 好像一直不被大家所熟知，一部分原因是出现了 WebSocket，这个提供了更丰富的协议来执行双向、全双工通信。对于游戏、即时通信以及需要双向近乎实时更新的场景，拥有双向通道更具吸引力。\n但是，在某些情况下，不需要从客户端发送数据。而你只需要一些服务器操作的更新。比如：站内信、未读消息数、状态更新、股票行情、监控数量等场景，SSE 不管是从实现的难易和成本上都更加有优势。此外，SSE 具有 WebSocket 在设计上缺乏的多种功能，例如：自动重新连接、事件 ID 和发送任意事件的能力。\n1.8 PING # 1.8.1 PING 命令的作用是什么？ # PING 命令是一种常用的网络诊断工具，经常用来测试网络中主机之间的连通性和网络延迟。\n这里简单举一个例子，我们来 PING 一下百度。\n# 发送4个PING请求数据包到 www.baidu.com ❯ ping -c 4 www.baidu.com PING www.a.shifen.com (14.119.104.189): 56 data bytes 64 bytes from 14.119.104.189: icmp_seq=0 ttl=54 time=27.867 ms 64 bytes from 14.119.104.189: icmp_seq=1 ttl=54 time=28.732 ms 64 bytes from 14.119.104.189: icmp_seq=2 ttl=54 time=27.571 ms 64 bytes from 14.119.104.189: icmp_seq=3 ttl=54 time=27.581 ms --- www.a.shifen.com ping statistics --- 4 packets transmitted, 4 packets received, 0.0% packet loss round-trip min/avg/max/stddev = 27.571/27.938/28.732/0.474 ms PING 命令的输出结果通常包括以下几部分信息：\nICMP Echo Request（请求报文）信息：序列号、TTL（Time to Live）值。 目标主机的域名或 IP 地址：输出结果的第一行。 往返时间（RTT，Round-Trip Time）：从发送 ICMP Echo Request（请求报文）到接收到 ICMP Echo Reply（响应报文）的总时间，用来衡量网络连接的延迟。 统计结果（Statistics）：包括发送的 ICMP 请求数据包数量、接收到的 ICMP 响应数据包数量、丢包率、往返时间（RTT）的最小、平均、最大和标准偏差值。 如果 PING 对应的目标主机无法得到正确的响应，则表明这两个主机之间的连通性存在问题（有些主机或网络管理员可能禁用了对 ICMP 请求的回复，这样也会导致无法得到正确的响应）。如果往返时间（RTT）过高，则表明网络延迟过高。\n1.8.2 PING 命令的工作原理是什么？ # PING 基于网络层的 ICMP（Internet Control Message Protocol，互联网控制报文协议），其主要原理就是通过在网络上发送和接收 ICMP 报文实现的。\nICMP 报文中包含了类型字段，用于标识 ICMP 报文类型。ICMP 报文的类型有很多种，但大致可以分为两类：\n查询报文类型：向目标主机发送请求并期望得到响应。 差错报文类型：向源主机发送错误信息，用于报告网络中的错误情况。 PING 用到的 ICMP Echo Request（类型为 8 ） 和 ICMP Echo Reply（类型为 0） 属于查询报文类型 。\nPING 命令会向目标主机发送 ICMP Echo Request。 如果两个主机的连通性正常，目标主机会返回一个对应的 ICMP Echo Reply。 1.9 DNS # 1.9.1 DNS 的作用是什么？ # DNS（Domain Name System）域名管理系统，是当用户使用浏览器访问网址之后，使用的第一个重要协议。DNS 要解决的是域名和 IP 地址的映射问题。\n在一台电脑上，可能存在浏览器 DNS 缓存，操作系统 DNS 缓存，路由器 DNS 缓存。如果以上缓存都查询不到，那么 DNS 就闪亮登场了。\n目前 DNS 的设计采用的是分布式、层次数据库结构，DNS 是应用层协议，它可以在 UDP 或 TCP 协议之上运行，端口为 53 。\n1.9.2 DNS 服务器有哪些？根服务器有多少个？ # DNS 服务器自底向上可以依次分为以下几个层级(所有 DNS 服务器都属于以下四个类别之一):\n根 DNS 服务器。根 DNS 服务器提供 TLD 服务器的 IP 地址。目前世界上只有 13 组根服务器，我国境内目前仍没有根服务器。 顶级域 DNS 服务器（TLD 服务器）。顶级域是指域名的后缀，如com、org、net和edu等。国家也有自己的顶级域，如uk、fr和ca。TLD 服务器提供了权威 DNS 服务器的 IP 地址。 权威 DNS 服务器。在因特网上具有公共可访问主机的每个组织机构必须提供公共可访问的 DNS 记录，这些记录将这些主机的名字映射为 IP 地址。 本地 DNS 服务器。每个 ISP（互联网服务提供商）都有一个自己的本地 DNS 服务器。当主机发出 DNS 请求时，该请求被发往本地 DNS 服务器，它起着代理的作用，并将该请求转发到 DNS 层次结构中。严格说来，不属于 DNS 层级结构 世界上并不是只有 13 台根服务器，这是很多人普遍的误解，网上很多文章也是这么写的。实际上，现在根服务器数量远远超过这个数量。最初确实是为 DNS 根服务器分配了 13 个 IP 地址，每个 IP 地址对应一个不同的根 DNS 服务器。然而，由于互联网的快速发展和增长，这个原始的架构变得不太适应当前的需求。为了提高 DNS 的可靠性、安全性和性能，目前这 13 个 IP 地址中的每一个都有多个服务器，截止到 2023 年底，所有根服务器之和达到了 1700 多台，未来还会继续增加。\n1.9.3 DNS 解析的过程是什么样的？ # 整个过程的步骤比较多，我单独写了一篇文章详细介绍：DNS 域名系统详解（应用层） 。\n1.9.4 DNS 劫持了解吗？如何应对？ # DNS 劫持是一种网络攻击，它通过修改 DNS 服务器的解析结果，使用户访问的域名指向错误的 IP 地址，从而导致用户无法访问正常的网站，或者被引导到恶意的网站。DNS 劫持有时也被称为 DNS 重定向、DNS 欺骗或 DNS 污染。\n","date":"13 March 2025","externalUrl":null,"permalink":"/posts/1741877418704-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93-%E4%B8%8A/","section":"Posts","summary":"","title":"计算机网络总结 上","type":"posts"},{"content":" 计算机网络总结 （下） # 1.1 TCP 与 UDP # 1.1.1 TCP 与 UDP 的区别 # 是否面向连接：UDP 在传送数据之前不需要先建立连接。而 TCP 提供面向连接的服务，在传送数据之前必须先建立连接，数据传送结束后要释放连接。 是否是可靠传输：远地主机在收到 UDP 报文后，不需要给出任何确认，并且不保证数据不丢失，不保证是否顺序到达。TCP 提供可靠的传输服务，TCP 在传递数据之前，会有三次握手来建立连接，而且在数据传递时，有确认、窗口、重传、拥塞控制机制。通过 TCP 连接传输的数据，无差错、不丢失、不重复、并且按序到达。 是否有状态：这个和上面的“是否可靠传输”相对应。TCP 传输是有状态的，这个有状态说的是 TCP 会去记录自己发送消息的状态比如消息是否发送了、是否被接收了等等。为此 ，TCP 需要维持复杂的连接状态表。而 UDP 是无状态服务，简单来说就是不管发出去之后的事情了（这很渣男！）。 传输效率：由于使用 TCP 进行传输的时候多了连接、确认、重传等机制，所以 TCP 的传输效率要比 UDP 低很多。 传输形式：TCP 是面向字节流的，UDP 是面向报文的。 首部开销：TCP 首部开销（20 ～ 60 字节）比 UDP 首部开销（8 字节）要大。 是否提供广播或多播服务：TCP 只支持点对点通信，UDP 支持一对一、一对多、多对一、多对多； …… TCP UDP 是否面向连接 是 否 是否可靠 是 否 是否有状态 是 否 传输效率 较慢 较快 传输形式 字节流 数据报文段 首部开销 20 ～ 60 bytes 8 bytes 是否提供广播或多播服务 否 是 1.1.2 什么时候选择 TCP，什么时候选 UDP? # UDP 一般用于即时通信，比如：语音、 视频、直播等等。这些场景对传输数据的准确性要求不是特别高，比如你看视频即使少个一两帧，实际给人的感觉区别也不大。 TCP 用于对传输准确性要求特别高的场景，比如文件传输、发送和接收邮件、远程登录等等。 1.1.3 HTTP 基于 TCP 还是 UDP？ # HTTP 协议是基于 TCP 协议的，所以发送 HTTP 请求之前首先要建立 TCP 连接也就是要经历 3 次握手。\n🐛 修正（参见 issue#1915）：\nHTTP/3.0 之前是基于 TCP 协议的，而 HTTP/3.0 将弃用 TCP，改用 基于 UDP 的 QUIC 协议 。\n此变化解决了 HTTP/2 中存在的队头阻塞问题。队头阻塞是指在 HTTP/2.0 中，多个 HTTP 请求和响应共享一个 TCP 连接，如果其中一个请求或响应因为网络拥塞或丢包而被阻塞，那么后续的请求或响应也无法发送，导致整个连接的效率降低。这是由于 HTTP/2.0 在单个 TCP 连接上使用了多路复用，受到 TCP 拥塞控制的影响，少量的丢包就可能导致整个 TCP 连接上的所有流被阻塞。HTTP/3.0 在一定程度上解决了队头阻塞问题，一个连接建立多个不同的数据流，这些数据流之间独立互不影响，某个数据流发生丢包了，其数据流不受影响（本质上是多路复用+轮询）。\n除了解决队头阻塞问题，HTTP/3.0 还可以减少握手过程的延迟。在 HTTP/2.0 中，如果要建立一个安全的 HTTPS 连接，需要经过 TCP 三次握手和 TLS 握手：\nTCP 三次握手：客户端和服务器交换 SYN 和 ACK 包，建立一个 TCP 连接。这个过程需要 1.5 个 RTT（round-trip time），即一个数据包从发送到接收的时间。 TLS 握手：客户端和服务器交换密钥和证书，建立一个 TLS 加密层。这个过程需要至少 1 个 RTT（TLS 1.3）或者 2 个 RTT（TLS 1.2）。 所以，HTTP/2.0 的连接建立就至少需要 2.5 个 RTT（TLS 1.3）或者 3.5 个 RTT（TLS 1.2）。而在 HTTP/3.0 中，使用的 QUIC 协议（TLS 1.3，TLS 1.3 除了支持 1 个 RTT 的握手，还支持 0 个 RTT 的握手）连接建立仅需 0-RTT 或者 1-RTT。这意味着 QUIC 在最佳情况下不需要任何的额外往返时间就可以建立新连接。\n相关证明可以参考下面这两个链接：\nhttps://zh.wikipedia.org/zh/HTTP/3 https://datatracker.ietf.org/doc/rfc9114/ 1.1.4 使用 TCP 的协议有哪些?使用 UDP 的协议有哪些? # 运行于 TCP 协议之上的协议：\nHTTP 协议（HTTP/3.0 之前）：超文本传输协议（HTTP，HyperText Transfer Protocol)是一种用于传输超文本和多媒体内容的协议，主要是为 Web 浏览器与 Web 服务器之间的通信而设计的。当我们使用浏览器浏览网页的时候，我们网页就是通过 HTTP 请求进行加载的。 HTTPS 协议：更安全的超文本传输协议(HTTPS,Hypertext Transfer Protocol Secure)，身披 SSL 外衣的 HTTP 协议 FTP 协议：文件传输协议 FTP（File Transfer Protocol）是一种用于在计算机之间传输文件的协议，可以屏蔽操作系统和文件存储方式。注意 ⚠️：FTP 是一种不安全的协议，因为它在传输过程中不会对数据进行加密。建议在传输敏感数据时使用更安全的协议，如 SFTP。 SMTP 协议：简单邮件传输协议（SMTP，Simple Mail Transfer Protocol）的缩写，是一种用于发送电子邮件的协议。注意 ⚠️：SMTP 协议只负责邮件的发送，而不是接收。要从邮件服务器接收邮件，需要使用 POP3 或 IMAP 协议。 POP3/IMAP 协议：两者都是负责邮件接收的协议。IMAP 协议是比 POP3 更新的协议，它在功能和性能上都更加强大。IMAP 支持邮件搜索、标记、分类、归档等高级功能，而且可以在多个设备之间同步邮件状态。几乎所有现代电子邮件客户端和服务器都支持 IMAP。 Telnet 协议：用于通过一个终端登陆到其他服务器。Telnet 协议的最大缺点之一是所有数据（包括用户名和密码）均以明文形式发送，这有潜在的安全风险。这就是为什么如今很少使用 Telnet，而是使用一种称为 SSH 的非常安全的网络传输协议的主要原因。 SSH 协议 : SSH（ Secure Shell）是目前较可靠，专为远程登录会话和其他网络服务提供安全性的协议。利用 SSH 协议可以有效防止远程管理过程中的信息泄露问题。SSH 建立在可靠的传输协议 TCP 之上。 …… 运行于 UDP 协议之上的协议：\nHTTP 协议（HTTP/3.0 ）： HTTP/3.0 弃用 TCP，改用基于 UDP 的 QUIC 协议 。 DHCP 协议：动态主机配置协议，动态配置 IP 地址 DNS：域名系统（DNS，Domain Name System）将人类可读的域名 (例如，www.baidu.com) 转换为机器可读的 IP 地址 (例如，220.181.38.148)。 我们可以将其理解为专为互联网设计的电话薄。实际上，DNS 同时支持 UDP 和 TCP 协议。 …… 1.1.5 TCP 三次握手和四次挥手（非常重要） # 相关面试题：\n为什么要三次握手? 第 2 次握手传回了 ACK，为什么还要传回 SYN？ 为什么要四次挥手？ 为什么不能把服务器发送的 ACK 和 FIN 合并起来，变成三次挥手？ 如果第二次挥手时服务器的 ACK 没有送达客户端，会怎样？ 为什么第四次挥手客户端需要等待 2*MSL（报文段最长寿命）时间后才进入 CLOSED 状态？ 参考答案：TCP 三次握手和四次挥手（传输层） 。\n1.1.6 TCP 如何保证传输的可靠性？（重要） # TCP 传输可靠性保障（传输层）\n1.2 IP # 1.2.1 IP 协议的作用是什么？ # IP（Internet Protocol，网际协议） 是 TCP/IP 协议中最重要的协议之一，属于网络层的协议，主要作用是定义数据包的格式、对数据包进行路由和寻址，以便它们可以跨网络传播并到达正确的目的地。\n目前 IP 协议主要分为两种，一种是过去的 IPv4，另一种是较新的 IPv6，目前这两种协议都在使用，但后者已经被提议来取代前者。\n1.2.2 什么是 IP 地址？IP 寻址如何工作？ # 每个连入互联网的设备或域（如计算机、服务器、路由器等）都被分配一个 IP 地址（Internet Protocol address），作为唯一标识符。每个 IP 地址都是一个字符序列，如 192.168.1.1（IPv4）、2001:0db8:85a3:0000:0000:8a2e:0370:7334（IPv6） 。\n当网络设备发送 IP 数据包时，数据包中包含了 源 IP 地址 和 目的 IP 地址 。源 IP 地址用于标识数据包的发送方设备或域，而目的 IP 地址则用于标识数据包的接收方设备或域。这类似于一封邮件中同时包含了目的地地址和回邮地址。\n网络设备根据目的 IP 地址来判断数据包的目的地，并将数据包转发到正确的目的地网络或子网络，从而实现了设备间的通信。\n这种基于 IP 地址的寻址方式是互联网通信的基础，它允许数据包在不同的网络之间传递，从而实现了全球范围内的网络互联互通。IP 地址的唯一性和全局性保证了网络中的每个设备都可以通过其独特的 IP 地址进行标识和寻址。\n1.2.3 什么是 IP 地址过滤？ # IP 地址过滤（IP Address Filtering） 简单来说就是限制或阻止特定 IP 地址或 IP 地址范围的访问。例如，你有一个图片服务突然被某一个 IP 地址攻击，那我们就可以禁止这个 IP 地址访问图片服务。\nIP 地址过滤是一种简单的网络安全措施，实际应用中一般会结合其他网络安全措施，如认证、授权、加密等一起使用。单独使用 IP 地址过滤并不能完全保证网络的安全。\n1.2.4 IPv4 和 IPv6 有什么区别？ # IPv4（Internet Protocol version 4） 是目前广泛使用的 IP 地址版本，其格式是四组由点分隔的数字，例如：123.89.46.72。IPv4 使用 32 位地址作为其 Internet 地址，这意味着共有约 42 亿（ 2^32）个可用 IP 地址。\n这么少当然不够用啦！为了解决 IP 地址耗尽的问题，最根本的办法是采用具有更大地址空间的新版本 IP 协议 - IPv6（Internet Protocol version 6）。IPv6 地址使用更复杂的格式，该格式使用由单或双冒号分隔的一组数字和字母，例如：2001:0db8:85a3:0000:0000:8a2e:0370:7334 。IPv6 使用 128 位互联网地址，这意味着越有 2^128（3 开头的 39 位数字，恐怖如斯） 个可用 IP 地址。\n除了更大的地址空间之外，IPv6 的优势还包括：\n无状态地址自动配置（Stateless Address Autoconfiguration，简称 SLAAC）：主机可以直接通过根据接口标识和网络前缀生成全局唯一的 IPv6 地址，而无需依赖 DHCP（Dynamic Host Configuration Protocol）服务器，简化了网络配置和管理。 NAT（Network Address Translation，网络地址转换） 成为可选项：IPv6 地址资源充足，可以给全球每个设备一个独立的地址。 对标头结构进行了改进：IPv6 标头结构相较于 IPv4 更加简化和高效，减少了处理开销，提高了网络性能。 可选的扩展头：允许在 IPv6 标头中添加不同的扩展头（Extension Headers），用于实现不同类型的功能和选项。 ICMPv6（Internet Control Message Protocol for IPv6）：IPv6 中的 ICMPv6 相较于 IPv4 中的 ICMP 有了一些改进，如邻居发现、路径 MTU 发现等功能的改进，从而提升了网络的可靠性和性能。 …… 1.2.5 如何获取客户端真实 IP？ # 获取客户端真实 IP 的方法有多种，主要分为应用层方法、传输层方法和网络层方法。\n应用层方法 ：\n通过 X-Forwarded-For 请求头获取，简单方便。不过，这种方法无法保证获取到的是真实 IP，这是因为 X-Forwarded-For 字段可能会被伪造。如果经过多个代理服务器，X-Forwarded-For 字段可能会有多个值（附带了整个请求链中的所有代理服务器 IP 地址）。并且，这种方法只适用于 HTTP 和 SMTP 协议。\n传输层方法：\n利用 TCP Options 字段承载真实源 IP 信息。这种方法适用于任何基于 TCP 的协议，不受应用层的限制。不过，这并非是 TCP 标准所支持的，所以需要通信双方都进行改造。也就是：对于发送方来说，需要有能力把真实源 IP 插入到 TCP Options 里面。对于接收方来说，需要有能力把 TCP Options 里面的 IP 地址读取出来。\n也可以通过 Proxy Protocol 协议来传递客户端 IP 和 Port 信息。这种方法可以利用 Nginx 或者其他支持该协议的反向代理服务器来获取真实 IP 或者在业务服务器解析真实 IP。\n网络层方法：\n隧道 +DSR 模式。这种方法可以适用于任何协议，就是实施起来会比较麻烦，也存在一定限制，实际应用中一般不会使用这种方法。\n1.2.6 NAT 的作用是什么？ # NAT（Network Address Translation，网络地址转换） 主要用于在不同网络之间转换 IP 地址。它允许将私有 IP 地址（如在局域网中使用的 IP 地址）映射为公有 IP 地址（在互联网中使用的 IP 地址）或者反向映射，从而实现局域网内的多个设备通过单一公有 IP 地址访问互联网。\nNAT 不光可以缓解 IPv4 地址资源短缺的问题，还可以隐藏内部网络的实际拓扑结构，使得外部网络无法直接访问内部网络中的设备，从而提高了内部网络的安全性。\n相关阅读：NAT 协议详解（网络层）。\n1.3 ARP # 1.3.1 什么是 Mac 地址？ # MAC 地址的全称是 媒体访问控制地址（Media Access Control Address）。如果说，互联网中每一个资源都由 IP 地址唯一标识（IP 协议内容），那么一切网络设备都由 MAC 地址唯一标识。\n可以理解为，MAC 地址是一个网络设备真正的身份证号，IP 地址只是一种不重复的定位方式（比如说住在某省某市某街道的张三，这种逻辑定位是 IP 地址，他的身份证号才是他的 MAC 地址），也可以理解为 MAC 地址是身份证号，IP 地址是邮政地址。MAC 地址也有一些别称，如 LAN 地址、物理地址、以太网地址等。\n还有一点要知道的是，不仅仅是网络资源才有 IP 地址，网络设备也有 IP 地址，比如路由器。但从结构上说，路由器等网络设备的作用是组成一个网络，而且通常是内网，所以它们使用的 IP 地址通常是内网 IP，内网的设备在与内网以外的设备进行通信时，需要用到 NAT 协议。\nMAC 地址的长度为 6 字节（48 比特），地址空间大小有 280 万亿之多（ $2^{48}$ ），MAC 地址由 IEEE 统一管理与分配，理论上，一个网络设备中的网卡上的 MAC 地址是永久的。不同的网卡生产商从 IEEE 那里购买自己的 MAC 地址空间（MAC 的前 24 比特），也就是前 24 比特由 IEEE 统一管理，保证不会重复。而后 24 比特，由各家生产商自己管理，同样保证生产的两块网卡的 MAC 地址不会重复。\nMAC 地址具有可携带性、永久性，身份证号永久地标识一个人的身份，不论他到哪里都不会改变。而 IP 地址不具有这些性质，当一台设备更换了网络，它的 IP 地址也就可能发生改变，也就是它在互联网中的定位发生了变化。\n最后，记住，MAC 地址有一个特殊地址：FF-FF-FF-FF-FF-FF（全 1 地址），该地址表示广播地址。\n1.3.2 ARP 协议解决了什么问题？ # ARP 协议，全称 地址解析协议（Address Resolution Protocol），它解决的是网络层地址和链路层地址之间的转换问题。因为一个 IP 数据报在物理上传输的过程中，总是需要知道下一跳（物理上的下一个目的地）该去往何处，但 IP 地址属于逻辑地址，而 MAC 地址才是物理地址，ARP 协议解决了 IP 地址转 MAC 地址的一些问题。\n1.3.3 ARP 协议的工作原理？ # ARP 协议详解(网络层)\n1.3.4 复习建议 # 非常推荐大家看一下 《图解 HTTP》 这本书，这本书页数不多，但是内容很是充实，不管是用来系统的掌握网络方面的一些知识还是说纯粹为了应付面试都有很大帮助。下面的一些文章只是参考。大二学习这门课程的时候，我们使用的教材是 《计算机网络第七版》（谢希仁编著），不推荐大家看这本教材，书非常厚而且知识偏理论，不确定大家能不能心平气和的读完。\n","date":"13 March 2025","externalUrl":null,"permalink":"/posts/1741877435822-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93-%E4%B8%8B/","section":"Posts","summary":"","title":"计算机网络总结 下","type":"posts"},{"content":"","date":"11 March 2025","externalUrl":null,"permalink":"/tags/io/","section":"Tags","summary":"","title":"IO","type":"tags"},{"content":"an example to get you started\n其他流 # 1.1 缓冲流 # 缓冲流,也叫高效流，是对4个基本的FileXxx 流的增强，所以也是4个流，按照数据类型分类：\n字节缓冲流：BufferedInputStream，BufferedOutputStream 字符缓冲流：BufferedReader，BufferedWriter 缓冲流的基本原理，是在创建流对象时，会创建一个内置的默认大小的缓冲区数组，通过缓冲区读写，减少系统IO次数，从而提高读写的效率。\n1.1.1 字节缓冲流 # 构造方法：\npublic BufferedInputStream(InputStream in) ：创建一个 新的缓冲输入流。 public BufferedOutputStream(OutputStream out)： 创建一个新的缓冲输出流。 1.1.2 字符缓冲流 # 构造方法：\npublic BufferedReader(Reader in) ：创建一个 新的缓冲输入流。 public BufferedWriter(Writer out)： 创建一个新的缓冲输出流。 特有方法：\n字符缓冲流的基本方法与普通字符流调用方式一致，不再阐述，我们来看它们具备的特有方法。\nBufferedReader：public String readLine(): 读一行文字。 BufferedWriter：public void newLine(): 写一行行分隔符,由系统属性定义符号。 1.2 转换流 # 字符编码\n计算机中储存的信息都是用二进制数表示的，而我们在屏幕上看到的数字、英文、标点符号、汉字等字符是二进制数转换之后的结果。按照某种规则，将字符存储到计算机中，称为编码 。反之，将存储在计算机中的二进制数按照某种规则解析显示出来，称为解码 。比如说，按照A规则存储，同样按照A规则解析，那么就能显示正确的文本符号。反之，按照A规则存储，再按照B规则解析，就会导致乱码现象。\n编码:字符(能看懂的)\u0026ndash;字节(看不懂的)\n解码:字节(看不懂的)\u0026ndash;\u0026gt;字符(能看懂的)\n字符编码Character Encoding : 就是一套自然语言的字符与二进制数之间的对应规则。\n编码表:生活中文字和计算机中二进制的对应规则\n1.2.1字符集 # 字符集 Charset：也叫编码表。是一个系统支持的所有字符的集合，包括各国家文字、标点符号、图形符号、数字等。\n计算机要准确的存储和识别各种字符集符号，需要进行字符编码，一套字符集必然至少有一套字符编码。常见字符集有ASCII字符集、GBK字符集、Unicode字符集等。\n可见，当指定了编码，它所对应的字符集自然就指定了，所以编码才是我们最终要关心的。\nASCII字符集 ： ASCII（American Standard Code for Information Interchange，美国信息交换标准代码）是基于拉丁字母的一套电脑编码系统，用于显示现代英语，主要包括控制字符（回车键、退格、换行键等）和可显示字符（英文大小写字符、阿拉伯数字和西文符号）。 基本的ASCII字符集，使用7位（bits）表示一个字符，共128字符。ASCII的扩展字符集使用8位（bits）表示一个字符，共256字符，方便支持欧洲常用字符。 ISO-8859-1字符集： 拉丁码表，别名Latin-1，用于显示欧洲使用的语言，包括荷兰、丹麦、德语、意大利语、西班牙语等。 ISO-8859-1使用单字节编码，兼容ASCII编码。 GBxxx字符集： GB就是国标的意思，是为了显示中文而设计的一套字符集。 GB2312：简体中文码表。一个小于127的字符的意义与原来相同。但两个大于127的字符连在一起时，就表示一个汉字，这样大约可以组合了包含7000多个简体汉字，此外数学符号、罗马希腊的字母、日文的假名们都编进去了，连在ASCII里本来就有的数字、标点、字母都统统重新编了两个字节长的编码，这就是常说的\u0026quot;全角\u0026quot;字符，而原来在127号以下的那些就叫\u0026quot;半角\u0026quot;字符了。 GBK：最常用的中文码表。是在GB2312标准基础上的扩展规范，使用了双字节编码方案，共收录了21003个汉字，完全兼容GB2312标准，同时支持繁体汉字以及日韩汉字等。 GB18030：最新的中文码表。收录汉字70244个，采用多字节编码，每个字可以由1个、2个或4个字节组成。支持中国国内少数民族的文字，同时支持繁体汉字以及日韩汉字等。 Unicode字符集 ： Unicode编码系统为表达任意语言的任意字符而设计，是业界的一种标准，也称为统一码、标准万国码。 它最多使用4个字节的数字来表达每个字母、符号，或者文字。有三种编码方案，UTF-8、UTF-16和UTF-32。最为常用的UTF-8编码。 UTF-8编码，可以用来表示Unicode标准中任何字符，它是电子邮件、网页及其他存储或传送文字的应用中，优先采用的编码。互联网工程工作小组（IETF）要求所有互联网协议都必须支持UTF-8编码。所以，我们开发Web应用，也要使用UTF-8编码。它使用一至四个字节为每个字符编码，编码规则： 128个US-ASCII字符，只需一个字节编码。 拉丁文等字符，需要二个字节编码。 大部分常用字（含中文），使用三个字节编码。 其他极少使用的Unicode辅助字符，使用四字节编码。 编码引出的问题：\n在IDEA中，使用FileReader 读取项目中的文本文件。由于IDEA的设置，都是默认的UTF-8编码，所以没有任何问题。但是，当读取Windows系统中创建的文本文件时，由于Windows系统的默认是GBK编码，就会出现乱码。\n1.2.2 InputStreamReader类 # 转换流java.io.InputStreamReader，是Reader的子类，是从字节流到字符流的桥梁。它读取字节，并使用指定的字符集将其解码为字符。它的字符集可以由名称指定，也可以接受平台的默认字符集。\n构造方法：\nInputStreamReader(InputStream in): 创建一个使用默认字符集的字符流。 InputStreamReader(InputStream in, String charsetName): 创建一个指定字符集的字符流。 指定编码读取：\n// 定义文件路径,文件为gbk编码 String FileName = \u0026#34;E:\\\\file_gbk.txt\u0026#34;; // 创建流对象,默认UTF8编码 InputStreamReader isr = new InputStreamReader(new FileInputStream(FileName)); // 创建流对象,指定GBK编码 InputStreamReader isr2 = new InputStreamReader(new FileInputStream(FileName) , \u0026#34;GBK\u0026#34;); // 定义变量,保存字符 int read; // 使用默认编码字符流读取,乱码 while ((read = isr.read()) != -1) { System.out.print((char)read); // ��Һ� } isr.close(); // 使用指定编码字符流读取,正常解析 while ((read = isr2.read()) != -1) { System.out.print((char)read);// 大家好 } isr2.close(); } 1.2.3 OutputStreamWriter类 # 转换流java.io.OutputStreamWriter ，是Writer的子类，是从字符流到字节流的桥梁。使用指定的字符集将字符编码为字节。它的字符集可以由名称指定，也可以接受平台的默认字符集。\n构造方法\nOutputStreamWriter(OutputStream in): 创建一个使用默认字符集的字符流。 OutputStreamWriter(OutputStream in, String charsetName): 创建一个指定字符集的字符流。 转换流理解图解\n1.3 打印流 # 平时我们在控制台打印输出，是调用print方法和println方法完成的，这两个方法都来自于java.io.PrintStream类，该类能够方便地打印各种数据类型的值，是一种便捷的输出方式。\n1.3.1 PrintStream类 # 构造方法\npublic PrintStream(String fileName) ： 使用指定的文件名创建一个新的打印流。\n改变打印流向\nSystem.out就是PrintStream类型的，只不过它的流向是系统规定的，打印在控制台上。不过，既然是流对象，我们就可以玩一个\u0026quot;小把戏\u0026quot;，改变它的流向。\npublic class PrintDemo { public static void main(String[] args) throws IOException { // 调用系统的打印流,控制台直接输出97 System.out.println(97); // 创建打印流,指定文件的名称 PrintStream ps = new PrintStream(\u0026#34;ps.txt\u0026#34;); // 设置系统的打印流流向,输出到ps.txt System.setOut(ps); // 调用系统的打印流,ps.txt中输出97 System.out.println(97); } } 1.4 压缩流和解压缩流 # 压缩流：\n​\t负责压缩文件或者文件夹\n解压缩流：\n​\t负责把压缩包中的文件和文件夹解压出来\n//1.创建一个File表示要解压的压缩包 File src = new File(\u0026#34;D:\\\\aaa.zip\u0026#34;); //2.创建一个File表示解压的目的地 File dest = new File(\u0026#34;D:\\\\\u0026#34;); //调用方法 unzip(src,dest); //压缩流 toZip(src,dest); ","date":"11 March 2025","externalUrl":null,"permalink":"/posts/1741693798119-io-%E5%85%B6%E4%BB%96%E6%B5%81/","section":"Posts","summary":"","title":"IO 其他流","type":"posts"},{"content":" IO流简介 # IO 即 Input/Output，输入和输出。==数据输入到计算机内存的过程即输入，反之输出到外部存储（比如数据库，文件，远程主机）的过程即输出。数据传输过程类似于水流，因此称为 IO 流。==IO 流在 Java 中分为输入流和输出流，而根据数据的处理方式又分为字节流和字符流。\nJava IO 流的 40 多个类都是从如下 4 个抽象类基类中派生出来的。\nInputStream/Reader: 所有的输入流的基类，前者是字节输入流，后者是字符输入流。 OutputStream/Writer: 所有输出流的基类，前者是字节输出流，后者是字符输出流。 IO基础总结 # 1.1 字节流 # 一切文件数据(文本、图片、视频等)在存储时，都是以二进制数字的形式保存，都一个一个的字节，那么传输时一样如此。所以，**字节流可以传输任意文件数据。**在操作流的时候，我们要时刻明确，无论使用什么样的流对象，底层传输的始终为二进制数据。\n1.1.1 InputStream（字节输入流） # InputStream用于从源头（通常是文件）读取数据（字节信息）到内存中，java.io.InputStream抽象类是所有字节输入流的父类。\nInputStream 常用方法：\npublic abstract int read()：返回输入流中下一个字节的数据。返回的值介于 0 到 255 之间。如果未读取任何字节，则代码返回 -1 ，表示文件结束。 public int read(byte[] b)： 从输入流中读取一些字节存储到数组 b 中。如果数组 b 的长度为零，则不读取。如果没有可用字节读取，返回 -1。如果有可用字节读取，则最多读取的字节数最多等于 b.length ， 返回读取的字节数。这个方法等价于 read(b, 0, b.length)。 read(byte b[], int off, int len)：在read(byte b[ ]) 方法的基础上增加了 off 参数（偏移量）和 len 参数（要读取的最大字节数）。 skip(long n)：忽略输入流中的 n 个字节 ,返回实际忽略的字节数。 available()：返回输入流中可以读取的字节数。 public void close() ：关闭输入流释放相关的系统资源。 从 Java 9 开始，InputStream 新增加了多个实用的方法：\nreadAllBytes()：读取输入流中的所有字节，返回字节数组。 readNBytes(byte[] b, int off, int len)：阻塞直到读取 len 个字节。 transferTo(OutputStream out)：将所有字节从一个输入流传递到一个输出流。 FileInputStream 是一个比较常用的字节输入流对象，可直接指定文件路径，可以直接读取单字节数据，也可以读取至字节数组中。\n构造方法\nFileInputStream(File file)： 通过打开与实际文件的连接来创建一个 FileInputStream ，该文件由文件系统中的 File对象 file命名。 FileInputStream(String name)： 通过打开与实际文件的连接来创建一个 FileInputStream ，该文件由文件系统中的路径名 name命名。 当你创建一个流对象时，必须传入一个文件路径。该路径下，如果没有该文件,会抛出FileNotFoundException 。\n读取字节数据\n读取字节：read方法，每次可以读取一个字节的数据，提升为int类型，读取到文件末尾，返回-1。\n虽然读取了一个字节，但是会自动提升为int类型。 流操作完毕后，必须释放系统资源，调用close方法，千万记得。 使用字节数组读取：read(byte[] b)，每次读取b的长度个字节到数组中，返回读取到的有效字节个数，读取到末尾时，返回-1 。\n使用数组读取，每次读取多个字节，减少了系统间的IO操作次数，从而提高了读写的效率，建议开发中使用。\nFileInputStream 代码示例：\ntry (InputStream fis = new FileInputStream(\u0026#34;input.txt\u0026#34;)) { System.out.println(\u0026#34;Number of remaining bytes:\u0026#34; + fis.available()); int content; long skip = fis.skip(2); System.out.println(\u0026#34;The actual number of bytes skipped:\u0026#34; + skip); System.out.print(\u0026#34;The content read from file:\u0026#34;); while ((content = fis.read()) != -1) { System.out.print((char) content); } } catch (IOException e) { e.printStackTrace(); } input.txt 文件内容：\n输出：\nNumber of remaining bytes:11 The actual number of bytes skipped:2 The content read from file:JavaGuide 不过，一般我们是不会直接单独使用 FileInputStream ，通常会配合 BufferedInputStream（字节缓冲输入流，后文会讲到）来使用。\n像下面这段代码在我们的项目中就比较常见，我们通过 readAllBytes() 读取输入流所有字节并将其直接赋值给一个 String 对象。\n// 新建一个 BufferedInputStream 对象 BufferedInputStream bufferedInputStream = new BufferedInputStream(new FileInputStream(\u0026#34;input.txt\u0026#34;)); // 读取文件的内容并复制到 String 对象中 String result = new String(bufferedInputStream.readAllBytes()); System.out.println(result); DataInputStream 用于读取指定类型数据，不能单独使用，必须结合其它流，比如 FileInputStream 。\nFileInputStream fileInputStream = new FileInputStream(\u0026#34;input.txt\u0026#34;); //必须将fileInputStream作为构造参数才能使用 DataInputStream dataInputStream = new DataInputStream(fileInputStream); //可以读取任意具体的类型数据 dataInputStream.readBoolean(); dataInputStream.readInt(); dataInputStream.readUTF(); ObjectInputStream 用于从输入流中读取 Java 对象（反序列化），ObjectOutputStream 用于将对象写入到输出流(序列化)。\nObjectInputStream input = new ObjectInputStream(new FileInputStream(\u0026#34;object.data\u0026#34;)); MyClass object = (MyClass) input.readObject(); input.close(); 另外，用于序列化和反序列化的类必须实现 Serializable 接口，对象中如果有属性不想被序列化，使用 transient 修饰。\n1.1.2 OutputStream(字节输出流) # OutputStream用于将数据（字节信息）写入到目的地（通常是文件），java.io.OutputStream抽象类是所有字节输出流的父类。\nOutputStream 常用方法：\npublic void close() ：关闭此输出流并释放与此流相关联的任何系统资源。 public void flush() ：刷新此输出流并强制任何缓冲的输出字节被写出。 public void write(byte[] b)：将 b.length字节从指定的字节数组写入此输出流，等价于 write(b, 0, b.length) 。 public void write(byte[] b, int off, int len) ：在write(byte b[ ]) 方法的基础上增加了 off 参数（偏移量）和 len 参数（要读取的最大字节数）。 public abstract void write(int b) ：将指定的字节输出流。 小贴士：\nclose方法，当完成流的操作时，必须调用此方法，释放系统资源。\nFileOutputStream 是最常用的字节输出流对象，可直接指定文件路径，可以直接输出单字节数据，也可以输出指定的字节数组。\n构造方法\npublic FileOutputStream(File file)：创建文件输出流以写入由指定的 File对象表示的文件。 public FileOutputStream(String name)： 创建文件输出流以指定的名称写入文件。 当你创建一个流对象时，必须传入一个文件路径。该路径下，如果没有这个文件，会创建该文件。如果有这个文件，会清空这个文件的数据。\n写出字节数据\n写出字节：write(int b) 方法，每次可以写出一个字节数据。\n虽然参数为int类型四个字节，但是只会保留一个字节的信息写出。 流操作完毕后，必须释放系统资源，调用close方法，千万记得。 写出字节数组：write(byte[] b)，每次可以写出数组中的数据。\n写出指定长度字节数组：write(byte[] b, int off, int len) ,每次写出从off索引开始，len个字节。\n数据追加续写\n经过以上的演示，每次程序运行，创建输出流对象，都会清空目标文件中的数据。如何保留目标文件中数据，还能继续添加新数据呢？\npublic FileOutputStream(File file, boolean append)： 创建文件输出流以写入由指定的 File对象表示的文件。 public FileOutputStream(String name, boolean append)： 创建文件输出流以指定的名称写入文件。 这两个构造方法，参数中都需要传入一个boolean类型的值，true 表示追加数据，false 表示清空原有数据。这样创建的输出流对象，就可以指定是否追加续写了。\n写出换行\nWindows系统里，换行符号是\\r\\n 。\n回车符\\r和换行符\\n ： 回车符：回到一行的开头（return）。 换行符：下一行（newline）。 系统中的换行： Windows系统里，每行结尾是 回车+换行 ，即\\r\\n； Unix系统里，每行结尾只有 换行 ，即\\n； Mac系统里，每行结尾是 回车 ，即\\r。从 Mac OS X开始与Linux统一。 FileOutputStream 代码示例：\ntry (FileOutputStream output = new FileOutputStream(\u0026#34;output.txt\u0026#34;)) { byte[] array = \u0026#34;JavaGuide\u0026#34;.getBytes(); output.write(array); } catch (IOException e) { e.printStackTrace(); } 运行结果：\n类似于 FileInputStream，FileOutputStream 通常也会配合 BufferedOutputStream（字节缓冲输出流，后文会讲到）来使用。\nFileOutputStream fileOutputStream = new FileOutputStream(\u0026#34;output.txt\u0026#34;); BufferedOutputStream bos = new BufferedOutputStream(fileOutputStream) DataOutputStream 用于写入指定类型数据，不能单独使用，必须结合其它流，比如 FileOutputStream 。\n// 输出流 FileOutputStream fileOutputStream = new FileOutputStream(\u0026#34;out.txt\u0026#34;); DataOutputStream dataOutputStream = new DataOutputStream(fileOutputStream); // 输出任意数据类型 dataOutputStream.writeBoolean(true); dataOutputStream.writeByte(1); ObjectInputStream 用于从输入流中读取 Java 对象（ObjectInputStream,反序列化），ObjectOutputStream将对象写入到输出流(ObjectOutputStream，序列化)。\nObjectOutputStream output = new ObjectOutputStream(new FileOutputStream(\u0026#34;file.txt\u0026#34;) Person person = new Person(\u0026#34;Guide哥\u0026#34;, \u0026#34;JavaGuide作者\u0026#34;); output.writeObject(person); 1.2 字符流 # 不管是文件读写还是网络发送接收，信息的最小存储单元都是字节。 那为什么 I/O 流操作要分为字节流操作和字符流操作呢？\n个人认为主要有两点原因：\n字符流是由 Java 虚拟机将字节转换得到的，这个过程还算是比较耗时。 如果我们不知道编码类型就很容易出现乱码问题。 比如遇到中文字符时，可能不会显示完整的字符，那是因为一个中文字符可能占用多个字节存储。所以Java提供一些字符流类，以字符为单位读写数据，专门用于处理文本文件。\n乱码问题这个很容易就可以复现，我们只需要将上面提到的 FileInputStream 代码示例中的 input.txt 文件内容改为中文即可，原代码不需要改动。\n输出：\nNumber of remaining bytes:9 The actual number of bytes skipped:2 The content read from file:§å®¶å¥½ 可以很明显地看到读取出来的内容已经变成了乱码。\n因此，I/O 流就干脆提供了一个直接操作字符的接口，方便我们平时对字符进行流操作。如果音频文件、图片等媒体文件用字节流比较好，如果涉及到字符的话使用字符流比较好。\n字符流默认采用的是 Unicode 编码，我们可以通过构造方法自定义编码。\nUnicode 本身只是一种字符集，它为每个字符分配一个唯一的数字编号，并没有规定具体的存储方式。UTF-8、UTF-16、UTF-32 都是 Unicode 的编码方式，它们使用不同的字节数来表示 Unicode 字符。例如，UTF-8 :英文占 1 字节，中文占 3 字节。\n1.2.1 Reader(字符输入流) # Reader用于从源头（通常是文件）读取数据（字符信息）到内存中，java.io.Reader抽象类是所有字符输入流的父类。\nReader 用于读取文本， InputStream 用于读取原始字节。\nReader 常用方法：\npublic int read() : 从输入流读取一个字符。 public int read(char[] cbuf) : 从输入流中读取一些字符，并将它们存储到字符数组 cbuf中，等价于 read(cbuf, 0, cbuf.length) 。 read(char[] cbuf, int off, int len)：在read(char[] cbuf) 方法的基础上增加了 off 参数（偏移量）和 len 参数（要读取的最大字符数）。 skip(long n)：忽略输入流中的 n 个字符 ,返回实际忽略的字符数。 public void close() : 关闭输入流并释放相关的系统资源。 InputStreamReader 是字节流转换为字符流的桥梁，其子类 FileReader 是基于该基础上的封装，可以直接操作字符文件。\n// 字节流转换为字符流的桥梁 public class InputStreamReader extends Reader { } // 用于读取字符文件 public class FileReader extends InputStreamReader { } java.io.FileReader 类是读取字符文件的便利类。构造时使用系统默认的字符编码和默认字节缓冲区。\n小贴士：\n字符编码：字节与字符的对应规则。Windows系统的中文编码默认是GBK编码表。\nidea中UTF-8\n字节缓冲区：一个字节数组，用来临时存储字节数据。\n构造方法\nFileReader(File file)： 创建一个新的 FileReader ，给定要读取的File对象。 FileReader(String fileName)： 创建一个新的 FileReader ，给定要读取的文件的名称。 当你创建一个流对象时，必须传入一个文件路径。类似于FileInputStream 。\n读取字符数据\n读取字符：read方法，每次可以读取一个字符的数据，提升为int类型，读取到文件末尾，返回-1，循环读取。\n虽然读取了一个字符，但是会自动提升为int类型。\n使用字符数组读取：read(char[] cbuf)，每次读取b的长度个字符到数组中，返回读取到的有效字符个数，读取到末尾时，返回-1 。\nFileReader 代码示例：\ntry (FileReader fileReader = new FileReader(\u0026#34;input.txt\u0026#34;);) { int content; long skip = fileReader.skip(3); System.out.println(\u0026#34;The actual number of bytes skipped:\u0026#34; + skip); System.out.print(\u0026#34;The content read from file:\u0026#34;); while ((content = fileReader.read()) != -1) { System.out.print((char) content); } } catch (IOException e) { e.printStackTrace(); } input.txt 文件内容：\n输出：\nThe actual number of bytes skipped:3 The content read from file:我是Guide。 1.2.2 Writer(字符输出流) # Writer用于将数据（字符信息）写入到目的地（通常是文件），java.io.Writer抽象类是所有字符输出流的父类。\nWriter 常用方法：\nvoid write(int c) : 写入单个字符。 void write(char[] cbuf) ：写入字符数组 cbuf，等价于write(cbuf, 0, cbuf.length)。 abstract void write(char[] cbuf, int off, int len) ：在write(char[] cbuf) 方法的基础上增加了 off 参数（偏移量）和 len 参数（要读取的最大字符数）。 void write(String str)：写入字符串，等价于 write(str, 0, str.length()) 。 void write(String str, int off, int len)：在write(String str) 方法的基础上增加了 off 参数（偏移量）和 len 参数（要读取的最大字符数）。 append(CharSequence csq)：将指定的字符序列附加到指定的 Writer 对象并返回该 Writer 对象。 append(char c)：将指定的字符附加到指定的 Writer 对象并返回该 Writer 对象。 void flush()：刷新此输出流并强制写出所有缓冲的输出字符。 void close():关闭输出流释放相关的系统资源。 OutputStreamWriter 是字符流转换为字节流的桥梁，其子类 FileWriter 是基于该基础上的封装，可以直接将字符写入到文件。\n// 字符流转换为字节流的桥梁 public class OutputStreamWriter extends Writer { } // 用于写入字符到文件 public class FileWriter extends OutputStreamWriter { } 构造方法\nFileWriter(File file)： 创建一个新的 FileWriter，给定要读取的File对象。 FileWriter(String fileName)： 创建一个新的 FileWriter，给定要读取的文件的名称。 当你创建一个流对象时，必须传入一个文件路径，类似于FileOutputStream。\n基本写出数据\n写出字符：write(int b) 方法，每次可以写出一个字符数据。\n虽然参数为int类型四个字节，但是只会保留一个字符的信息写出。 未调用close方法，数据只是保存到了缓冲区，并未写出到文件中。 关闭和刷新\n因为内置缓冲区的原因，如果不关闭输出流，无法写出字符到文件中。但是关闭的流对象，是无法继续写出数据的。如果我们既想写出数据，又想继续使用流，就需要flush 方法了。\nflush ：刷新缓冲区，流对象可以继续使用。 close :先刷新缓冲区，然后通知系统释放资源。流对象不可以再被使用了。 即便是flush方法写出了数据，操作的最后还是要调用close方法，释放系统资源。\n写出其他数据\n写出字符数组 ：write(char[] cbuf) 和 write(char[] cbuf, int off, int len) ，每次可以写出字符数组中的数据，用法类似FileOutputStream。\n写出字符串：write(String str) 和 write(String str, int off, int len) ，每次可以写出字符串中的数据，更为方便。\n续写和换行：操作类似于FileOutputStream。\n字符流，只能操作文本文件，不能操作图片，视频等非文本文件。\n当我们单纯读或者写文本文件时 使用字符流 其他情况使用字节流\nFileWriter 代码示例：\ntry (Writer output = new FileWriter(\u0026#34;output.txt\u0026#34;)) { output.write(\u0026#34;你好，我是Guide。\u0026#34;); } catch (IOException e) { e.printStackTrace(); } 输出结果：\n1.3 字节缓冲流 # IO 操作是很消耗性能的，缓冲流将数据加载至缓冲区，一次性读取/写入多个字节，从而避免频繁的 IO 操作，提高流的传输效率。\n字节缓冲流这里采用了装饰器模式来增强 InputStream 和OutputStream子类对象的功能。\n举个例子，我们可以通过 BufferedInputStream（字节缓冲输入流）来增强 FileInputStream 的功能。\n// 新建一个 BufferedInputStream 对象 BufferedInputStream bufferedInputStream = new BufferedInputStream(new FileInputStream(\u0026#34;input.txt\u0026#34;)); 字节流和字节缓冲流的性能差别主要体现在我们使用两者的时候都是调用 write(int b) 和 read() 这两个一次只读取一个字节的方法的时候。由于字节缓冲流内部有缓冲区（字节数组），因此，字节缓冲流会先将读取到的字节存放在缓存区，大幅减少 IO 次数，提高读取效率。\n我使用 write(int b) 和 read() 方法，分别通过字节流和字节缓冲流复制一个 524.9 mb 的 PDF 文件耗时对比如下：\n使用缓冲流复制PDF文件总耗时:15428 毫秒 使用普通字节流复制PDF文件总耗时:2555062 毫秒 两者耗时差别非常大，缓冲流耗费的时间是字节流的 1/165。\n测试代码如下:\n@Test void copy_pdf_to_another_pdf_buffer_stream() { // 记录开始时间 long start = System.currentTimeMillis(); try (BufferedInputStream bis = new BufferedInputStream(new FileInputStream(\u0026#34;深入理解计算机操作系统.pdf\u0026#34;)); BufferedOutputStream bos = new BufferedOutputStream(new FileOutputStream(\u0026#34;深入理解计算机操作系统-副本.pdf\u0026#34;))) { int content; while ((content = bis.read()) != -1) { bos.write(content); } } catch (IOException e) { e.printStackTrace(); } // 记录结束时间 long end = System.currentTimeMillis(); System.out.println(\u0026#34;使用缓冲流复制PDF文件总耗时:\u0026#34; + (end - start) + \u0026#34; 毫秒\u0026#34;); } @Test void copy_pdf_to_another_pdf_stream() { // 记录开始时间 long start = System.currentTimeMillis(); try (FileInputStream fis = new FileInputStream(\u0026#34;深入理解计算机操作系统.pdf\u0026#34;); FileOutputStream fos = new FileOutputStream(\u0026#34;深入理解计算机操作系统-副本.pdf\u0026#34;)) { int content; while ((content = fis.read()) != -1) { fos.write(content); } } catch (IOException e) { e.printStackTrace(); } // 记录结束时间 long end = System.currentTimeMillis(); System.out.println(\u0026#34;使用普通流复制PDF文件总耗时:\u0026#34; + (end - start) + \u0026#34; 毫秒\u0026#34;); } 如果是调用 read(byte b[]) 和 write(byte b[], int off, int len) 这两个写入一个字节数组的方法的话，只要字节数组的大小合适，两者的性能差距其实不大，基本可以忽略。\n这次我们使用 read(byte b[]) 和 write(byte b[], int off, int len) 方法，分别通过字节流和字节缓冲流复制一个 524.9 mb 的 PDF 文件耗时对比如下：\n使用缓冲流复制PDF文件总耗时:695 毫秒 使用普通字节流复制PDF文件总耗时:989 毫秒 两者耗时差别不是很大，缓冲流的性能要略微好一点点。\n测试代码如下：\n@Test void copy_pdf_to_another_pdf_with_byte_array_buffer_stream() { // 记录开始时间 long start = System.currentTimeMillis(); try (BufferedInputStream bis = new BufferedInputStream(new FileInputStream(\u0026#34;深入理解计算机操作系统.pdf\u0026#34;)); BufferedOutputStream bos = new BufferedOutputStream(new FileOutputStream(\u0026#34;深入理解计算机操作系统-副本.pdf\u0026#34;))) { int len; byte[] bytes = new byte[4 * 1024]; while ((len = bis.read(bytes)) != -1) { bos.write(bytes, 0, len); } } catch (IOException e) { e.printStackTrace(); } // 记录结束时间 long end = System.currentTimeMillis(); System.out.println(\u0026#34;使用缓冲流复制PDF文件总耗时:\u0026#34; + (end - start) + \u0026#34; 毫秒\u0026#34;); } @Test void copy_pdf_to_another_pdf_with_byte_array_stream() { // 记录开始时间 long start = System.currentTimeMillis(); try (FileInputStream fis = new FileInputStream(\u0026#34;深入理解计算机操作系统.pdf\u0026#34;); FileOutputStream fos = new FileOutputStream(\u0026#34;深入理解计算机操作系统-副本.pdf\u0026#34;)) { int len; byte[] bytes = new byte[4 * 1024]; while ((len = fis.read(bytes)) != -1) { fos.write(bytes, 0, len); } } catch (IOException e) { e.printStackTrace(); } // 记录结束时间 long end = System.currentTimeMillis(); System.out.println(\u0026#34;使用普通流复制PDF文件总耗时:\u0026#34; + (end - start) + \u0026#34; 毫秒\u0026#34;); } 1.3.1 BufferedInputStream(字节缓冲输入流) # BufferedInputStream 从源头（通常是文件）读取数据（字节信息）到内存的过程中不会一个字节一个字节的读取，而是会先将读取到的字节存放在缓存区，并从内部缓冲区中单独读取字节。这样大幅减少了 IO 次数，提高了读取效率。\nBufferedInputStream 内部维护了一个缓冲区，这个缓冲区实际就是一个字节数组，通过阅读 BufferedInputStream 源码即可得到这个结论。\npublic class BufferedInputStream extends FilterInputStream { // 内部缓冲区数组 protected volatile byte buf[]; // 缓冲区的默认大小 private static int DEFAULT_BUFFER_SIZE = 8192; // 使用默认的缓冲区大小 public BufferedInputStream(InputStream in) { this(in, DEFAULT_BUFFER_SIZE); } // 自定义缓冲区大小 public BufferedInputStream(InputStream in, int size) { super(in); if (size \u0026lt;= 0) { throw new IllegalArgumentException(\u0026#34;Buffer size \u0026lt;= 0\u0026#34;); } buf = new byte[size]; } } 缓冲区的大小默认为 8192 字节，当然了，你也可以通过 BufferedInputStream(InputStream in, int size) 这个构造方法来指定缓冲区的大小。\n1.3.2 BufferedOutputStream(字节缓冲输出流) # BufferedOutputStream 将数据（字节信息）写入到目的地（通常是文件）的过程中不会一个字节一个字节的写入，而是会先将要写入的字节存放在缓存区，并从内部缓冲区中单独写入字节。这样大幅减少了 IO 次数，提高了读取效率\ntry (BufferedOutputStream bos = new BufferedOutputStream(new FileOutputStream(\u0026#34;output.txt\u0026#34;))) { byte[] array = \u0026#34;JavaGuide\u0026#34;.getBytes(); bos.write(array); } catch (IOException e) { e.printStackTrace(); } 类似于 BufferedInputStream ，BufferedOutputStream 内部也维护了一个缓冲区，并且，这个缓存区的大小也是 8192 字节。\n1.4 字符缓冲流 # BufferedReader （字符缓冲输入流）和 BufferedWriter（字符缓冲输出流）类似于 BufferedInputStream（字节缓冲输入流）和BufferedOutputStream（字节缓冲输入流），内部都维护了一个字节数组作为缓冲区。不过，前者主要是用来操作字符信息。\n1.5 打印流 # 下面这段代码大家经常使用吧？\nSystem.out.print(\u0026#34;Hello！\u0026#34;); System.out.println(\u0026#34;Hello！\u0026#34;); System.out 实际是用于获取一个 PrintStream 对象，print方法实际调用的是 PrintStream 对象的 write 方法。\nPrintStream 属于字节打印流，与之对应的是 PrintWriter （字符打印流）。PrintStream 是 OutputStream 的子类，PrintWriter 是 Writer 的子类。\npublic class PrintStream extends FilterOutputStream implements Appendable, Closeable { } public class PrintWriter extends Writer { } 1.6 随机访问流 # 这里要介绍的随机访问流指的是支持随意跳转到文件的任意位置进行读写的 RandomAccessFile 。\nRandomAccessFile 的构造方法如下，我们可以指定 mode（读写模式）。\n// openAndDelete 参数默认为 false 表示打开文件并且这个文件不会被删除 public RandomAccessFile(File file, String mode) throws FileNotFoundException { this(file, mode, false); } // 私有方法 private RandomAccessFile(File file, String mode, boolean openAndDelete) throws FileNotFoundException{ // 省略大部分代码 } 读写模式主要有下面四种：\nr : 只读模式。 rw: 读写模式 rws: 相对于 rw，rws 同步更新对“文件的内容”或“元数据”的修改到外部存储设备。 rwd : 相对于 rw，rwd 同步更新对“文件的内容”的修改到外部存储设备。 文件内容指的是文件中实际保存的数据，元数据则是用来描述文件属性比如文件的大小信息、创建和修改时间。\nRandomAccessFile 中有一个文件指针用来表示下一个将要被写入或者读取的字节所处的位置。我们可以通过 RandomAccessFile 的 seek(long pos) 方法来设置文件指针的偏移量（距文件开头 pos 个字节处）。如果想要获取文件指针当前的位置的话，可以使用 getFilePointer() 方法。\nRandomAccessFile 代码示例：\nRandomAccessFile randomAccessFile = new RandomAccessFile(new File(\u0026#34;input.txt\u0026#34;), \u0026#34;rw\u0026#34;); System.out.println(\u0026#34;读取之前的偏移量：\u0026#34; + randomAccessFile.getFilePointer() + \u0026#34;,当前读取到的字符\u0026#34; + (char) randomAccessFile.read() + \u0026#34;，读取之后的偏移量：\u0026#34; + randomAccessFile.getFilePointer()); // 指针当前偏移量为 6 randomAccessFile.seek(6); System.out.println(\u0026#34;读取之前的偏移量：\u0026#34; + randomAccessFile.getFilePointer() + \u0026#34;,当前读取到的字符\u0026#34; + (char) randomAccessFile.read() + \u0026#34;，读取之后的偏移量：\u0026#34; + randomAccessFile.getFilePointer()); // 从偏移量 7 的位置开始往后写入字节数据 randomAccessFile.write(new byte[]{\u0026#39;H\u0026#39;, \u0026#39;I\u0026#39;, \u0026#39;J\u0026#39;, \u0026#39;K\u0026#39;}); // 指针当前偏移量为 0，回到起始位置 randomAccessFile.seek(0); System.out.println(\u0026#34;读取之前的偏移量：\u0026#34; + randomAccessFile.getFilePointer() + \u0026#34;,当前读取到的字符\u0026#34; + (char) randomAccessFile.read() + \u0026#34;，读取之后的偏移量：\u0026#34; + randomAccessFile.getFilePointer()); input.txt 文件内容：\n输出：\n读取之前的偏移量：0,当前读取到的字符A，读取之后的偏移量：1 读取之前的偏移量：6,当前读取到的字符G，读取之后的偏移量：7 读取之前的偏移量：0,当前读取到的字符A，读取之后的偏移量：1 input.txt 文件内容变为 ABCDEFGHIJK 。\nRandomAccessFile 的 write 方法在写入对象的时候如果对应的位置已经有数据的话，会将其覆盖掉。\nRandomAccessFile randomAccessFile = new RandomAccessFile(new File(\u0026#34;input.txt\u0026#34;), \u0026#34;rw\u0026#34;); randomAccessFile.write(new byte[]{\u0026#39;H\u0026#39;, \u0026#39;I\u0026#39;, \u0026#39;J\u0026#39;, \u0026#39;K\u0026#39;}); 假设运行上面这段程序之前 input.txt 文件内容变为 ABCD ，运行之后则变为 HIJK 。\nRandomAccessFile 比较常见的一个应用就是实现大文件的 断点续传 。何谓断点续传？简单来说就是上传文件中途暂停或失败（比如遇到网络问题）之后，不需要重新上传，只需要上传那些未成功上传的文件分片即可。分片（先将文件切分成多个文件分片）上传是断点续传的基础。\nRandomAccessFile 可以帮助我们合并文件分片，示例代码如下：\n","date":"11 March 2025","externalUrl":null,"permalink":"/posts/1741693735755-io%E5%9F%BA%E7%A1%80%E6%80%BB%E7%BB%93/","section":"Posts","summary":"","title":"IO基础总结","type":"posts"},{"content":" IO模型详解 # 1.1 I/O # 1.1.1 何为I/O? # I/O（Input/Output） 即输入／输出 。\n我们先从计算机结构的角度来解读一下 I/O。\n根据冯.诺依曼结构，计算机结构分为 5 大部分：运算器、控制器、存储器、输入设备、输出设备。\n输入设备（比如键盘）和输出设备（比如显示器）都属于外部设备。网卡、硬盘这种既可以属于输入设备，也可以属于输出设备。\n输入设备向计算机输入数据，输出设备接收计算机输出的数据。\n从计算机结构的视角来看的话， I/O 描述了计算机系统与外部设备之间通信的过程。\n我们再先从应用程序的角度来解读一下 I/O。\n根据大学里学到的操作系统相关的知识：为了保证操作系统的稳定性和安全性，一个进程的地址空间划分为 用户空间（User space） 和 内核空间（Kernel space ） 。\n像我们平常运行的应用程序都是运行在用户空间，只有内核空间才能进行系统态级别的资源有关的操作，比如文件管理、进程通信、内存管理等等。也就是说，我们想要进行 IO 操作，一定是要依赖内核空间的能力。\n并且，用户空间的程序不能直接访问内核空间。\n当想要执行 IO 操作时，由于没有执行这些操作的权限，只能发起系统调用请求操作系统帮忙完成。\n因此，用户进程想要执行 IO 操作的话，必须通过 系统调用 来间接访问内核空间\n我们在平常开发过程中接触最多的就是 磁盘 IO（读写文件） 和 网络 IO（网络请求和响应）。\n从应用程序的视角来看的话，我们的应用程序对操作系统的内核发起 IO 调用（系统调用），操作系统负责的内核执行具体的 IO 操作。也就是说，我们的应用程序实际上只是发起了 IO 操作的调用而已，具体 IO 的执行是由操作系统的内核来完成的。\n当应用程序发起 I/O 调用后，会经历两个步骤：\n内核等待 I/O 设备准备好数据 内核将数据从内核空间拷贝到用户空间。 1.1.2 有哪些常见的 IO 模型? # UNIX 系统下， IO 模型一共有 5 种：同步阻塞 I/O、同步非阻塞 I/O、I/O 多路复用、信号驱动 I/O 和异步 I/O。\n这也是我们经常提到的 5 种 IO 模型。\n1.2 Java中常见的3中IO模型 # 1.2.1 BIO（Blocking I/O） # BIO 属于同步阻塞 IO 模型 。\n同步阻塞 IO 模型中，应用程序发起 read 调用后，会一直阻塞，直到内核把数据拷贝到用户空间。\n在客户端连接数量不高的情况下，是没问题的。但是，当面对十万甚至百万级连接的时候，传统的 BIO 模型是无能为力的。因此，我们需要一种更高效的 I/O 处理模型来应对更高的并发量。\n1.2.2 NIO (Non-blocking/New I/O) # Java 中的 NIO 于 Java 1.4 中引入，对应 java.nio 包，提供了 Channel , Selector，Buffer 等抽象。NIO 中的 N 可以理解为 Non-blocking，不单纯是 New。它是支持面向缓冲的，基于通道的 I/O 操作方法。 对于高负载、高并发的（网络）应用，应使用 NIO 。\nJava 中的 NIO 可以看作是 I/O 多路复用模型。也有很多人认为，Java 中的 NIO 属于同步非阻塞 IO 模型。\n跟着我的思路往下看看，相信你会得到答案！\n我们先来看看 同步非阻塞 IO 模型。\n同步非阻塞 IO 模型中，应用程序会一直发起 read 调用，等待数据从内核空间拷贝到用户空间的这段时间里，线程依然是阻塞的，直到在内核把数据拷贝到用户空间。\n相比于同步阻塞 IO 模型，同步非阻塞 IO 模型确实有了很大改进。通过轮询操作，避免了一直阻塞。\n但是，这种 IO 模型同样存在问题：应用程序不断进行 I/O 系统调用轮询数据是否已经准备好的过程是十分消耗 CPU 资源的。\n这个时候，I/O 多路复用模型 就上场了。\nIO 多路复用模型中，线程首先发起 select 调用，询问内核数据是否准备就绪，等内核把数据准备好了，用户线程再发起 read 调用。read 调用的过程（数据从内核空间 -\u0026gt; 用户空间)还是阻塞的。\n目前支持 IO 多路复用的系统调用，有 select，epoll 等等。select 系统调用，目前几乎在所有的操作系统上都有支持。\nselect 调用：内核提供的系统调用，它支持一次查询多个系统调用的可用状态。几乎所有的操作系统都支持。 epoll 调用：linux 2.6 内核，属于 select 调用的增强版本，优化了 IO 的执行效率。 面试必备：对 select，poll，epoll 的详细解析_poll和select和epoll的作用-CSDN博客\nIO 多路复用模型，通过减少无效的系统调用，减少了对 CPU 资源的消耗。\nJava 中的 NIO ，有一个非常重要的选择器 ( Selector ) 的概念，也可以被称为 多路复用器。通过它，只需要一个线程便可以管理多个客户端连接。当客户端数据到了之后，才会为其服务。\n1.2.3.1 Buffer # 一个 Buffer 本质上是内存中的一块，我们可以将数据写入这块内存，之后从这块内存获取数据。\njava.nio 定义了以下几个 Buffer 的实现:\n其实核心是最后的 ByteBuffer，前面的一大串类只是包装了一下它而已，我们使用最多的通常也是 ByteBuffer。\n我们应该将 Buffer 理解为一个数组，IntBuffer、CharBuffer、DoubleBuffer 等分别对应 int[]、char[]、double[] 等。\nMappedByteBuffer 用于实现内存映射文件，也不是本文关注的重点。\n我觉得操作 Buffer 和操作数组、类集差不多，只不过大部分时候我们都把它放到了 NIO 的场景里面来使用而已。下面介绍 Buffer 中的几个重要属性和几个重要方法。\nposition、limit、capacity\n就像数组有数组容量，每次访问元素要指定下标，Buffer 中也有几个重要属性：position、limit、capacity。\nJava NIO:Buffer、Channel 和 Selector详解（通俗易懂）_java 流读取数据和channel读取数据底层流程-CSDN博客\n1.2.3 AIO（Asynchronous I/O） # AIO 也就是 NIO 2。Java 7 中引入了 NIO 的改进版 NIO 2,它是异步 IO 模型。\n异步 IO 是基于事件和回调机制实现的，也就是应用操作之后会直接返回，不会堵塞在那里，当后台处理完成，操作系统会通知相应的线程进行后续的操作。\n目前来说 AIO 的应用还不是很广泛。Netty 之前也尝试使用过 AIO，不过又放弃了。这是因为，Netty 使用了 AIO 之后，在 Linux 系统上的性能并没有多少提升。\n最后，来一张图，简单总结一下 Java 中的 BIO、NIO、AIO。\n1.2.4 BIO、NIO、AIO有什么区别 # 他们三者都是Java中常用的I/O模型，我们从以下三个维度进行对比：\n1.阻塞与非阻塞：\nBIO是阻塞式I/O模型，线程会一直被阻塞等待操作完成。 NIO是非阻塞式I/O模型，线程可以去做其他任务，当I/O操作完成时得到通知。 AIO也是非阻塞式I/O模型，不需要用户线程关注I/O事件，由操作系统通过回调机制处理。 2.缓冲区：\nBIO使用传统的字节流和字符流，需要为输入输出流分别创建缓冲区。 NIO引入了基于通道和缓冲区的I/O方式，使用一个缓冲区完成数据读写操作。 AIO则不需要缓冲区，使用异步回调方式进行操作。 3.线程模型：\nBIO采用一个线程处理一个请求方式，面对高并发时线程数量急剧增加，容易导致系统崩溃。 NIO采用多路复用器来监听多个客户端请求，使用一个线程处理，减少线程数量，提高系统性能。 AIO依靠操作系统完成I/O操作，不需要额外的线程池或多路复用器。 综上所述，BIO、NIO、AIO的区别主要在于阻塞与非阻塞、缓冲区和线程模型等方面。根据具体应用场景选择合适的I/O模型可以提高程序的性能和可扩展性。\nIO异常 # 2.1 IO异常的处理 # JDK7前处理：\n建议使用try...catch...finally 代码块，处理异常部分\nJDK7的处理：\ntry-with-resource 语句，该语句确保了每个资源在语句结束时关闭。所谓的资源（resource）是指在程序完成后，必须关闭的对象。\n格式：\ntry (创建流对象语句，如果多个,使用\u0026#39;;\u0026#39;隔开) { // 读写数据 } catch (IOException e) { e.printStackTrace(); } JDK9的改进：\nJDK9中try-with-resource 的改进，对于引入对象的方式，支持的更加简洁。被引入的对象，同样可以自动关闭，无需手动close。\n改进前格式：\n// 被final修饰的对象 final Resource resource1 = new Resource(\u0026#34;resource1\u0026#34;); // 普通对象 Resource resource2 = new Resource(\u0026#34;resource2\u0026#34;); // 引入方式：创建新的变量保存 try (Resource r1 = resource1; Resource r2 = resource2) { // 使用对象 } 改进后格式：\n// 被final修饰的对象 final Resource resource1 = new Resource(\u0026#34;resource1\u0026#34;); // 普通对象 Resource resource2 = new Resource(\u0026#34;resource2\u0026#34;); // 引入方式：直接引入 try (resource1; resource2) { // 使用对象 } ","date":"11 March 2025","externalUrl":null,"permalink":"/posts/1741693774639-io%E6%A8%A1%E5%9E%8B%E8%AF%A6%E8%A7%A3/","section":"Posts","summary":"","title":"IO模型详解","type":"posts"},{"content":" IO设计模式总结 # 1.1 装饰器模式 # 装饰器（Decorator）模式 可以在不改变原有对象的情况下拓展其功能。\n装饰器模式通过组合替代继承来扩展原始类的功能，在一些继承关系比较复杂的场景（IO 这一场景各种类的继承关系就比较复杂）更加实用。\n对于字节流来说， FilterInputStream （对应输入流）和FilterOutputStream（对应输出流）是装饰器模式的核心，分别用于增强 InputStream 和OutputStream子类对象的功能。\n我们常见的BufferedInputStream(字节缓冲输入流)、DataInputStream 等等都是FilterInputStream 的子类，BufferedOutputStream（字节缓冲输出流）、DataOutputStream等等都是FilterOutputStream的子类。\n举个例子，我们可以通过 BufferedInputStream（字节缓冲输入流）来增强 FileInputStream 的功能。\nBufferedInputStream 构造函数如下：\npublic BufferedInputStream(InputStream in) { this(in, DEFAULT_BUFFER_SIZE); } public BufferedInputStream(InputStream in, int size) { super(in); if (size \u0026lt;= 0) { throw new IllegalArgumentException(\u0026#34;Buffer size \u0026lt;= 0\u0026#34;); } buf = new byte[size]; } 可以看出，BufferedInputStream 的构造函数其中的一个参数就是 InputStream 。\nBufferedInputStream 代码示例：\ntry (BufferedInputStream bis = new BufferedInputStream(new FileInputStream(\u0026#34;input.txt\u0026#34;))) { int content; long skip = bis.skip(2); while ((content = bis.read()) != -1) { System.out.print((char) content); } } catch (IOException e) { e.printStackTrace(); } 这个时候，你可以会想了：为啥我们直接不弄一个BufferedFileInputStream（字符缓冲文件输入流）呢？\nBufferedFileInputStream bfis = new BufferedFileInputStream(\u0026#34;input.txt\u0026#34;); 如果 InputStream的子类比较少的话，这样做是没问题的。不过， InputStream的子类实在太多，继承关系也太复杂了。如果我们为每一个子类都定制一个对应的缓冲输入流，那岂不是太麻烦了。\n如果你对 IO 流比较熟悉的话，你会发现ZipInputStream 和ZipOutputStream 还可以分别增强 BufferedInputStream 和 BufferedOutputStream 的能力。\nBufferedInputStream bis = new BufferedInputStream(new FileInputStream(fileName)); ZipInputStream zis = new ZipInputStream(bis); BufferedOutputStream bos = new BufferedOutputStream(new FileOutputStream(fileName)); ZipOutputStream zipOut = new ZipOutputStream(bos); ZipInputStream 和ZipOutputStream 分别继承自InflaterInputStream 和DeflaterOutputStream。\npublic class InflaterInputStream extends FilterInputStream { } public class DeflaterOutputStream extends FilterOutputStream { } 这也是装饰器模式很重要的一个特征，那就是可以对原始类嵌套使用多个装饰器。\n为了实现这一效果，装饰器类需要跟原始类继承相同的抽象类或者实现相同的接口。上面介绍到的这些 IO 相关的装饰类和原始类共同的父类是 InputStream 和OutputStream。\n对于字符流来说，BufferedReader 可以用来增加 Reader （字符输入流）子类的功能，BufferedWriter 可以用来增加 Writer （字符输出流）子类的功能。\nBufferedWriter bw = new BufferedWriter(new OutputStreamWriter(new FileOutputStream(fileName), \u0026#34;UTF-8\u0026#34;)); IO 流中的装饰器模式应用的例子实在是太多了，不需要特意记忆，完全没必要哈！搞清了装饰器模式的核心之后，你在使用的时候自然就会知道哪些地方运用到了装饰器模式。\n1.2 适配器模式 # 适配器（Adapter Pattern）模式 主要用于接口互不兼容的类的协调工作，你可以将其联想到我们日常经常使用的电源适配器。\n适配器模式中存在被适配的对象或者类称为 适配者(Adaptee) ，作用于适配者的对象或者类称为适配器(Adapter) 。适配器分为对象适配器和类适配器。类适配器使用继承关系来实现，对象适配器使用组合关系来实现。\nIO 流中的字符流和字节流的接口不同，它们之间可以协调工作就是基于适配器模式来做的，更准确点来说是对象适配器。通过适配器，我们可以将字节流对象适配成一个字符流对象，这样我们可以直接通过字节流对象来读取或者写入字符数据。\nInputStreamReader 和 OutputStreamWriter 就是两个适配器(Adapter)， 同时，它们两个也是字节流和字符流之间的桥梁。InputStreamReader 使用 StreamDecoder （流解码器）对字节进行解码，实现字节流到字符流的转换， OutputStreamWriter 使用StreamEncoder（流编码器）对字符进行编码，实现字符流到字节流的转换。\nInputStream 和 OutputStream 的子类是被适配者， InputStreamReader 和 OutputStreamWriter是适配器。\n// InputStreamReader 是适配器，FileInputStream 是被适配的类 InputStreamReader isr = new InputStreamReader(new FileInputStream(fileName), \u0026#34;UTF-8\u0026#34;); // BufferedReader 增强 InputStreamReader 的功能（装饰器模式） BufferedReader bufferedReader = new BufferedReader(isr); java.io.InputStreamReader 部分源码：\npublic class InputStreamReader extends Reader { //用于解码的对象 private final StreamDecoder sd; public InputStreamReader(InputStream in) { super(in); try { // 获取 StreamDecoder 对象 sd = StreamDecoder.forInputStreamReader(in, this, (String)null); } catch (UnsupportedEncodingException e) { throw new Error(e); } } // 使用 StreamDecoder 对象做具体的读取工作 public int read() throws IOException { return sd.read(); } } java.io.OutputStreamWriter 部分源码：\npublic class OutputStreamWriter extends Writer { // 用于编码的对象 private final StreamEncoder se; public OutputStreamWriter(OutputStream out) { super(out); try { // 获取 StreamEncoder 对象 se = StreamEncoder.forOutputStreamWriter(out, this, (String)null); } catch (UnsupportedEncodingException e) { throw new Error(e); } } // 使用 StreamEncoder 对象做具体的写入工作 public void write(int c) throws IOException { se.write(c); } } 适配器模式和装饰器模式有什么区别呢？\n装饰器模式 更侧重于动态地增强原始类的功能，装饰器类需要跟原始类继承相同的抽象类或者实现相同的接口。并且，装饰器模式支持对原始类嵌套使用多个装饰器。\n适配器模式 更侧重于让接口不兼容而不能交互的类可以一起工作，当我们调用适配器对应的方法时，适配器内部会调用适配者类或者和适配类相关的类的方法，这个过程透明的。就比如说 StreamDecoder （流解码器）和StreamEncoder（流编码器）就是分别基于 InputStream 和 OutputStream 来获取 FileChannel对象并调用对应的 read 方法和 write 方法进行字节数据的读取和写入。\nStreamDecoder(InputStream in, Object lock, CharsetDecoder dec) { // 省略大部分代码 // 根据 InputStream 对象获取 FileChannel 对象 ch = getChannel((FileInputStream)in); } 适配器和适配者两者不需要继承相同的抽象类或者实现相同的接口。\n另外，FutureTask 类使用了适配器模式，Executors 的内部类 RunnableAdapter 实现属于适配器，用于将 Runnable 适配成 Callable。\nFutureTask参数包含 Runnable 的一个构造方法：\npublic FutureTask(Runnable runnable, V result) { // 调用 Executors 类的 callable 方法 this.callable = Executors.callable(runnable, result); this.state = NEW; } Executors中对应的方法和适配器：\n// 实际调用的是 Executors 的内部类 RunnableAdapter 的构造方法 public static \u0026lt;T\u0026gt; Callable\u0026lt;T\u0026gt; callable(Runnable task, T result) { if (task == null) throw new NullPointerException(); return new RunnableAdapter\u0026lt;T\u0026gt;(task, result); } // 适配器 static final class RunnableAdapter\u0026lt;T\u0026gt; implements Callable\u0026lt;T\u0026gt; { final Runnable task; final T result; RunnableAdapter(Runnable task, T result) { this.task = task; this.result = result; } public T call() { task.run(); return result; } } 1.3 工厂模式 # 工厂模式用于创建对象，NIO 中大量用到了工厂模式，比如 Files 类的 newInputStream 方法用于创建 InputStream 对象（静态工厂）、 Paths 类的 get 方法创建 Path 对象（静态工厂）、ZipFileSystem 类（sun.nio包下的类，属于 java.nio 相关的一些内部实现）的 getPath 的方法创建 Path 对象（简单工厂）。\nInputStream is = Files.newInputStream(Paths.get(generatorLogoPath)) 1.4 观察者模式 # NIO 中的文件目录监听服务使用到了观察者模式。\nNIO 中的文件目录监听服务基于 WatchService 接口和 Watchable 接口。WatchService 属于观察者，Watchable 属于被观察者。\nWatchable接口定义了一个用于将对象注册到WatchService（监控服务） 并绑定监听事件的方法 register。\npublic interface Path extends Comparable\u0026lt;Path\u0026gt;, Iterable\u0026lt;Path\u0026gt;, Watchable{ } public interface Watchable { WatchKey register(WatchService watcher, WatchEvent.Kind\u0026lt;?\u0026gt;[] events, WatchEvent.Modifier... modifiers) throws IOException; } WatchService 用于监听文件目录的变化，同一个 WatchService 对象能够监听多个文件目录。\n// 创建 WatchService 对象 WatchService watchService = FileSystems.getDefault().newWatchService(); // 初始化一个被监控文件夹的 Path 类: Path path = Paths.get(\u0026#34;workingDirectory\u0026#34;); // 将这个 path 对象注册到 WatchService（监控服务） 中去 WatchKey watchKey = path.register( watchService, StandardWatchEventKinds...); Path 类 register 方法的第二个参数 events （需要监听的事件）为可变长参数，也就是说我们可以同时监听多种事件。\nWatchKey register(WatchService watcher, WatchEvent.Kind\u0026lt;?\u0026gt;... events) throws IOException; 常用的监听事件有 3 种：\nStandardWatchEventKinds.ENTRY_CREATE：文件创建。 StandardWatchEventKinds.ENTRY_DELETE : 文件删除。 StandardWatchEventKinds.ENTRY_MODIFY : 文件修改。 register 方法返回 WatchKey 对象，通过WatchKey 对象可以获取事件的具体信息比如文件目录下是创建、删除还是修改了文件、创建、删除或者修改的文件的具体名称是什么。\nWatchKey key; while ((key = watchService.take()) != null) { for (WatchEvent\u0026lt;?\u0026gt; event : key.pollEvents()) { // 可以调用 WatchEvent 对象的方法做一些事情比如输出事件的具体上下文信息 } key.reset(); } WatchService 内部是通过一个 daemon thread（守护线程）采用定期轮询的方式来检测文件的变化，简化后的源码如下所示。\nclass PollingWatchService extends AbstractWatchService { // 定义一个 daemon thread（守护线程）轮询检测文件变化 private final ScheduledExecutorService scheduledExecutor; PollingWatchService() { scheduledExecutor = Executors .newSingleThreadScheduledExecutor(new ThreadFactory() { @Override public Thread newThread(Runnable r) { Thread t = new Thread(r); t.setDaemon(true); return t; }}); } void enable(Set\u0026lt;? extends WatchEvent.Kind\u0026lt;?\u0026gt;\u0026gt; events, long period) { synchronized (this) { // 更新监听事件 this.events = events; // 开启定期轮询 Runnable thunk = new Runnable() { public void run() { poll(); }}; this.poller = scheduledExecutor .scheduleAtFixedRate(thunk, period, period, TimeUnit.SECONDS); } } } ","date":"11 March 2025","externalUrl":null,"permalink":"/posts/1741693758733-io%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E6%80%BB%E7%BB%93/","section":"Posts","summary":"","title":"IO设计模式总结","type":"posts"},{"content":" List # 1.1 ArrayList # ArrayList集合的特点：\n​\t==长度可以变化，只能存储引用数据类型。==\n泛型的使用：\n​\t用于约束集合中存储元素的数据类型。\n1.1.1 ArrayList类常用方法 # 1.2.1 构造方法\n方法名 说明 public ArrayList() 创建一个空的集合对象 1.2.2 成员方法\n方法名 说明 public boolean add(要添加的元素) 将指定的元素追加到此集合的末尾 public boolean remove(要删除的元素) 删除指定元素,返回值表示是否删除成功 public E remove(int index) 删除指定索引处的元素，返回被删除的元素 public E set(int index,E element) 修改指定索引处的元素，返回被修改的元素 public E get(int index) 返回指定索引处的元素 public int size() 返回集合中的元素的个数 1.1.2 ArrayList 和 Array（数组）的区别 # ArrayList 内部基于动态数组实现，比 Array（静态数组） 使用起来更加灵活：\nArrayList会根据实际存储的元素动态地扩容或缩容，而 Array 被创建之后就不能改变它的长度了。 ArrayList 允许你使用泛型来确保类型安全，Array 则不可以。 ArrayList 中只能存储对象。对于基本类型数据，需要使用其对应的包装类（如 Integer、Double 等）。Array 可以直接存储基本类型数据，也可以存储对象。 ArrayList 支持插入、删除、遍历等常见操作，并且提供了丰富的 API 操作方法，比如 add()、remove()等。Array 只是一个固定长度的数组，只能按照下标访问其中的元素，不具备动态添加、删除元素的能力。 ArrayList创建时不需要指定大小，而Array创建时必须指定大小。 下面是二者使用的简单对比：\nArray：\n// 初始化一个 String 类型的数组 String[] stringArr = new String[]{\u0026#34;hello\u0026#34;, \u0026#34;world\u0026#34;, \u0026#34;!\u0026#34;}; // 修改数组元素的值 stringArr[0] = \u0026#34;goodbye\u0026#34;; System.out.println(Arrays.toString(stringArr));// [goodbye, world, !] // 删除数组中的元素，需要手动移动后面的元素 for (int i = 0; i \u0026lt; stringArr.length - 1; i++) { stringArr[i] = stringArr[i + 1]; } stringArr[stringArr.length - 1] = null; System.out.println(Arrays.toString(stringArr));// [world, !, null] ArrayList ：\n// 初始化一个 String 类型的 ArrayList ArrayList\u0026lt;String\u0026gt; stringList = new ArrayList\u0026lt;\u0026gt;(Arrays.asList(\u0026#34;hello\u0026#34;, \u0026#34;world\u0026#34;, \u0026#34;!\u0026#34;)); // 添加元素到 ArrayList 中 stringList.add(\u0026#34;goodbye\u0026#34;); System.out.println(stringList);// [hello, world, !, goodbye] // 修改 ArrayList 中的元素 stringList.set(0, \u0026#34;hi\u0026#34;); System.out.println(stringList);// [hi, world, !, goodbye] // 删除 ArrayList 中的元素 stringList.remove(0); System.out.println(stringList); // [world, !, goodbye] ArrayList 和 Vector 的区别？\nArrayList 是 List 的主要实现类，底层使用 Object[]存储，适用于频繁的查找工作，线程不安全 。 Vector 是 List 的古老实现类，底层使用Object[] 存储，==线程安全。== Vector 和 Stack（/stæk/） 的区别？\nVector 和 Stack 两者都是线程安全的，都是使用 synchronized（/ˈsɪŋkrənaɪzd/） 关键字进行同步处理。 Stack 继承自 Vector，是一个后进先出的栈，而 Vector 是一个列表。 随着 Java 并发编程的发展，Vector 和 Stack 已经被淘汰，推荐使用并发集合类（例如 ConcurrentHashMap、CopyOnWriteArrayList 等）或者手动实现线程安全的方法来提供安全的多线程操作支持。\n1.1.3 ArrayList 可以添加null值吗？ # ArrayList 中可以存储任何类型的对象，包括 null 值。不过，不建议向ArrayList 中添加 null 值， null 值无意义，会让代码难以维护比如忘记做判空处理就会导致空指针异常。\n示例代码：\nArrayList\u0026lt;String\u0026gt; listOfStrings = new ArrayList\u0026lt;\u0026gt;(); listOfStrings.add(null); listOfStrings.add(\u0026#34;java\u0026#34;); System.out.println(listOfStrings); 输出：\n[null, java] 1.1.4 ArrayList 插入和删除元素的时间复杂度 # 对于插入：\n头部插入：由于需要将所有元素都依次向后移动一个位置，因此时间复杂度是 O(n)。 尾部插入：当 ArrayList 的容量未达到极限时，往列表末尾插入元素的时间复杂度是 O(1)，因为它只需要在数组末尾添加一个元素即可；当容量已达到极限并且需要扩容时，则需要执行一次 O(n) 的操作将原数组复制到新的更大的数组中，然后再执行 O(1) 的操作添加元素。 指定位置插入：需要将目标位置之后的所有元素都向后移动一个位置，然后再把新元素放入指定位置。这个过程需要移动平均 n/2 个元素，因此时间复杂度为 O(n)。 对于删除：\n头部删除：由于需要将所有元素依次向前移动一个位置，因此时间复杂度是 O(n)。 尾部删除：当删除的元素位于列表末尾时，时间复杂度为 O(1)。 指定位置删除：需要将目标元素之后的所有元素向前移动一个位置以填补被删除的空白位置，因此需要移动平均 n/2 个元素，时间复杂度为 O(n)。 这里简单列举一个例子：\n// ArrayList的底层数组大小为10，此时存储了7个元素 +---+---+---+---+---+---+---+---+---+---+ | 1 | 2 | 3 | 4 | 5 | 6 | 7 | | | | +---+---+---+---+---+---+---+---+---+---+ 0 1 2 3 4 5 6 7 8 9 // 在索引为1的位置插入一个元素8，该元素后面的所有元素都要向右移动一位 +---+---+---+---+---+---+---+---+---+---+ | 1 | 8 | 2 | 3 | 4 | 5 | 6 | 7 | | | +---+---+---+---+---+---+---+---+---+---+ 0 1 2 3 4 5 6 7 8 9 // 删除索引为1的位置的元素，该元素后面的所有元素都要向左移动一位 +---+---+---+---+---+---+---+---+---+---+ | 1 | 2 | 3 | 4 | 5 | 6 | 7 | | | | +---+---+---+---+---+---+---+---+---+---+ 0 1 2 3 4 5 6 7 8 9 1.2 LinkedList # LinkedList集合的特有功能：\n特有方法\n方法名 说明 public void addFirst(E e) 在该列表开头插入指定的元素 public void addLast(E e) 将指定的元素追加到此列表的末尾 public E getFirst() 返回此列表中的第一个元素 public E getLast() 返回此列表中的最后一个元素 public E removeFirst() 从此列表中删除并返回第一个元素 public E removeLast() 从此列表中删除并返回最后一个元素 1.2.1 LinkedList 插入和删除元素的时间复杂度 # 头部插入/删除：只需要修改头结点的指针即可完成插入/删除操作，因此时间复杂度为 O(1)。 尾部插入/删除：只需要修改尾结点的指针即可完成插入/删除操作，因此时间复杂度为 O(1)。 指定位置插入/删除：需要先移动到指定位置，再修改指定节点的指针完成插入/删除，不过由于有头尾指针，可以从较近的指针出发，因此需要遍历平均 n/4 个元素，时间复杂度为 O(n)。 这里简单列举一个例子：假如我们要删除节点 9 的话，需要先遍历链表找到该节点。然后，再执行相应节点指针指向的更改.\n1.2.2 LinkedList 为什么不能实现 RandomAccess接口 # RandomAccess 是一个标记接口，用来表明实现该接口的类支持随机访问（即可以通过索引快速访问元素）。由于 LinkedList 底层数据结构是链表，内存地址不连续，只能通过指针来定位，不支持随机快速访问，所以不能实现 RandomAccess 接口。\n1.2.3 LinkedList源码分析 # 底层是双向链表结构\n核心步骤如下：\n刚开始创建的时候，底层创建了两个变量：一个记录头结点first，一个记录尾结点last，默认为null 添加第一个元素时，底层创建一个结点对象，first和last都记录这个结点的地址值 添加第二个元素时，底层创建一个结点对象，第一个结点会记录第二个结点的地址值，last会记录新结点的地址值 1.2.4 ArrayList 与 LinkedList 区别？ # 是否保证线程安全： ArrayList 和 LinkedList 都是不同步的，也就是不保证线程安全； 底层数据结构： ArrayList 底层使用的是 Object 数组；LinkedList 底层使用的是 双向链表 数据结构（JDK1.6 之前为循环链表，JDK1.7 取消了循环。注意双向链表和双向循环链表的区别，下面有介绍到！） 插入和删除是否受元素位置的影响： ArrayList 采用数组存储，所以插入和删除元素的时间复杂度受元素位置的影响。 比如：执行add(E e)方法的时候， ArrayList 会默认在将指定的元素追加到此列表的末尾，这种情况时间复杂度就是 O(1)。但是如果要在指定位置 i 插入和删除元素的话（add(int index, E element)），时间复杂度就为 O(n)。因为在进行上述操作的时候集合中第 i 和第 i 个元素之后的(n-i)个元素都要执行向后位/向前移一位的操作。 LinkedList 采用链表存储，所以在头尾插入或者删除元素不受元素位置的影响（add(E e)、addFirst(E e)、addLast(E e)、removeFirst()、 removeLast()），时间复杂度为 O(1)，如果是要在指定位置 i 插入和删除元素的话（add(int index, E element)，remove(Object o),remove(int index)）， 时间复杂度为 O(n) ，因为需要先移动到指定位置再插入和删除。 是否支持快速随机访问： LinkedList 不支持高效的随机元素访问，而 ArrayList（实现了 RandomAccess 接口） 支持。快速随机访问就是通过元素的序号快速获取元素对象(对应于get(int index)方法)。 内存空间占用： ArrayList 的空间浪费主要体现在在 list 列表的结尾会预留一定的容量空间，而 LinkedList 的空间花费则体现在它的每一个元素都需要消耗比 ArrayList 更多的空间（因为要存放直接后继和直接前驱以及数据）。 我们在项目中一般是不会使用到 LinkedList 的，需要用到 LinkedList 的场景几乎都可以使用 ArrayList 来代替，并且，性能通常会更好！就连 LinkedList 的作者约书亚 · 布洛克（Josh Bloch）自己都说从来不会使用 LinkedList 。\n另外，不要下意识地认为 LinkedList 作为链表就最适合元素增删的场景。我在上面也说了，LinkedList 仅仅在头尾插入或者删除元素的时候时间复杂度近似 O(1)，其他情况增删元素的平均时间复杂度都是 O(n) 。\n1.2.4.1 双向链表和双向循环链表 # 双向链表： 包含两个指针，一个 prev 指向前一个节点，一个 next 指向后一个节点。\n双向循环链表： 最后一个节点的 next 指向 head，而 head 的 prev 指向最后一个节点，构成一个环.\n1.2.4.2 RandomAccess 接口 # public interface RandomAccess { } 查看源码我们发现实际上 RandomAccess 接口中什么都没有定义。所以，在我看来 RandomAccess 接口不过是一个标识罢了。标识什么？ 标识实现这个接口的类具有随机访问功能。\n在 binarySearch() 方法中，它要判断传入的 list 是否 RandomAccess 的实例，如果是，调用indexedBinarySearch()方法，如果不是，那么调用iteratorBinarySearch()方法\npublic static \u0026lt;T\u0026gt; int binarySearch(List\u0026lt;? extends Comparable\u0026lt;? super T\u0026gt;\u0026gt; list, T key) { if (list instanceof RandomAccess || list.size()\u0026lt;BINARYSEARCH_THRESHOLD) return Collections.indexedBinarySearch(list, key); else return Collections.iteratorBinarySearch(list, key); } ArrayList 实现了 RandomAccess 接口， 而 LinkedList 没有实现。为什么呢？我觉得还是和底层数据结构有关！ArrayList 底层是数组，而 LinkedList 底层是链表。数组天然支持随机访问，时间复杂度为 O(1)，所以称为快速随机访问。链表需要遍历到特定位置才能访问特定位置的元素，时间复杂度为 O(n)，所以不支持快速随机访问。ArrayList 实现了 RandomAccess 接口，就表明了他具有快速随机访问功能。 RandomAccess 接口只是标识，并不是说 ArrayList 实现 RandomAccess 接口才具有快速随机访问功能的！\n1.3 CopyOnWriteArrayList # 1.3.1 Copy-On-Write # Copy-On-Write是一种在计算机科学中常见的优化技术，主要应用于需要频繁读取但很少修改的数据结构上。 简单的说就是在计算机中就是==当你想要对一块内存进行修改时，我们不在原有内存块中进行写操作，而是将内存拷贝一份，在新的内存中进行写操作，写完之后将指向原来内存指针指向新的内存，原来的内存就可以进行回收。== 既然是一种优化策略，我们看一段代码：\nimport java.util.ArrayList; import java.util.Arrays; import java.util.Iterator; import java.util.List; /** \\* @author 百里 */ public class BaiLiIteratorTest { private static List\u0026lt;String\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); public static void main(String[] args) { list.add(\u0026#34;1\u0026#34;); list.add(\u0026#34;2\u0026#34;); list.add(\u0026#34;3\u0026#34;); Iterator\u0026lt;String\u0026gt; iter = list.iterator(); while (iter.hasNext()) { System.err.println(iter.next()); } System.err.println(Arrays.toString(list.toArray())); } } 上面的Demo在单线程下执行时没什么毛病，但是在多线程的环境中，就可能出异常，为什么呢？ 因为多线程迭代时如果有其他线程对这个集合list进行增减元素，会抛出java.util.ConcurrentModificationException的异常。 我们以增加元素为例子，运行下面这Demo：\nimport java.util.ArrayList; import java.util.Iterator; import java.util.List; import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; /** \\* 并发迭代器问题示例代码 \\* @author 百里 */ public class BaiLiConcurrentIteratorTest { // 创建一个ArrayList对象 private static List\u0026lt;String\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); public static void main(String[] args) throws InterruptedException { // 给ArrayList添加三个元素：\u0026#34;1\u0026#34;、\u0026#34;2\u0026#34;和\u0026#34;3\u0026#34; list.add(\u0026#34;1\u0026#34;); list.add(\u0026#34;2\u0026#34;); list.add(\u0026#34;3\u0026#34;); // 开启线程池，提交10个线程用于在list尾部添加5个元素\u0026#34;121\u0026#34; ExecutorService service = Executors.newFixedThreadPool(10); for (int i = 0; i \u0026lt; 10; i++) { service.execute(() -\u0026gt; { for (int j = 0; j \u0026lt; 5; j++) { list.add(\u0026#34;121\u0026#34;); } }); } // 使用Iterator迭代器遍历list并输出元素值 Iterator\u0026lt;String\u0026gt; iter = list.iterator(); for (int i = 0; i \u0026lt; 10; i++) { service.execute(() -\u0026gt; { while (iter.hasNext()) { System.err.println(iter.next()); try { Thread.sleep(10); } catch (InterruptedException e) { e.printStackTrace(); } } }); } service.shutdown(); } } 通过上面的案例，我们可以看到：\n多线程场景下迭代器遍历集合的读取操作和其他线程对集合进行写入操作会导致出现并发修改异常 解决方案：\nCopyOnWriteArrayList避免了多线程操作List线程不安全的问题 1.3.2 CopyOnWriteArrayList # 从JDK1.5开始Java并发包里提供了两个使用CopyOnWrite机制实现的并发容器，它们是CopyOnWriteArrayList和CopyOnWriteArraySet。CopyOnWrite容器非常有用，可以在非常多的并发场景中使用到。\n1.3.2.1 CopyOnWriteArrayList原理 # 在写操作(add、remove等)时，不直接对原数据进行修改，而是先将原数据复制一份，然后在新复制的数据上执行写操作，最后将原数据引用指向新数据。这样做的好处是读操作(get、iterator等)可以不加锁，因为读取的数据始终是不变的。 接下来我们就看下源码怎么实现的。\n1.3.2.2 CopyOnWriteArrayList简单源码解读 # add()方法源码：\n/** \\* Appends the specified element to the end of this list. * \\* @param e element to be appended to this list \\* @return {@code true} (as specified by {@link Collection#add}) */ public boolean add(E e) { final ReentrantLock lock = this.lock;//重入锁 lock.lock();//加锁 try { Object[] elements = getArray(); int len = elements.length; Object[] newElements = Arrays.copyOf(elements, len + 1);//拷贝新数组 newElements[len] = e; setArray(newElements);//将引用指向新数组 1 return true; } finally { lock.unlock();//解锁 } } 可以看到，CopyOnWriteArrayList中的写操作都需要先获取锁，然后再将当前的元素数组复制一份，并在新复制的元素数组上执行写操作，最后将数组引用指向新数组。\n@SuppressWarnings(\u0026#34;unchecked\u0026#34;) public E next() { if (! hasNext()) //是否存在下一个元素 throw new NoSuchElementException(); //没有下一个元素，则会抛出NoSuchElementException异常 //snapshot是一个类成员变量，它是在创建迭代器时通过复制集合内容而获得的一个数组。 //cursor是另一个类成员变量，初始值为0，并在每次调用next()时自增1，表示当前返回元素的位置。 return (E) snapshot[cursor++]; } 而读操作不需要加锁，直接返回当前的元素数组即可。 这种写时复制的机制保证了读操作的线程安全性，但是会牺牲一些写操作的性能，因为每次修改都需要复制一份数组。因此，适合读远多于写的场合。 所以我们将多线程Demo中的ArrayList改为CopyOnWriteArrayList，执行就不会报错\nimport java.util.Iterator; import java.util.concurrent.CopyOnWriteArrayList; import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; /** \\* 并发迭代器问题示例代码 \\* @author 百里 */ public class BaiLiConcurrentIteratorTest { // 创建一个ArrayList对象 private static CopyOnWriteArrayList\u0026lt;String\u0026gt; list = new CopyOnWriteArrayList\u0026lt;\u0026gt;(); public static void main(String[] args) throws InterruptedException { // 给ArrayList添加三个元素：\u0026#34;1\u0026#34;、\u0026#34;2\u0026#34;和\u0026#34;3\u0026#34; list.add(\u0026#34;1\u0026#34;); list.add(\u0026#34;2\u0026#34;); list.add(\u0026#34;3\u0026#34;); // 开启线程池，提交10个线程用于在list尾部添加5个元素\u0026#34;121\u0026#34; ExecutorService service = Executors.newFixedThreadPool(10); for (int i = 0; i \u0026lt; 10; i++) { service.execute(() -\u0026gt; { for (int j = 0; j \u0026lt; 5; j++) { list.add(\u0026#34;121\u0026#34;); } }); } // 使用Iterator迭代器遍历list并输出元素值 Iterator\u0026lt;String\u0026gt; iter = list.iterator(); for (int i = 0; i \u0026lt; 10; i++) { service.execute(() -\u0026gt; { while (iter.hasNext()) { System.err.println(iter.next()); try { Thread.sleep(10); } catch (InterruptedException e) { e.printStackTrace(); } } }); } service.shutdown(); } } 1.3.3 CopyOnWriteArrayList优缺点 # 优点：\n**线程安全。**CopyOnWriteArrayList是线程安全的，由于写操作对原数据进行复制，因此写操作不会影响读操作，读操作可以不加锁，降低了并发冲突的概率。 **不会抛出ConcurrentModificationException异常。**由于读操作遍历的是不变的数组副本，因此不会抛出ConcurrentModificationException异常。 缺点：\n**写操作性能较低。**由于每一次写操作都需要将元素复制一份，因此写操作的性能较低。 **内存占用增加。**由于每次写操作都需要创建一个新的数组副本，因此内存占用会增加，特别是当集合中有大量数据时，内存占用较高。 **数据一致性问题。**由于读操作遍历的是不变的数组副本，因此在对数组执行写操作期间，读操作可能读取到旧的数组数据，这就涉及到数据一致性问题。 1.3.4 CopyOnWriteArrayList使用场景 # **读多写少。**为什么？因为写的时候会复制新集合 **集合不大。**为什么？因为写的时候会复制新集合 **实时性要求不高。**为什么，。。。。。。。。。。。。。。。。。。因为有可能会读取到旧的集合数据 ArrayList 扩容机制 # 核心步骤：\n创建ArrayList对象的时候，他在底层先创建了一个长度为10的数组。\n数组名字：elementDate，定义变量size。\nsize这个变量有两层含义： ①：元素的个数，也就是集合的长度 ②：下一个元素的存入位置\n添加元素，添加完毕后，size++\n扩容时机一：\n**当存满时候，会创建一个新的数组，新数组的长度，是原来的1.5倍，也就是长度为15.再把所有的元素，全拷贝到新数组中。**如果继续添加数据，这个长度为15的数组也满了，那么下次还会继续扩容，还是1.5倍。 扩容时机二：\n一次性添加多个数据，扩容1.5倍不够，怎么办呀？\n如果一次添加多个元素，1.5倍放不下，那么新创建数组的长度以实际为准。\n","date":"11 March 2025","externalUrl":null,"permalink":"/posts/1741680503414-java-list/","section":"Posts","summary":"","title":"java List","type":"posts"},{"content":" Map # Map集合概述：\ninterface Map\u0026lt;K,V\u0026gt; K：键的类型；V：值的类型 Map集合的特点：\n双列集合,一个键对应一个值 键不可以重复,值可以重复 1.1 Map集合的基本功能 # 方法介绍 方法名 说明 V put(K key,V value) 添加元素 V remove(Object key) 根据键删除键值对元素 void clear() 移除所有的键值对元素 boolean containsKey(Object key) 判断集合是否包含指定的键 boolean containsValue(Object value) 判断集合是否包含指定的值 boolean isEmpty() 判断集合是否为空 int size() 集合的长度，也就是集合中键值对的个数 1.1.1 Map集合的获取功能 # 方法介绍\n方法名 说明 V get(Object key) 根据键获取值 Set keySet() 获取所有键的集合 Collection values() 获取所有值的集合 Set\u0026lt;Map.Entry\u0026lt;K,V\u0026raquo; entrySet() 获取所有键值对对象的集合 1.2 HashMap集合 # HashMap集合概述和特点\nHashMap底层是哈希表结构的 依赖hashCode方法和equals方法保证键的唯一 如果键要存储的是自定义对象，需要重写hashCode和equals方法 1.2.1 HashMap和Hashtable的区别 # 线程是否安全： HashMap 是非线程安全的，Hashtable 是线程安全的,因为 Hashtable 内部的方法基本都经过synchronized 修饰。（如果你要保证线程安全的话就使用 ConcurrentHashMap 吧！）； 效率： 因为线程安全的问题，HashMap 要比 Hashtable 效率高一点。另外，Hashtable 基本被淘汰，不要在代码中使用它； 对 Null key 和 Null value 的支持： HashMap 可以存储 null 的 key 和 value，但 null 作为键只能有一个，null 作为值可以有多个；Hashtable 不允许有 null 键和 null 值，否则会抛出 NullPointerException。 初始容量大小和每次扩充容量大小的不同： ① 创建时如果不指定容量初始值，Hashtable 默认的初始大小为 11，之后每次扩充，容量变为原来的 2n+1。HashMap 默认的初始化大小为 16。之后每次扩充，容量变为原来的 2 倍。② 创建时如果给定了容量初始值，那么 Hashtable 会直接使用你给定的大小，而 HashMap 会将其扩充为 2 的幂次方大小（HashMap 中的tableSizeFor()方法保证，下面给出了源代码）。也就是说 HashMap 总是使用 2 的幂作为哈希表的大小,后面会介绍到为什么是 2 的幂次方。 底层数据结构： JDK1.8 以后的 HashMap 在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为 8）时，将链表转化为红黑树（将链表转换成红黑树前会判断，如果当前数组的长度小于 64，那么会选择先进行数组扩容，而不是转换为红黑树），以减少搜索时间（后文中我会结合源码对这一过程进行分析）。Hashtable 没有这样的机制。 哈希函数的实现：HashMap 对哈希值进行了高位和低位的混合扰动处理以减少冲突，而 Hashtable 直接使用键的 hashCode() 值。 HashMap 中带有初始容量的构造函数：\npublic HashMap(int initialCapacity, float loadFactor) { if (initialCapacity \u0026lt; 0) throw new IllegalArgumentException(\u0026#34;Illegal initial capacity: \u0026#34; + initialCapacity); if (initialCapacity \u0026gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor \u0026lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(\u0026#34;Illegal load factor: \u0026#34; + loadFactor); this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity); } public HashMap(int initialCapacity) { this(initialCapacity, DEFAULT_LOAD_FACTOR); } 下面这个方法保证了 HashMap 总是使用 2 的幂作为哈希表的大小。\n/** * Returns a power of two size for the given target capacity. */ static final int tableSizeFor(int cap) { int n = cap - 1; n |= n \u0026gt;\u0026gt;\u0026gt; 1; n |= n \u0026gt;\u0026gt;\u0026gt; 2; n |= n \u0026gt;\u0026gt;\u0026gt; 4; n |= n \u0026gt;\u0026gt;\u0026gt; 8; n |= n \u0026gt;\u0026gt;\u0026gt; 16; return (n \u0026lt; 0) ? 1 : (n \u0026gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1; } 1.2.2 HashMap 和 HashSet 区别 # 如果你看过 HashSet 源码的话就应该知道：HashSet 底层就是基于 HashMap 实现的。（HashSet 的源码非常非常少，因为除了 clone()、writeObject()、readObject()是 HashSet 自己不得不实现之外，其他方法都是直接调用 HashMap 中的方法。\nHashMap HashSet 实现了 Map 接口 实现 Set 接口 存储键值对 仅存储对象 调用 put()向 map 中添加元素 调用 add()方法向 Set 中添加元素 HashMap 使用键（Key）计算 hashcode HashSet 使用成员对象来计算 hashcode 值，对于两个对象来说 hashcode 可能相同，所以equals()方法用来判断对象的相等性 1.2.3 HashMap和TreeMap区别 # TreeMap 和HashMap 都继承自AbstractMap ，但是需要注意的是TreeMap它还实现了NavigableMap接口和SortedMap 接口。\n实现 NavigableMap 接口让 TreeMap 有了对集合内元素的搜索的能力。\nNavigableMap 接口提供了丰富的方法来探索和操作键值对:\n定向搜索: ceilingEntry(), floorEntry(), higherEntry()和 lowerEntry() 等方法可以用于定位大于等于、小于等于、严格大于、严格小于给定键的最接近的键值对。 子集操作: subMap(), headMap()和 tailMap() 方法可以高效地创建原集合的子集视图，而无需复制整个集合。 逆序视图:descendingMap() 方法返回一个逆序的 NavigableMap 视图，使得可以反向迭代整个 TreeMap。 边界操作: firstEntry(), lastEntry(), pollFirstEntry()和 pollLastEntry() 等方法可以方便地访问和移除元素。 这些方法都是基于红黑树数据结构的属性实现的，红黑树保持平衡状态，从而保证了搜索操作的时间复杂度为 O(log n)，这让 TreeMap 成为了处理有序集合搜索问题的强大工具。\n实现SortedMap接口让 TreeMap 有了对集合中的元素根据键排序的能力。默认是按 key 的升序排序，不过我们也可以指定排序的比较器。示例代码如下：\n/** * @author shuang.kou * @createTime 2020年06月15日 17:02:00 */ public class Person { private Integer age; public Person(Integer age) { this.age = age; } public Integer getAge() { return age; } public static void main(String[] args) { TreeMap\u0026lt;Person, String\u0026gt; treeMap = new TreeMap\u0026lt;\u0026gt;(new Comparator\u0026lt;Person\u0026gt;() { @Override public int compare(Person person1, Person person2) { int num = person1.getAge() - person2.getAge(); return Integer.compare(num, 0); } }); treeMap.put(new Person(3), \u0026#34;person1\u0026#34;); treeMap.put(new Person(18), \u0026#34;person2\u0026#34;); treeMap.put(new Person(35), \u0026#34;person3\u0026#34;); treeMap.put(new Person(16), \u0026#34;person4\u0026#34;); treeMap.entrySet().stream().forEach(personStringEntry -\u0026gt; { System.out.println(personStringEntry.getValue()); }); } } 输出:\nperson1 person4 person2 person3 可以看出，TreeMap 中的元素已经是按照 Person 的 age 字段的升序来排列了。\n上面，我们是通过传入匿名内部类的方式实现的，你可以将代码替换成 Lambda 表达式实现的方式：\nTreeMap\u0026lt;Person, String\u0026gt; treeMap = new TreeMap\u0026lt;\u0026gt;((person1, person2) -\u0026gt; { int num = person1.getAge() - person2.getAge(); return Integer.compare(num, 0); }); 综上，相比于HashMap来说， TreeMap 主要多了对集合中的元素根据键排序的能力以及对集合内元素的搜索的能力。\n1.2.4 HashSet如何检查重复 # 以下内容摘自我的 Java 启蒙书《Head first java》第二版：\n当你把对象加入HashSet时，HashSet 会先计算对象的hashcode值来判断对象加入的位置，同时也会与其他加入的对象的 hashcode 值作比较，如果没有相符的 hashcode，HashSet 会假设对象没有重复出现。但是如果发现有相同 hashcode 值的对象，这时会调用equals()方法来检查 hashcode 相等的对象是否真的相同。如果两者相同，HashSet 就不会让加入操作成功。\n在 JDK1.8 中，HashSet的add()方法只是简单的调用了HashMap的put()方法，并且判断了一下返回值以确保是否有重复元素。直接看一下HashSet中的源码：\n// Returns: true if this set did not already contain the specified element // 返回值：当 set 中没有包含 add 的元素时返回真 public boolean add(E e) { return map.put(e, PRESENT)==null; } 而在HashMap的putVal()方法中也能看到如下说明:\n// Returns : previous value, or null if none // 返回值：如果插入位置没有元素返回null，否则返回上一个元素 final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) { ... } 也就是说，在 JDK1.8 中，实际上无论HashSet中是否已经存在了某元素，HashSet都会直接插入，只是会在add()方法的返回值处告诉我们插入前是否存在相同元素。\n1.2.5 HashMap的底层实现 # 1.2.5.1 JDK1.8 之前 # JDK1.8 之前 HashMap 底层是 数组和链表 结合在一起使用也就是 链表散列。HashMap 通过 key 的 hashcode 经过扰动函数处理过后得到 hash 值，然后通过 (n - 1) \u0026amp; hash 判断当前元素存放的位置（这里的 n 指的是数组的长度），如果当前位置存在元素的话，就判断该元素与要存入的元素的 hash 值以及 key 是否相同，如果相同的话，直接覆盖，不相同就通过拉链法解决冲突。\nHashMap 中的扰动函数（hash 方法）是用来优化哈希值的分布。通过对原始的 hashCode() 进行额外处理，扰动函数可以减小由于糟糕的 hashCode() 实现导致的碰撞，从而提高数据的分布均匀性。\nJDK 1.8 HashMap 的 hash 方法源码：\nJDK 1.8 的 hash 方法 相比于 JDK 1.7 hash 方法更加简化，但是原理不变。\nstatic final int hash(Object key) { int h; // key.hashCode()：返回散列值也就是hashcode // ^：按位异或 // \u0026gt;\u0026gt;\u0026gt;:无符号右移，忽略符号位，空位都以0补齐 return (key == null) ? 0 : (h = key.hashCode()) ^ (h \u0026gt;\u0026gt;\u0026gt; 16); } 对比一下 JDK1.7 的 HashMap 的 hash 方法源码.\nstatic int hash(int h) { // This function ensures that hashCodes that differ only by // constant multiples at each bit position have a bounded // number of collisions (approximately 8 at default load factor). h ^= (h \u0026gt;\u0026gt;\u0026gt; 20) ^ (h \u0026gt;\u0026gt;\u0026gt; 12); return h ^ (h \u0026gt;\u0026gt;\u0026gt; 7) ^ (h \u0026gt;\u0026gt;\u0026gt; 4); } 相比于 JDK1.8 的 hash 方法 ，JDK 1.7 的 hash 方法的性能会稍差一点点，因为毕竟扰动了 4 次。\n所谓 “拉链法” 就是：将链表和数组相结合。也就是说创建一个链表数组，数组中每一格就是一个链表。若遇到哈希冲突，则将冲突的值加到链表中即可。\n1.2.5.2 JDK1.8 之后 # 相比于之前的版本， JDK1.8 之后在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为 8）（将链表转换成红黑树前会判断，如果当前数组的长度小于 64，那么会选择先进行数组扩容，而不是转换为红黑树）时，将链表转化为红黑树，以减少搜索时间。\nTreeMap、TreeSet 以及 JDK1.8 之后的 HashMap 底层都用到了红黑树。红黑树就是为了解决二叉查找树的缺陷，因为二叉查找树在某些情况下会退化成一个线性结构。\n我们来结合源码分析一下 HashMap 链表到红黑树的转换。\n1、 putVal 方法中执行链表转红黑树的判断逻辑。\n链表的长度大于 8 的时候，就执行 treeifyBin （转换红黑树）的逻辑。\n// 遍历链表 for (int binCount = 0; ; ++binCount) { // 遍历到链表最后一个节点 if ((e = p.next) == null) { p.next = newNode(hash, key, value, null); // 如果链表元素个数大于TREEIFY_THRESHOLD（8） if (binCount \u0026gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st // 红黑树转换（并不会直接转换成红黑树） treeifyBin(tab, hash); break; } if (e.hash == hash \u0026amp;\u0026amp; ((k = e.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k)))) break; p = e; } 2、treeifyBin 方法中判断是否真的转换为红黑树。\nfinal void treeifyBin(Node\u0026lt;K,V\u0026gt;[] tab, int hash) { int n, index; Node\u0026lt;K,V\u0026gt; e; // 判断当前数组的长度是否小于 64 if (tab == null || (n = tab.length) \u0026lt; MIN_TREEIFY_CAPACITY) // 如果当前数组的长度小于 64，那么会选择先进行数组扩容 resize(); else if ((e = tab[index = (n - 1) \u0026amp; hash]) != null) { // 否则才将列表转换为红黑树 TreeNode\u0026lt;K,V\u0026gt; hd = null, tl = null; do { TreeNode\u0026lt;K,V\u0026gt; p = replacementTreeNode(e, null); if (tl == null) hd = p; else { p.prev = tl; tl.next = p; } tl = p; } while ((e = e.next) != null); if ((tab[index] = hd) != null) hd.treeify(tab); } } 将链表转换成红黑树前会判断，如果当前数组的长度小于 64，那么会选择先进行数组扩容，而不是转换为红黑树。\n1.2.6 HashMap 的长度为什么是2的幂次方 # 为了让 HashMap 存取高效并减少碰撞，我们需要确保数据尽量均匀分布。哈希值在 Java 中通常使用 int 表示，其范围是 -2147483648 ~ 2147483647前后加起来大概 40 亿的映射空间，只要哈希函数映射得比较均匀松散，一般应用是很难出现碰撞的。但是，问题是一个 40 亿长度的数组，内存是放不下的。所以，这个散列值是不能直接拿来用的。用之前还要先做对数组的长度取模运算，得到的余数才能用来要存放的位置也就是对应的数组下标。\n这个算法应该如何设计呢？\n我们首先可能会想到采用 % 取余的操作来实现。但是，重点来了：“取余(%)操作中如果除数是 2 的幂次则等价于与其除数减一的与(\u0026amp;)操作（也就是说 hash%length==hash\u0026amp;(length-1) 的前提是 length 是 2 的 n 次方）。” 并且，采用二进制位操作 \u0026amp; 相对于 % 能够提高运算效率。\n除了上面所说的位运算比取余效率高之外，我觉得更重要的一个原因是：长度是 2 的幂次方，可以让 HashMap 在扩容的时候更均匀。例如:\nlength = 8 时，length - 1 = 7 的二进制位0111 length = 16 时，length - 1 = 15 的二进制位1111 这时候原本存在 HashMap 中的元素计算新的数组位置时 hash\u0026amp;(length-1)，取决 hash 的第四个二进制位（从右数），会出现两种情况：\n第四个二进制位为 0，数组位置不变，也就是说当前元素在新数组和旧数组的位置相同。 第四个二进制位为 1，数组位置在新数组扩容之后的那一部分。 这里列举一个例子：\n假设有一个元素的哈希值为 10101100 旧数组元素位置计算： hash = 10101100 length - 1 = 00000111 \u0026amp; ----------------- index = 00000100 (4) 新数组元素位置计算： hash = 10101100 length - 1 = 00001111 \u0026amp; ----------------- index = 00001100 (12) 看第四位（从右数）： 1.高位为 0：位置不变。 2.高位为 1：移动到新位置（原索引位置+原容量）。 ⚠️注意：这里列举的场景看的是第四个二进制位，更准确点来说看的是高位（从右数），例如 length = 32 时，length - 1 = 31，二进制为 11111，这里看的就是第五个二进制位。\n也就是说扩容之后，在旧数组元素 hash 值比较均匀（至于 hash 值均不均匀，取决于前面讲的对象的 hashcode() 方法和扰动函数）的情况下，新数组元素也会被分配的比较均匀，最好的情况是会有一半在新数组的前半部分，一半在新数组后半部分。\n这样也使得扩容机制变得简单和高效，扩容后只需检查哈希值高位的变化来决定元素的新位置，要么位置不变（高位为 0），要么就是移动到新位置（高位为 1，原索引位置+原容量）。\n最后，简单总结一下 HashMap 的长度是 2 的幂次方的原因：\n位运算效率更高：位运算(\u0026amp;)比取余运算(%)更高效。当长度为 2 的幂次方时，hash % length 等价于 hash \u0026amp; (length - 1)。 可以更好地保证哈希值的均匀分布：扩容之后，在旧数组元素 hash 值比较均匀的情况下，新数组元素也会被分配的比较均匀，最好的情况是会有一半在新数组的前半部分，一半在新数组后半部分。 扩容机制变得简单和高效：扩容后只需检查哈希值高位的变化来决定元素的新位置，要么位置不变（高位为 0），要么就是移动到新位置（高位为 1，原索引位置+原容量）。 1.2.7 HashMap 多线程操作导致死循环问题 # JDK1.7 及之前版本的 HashMap 在多线程环境下扩容操作可能存在死循环问题，这是由于当一个桶位中有多个元素需要进行扩容时，多个线程同时对链表进行操作，头插法可能会导致链表中的节点指向错误的位置，从而形成一个环形链表，进而使得查询元素的操作陷入死循环无法结束。\n为了解决这个问题，JDK1.8 版本的 HashMap 采用了尾插法而不是头插法来避免链表倒置，使得插入的节点永远都是放在链表的末尾，避免了链表中的环形结构。但是还是不建议在多线程下使用 HashMap，因为多线程下使用 HashMap 还是会存在数据覆盖的问题。并发环境下，推荐使用 ConcurrentHashMap 。\n一般面试中这样介绍就差不多，不需要记各种细节，个人觉得也没必要记。如果想要详细了解 HashMap 扩容导致死循环问题，可以看看耗子叔的这篇文章：Java HashMap 的死循环。\n1.2.8 HashMap 为什么线程不安全 # JDK1.7 及之前版本，在多线程环境下，HashMap 扩容时会造成死循环和数据丢失的问题。\n数据丢失这个在 JDK1.7 和 JDK 1.8 中都存在，这里以 JDK 1.8 为例进行介绍。\nJDK 1.8 后，在 HashMap 中，多个键值对可能会被分配到同一个桶（bucket），并以链表或红黑树的形式存储。多个线程对 HashMap 的 put 操作会导致线程不安全，具体来说会有数据覆盖的风险。\n举个例子：\n两个线程 1,2 同时进行 put 操作，并且发生了哈希冲突（hash 函数计算出的插入下标是相同的）。 不同的线程可能在不同的时间片获得 CPU 执行的机会，当前线程 1 执行完哈希冲突判断后，由于时间片耗尽挂起。线程 2 先完成了插入操作。 随后，线程 1 获得时间片，由于之前已经进行过 hash 碰撞的判断，所有此时会直接进行插入，这就导致线程 2 插入的数据被线程 1 覆盖了。 public V put(K key, V value) { return putVal(hash(key), key, value, false, true); } final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) { // ... // 判断是否出现 hash 碰撞 // (n - 1) \u0026amp; hash 确定元素存放在哪个桶中，桶为空，新生成结点放入桶中(此时，这个结点是放在数组中) if ((p = tab[i = (n - 1) \u0026amp; hash]) == null) tab[i] = newNode(hash, key, value, null); // 桶中已经存在元素（处理hash冲突） else { // ... } 还有一种情况是这两个线程同时 put 操作导致 size 的值不正确，进而导致数据覆盖的问题：\n线程 1 执行 if(++size \u0026gt; threshold) 判断时，假设获得 size 的值为 10，由于时间片耗尽挂起。 线程 2 也执行 if(++size \u0026gt; threshold) 判断，获得 size 的值也为 10，并将元素插入到该桶位中，并将 size 的值更新为 11。 随后，线程 1 获得时间片，它也将元素放入桶位中，并将 size 的值更新为 11。 线程 1、2 都执行了一次 put 操作，但是 size 的值只增加了 1，也就导致实际上只有一个元素被添加到了 HashMap 中。 public V put(K key, V value) { return putVal(hash(key), key, value, false, true); } final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) { // ... // 实际大小大于阈值则扩容 if (++size \u0026gt; threshold) resize(); // 插入后回调 afterNodeInsertion(evict); return null; } 1.2.9 HashMap 常见的遍历方式 # HashMap 的 7 种遍历方式与性能分析！\n🐛 修正（参见：issue#1411）：\n这篇文章对于 parallelStream 遍历方式的性能分析有误，先说结论：存在阻塞时 parallelStream 性能最高, 非阻塞时 parallelStream 性能最低 。\n当遍历不存在阻塞时, parallelStream 的性能是最低的：\nBenchmark Mode Cnt Score Error Units Test.entrySet avgt 5 288.651 ± 10.536 ns/op Test.keySet avgt 5 584.594 ± 21.431 ns/op Test.lambda avgt 5 221.791 ± 10.198 ns/op Test.parallelStream avgt 5 6919.163 ± 1116.139 ns/op 加入阻塞代码Thread.sleep(10)后, parallelStream 的性能才是最高的:\nBenchmark Mode Cnt Score Error Units Test.entrySet avgt 5 1554828440.000 ± 23657748.653 ns/op Test.keySet avgt 5 1550612500.000 ± 6474562.858 ns/op Test.lambda avgt 5 1551065180.000 ± 19164407.426 ns/op Test.parallelStream avgt 5 186345456.667 ± 3210435.590 ns/op 1.3 TreeMap集合 # TreeMap集合概述和特点\nTreeMap底层是红黑树结构 依赖自然排序或者比较器排序,对键进行排序 如果键存储的是自定义对象,需要实现Comparable接口或者在创建TreeMap对象时候给出比较器排序规则 1.4 ConcurrentHashMap # ConcurrentHashMap 是一种线程安全的高效Map集合\n底层数据结构：\nJDK1.7底层采用分段的数组+链表实现 JDK1.8 采用的数据结构跟HashMap1.8的结构一样，数组+链表/红黑二叉树。 在jdk1.7中 ConcurrentHashMap 里包含一个 Segment 数组。Segment 的结构和HashMap类似，是一 种数组和链表结构，一个 Segment 包含一个 HashEntry 数组，每个 HashEntry 是一个链表结构 的元素，每个 Segment 守护着一个HashEntry数组里的元素，当对 HashEntry 数组的数据进行修 改时，必须首先获得对应的 Segment的锁。\nSegment 是一种可重入的锁 ReentrantLock，每个 Segment 守护一个HashEntry 数组里得元 素，当对 HashEntry 数组的数据进行修改时，必须首先获得对应的 Segment 锁\n在jdk1.8中的ConcurrentHashMap 做了较大的优化，性能提升了不少。首先是它的数据结构与jdk1.8的hashMap数据结构完全一致。其次是放弃了Segment臃肿的设计，取而代之的是采用Node + CAS + Synchronized来保 证并发安全进行实现，synchronized只锁定当前链表或红黑二叉树的首节点，这样只要hash不冲 突，就不会产生并发 , 效率得到提升\nHashtable出现的原因 : 在集合类中HashMap是比较常用的集合对象，但是HashMap是线程不安全的(多线程环境下可能会存在问题)。为了保证数据的安全性我们可以使用Hashtable，但是Hashtable的效率低下。\nConcurrentHashMap出现的原因 : 在集合类中HashMap是比较常用的集合对象，但是HashMap是线程不安全的(多线程环境下可能会存在问题)。为了保证数据的安全性我们可以使用Hashtable，但是Hashtable的效率低下。\n基于以上两个原因我们可以使用JDK1.5以后所提供的ConcurrentHashMap。\n体系结构 :\n总结 :\n​\t1 ，HashMap是线程不安全的。多线程环境下会有数据安全问题\n​\t2 ，Hashtable是线程安全的，但是会将整张表锁起来，效率低下\n​\t3，ConcurrentHashMap也是线程安全的，效率较高。 在JDK7和JDK8中，底层原理不一样。\n1.4.1 并发工具类-ConcurrentHashMap1.7原理 # 1.4.2 并发工具类-ConcurrentHashMap1.8原理 # 总结 :\n​\t1，如果使用空参构造创建ConcurrentHashMap对象，则什么事情都不做。 在第一次添加元素的时候创建哈希表\n​\t2，计算当前元素应存入的索引。\n​\t3，如果该索引位置为null，则利用cas算法，将本结点添加到数组中。\n​\t4，如果该索引位置不为null，则利用volatile关键字获得当前位置最新的结点地址，挂在他下面，变成链表。\n​\t5，当链表的长度大于等于8时，自动转换成红黑树6，以链表或者红黑树头结点为锁对象，配合悲观锁保证多线程操作集合时数据的安全性\n1.5 ConcurrentHashMap 和 Hashtable 的区别 # ConcurrentHashMap 和 Hashtable 的区别主要体现在实现线程安全的方式上不同。\n底层数据结构： JDK1.7 的 ConcurrentHashMap 底层采用 分段的数组+链表 实现，JDK1.8 采用的数据结构跟 HashMap1.8 的结构一样，数组+链表/红黑二叉树。Hashtable 和 JDK1.8 之前的 HashMap 的底层数据结构类似都是采用 数组+链表 的形式，数组是 HashMap 的主体，链表则是主要为了解决哈希冲突而存在的； 实现线程安全的方式（重要）： 在 JDK1.7 的时候，ConcurrentHashMap 对整个桶数组进行了分割分段(Segment，分段锁)，每一把锁只锁容器其中一部分数据（下面有示意图），多线程访问容器里不同数据段的数据，就不会存在锁竞争，提高并发访问率。 到了 JDK1.8 的时候，ConcurrentHashMap 已经摒弃了 Segment 的概念，而是直接用 Node 数组+链表+红黑树的数据结构来实现，并发控制使用 synchronized 和 CAS 来操作。（JDK1.6 以后 synchronized 锁做了很多优化） 整个看起来就像是优化过且线程安全的 HashMap，虽然在 JDK1.8 中还能看到 Segment 的数据结构，但是已经简化了属性，只是为了兼容旧版本； Hashtable(同一把锁) :使用 synchronized 来保证线程安全，效率非常低下。当一个线程访问同步方法时，其他线程也访问同步方法，可能会进入阻塞或轮询状态，如使用 put 添加元素，另一个线程不能使用 put 添加元素，也不能使用 get，竞争会越来越激烈效率越低。 下面，我们再来看看两者底层数据结构的对比图。\nHashtable :\nJDK1.7 的 ConcurrentHashMap：\nConcurrentHashMap 是由 Segment 数组结构和 HashEntry 数组结构组成。\nSegment 数组中的每个元素包含一个 HashEntry 数组，每个 HashEntry 数组属于链表结构。\nJDK1.8 的 ConcurrentHashMap：\nJDK1.8 的 ConcurrentHashMap 不再是 Segment 数组 + HashEntry 数组 + 链表，而是 Node 数组 + 链表 / 红黑树。不过，Node 只能用于链表的情况，红黑树的情况需要使用 TreeNode。当冲突链表达到一定长度时，链表会转换成红黑树。\nTreeNode是存储红黑树节点，被TreeBin包装。TreeBin通过root属性维护红黑树的根结点，因为红黑树在旋转的时候，根结点可能会被它原来的子节点替换掉，在这个时间点，如果有其他线程要写这棵红黑树就会发生线程不安全问题，所以在 ConcurrentHashMap 中TreeBin通过waiter属性维护当前使用这棵红黑树的线程，来防止其他线程的进入。\nstatic final class TreeBin\u0026lt;K,V\u0026gt; extends Node\u0026lt;K,V\u0026gt; { TreeNode\u0026lt;K,V\u0026gt; root; volatile TreeNode\u0026lt;K,V\u0026gt; first; volatile Thread waiter; volatile int lockState; // values for lockState static final int WRITER = 1; // set while holding write lock static final int WAITER = 2; // set when waiting for write lock static final int READER = 4; // increment value for setting read lock ... } 1.6 ConcurrentHashMap 线程安全的具体实现方式 # 1.6.1 JDK1.8 之前 # 首先将数据分为一段一段（这个“段”就是 Segment）的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据时，其他段的数据也能被其他线程访问。\nConcurrentHashMap 是由 Segment 数组结构和 HashEntry 数组结构组成。\nSegment 继承了 ReentrantLock,所以 Segment 是一种可重入锁，扮演锁的角色。HashEntry 用于存储键值对数据。\nstatic class Segment\u0026lt;K,V\u0026gt; extends ReentrantLock implements Serializable { } 一个 ConcurrentHashMap 里包含一个 Segment 数组，Segment 的个数一旦初始化就不能改变。 Segment 数组的大小默认是 16，也就是说默认可以同时支持 16 个线程并发写。\nSegment 的结构和 HashMap 类似，是一种数组和链表结构，一个 Segment 包含一个 HashEntry 数组，每个 HashEntry 是一个链表结构的元素，每个 Segment 守护着一个 HashEntry 数组里的元素，当对 HashEntry 数组的数据进行修改时，必须首先获得对应的 Segment 的锁。也就是说，对同一 Segment 的并发写入会被阻塞，不同 Segment 的写入是可以并发执行的。\n1.6.2 JDK1.8 之后 # Java 8 几乎完全重写了 ConcurrentHashMap，代码量从原来 Java 7 中的 1000 多行，变成了现在的 6000 多行。\nConcurrentHashMap 取消了 Segment 分段锁，采用 Node + CAS + synchronized 来保证并发安全。数据结构跟 HashMap 1.8 的结构类似，数组+链表/红黑二叉树。Java 8 在链表长度超过一定阈值（8）时将链表（寻址时间复杂度为 O(N)）转换为红黑树（寻址时间复杂度为 O(log(N))）。\nJava 8 中，锁粒度更细，synchronized 只锁定当前链表或红黑二叉树的首节点，这样只要 hash 不冲突，就不会产生并发，就不会影响其他 Node 的读写，效率大幅提升。\n1.6.3 差异 # 线程安全实现方式：JDK 1.7 采用 Segment 分段锁来保证安全， Segment 是继承自 ReentrantLock。JDK1.8 放弃了 Segment 分段锁的设计，采用 Node + CAS + synchronized 保证线程安全，锁粒度更细，synchronized 只锁定当前链表或红黑二叉树的首节点。 Hash 碰撞解决方法 : JDK 1.7 采用拉链法，JDK1.8 采用拉链法结合红黑树（链表长度超过一定阈值时，将链表转换为红黑树）。 并发度：JDK 1.7 最大并发度是 Segment 的个数，默认是 16。JDK 1.8 最大并发度是 Node 数组的大小，并发度更大。 1.6.4 ConcurrentHashMap 为什么key和 value 不能为null? # ConcurrentHashMap 的 key 和 value 不能为 null 主要是为了避免二义性。null 是一个特殊的值，表示没有对象或没有引用。如果你用 null 作为键，那么你就无法区分这个键是否存在于 ConcurrentHashMap 中，还是根本没有这个键。同样，如果你用 null 作为值，那么你就无法区分这个值是否是真正存储在 ConcurrentHashMap 中的，还是因为找不到对应的键而返回的。\n拿 get 方法取值来说，返回的结果为 null 存在两种情况：\n值没有在集合中 ； 值本身就是 null。 这也就是二义性的由来。\n具体可以参考 ConcurrentHashMap 源码分析 。\n多线程环境下，存在一个线程操作该 ConcurrentHashMap 时，其他的线程将该 ConcurrentHashMap 修改的情况，所以无法通过 containsKey(key) 来判断否存在这个键值对，也就没办法解决二义性问题了。\n与此形成对比的是，HashMap 可以存储 null 的 key 和 value，但 null 作为键只能有一个，null 作为值可以有多个。如果传入 null 作为参数，就会返回 hash 值为 0 的位置的值。单线程环境下，不存在一个线程操作该 HashMap 时，其他的线程将该 HashMap 修改的情况，所以可以通过 contains(key)来做判断是否存在这个键值对，从而做相应的处理，也就不存在二义性问题。\n也就是说，多线程下无法正确判定键值对是否存在（存在其他线程修改的情况），单线程是可以的（不存在其他线程修改的情况）。\n如果你确实需要在 ConcurrentHashMap 中使用 null 的话，可以使用一个特殊的静态空对象来代替 null。\npublic static final Object NULL = new Object(); 最后，再分享一下 ConcurrentHashMap 作者本人 (Doug Lea)对于这个问题的回答：\nThe main reason that nulls aren\u0026rsquo;t allowed in ConcurrentMaps (ConcurrentHashMaps, ConcurrentSkipListMaps) is that ambiguities that may be just barely tolerable in non-concurrent maps can\u0026rsquo;t be accommodated. The main one is that if map.get(key) returns null, you can\u0026rsquo;t detect whether the key explicitly maps to null vs the key isn\u0026rsquo;t mapped. In a non-concurrent map, you can check this via map.contains(key), but in a concurrent one, the map might have changed between calls.\n翻译过来之后的，大致意思还是单线程下可以容忍歧义，而多线程下无法容忍。\n1.6.5 ConcurrentHashMap 能保证复合操作的原子性吗 # ConcurrentHashMap 是线程安全的，意味着它可以保证多个线程同时对它进行读写操作时，不会出现数据不一致的情况，也不会导致 JDK1.7 及之前版本的 HashMap 多线程操作导致死循环问题。但是，这并不意味着它可以保证所有的复合操作都是原子性的，一定不要搞混了！\n复合操作是指由多个基本操作(如put、get、remove、containsKey等)组成的操作，例如先判断某个键是否存在containsKey(key)，然后根据结果进行插入或更新put(key, value)。这种操作在执行过程中可能会被其他线程打断，导致结果不符合预期。\n例如，有两个线程 A 和 B 同时对 ConcurrentHashMap 进行复合操作，如下：\n// 线程 A if (!map.containsKey(key)) { map.put(key, value); } // 线程 B if (!map.containsKey(key)) { map.put(key, anotherValue); } 如果线程 A 和 B 的执行顺序是这样：\n线程 A 判断 map 中不存在 key 线程 B 判断 map 中不存在 key 线程 B 将 (key, anotherValue) 插入 map 线程 A 将 (key, value) 插入 map 那么最终的结果是 (key, value)，而不是预期的 (key, anotherValue)。这就是复合操作的非原子性导致的问题。\n那如何保证 ConcurrentHashMap 复合操作的原子性呢？\nConcurrentHashMap 提供了一些原子性的复合操作，如 putIfAbsent、compute、computeIfAbsent 、computeIfPresent、merge等。这些方法都可以接受一个函数作为参数，根据给定的 key 和 value 来计算一个新的 value，并且将其更新到 map 中。\n上面的代码可以改写为：\n// 线程 A map.putIfAbsent(key, value); // 线程 B map.putIfAbsent(key, anotherValue); 或者：\n// 线程 A map.computeIfAbsent(key, k -\u0026gt; value); // 线程 B map.computeIfAbsent(key, k -\u0026gt; anotherValue); 很多同学可能会说了，这种情况也能加锁同步呀！确实可以，但不建议使用加锁的同步机制，违背了使用 ConcurrentHashMap 的初衷。在使用 ConcurrentHashMap 的时候，尽量使用这些原子性的复合操作方法来保证原子性。\n1.6.6 并发工具类-CountDownLatch # CountDownLatch类 :\n方法 解释 public CountDownLatch(int count) 参数传递线程数，表示等待线程数量 public void await() 让线程等待 public void countDown() 当前线程执行完毕 使用场景： 让某一条线程等待其他线程执行完毕之后再执行\n总结 :\n​\t1. CountDownLatch(int count)：参数写等待线程的数量。并定义了一个计数器。\n​\t2. await()：让线程等待，当计数器为0时，会唤醒等待的线程\n​\t3. countDown()： 线程执行完毕时调用，会将计数器-1。\n1.6.7 并发工具类-Semaphore # 使用场景 :\n​\t可以控制访问特定资源的线程数量。\n","date":"11 March 2025","externalUrl":null,"permalink":"/posts/1741680552080-java-map/","section":"Posts","summary":"","title":"java Map","type":"posts"},{"content":" Queue # Queue（队列）是一种 FIFO（First-In-First-Out，先进先出） 的数据结构，常用于任务调度、消息队列、生产者-消费者模型等场景。\n在 Java 中，Queue 是 java.util.Queue 接口的一个抽象，常见的实现有 LinkedList、PriorityQueue、ArrayDeque 等。\n1.1 Queue 主要方法 # Queue 继承自 Collection，并定义了以下核心方法：\n方法 描述 抛出异常 返回特殊值（null/false） add(E e) 添加 元素 IllegalStateException ❌ offer(E e) 添加 元素 ❌ false remove() 删除 队头元素 NoSuchElementException ❌ poll() 删除 队头元素 ❌ null element() 获取 队头元素（不删除） NoSuchElementException ❌ peek() 获取 队头元素（不删除） ❌ null 推荐使用 offer()、poll()、peek()，避免异常。 add()、remove()、element() 在操作失败时抛出异常，不安全！\n1.2 Queue 常见实现类 # 1.2.1 LinkedList（基于链表，双向队列） # 实现：Queue + Deque\n特点：支持 FIFO 队列 和 双向队列\n应用场景：需要动态扩展容量的 普通队列\n示例：\njava复制编辑Queue\u0026lt;Integer\u0026gt; queue = new LinkedList\u0026lt;\u0026gt;(); queue.offer(10); queue.offer(20); System.out.println(queue.poll()); // 10 1.2.2 PriorityQueue（优先队列，基于小顶堆） # 实现：Queue + 最小堆（默认最小堆）\n特点：元素按照优先级排序，非 FIFO\n应用场景：任务调度、最短路径算法（Dijkstra）\n示例：\njava复制编辑Queue\u0026lt;Integer\u0026gt; pq = new PriorityQueue\u0026lt;\u0026gt;(); pq.offer(30); pq.offer(10); pq.offer(20); System.out.println(pq.poll()); // 10（最小值先出） 1.2.3 ArrayDeque（基于数组，双向队列） # 实现：Queue + Deque\n特点：\n比 LinkedList 更快（无额外的节点开销） 支持双端操作 应用场景：性能要求较高的 普通队列\n示例：\njava复制编辑Queue\u0026lt;Integer\u0026gt; deque = new ArrayDeque\u0026lt;\u0026gt;(); deque.offer(10); deque.offer(20); System.out.println(deque.poll()); // 10 1.3 并发安全的 Queue # 1.3.1 ConcurrentLinkedQueue（线程安全，非阻塞） # 实现：无锁 CAS（Compare-And-Swap）\n特点：\n适用于高并发场景 不阻塞，性能优于 synchronized 应用场景：多线程环境（高性能）\n示例：\njava复制编辑Queue\u0026lt;Integer\u0026gt; queue = new ConcurrentLinkedQueue\u0026lt;\u0026gt;(); queue.offer(10); queue.offer(20); System.out.println(queue.poll()); // 10 1.3.2 BlockingQueue（阻塞队列，适用于生产者-消费者模式） # 实现：LinkedBlockingQueue / ArrayBlockingQueue\n特点：\n阻塞操作（put() \u0026amp; take()） 适用于多线程环境 应用场景：生产者-消费者模型\n示例：\njava复制编辑BlockingQueue\u0026lt;Integer\u0026gt; queue = new LinkedBlockingQueue\u0026lt;\u0026gt;(); queue.put(10); System.out.println(queue.take()); // 10（若队列为空，则阻塞等待） 1.4 总结 # 实现类 底层结构 线程安全 适用场景 LinkedList 链表 ❌ 普通 FIFO 队列 PriorityQueue 最小堆 ❌ 任务调度 ArrayDeque 数组 ❌ 高性能队列 ConcurrentLinkedQueue 无锁链表 ✅ 高并发 BlockingQueue 链表 / 数组 ✅ 生产者-消费者 推荐\n普通场景：LinkedList / ArrayDeque 高并发：ConcurrentLinkedQueue 生产者-消费者：BlockingQueue 1.5 Queue 与 Deque 的区别 # Queue 是单端队列，只能从一端插入元素，另一端删除元素，实现上一般遵循 先进先出（FIFO） 规则。\nQueue 扩展了 Collection 的接口，根据 因为容量问题而导致操作失败后处理方式的不同 可以分为两类方法: 一种在操作失败后会抛出异常，另一种则会返回特殊值。\nQueue 接口 抛出异常 返回特殊值 插入队尾 add(E e) offer(E e) 删除队首 remove() poll() 查询队首元素 element() peek() Deque 是双端队列，在队列的两端均可以插入或删除元素。\nDeque 扩展了 Queue 的接口, 增加了在队首和队尾进行插入和删除的方法，同样根据失败后处理方式的不同分为两类：\nDeque 接口 抛出异常 返回特殊值 插入队首 addFirst(E e) offerFirst(E e) 插入队尾 addLast(E e) offerLast(E e) 删除队首 removeFirst() pollFirst() 删除队尾 removeLast() pollLast() 查询队首元素 getFirst() peekFirst() 查询队尾元素 getLast() peekLast() 事实上，Deque 还提供有 push() 和 pop() 等其他方法，可用于模拟栈。\n1.6 ArrayDeque与LinkedList的区别 # ArrayDeque 和 LinkedList 都实现了 Deque 接口，两者都具有队列的功能，但两者有什么区别呢？\nArrayDeque 是基于可变长的数组和双指针来实现，而 LinkedList 则通过链表来实现。 ArrayDeque 不支持存储 NULL 数据，但 LinkedList 支持。 ArrayDeque 是在 JDK1.6 才被引入的，而LinkedList 早在 JDK1.2 时就已经存在。 ArrayDeque 插入时可能存在扩容过程, 不过均摊后的插入操作依然为 O(1)。虽然 LinkedList 不需要扩容，但是每次插入数据时均需要申请新的堆空间，均摊性能相比更慢。 从性能的角度上，选用 ArrayDeque 来实现队列要比 LinkedList 更好。此外，ArrayDeque 也可以用于实现栈。\n1.7 PriorityQueue # PriorityQueue 是在 JDK1.5 中被引入的, 其与 Queue 的区别在于元素出队顺序是与优先级相关的，即总是优先级最高的元素先出队。\n这里列举其相关的一些要点：\nPriorityQueue 利用了二叉堆的数据结构来实现的，底层使用可变长的数组来存储数据 PriorityQueue 通过堆元素的上浮和下沉，实现了在 O(logn) 的时间复杂度内插入元素和删除堆顶元素。 PriorityQueue 是非线程安全的，且不支持存储 NULL 和 non-comparable 的对象。 PriorityQueue 默认是小顶堆，但可以接收一个 Comparator 作为构造参数，从而来自定义元素优先级的先后。 PriorityQueue 在面试中可能更多的会出现在手撕算法的时候，典型例题包括堆排序、求第 K 大的数、带权图的遍历等，所以需要会熟练使用才行。\n1.8 BlockingQueue # BlockingQueue （阻塞队列）是一个接口，继承自 Queue。BlockingQueue阻塞的原因是其支持当队列没有元素时一直阻塞，直到有元素；还支持如果队列已满，一直等到队列可以放入新元素时再放入。\npublic interface BlockingQueue\u0026lt;E\u0026gt; extends Queue\u0026lt;E\u0026gt; { // ... } BlockingQueue 常用于生产者-消费者模型中，生产者线程会向队列中添加数据，而消费者线程会从队列中取出数据进行处理。\nBlockingQueue的实现类\nArrayBlockingQueue：使用数组实现的有界阻塞队列。在创建时需要指定容量大小，并支持公平和非公平两种方式的锁访问机制。 LinkedBlockingQueue：使用单向链表实现的可选有界阻塞队列。在创建时可以指定容量大小，如果不指定则默认为Integer.MAX_VALUE。和ArrayBlockingQueue不同的是， 它仅支持非公平的锁访问机制。 PriorityBlockingQueue：支持优先级排序的无界阻塞队列。元素必须实现Comparable接口或者在构造函数中传入Comparator对象，并且不能插入 null 元素。 SynchronousQueue：同步队列，是一种不存储元素的阻塞队列。每个插入操作都必须等待对应的删除操作，反之删除操作也必须等待插入操作。因此，SynchronousQueue通常用于线程之间的直接传递数据。 DelayQueue：延迟队列，其中的元素只有到了其指定的延迟时间，才能够从队列中出队。 …… 日常开发中，这些队列使用的其实都不多，了解即可。\n1.9 ArrayBlockingQueue和LinkedBlockingQueue的区别 # ArrayBlockingQueue 和 LinkedBlockingQueue 是 Java 并发包中常用的两种阻塞队列实现，它们都是线程安全的。不过，不过它们之间也存在下面这些区别：\n底层实现：ArrayBlockingQueue 基于数组实现，而 LinkedBlockingQueue 基于链表实现。 是否有界：ArrayBlockingQueue 是有界队列，必须在创建时指定容量大小。LinkedBlockingQueue 创建时可以不指定容量大小，默认是Integer.MAX_VALUE，也就是无界的。但也可以指定队列大小，从而成为有界的。 锁是否分离： ArrayBlockingQueue中的锁是没有分离的，即生产和消费用的是同一个锁；LinkedBlockingQueue中的锁是分离的，即生产用的是putLock，消费是takeLock，这样可以防止生产者和消费者线程之间的锁争夺。 内存占用：ArrayBlockingQueue 需要提前分配数组内存，而 LinkedBlockingQueue 则是动态分配链表节点内存。这意味着，ArrayBlockingQueue 在创建时就会占用一定的内存空间，且往往申请的内存比实际所用的内存更大，而LinkedBlockingQueue 则是根据元素的增加而逐渐占用内存空间。 ","date":"11 March 2025","externalUrl":null,"permalink":"/posts/1741680533990-java-queue/","section":"Posts","summary":"","title":"java Queue","type":"posts"},{"content":" Set # Set集合概述和特点：\n不可以存储重复元素 没有索引,不能使用普通for循环遍历 Set集合的使用：\n存储字符串并遍历；\n1.1 TreeSet集合 # TreeSet集合概述和特点：\n不可以存储重复元素\n没有索引\n可以将元素按照规则进行排序\nTreeSet()：根据其元素的自然排序1\n进行排序\nTreeSet(Comparator comparator) ：根据指定的比较器进行排序\n两种比较方式总结：\n自然排序: 自定义类实现Comparable接口,重写compareTo方法,根据返回值进行排序 比较器排序: 创建TreeSet对象的时候传递Comparator的实现类对象,重写compare方法,根据返回值进行排序 在使用的时候,默认使用自然排序,当自然排序不满足现在的需求时,必须使用比较器排序 两种方式中关于返回值的规则\n如果返回值为负数，表示当前存入的元素是较小值，存左边 如果返回值为0，表示当前存入的元素跟集合中元素重复了，不存 如果返回值为正数，表示当前存入的元素是较大值，存右边 1.2 HashSet集合 # HashSet集合概述和特点：\n底层数据结构是哈希表 存取无序 不可以存储重复元素 没有索引,不能使用普通for循环遍历 哈希值：\n哈希值简介\n​\t是JDK根据对象的地址或者字符串或者数字算出来的int类型的数值\n如何获取哈希值\n​\tObject类中的public int hashCode()：返回对象的哈希码值\n哈希值的特点\n同一个对象多次调用hashCode()方法返回的哈希值是相同的 默认情况下，不同对象的哈希值是不同的。而重写hashCode()方法，可以实现让不同对象的哈希值相同 哈希表结构：\nJDK1.8以前\n​\t数组 + 链表\nJDK1.8以后\n节点个数少于等于8个\n​\t数组 + 链表\n节点个数多于8个\n​\t数组 + 红黑树\n1.3 Comparable 和 Comparator 的区别 # Comparable 接口和 Comparator 接口都是 Java 中用于排序的接口，它们在实现类对象之间比较大小、排序等方面发挥了重要作用：\nComparable 接口实际上是出自java.lang包 ，它有一个 compareTo(Object obj)方法用来排序 Comparator接口实际上是出自 java.util 包，它有一个compare(Object obj1, Object obj2)方法用来排序 一般我们需要对一个集合使用自定义排序时，我们就要重写compareTo()方法或compare()方法，当我们需要对某一个集合实现两种排序方式，比如一个 song 对象中的歌名和歌手名分别采用一种排序方法的话，我们可以重写compareTo()方法和使用自制的Comparator方法或者以两个 Comparator 来实现歌名排序和歌星名排序，第二种代表我们只能使用两个参数版的 Collections.sort().\n1.3.1 Comparator 定制排序 # ArrayList\u0026lt;Integer\u0026gt; arrayList = new ArrayList\u0026lt;Integer\u0026gt;(); arrayList.add(-1); arrayList.add(3); arrayList.add(3); arrayList.add(-5); arrayList.add(7); arrayList.add(4); arrayList.add(-9); arrayList.add(-7); System.out.println(\u0026#34;原始数组:\u0026#34;); System.out.println(arrayList); // void reverse(List list)：反转 Collections.reverse(arrayList); System.out.println(\u0026#34;Collections.reverse(arrayList):\u0026#34;); System.out.println(arrayList); // void sort(List list),按自然排序的升序排序 Collections.sort(arrayList); System.out.println(\u0026#34;Collections.sort(arrayList):\u0026#34;); System.out.println(arrayList); // 定制排序的用法 Collections.sort(arrayList, new Comparator\u0026lt;Integer\u0026gt;() { @Override public int compare(Integer o1, Integer o2) { return o2.compareTo(o1); } }); System.out.println(\u0026#34;定制排序后：\u0026#34;); System.out.println(arrayList); Output:\n原始数组: [-1, 3, 3, -5, 7, 4, -9, -7] Collections.reverse(arrayList): [-7, -9, 4, 7, -5, 3, 3, -1] Collections.sort(arrayList): [-9, -7, -5, -1, 3, 3, 4, 7] 定制排序后： [7, 4, 3, 3, -1, -5, -7, -9] 重写 compareTo 方法实现按年龄来排序\n// person对象没有实现Comparable接口，所以必须实现，这样才不会出错，才可以使treemap中的数据按顺序排列 // 前面一个例子的String类已经默认实现了Comparable接口，详细可以查看String类的API文档，另外其他 // 像Integer类等都已经实现了Comparable接口，所以不需要另外实现了 public class Person implements Comparable\u0026lt;Person\u0026gt; { private String name; private int age; public Person(String name, int age) { super(); this.name = name; this.age = age; } public String getName() { return name; } public void setName(String name) { this.name = name; } public int getAge() { return age; } public void setAge(int age) { this.age = age; } /** * T重写compareTo方法实现按年龄来排序 */ @Override public int compareTo(Person o) { if (this.age \u0026gt; o.getAge()) { return 1; } if (this.age \u0026lt; o.getAge()) { return -1; } return 0; } } public static void main(String[] args) { TreeMap\u0026lt;Person, String\u0026gt; pdata = new TreeMap\u0026lt;Person, String\u0026gt;(); pdata.put(new Person(\u0026#34;张三\u0026#34;, 30), \u0026#34;zhangsan\u0026#34;); pdata.put(new Person(\u0026#34;李四\u0026#34;, 20), \u0026#34;lisi\u0026#34;); pdata.put(new Person(\u0026#34;王五\u0026#34;, 10), \u0026#34;wangwu\u0026#34;); pdata.put(new Person(\u0026#34;小红\u0026#34;, 5), \u0026#34;xiaohong\u0026#34;); // 得到key的值的同时得到key所对应的值 Set\u0026lt;Person\u0026gt; keys = pdata.keySet(); for (Person key : keys) { System.out.println(key.getAge() + \u0026#34;-\u0026#34; + key.getName()); } } Output:\n5-小红 10-王五 20-李四 30-张三 1.3.2 无序性和不可重复性的含义 # 无序性不等于随机性 ，无序性是指存储的数据在底层数组中并非按照数组索引的顺序添加 ，而是根据数据的哈希值决定的。 不可重复性是指添加的元素按照 equals() 判断时 ，返回 false，需要同时重写 equals() 方法和 hashCode() 方法。 1.4 HashSet，LinkedHashSet和TreeSet的异同 # HashSet、LinkedHashSet 和 TreeSet 都是 Set 接口的实现类，都能保证元素唯一，并且都不是线程安全的。 HashSet、LinkedHashSet 和 TreeSet 的主要区别在于底层数据结构不同。HashSet 的底层数据结构是哈希表（基于 HashMap 实现）。LinkedHashSet 的底层数据结构是链表和哈希表，元素的插入和取出顺序满足 FIFO2。TreeSet 底层数据结构是红黑树，元素是有序的，排序的方式有自然排序和定制排序。 底层数据结构不同又导致这三者的应用场景不同。HashSet 用于不需要保证元素插入和取出顺序的场景，LinkedHashSet 用于保证元素的插入和取出顺序满足 FIFO 的场景，TreeSet 用于支持对元素自定义排序规则的场景。 自然排序：一种默认的对象排序方式，它是根据对象的内在特征或属性来排序的。例如，对于整数，自然排序是按照数字的大小进行排序；对于字符串，自然排序是按照字母的字典顺序进行排序。自然排序通常是最直观和常见的排序方式，它使得对象在集合中以一种有序的方式存储和检索。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nFIFO是英文First In First Out 的缩写，是一种先进先出的数据缓存器，他与普通存储器的区别是没有外部读写地址线，这样使用起来非常简单，但缺点就是只能顺序写入数据，顺序的读出数据，其数据地址由内部读写指针自动加1完成，不能像普通存储器那样可以由地址线决定读取或写入某个指定的地址。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"11 March 2025","externalUrl":null,"permalink":"/posts/1741680519837-java-set/","section":"Posts","summary":"","title":"java Set","type":"posts"},{"content":"an example to get you started\nJava集合使用注意事项 # 1.1 集合判空 # 《阿里巴巴 Java 开发手册》的描述如下：\n判断所有集合内部的元素是否为空，使用 isEmpty() 方法，而不是 size()==0 的方式。\n这是因为 isEmpty() 方法的可读性更好，并且时间复杂度为 O(1)。\n绝大部分我们使用的集合的 size() 方法的时间复杂度也是 O(1)，不过，也有很多复杂度不是 O(1) 的，比如 java.util.concurrent 包下的某些集合（ConcurrentLinkedQueue、ConcurrentHashMap\u0026hellip;）。\n下面是 ConcurrentHashMap 的 size() 方法和 isEmpty() 方法的源码。\npublic int size() { long n = sumCount(); return ((n \u0026lt; 0L) ? 0 : (n \u0026gt; (long)Integer.MAX_VALUE) ? Integer.MAX_VALUE : (int)n); } final long sumCount() { CounterCell[] as = counterCells; CounterCell a; long sum = baseCount; if (as != null) { for (int i = 0; i \u0026lt; as.length; ++i) { if ((a = as[i]) != null) sum += a.value; } } return sum; } public boolean isEmpty() { return sumCount() \u0026lt;= 0L; // ignore transient negative values } 1.2 集合转Map # 《阿里巴巴 Java 开发手册》的描述如下：\n在使用 java.util.stream.Collectors 类的 toMap() 方法转为 Map 集合时，一定要注意当 value 为 null 时会抛 NPE 异常。\nclass Person { private String name; private String phoneNumber; // getters and setters } List\u0026lt;Person\u0026gt; bookList = new ArrayList\u0026lt;\u0026gt;(); bookList.add(new Person(\u0026#34;jack\u0026#34;,\u0026#34;18163138123\u0026#34;)); bookList.add(new Person(\u0026#34;martin\u0026#34;,null)); // 空指针异常 bookList.stream().collect(Collectors.toMap(Person::getName, Person::getPhoneNumber)); 下面我们来解释一下原因。\n首先，我们来看 java.util.stream.Collectors 类的 toMap() 方法 ，可以看到其内部调用了 Map 接口的 merge() 方法。\npublic static \u0026lt;T, K, U, M extends Map\u0026lt;K, U\u0026gt;\u0026gt; Collector\u0026lt;T, ?, M\u0026gt; toMap(Function\u0026lt;? super T, ? extends K\u0026gt; keyMapper, Function\u0026lt;? super T, ? extends U\u0026gt; valueMapper, BinaryOperator\u0026lt;U\u0026gt; mergeFunction, Supplier\u0026lt;M\u0026gt; mapSupplier) { BiConsumer\u0026lt;M, T\u0026gt; accumulator = (map, element) -\u0026gt; map.merge(keyMapper.apply(element), valueMapper.apply(element), mergeFunction); return new CollectorImpl\u0026lt;\u0026gt;(mapSupplier, accumulator, mapMerger(mergeFunction), CH_ID); } Map 接口的 merge() 方法如下，这个方法是接口中的默认实现。\n如果你还不了解 Java 8 新特性的话，请看这篇文章：《Java8 新特性总结》 。\ndefault V merge(K key, V value, BiFunction\u0026lt;? super V, ? super V, ? extends V\u0026gt; remappingFunction) { Objects.requireNonNull(remappingFunction); Objects.requireNonNull(value); V oldValue = get(key); V newValue = (oldValue == null) ? value : remappingFunction.apply(oldValue, value); if(newValue == null) { remove(key); } else { put(key, newValue); } return newValue; } merge() 方法会先调用 Objects.requireNonNull() 方法判断 value 是否为空。\npublic static \u0026lt;T\u0026gt; T requireNonNull(T obj) { if (obj == null) throw new NullPointerException(); return obj; } 1.3 集合遍历 # 《阿里巴巴 Java 开发手册》的描述如下：\n不要在 foreach 循环里进行元素的 remove/add 操作。remove 元素请使用 Iterator 方式，如果并发操作，需要对 Iterator 对象加锁。\n通过反编译你会发现 foreach 语法底层其实还是依赖 Iterator 。不过， remove/add 操作直接调用的是集合自己的方法，而不是 Iterator 的 remove/add方法\n这就导致 Iterator 莫名其妙地发现自己有元素被 remove/add ，然后，它就会抛出一个 ConcurrentModificationException 来提示用户发生了并发修改异常。这就是单线程状态下产生的 fail-fast 机制。\nfail-fast 机制：多个线程对 fail-fast 集合进行修改的时候，可能会抛出ConcurrentModificationException。 即使是单线程下也有可能会出现这种情况，上面已经提到过。\n相关阅读：什么是 fail-fast 。\nJava8 开始，可以使用 Collection#removeIf()方法删除满足特定条件的元素,如\nList\u0026lt;Integer\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); for (int i = 1; i \u0026lt;= 10; ++i) { list.add(i); } list.removeIf(filter -\u0026gt; filter % 2 == 0); /* 删除list中的所有偶数 */ System.out.println(list); /* [1, 3, 5, 7, 9] */ 除了上面介绍的直接使用 Iterator 进行遍历操作之外，你还可以：\n使用普通的 for 循环 使用 fail-safe 的集合类。java.util包下面的所有的集合类都是 fail-fast 的，而java.util.concurrent包下面的所有的类都是 fail-safe 的。 …… 1.4 集合去重 # 《阿里巴巴 Java 开发手册》的描述如下：\n可以利用 Set 元素唯一的特性，可以快速对一个集合进行去重操作，避免使用 List 的 contains() 进行遍历去重或者判断包含操作。\n这里我们以 HashSet 和 ArrayList 为例说明。\n// Set 去重代码示例 public static \u0026lt;T\u0026gt; Set\u0026lt;T\u0026gt; removeDuplicateBySet(List\u0026lt;T\u0026gt; data) { if (CollectionUtils.isEmpty(data)) { return new HashSet\u0026lt;\u0026gt;(); } return new HashSet\u0026lt;\u0026gt;(data); } // List 去重代码示例 public static \u0026lt;T\u0026gt; List\u0026lt;T\u0026gt; removeDuplicateByList(List\u0026lt;T\u0026gt; data) { if (CollectionUtils.isEmpty(data)) { return new ArrayList\u0026lt;\u0026gt;(); } List\u0026lt;T\u0026gt; result = new ArrayList\u0026lt;\u0026gt;(data.size()); for (T current : data) { if (!result.contains(current)) { result.add(current); } } return result; } 两者的核心差别在于 contains() 方法的实现。\nHashSet 的 contains() 方法底部依赖的 HashMap 的 containsKey() 方法，时间复杂度接近于 O（1）（没有出现哈希冲突的时候为 O（1））。\nprivate transient HashMap\u0026lt;E,Object\u0026gt; map; public boolean contains(Object o) { return map.containsKey(o); } 我们有 N 个元素插入进 Set 中，那时间复杂度就接近是 O (n)。\nArrayList 的 contains() 方法是通过遍历所有元素的方法来做的，时间复杂度接近是 O(n)。\npublic boolean contains(Object o) { return indexOf(o) \u0026gt;= 0; } public int indexOf(Object o) { if (o == null) { for (int i = 0; i \u0026lt; size; i++) if (elementData[i]==null) return i; } else { for (int i = 0; i \u0026lt; size; i++) if (o.equals(elementData[i])) return i; } return -1; } 1.5 集合转数组 # 《阿里巴巴 Java 开发手册》的描述如下：\n使用集合转数组的方法，必须使用集合的 toArray(T[] array)，传入的是类型完全一致、长度为 0 的空数组。\ntoArray(T[] array) 方法的参数是一个泛型数组，如果 toArray 方法中没有传递任何参数的话返回的是 Object类 型数组。\nString [] s= new String[]{ \u0026#34;dog\u0026#34;, \u0026#34;lazy\u0026#34;, \u0026#34;a\u0026#34;, \u0026#34;over\u0026#34;, \u0026#34;jumps\u0026#34;, \u0026#34;fox\u0026#34;, \u0026#34;brown\u0026#34;, \u0026#34;quick\u0026#34;, \u0026#34;A\u0026#34; }; List\u0026lt;String\u0026gt; list = Arrays.asList(s); Collections.reverse(list); //没有指定类型的话会报错 s=list.toArray(new String[0]); 由于 JVM 优化，new String[0]作为Collection.toArray()方法的参数现在使用更好，new String[0]就是起一个模板的作用，指定了返回数组的类型，0 是为了节省空间，因为它只是为了说明返回的类型。详见：https://shipilev.net/blog/2016/arrays-wisdom-ancients/\n1.6 数组转集合 # 《阿里巴巴 Java 开发手册》的描述如下：\n使用工具类 Arrays.asList() 把数组转换成集合时，不能使用其修改集合相关的方法， 它的 add/remove/clear 方法会抛出 UnsupportedOperationException 异常。\n我在之前的一个项目中就遇到一个类似的坑。\nArrays.asList()在平时开发中还是比较常见的，我们可以使用它将一个数组转换为一个 List 集合。\nString[] myArray = {\u0026#34;Apple\u0026#34;, \u0026#34;Banana\u0026#34;, \u0026#34;Orange\u0026#34;}; List\u0026lt;String\u0026gt; myList = Arrays.asList(myArray); //上面两个语句等价于下面一条语句 List\u0026lt;String\u0026gt; myList = Arrays.asList(\u0026#34;Apple\u0026#34;,\u0026#34;Banana\u0026#34;, \u0026#34;Orange\u0026#34;); JDK 源码对于这个方法的说明：\n/** *返回由指定数组支持的固定大小的列表。此方法作为基于数组和基于集合的API之间的桥梁， * 与 Collection.toArray()结合使用。返回的List是可序列化并实现RandomAccess接口。 */ public static \u0026lt;T\u0026gt; List\u0026lt;T\u0026gt; asList(T... a) { return new ArrayList\u0026lt;\u0026gt;(a); } 下面我们来总结一下使用注意事项。\n1、Arrays.asList()是泛型方法，传递的数组必须是对象数组，而不是基本类型。\nint[] myArray = {1, 2, 3}; List myList = Arrays.asList(myArray); System.out.println(myList.size());//1 System.out.println(myList.get(0));//数组地址值 System.out.println(myList.get(1));//报错：ArrayIndexOutOfBoundsException int[] array = (int[]) myList.get(0); System.out.println(array[0]);//1 当传入一个原生数据类型数组时，Arrays.asList() 的真正得到的参数就不是数组中的元素，而是数组对象本身！此时 List 的唯一元素就是这个数组，这也就解释了上面的代码。\n我们使用包装类型数组就可以解决这个问题。\nInteger[] myArray = {1, 2, 3}; 2、使用集合的修改方法: add()、remove()、clear()会抛出异常。\nList myList = Arrays.asList(1, 2, 3); myList.add(4);//运行时报错：UnsupportedOperationException myList.remove(1);//运行时报错：UnsupportedOperationException myList.clear();//运行时报错：UnsupportedOperationException Arrays.asList() 方法返回的并不是 java.util.ArrayList ，而是 java.util.Arrays 的一个内部类,这个内部类并没有实现集合的修改方法或者说并没有重写这些方法。\nList myList = Arrays.asList(1, 2, 3); System.out.println(myList.getClass());//class java.util.Arrays$ArrayList 下图是 java.util.Arrays$ArrayList 的简易源码，我们可以看到这个类重写的方法有哪些。\nprivate static class ArrayList\u0026lt;E\u0026gt; extends AbstractList\u0026lt;E\u0026gt; implements RandomAccess, java.io.Serializable { ... @Override public E get(int index) { ... } @Override public E set(int index, E element) { ... } @Override public int indexOf(Object o) { ... } @Override public boolean contains(Object o) { ... } @Override public void forEach(Consumer\u0026lt;? super E\u0026gt; action) { ... } @Override public void replaceAll(UnaryOperator\u0026lt;E\u0026gt; operator) { ... } @Override public void sort(Comparator\u0026lt;? super E\u0026gt; c) { ... } } 我们再看一下java.util.AbstractList的 add/remove/clear 方法就知道为什么会抛出 UnsupportedOperationException 了。\npublic E remove(int index) { throw new UnsupportedOperationException(); } public boolean add(E e) { add(size(), e); return true; } public void add(int index, E element) { throw new UnsupportedOperationException(); } public void clear() { removeRange(0, size()); } protected void removeRange(int fromIndex, int toIndex) { ListIterator\u0026lt;E\u0026gt; it = listIterator(fromIndex); for (int i=0, n=toIndex-fromIndex; i\u0026lt;n; i++) { it.next(); it.remove(); } } 那我们如何正确的将数组转换为 ArrayList ?\n1、手动实现工具类\n//JDK1.5+ static \u0026lt;T\u0026gt; List\u0026lt;T\u0026gt; arrayToList(final T[] array) { final List\u0026lt;T\u0026gt; l = new ArrayList\u0026lt;T\u0026gt;(array.length); for (final T s : array) { l.add(s); } return l; } Integer [] myArray = { 1, 2, 3 }; System.out.println(arrayToList(myArray).getClass());//class java.util.ArrayList 2、最简便的方法\nList list = new ArrayList\u0026lt;\u0026gt;(Arrays.asList(\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;)) 3、使用 Java8 的 Stream(推荐)\nInteger [] myArray = { 1, 2, 3 }; List myList = Arrays.stream(myArray).collect(Collectors.toList()); //基本类型也可以实现转换（依赖boxed的装箱操作） int [] myArray2 = { 1, 2, 3 }; List myList = Arrays.stream(myArray2).boxed().collect(Collectors.toList()); 4、使用 Guava\n对于不可变集合，你可以使用ImmutableList类及其of()与copyOf()工厂方法：（参数不能为空）\nList\u0026lt;String\u0026gt; il = ImmutableList.of(\u0026#34;string\u0026#34;, \u0026#34;elements\u0026#34;); // from varargs List\u0026lt;String\u0026gt; il = ImmutableList.copyOf(aStringArray); // from array 对于可变集合，你可以使用Lists类及其newArrayList()工厂方法：\nList\u0026lt;String\u0026gt; l1 = Lists.newArrayList(anotherListOrCollection); // from collection List\u0026lt;String\u0026gt; l2 = Lists.newArrayList(aStringArray); // from array List\u0026lt;String\u0026gt; l3 = Lists.newArrayList(\u0026#34;or\u0026#34;, \u0026#34;string\u0026#34;, \u0026#34;elements\u0026#34;); // from varargs 5、使用 Apache Commons Collections\nList\u0026lt;String\u0026gt; list = new ArrayList\u0026lt;String\u0026gt;(); CollectionUtils.addAll(list, str); 6、 使用 Java9 的 List.of()方法\nInteger[] array = {1, 2, 3}; List\u0026lt;Integer\u0026gt; list = List.of(array); ","date":"11 March 2025","externalUrl":null,"permalink":"/posts/1741680588759-java-%E9%9B%86%E5%90%88%E4%BD%BF%E7%94%A8%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9/","section":"Posts","summary":"","title":"java 集合使用注意事项","type":"posts"},{"content":"an example to get you started\n集合概述 # ==Java集合，也叫做容器，提供一种存储空间可变的存储模型，存储的数据容量可以发生改变==，主要是由两大接口派生而来：一个是 Collection接口，主要用于存放单一元素；另一个是 Map 接口，主要用于存放键值对。对于Collection 接口，下面又有三个主要的子接口：List、Set 、 Queue（/kjuː/）。\nJava 集合框架如下图所示：\n注：图中只列举了主要的继承派生关系，并没有列举所有关系。比方省略了AbstractList, NavigableSet等抽象类以及其他的一些辅助类，如想深入了解，可自行查看源码。\n1.2 List，Set，Queue，Map # List(对付顺序的好帮手): 存储的元素是有序的、可重复的。 Set(注重独一无二的性质): 存储的元素不可重复的。 Queue(实现排队功能的叫号机): 按特定的排队规则来确定先后顺序，存储的元素是有序的、可重复的。 Map(用 key 来搜索的专家): 使用键值对（key-value）存储，类似于数学上的函数 y=f(x)，\u0026ldquo;x\u0026rdquo; 代表 key，\u0026ldquo;y\u0026rdquo; 代表 value，key 是无序的、不可重复的，value 是无序的、可重复的，每个键最多映射到一个值。 1.3 集合框架底层数据结构 # 先来看一下 Collection 接口下面的集合。\n1.3.1 List # ArrayList：Object[] 数组，非线程安全；没有同步开销，性能优于Vector，扩容默认扩容1.5倍。 Vector：Object[] 数组，线程安全；扩容默认扩容2倍，性能不高，不如CopyOnWriteArrayList。 LinkedList：双向链表(JDK1.6 之前为循环链表，JDK1.7 取消了循环)。 1.3.2 Set # HashSet(无序，唯一): 基于 HashMap 实现的，底层采用 HashMap 来保存元素。 LinkedHashSet: LinkedHashSet 是 HashSet 的子类，并且其内部是通过 LinkedHashMap 来实现的。 TreeSet(有序，唯一): 红黑树(自平衡的排序二叉树)。 1.3.3 Queue(队列) # PriorityQueue: Object[] 数组来实现小顶堆。 DelayQueue:PriorityQueue。 ArrayDeque: 可扩容动态双向数组。 再来看看 Map 接口下面的集合。\n1.3.4 Map # HashMap：JDK1.8 之前 HashMap 由数组+链表组成的，数组是 HashMap 的主体，链表则是主要为了解决哈希冲突而存在的（“拉链法”解决冲突）。JDK1.8 以后在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为 8）（将链表转换成红黑树前会判断，如果当前数组的长度小于 64，那么会选择先进行数组扩容，而不是转换为红黑树）时，将链表转化为红黑树，以减少搜索时间。 LinkedHashMap：LinkedHashMap 继承自 HashMap，所以它的底层仍然是基于拉链式散列结构即由数组和链表或红黑树组成。另外，LinkedHashMap 在上面结构的基础上，**增加了一条双向链表，使得上面的结构可以保持键值对的插入顺序。**同时通过对链表进行相应的操作，实现了访问顺序相关逻辑。 Hashtable：数组+链表组成的，数组是 Hashtable 的主体，链表则是主要为了解决哈希冲突1而存在的。 TreeMap：红黑树（自平衡的排序二叉树）。 1.4 如何选用集合 # 我们主要根据集合的特点来选择合适的集合。比如：\n我们需要根据键值获取到元素值时就选用 Map 接口下的集合，需要排序时选择 TreeMap,不需要排序时就选择 HashMap,需要保证线程安全就选用 ConcurrentHashMap。 我们只需要存放元素值时，就选择实现Collection 接口的集合，需要保证元素唯一时选择实现 Set 接口的集合比如 TreeSet 或 HashSet，不需要就选择实现 List 接口的比如 ArrayList 或 LinkedList，然后再根据实现这些接口的集合的特点来选用。 1.5 为什么要使用集合 # 当我们需要存储一组类型相同的数据时，数组是最常用且最基本的容器之一。但是，使用数组存储对象存在一些不足之处，因为在**实际开发中，存储的数据类型多种多样且数量不确定。**这时，Java 集合就派上用场了。与数组相比，Java 集合提供了更灵活、更有效的方法来存储多个数据对象。Java 集合框架中的各种集合类和接口可以存储不同类型和数量的对象，同时还具有多样化的操作方式。相较于数组，Java 集合的优势在于它们的大小可变、支持泛型、具有内建算法等。总的来说，Java 集合提高了数据的存储和处理灵活性，可以更好地适应现代软件开发中多样化的数据需求，并支持高质量的代码编写。\n1.6 集合框架的核心接口 # Java中的集合框架提供了一组接口和类，用于存储和操作数据集合。其中一些核心接口包括：\nCollection接口：是集合框架中最通用的接口，用于表示一组对象。它是List、Set和Queue接口的父接口，定义了对集合进行基本操作的方法。 List接口：表示一个有序的、可重复的集合。List接口的实现类可以根据元素的插入顺序访问和操作集合中的元素。常见的List接口的实现类有ArrayList、LinkedList和Vector。 Set接口：表示一个无序的、不可重复的集合。Set接口的实现类不能包含重复的元素。常见的Set接口的实现类有HashSet、TreeSet和LinkedHashSet。 Queue接口：表示一个先进先出的集合。Queue接口的实现类通常用于实现队列数据结构。常见的Queue接口的实现类有LinkedList和PriorityQueue。 Map接口：表示一个键值对的映射集合。Map接口中的每个元素由一个键和一个值组成，并且每个键只能在Map中出现一次。常见的Map接口的实现类有HashMap、TreeMap和LinkedHashMap。 以上是Java集合框架中一些核心接口的介绍。这些接口提供了不同类型和功能的集合，可以根据需求选择合适的接口和实现类来存储和操作数据。\nCollection集合 # 数组和集合的区别：\n相同点\n都是容器,可以存储多个数据\n不同点\n数组的长度是不可变的,集合的长度是可变的\n数组可以存基本数据类型和引用数据类型\n==集合只能存引用数据类型,如果要存基本数据类型,需要存对应的包装类==\n集合在添加数据的时候不需要考虑索引，默认将数据添加到末尾\nCollection集合概述：\n是单例集合的顶层接口,它表示一组对象,这些对象也称为Collection的元素 JDK 不提供此接口的任何直接实现.它提供更具体的子接口(如Set和List)实现 创建Collection集合的对象：\n多态的方式 具体的实现类ArrayList 从集合中移除指定的元素 boolean removeIf(Object o) 根据条件进行移除 void clear() 清空集合中的元素 boolean contains(Object o) 判断集合中是否存在指定的元素 boolean isEmpty() 判断集合是否为空 int size() 集合的长度，也就是集合中元素的个数 Collection集合的遍历：\n迭代器遍历：\n迭代器介绍\n**迭代器是一种对象，它允许按顺序访问集合中的元素，而不需要知道集合的底层结构。**通过使用迭代器，我们可以遍历集合并访问其中的元素，而无需关心集合的具体实现方式。\nJava 提供了 Iterator 接口作为迭代器的基础接口。该接口定义了一组用于访问集合元素的方法，包括 hasNext、next 和 remove 等。\n使用迭代器\n获取集合的迭代器对象：通过调用集合的 iterator 方法获取迭代器对象。例如，对于 ArrayList 集合，可以使用 iterator() 方法获取迭代器对象\nList\u0026lt;String\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); // 添加元素到集合中 Iterator\u0026lt;String\u0026gt; iterator = list.iterator(); 遍历集合元素：通过使用迭代器的 hasNext 和 next 方法来遍历集合中的元素。hasNext 方法用于检查是否还有下一个元素，next 方法用于获取下一个元素的值。\nwhile (iterator.hasNext()) { String element = iterator.next(); // 处理元素 } 可选操作：迭代器还提供了 remove 方法，用于从集合中删除当前迭代的元素。需要注意的是，该方法只能在调用 next 方法后才能调用，且每次只能调用一次。\niterator.remove(); 迭代器的优势：\n抽象集合的实现：通过使用迭代器，我们可以在不了解集合内部实现的情况下遍历和访问集合元素。这样，集合的实现细节对外部代码是透明的。 安全性：迭代器提供了一种安全的方式来遍历集合。它通过维护迭代器的状态来保证在遍历过程中不会出现并发修改的问题。 通用性：迭代器是一种通用的设计模式，在 Java 中被广泛应用于各种集合类型。无论是数组、列表、集合还是映射，我们都可以使用迭代器来遍历和访问元素。 增强for:\n介绍\nJava 提供了增强的 for 循环（foreach 循环），可以简化迭代器的使用。它可以直接遍历集合中的元素，而不需要显式地使用迭代器。\n格式\nfor (String element : list) { // 处理元素 } ​\tfor(集合/数组中元素的数据类型 变量名 : 集合/数组名) {\n​\t// 已经将当前遍历到的元素封装到变量中了,直接使用变量即可\n​\t}\n遍历过程中的修改：\n在使用迭代器遍历集合时，如果需要在遍历过程中修改集合，应使用迭代器的 remove 方法，而不是直接操作集合。直接操作集合可能会导致并发修改异常。\nIterator\u0026lt;String\u0026gt; iterator = list.iterator(); while (iterator.hasNext()) { String element = iterator.next(); if (shouldRemove(element)) { iterator.remove(); // 使用迭代器删除元素 } } 避免重复创建迭代器：\n在迭代器的使用过程中，应避免在每次迭代时都创建新的迭代器对象。如果需要多次遍历集合，可以在第一次遍历时创建迭代器，并在后续的遍历中重复使用该迭代器。\nIterator\u0026lt;String\u0026gt; iterator = list.iterator(); while (iterator.hasNext()) { String element = iterator.next(); // 处理元素 } // 再次使用同一个迭代器进行遍历 while (iterator.hasNext()) { String element = iterator.next(); // 处理元素 } 使用迭代器的限制功能：\n迭代器提供了一些限制功能，如只读迭代器和单向迭代器。如果在遍历过程中不需要修改集合或只需要向前遍历，可以使用只读或单向迭代器，以提高性能和安全性。\nList\u0026lt;String\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); // 添加元素到集合中 Iterator\u0026lt;String\u0026gt; readOnlyIterator = list.iterator(); Iterator\u0026lt;String\u0026gt; forwardIterator = list.listIterator(); 示例代码：\nList\u0026lt;String\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); list.add(\u0026#34;Apple\u0026#34;); list.add(\u0026#34;Banana\u0026#34;); list.add(\u0026#34;Orange\u0026#34;); Iterator\u0026lt;String\u0026gt; iterator = list.iterator(); while (iterator.hasNext()) { String element = iterator.next(); System.out.println(element); } 细节点注意：\n1.报错NoSuchElementException\n2.迭代器遍历完毕，指针不会复位\n3.循环中只能用一次next方法\n4.迭代器遍历时，不能用集合的方法进行增加或者删除\nlambda表达式：\n利用forEach方法，再结合lambda表达式的方式进行遍历。\nlambda表达式大概长下面这个样子：\n//lambda表达式 coll.forEach(s -\u0026gt; System.out.println(s)); 哈希冲突（Hash Collision）是指在使用哈希表（如 HashMap、Hashtable）进行数据存储时，不同的输入（键）通过哈希函数映射到同一个哈希值（hash value）或者同一个哈希表索引位置的情况。换句话说，即使两个键是不同的，它们的哈希值可能相同，导致它们在哈希表中存储时被分配到同一个存储位置（或桶）中，这就是哈希冲突。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"11 March 2025","externalUrl":null,"permalink":"/posts/1741680487797-java-%E9%9B%86%E5%90%88%E6%A6%82%E8%BF%B0/","section":"Posts","summary":"","title":"java 集合概述","type":"posts"},{"content":"","date":"11 March 2025","externalUrl":null,"permalink":"/tags/%E5%9F%BA%E7%A1%80%E6%80%BB%E7%BB%93/","section":"Tags","summary":"","title":"基础总结","type":"tags"},{"content":" 常见API\u0026amp;对象克隆 # 1.1 Math类 # Math类所在包为java.lang包，因此在使用的时候不需要进行导包。并且Math类被final修饰了，因此该类是不能被继承的。Math类包含执行基本数字运算的方法，我们可以使用Math类完成基本的数学运算。\n常见方法：\npublic static int abs(int a)\t// 返回参数的绝对值 public static double ceil(double a)\t// 返回大于或等于参数的最小整数 public static double floor(double a)\t// 返回小于或等于参数的最大整数 public static int round(float a)\t// 按照四舍五入返回最接近参数的int类型的值 public static int max(int a,int b)\t// 获取两个int值中的较大值 public static int min(int a,int b)\t// 获取两个int值中的较小值 public static double pow (double a,double b)\t// 计算a的b次幂的值 public static double random()\t// 返回一个[0.0,1.0)的随机值 13.2 System类 # System类所在包为java.lang包，因此在使用的时候不需要进行导包。并且System类被final修饰了，因此该类是不能被继承的。System包含了系统操作的一些常用的方法。比如获取当前时间所对应的毫秒值，再比如终止当前JVM等等。我们不能直接通过new关键字去创建System类的对象。同时我们发现System类中的方法都是静态的，因此在使用的时候我们可以直接通过类名去调用。\n常见方法：\npublic static long currentTimeMillis()\t// 获取当前时间所对应的毫秒值（当前时间为0时区所对应的时间即就是英国格林尼治天文台旧址所在位置） public static void exit(int status)\t// 终止当前正在运行的Java虚拟机，0表示正常退出，非零表示异常退出 public static native void arraycopy(Object src, int srcPos, Object dest, int destPos, int length); // 进行数值元素copy arraycopy方法底层细节：\n1.如果数据源数组和目的地数组都是基本数据类型，那么两者的类型必须保持一致，否则会报错\n2.在拷贝的时候需要考虑数组的长度，如果超出范围也会报错\n3.如果数据源数组和目的地数组都是引用数据类型，那么子类类型可以赋值给父类类型\n13.3 Runtime # Runtime表示Java中运行时对象，可以获取到程序运行时设计到的一些信息。\n常见方法：\npublic static Runtime getRuntime()\t//当前系统的运行环境对象 public void exit(int status)\t//停止虚拟机 public int availableProcessors()\t//获得CPU的线程数 public long maxMemory()\t//JVM能从系统中获取总内存大小（单位byte） public long totalMemory()\t//JVM已经从系统中获取总内存大小（单位byte） public long freeMemory()\t//JVM剩余内存大小（单位byte） public Process exec(String command) //运行cmd命令 13.4 Object类\u0026amp;对象克隆 # Object类所在包是java.lang包。Object 是类层次结构的根，每个类都可以将 Object 作为超类。所有类都直接或者间接的继承自该类；换句话说，该类所具备的方法，其他所有类都继承了。但是一般情况下我们很少去主动的创建Object类的对象，调用其对应的方法。更多的是创建Object类的某个子类对象，然后通过子类对象调用Object类中的方法。\n常见方法：\n/** * native 方法，用于返回当前运行时对象的 Class 对象，使用了 final 关键字修饰，故不允许子类重写。 */ public final native Class\u0026lt;?\u0026gt; getClass() /** * native 方法，用于返回对象的哈希码，主要使用在哈希表中，比如 JDK 中的HashMap。 */ public native int hashCode() /** * 用于比较 2 个对象的内存地址是否相等，String 类对该方法进行了重写以用于比较字符串的值是否相等。 */ public boolean equals(Object obj) /** * native 方法，用于创建并返回当前对象的一份拷贝。 */ protected native Object clone() throws CloneNotSupportedException /** * 返回类的名字实例的哈希码的 16 进制的字符串。建议 Object 所有的子类都重写这个方法。 */ public String toString() /** * native 方法，并且不能重写。唤醒一个在此对象监视器上等待的线程(监视器相当于就是锁的概念)。如果有多个线程在等待只会任意唤醒一个。 */ public final native void notify() /** * native 方法，并且不能重写。跟 notify 一样，唯一的区别就是会唤醒在此对象监视器上等待的所有线程，而不是一个线程。 */ public final native void notifyAll() /** * native方法，并且不能重写。暂停线程的执行。注意：sleep 方法没有释放锁，而 wait 方法释放了锁 ，timeout 是等待时间。 */ public final native void wait(long timeout) throws InterruptedException /** * 多了 nanos 参数，这个参数表示额外时间（以纳秒为单位，范围是 0-999999）。 所以超时的时间还需要加上 nanos 纳秒。。 */ public final void wait(long timeout, int nanos) throws InterruptedException /** * 跟之前的2个wait方法一样，只不过该方法一直等待，没有超时时间这个概念 */ public final void wait() throws InterruptedException /** * 实例被垃圾回收器回收的时候触发的操作 */ protected void finalize() throws Throwable { } 在通过输出语句输出一个对象时，默认调用的就是toString()方法 输出地址值一般没有意义，我们可以通过重写toString方法去输出对应的成员变量信息（快捷键：atl + insert ， 空白处 右键 -\u0026gt; Generate -\u0026gt; 选择toString） toString方法的作用：以良好的格式，更方便的展示对象中的属性值 一般情况下Jdk所提供的类都会重写Object类中的toString方法 13.4.1 ==和equals()的区别 # == 对于基本类型和引用类型的作用效果是不同的：\n对于基本数据类型来说，== 比较的是值。 对于引用数据类型来说，== 比较的是对象的内存地址。 因为 Java 只有值传递，所以，对于 == 来说，不管是比较基本数据类型，还是引用数据类型的变量，其本质比较的都是值，只是引用类型变量存的值是对象的地址。\nequals() 不能用于判断基本数据类型的变量，只能用来判断两个对象是否相等。equals()方法存在于Object类中，而Object类是所有类的直接或间接父类，因此所有的类都有equals()方法。\nObject 类 equals() 方法：\npublic boolean equals(Object obj) { return (this == obj); } equals() 方法存在两种使用情况：\n类没有重写 equals()方法：通过equals()比较该类的两个对象时，等价于通过“==”比较这两个对象，使用的默认是 Object类equals()方法。 类重写了 equals()方法：一般我们都重写 equals()方法来比较两个对象中的属性是否相等；若它们的属性相等，则返回 true(即，认为这两个对象相等)。 String 中的 equals 方法是被重写过的，因为 Object 的 equals 方法是比较的对象的内存地址，而 String 的 equals 方法比较的是对象的值。\n当创建 String 类型的对象时，虚拟机会在常量池中查找有没有已经存在的值和要创建的值相同的对象，如果有就把它赋给当前引用。如果没有就在常量池中重新创建一个 String 对象。\n13.4.2 String#equals()和Object#equals()的区别 # String 中的 equals 方法是被重写过的，比较的是 String 字符串的值是否相等。 Object 的 equals 方法是比较的对象的内存地址。\n13.4.3 对象克隆 # 对象克隆的分类：\n深克隆和浅克隆，还有一个引用克隆，但不常见。\n浅克隆：\n​\t不管对象内部的属性是基本数据类型还是引用数据类型，都完全拷贝过来\n​\t基本数据类型拷贝过来的是具体的数据，引用数据类型拷贝过来的是地址值。也就是说，==浅拷贝（克隆）会在堆上创建一个新的对象（区别于引用拷贝的一点），不过，如果原对象内部的属性是引用类型的话，浅拷贝会直接复制内部对象的引用地址，也就是说拷贝对象和原对象共用同一个内部对象。==\n​\tObject类默认的是浅克隆，想要进行深克隆，就需要重写clone方法并修改里面的方法体。\n深克隆：\n​\t基本数据类型拷贝过来，字符串复用，引用数据类型会重新创建新的。也就是说，==深拷贝会完全复制整个对象，包括这个对象所包含的内部对象。==\n引用拷贝：\n简单来说，==引用拷贝就是两个不同的引用指向同一个对象。==\n13.4.4 hashCode() # hashCode()有什么用？\nhashCode() 的作用是获取哈希码（int 整数），也称为散列码。这个哈希码的作用是确定该对象在哈希表中的索引位置。\nng)\nhashCode() 定义在 JDK 的 Object 类中，这就意味着 Java 中的任何类都包含有 hashCode() 函数。另外需要注意的是：Object 的 hashCode() 方法是本地方法，也就是用 C 语言或 C++ 实现的。\n该方法在 Oracle OpenJDK8 中默认是 \u0026ldquo;使用线程局部状态来实现 Marsaglia\u0026rsquo;s xor-shift 随机数生成\u0026rdquo;, 并不是 \u0026ldquo;地址\u0026rdquo; 或者 \u0026ldquo;地址转换而来\u0026rdquo;, 不同 JDK/VM 可能不同在 Oracle OpenJDK8 中有六种生成方式 (其中第五种是返回地址), 通过添加 VM 参数: -XX:hashCode=4 启用第五种。\n散列表存储的是键值对(key-value)，它的特点是：能根据“键”快速的检索出对应的“值”。这其中就利用到了散列码！（可以快速找到所需要的对象）\n为什么要有hashCode?\n我们以“HashSet 如何检查重复”为例子来说明为什么要有 hashCode？\n下面这段内容摘自我的 Java 启蒙书《Head First Java》:\n当你把对象加入 HashSet 时，HashSet 会先计算对象的 hashCode 值来判断对象加入的位置，同时也会与其他已经加入的对象的 hashCode 值作比较，如果没有相符的 hashCode，HashSet 会假设对象没有重复出现。但是如果发现有相同 hashCode 值的对象，这时会调用 equals() 方法来检查 hashCode 相等的对象是否真的相同。如果两者相同，HashSet 就不会让其加入操作成功。如果不同的话，就会重新散列到其他位置。这样我们就大大减少了 equals 的次数，相应就大大提高了执行速度。\n其实， hashCode() 和 equals()都是用于比较两个对象是否相等。\n为什么 JDK 还要同时提供这两个方法呢？\n因为在一些容器（比如 HashMap、HashSet）中，有了 hashCode() 之后，判断元素是否在对应容器中的效率会更高（参考添加元素进HashSet的过程）！\n我们在前面也提到了添加元素进HashSet的过程，如果 HashSet 在对比的时候，同样的 hashCode 有多个对象，它会继续使用 equals() 来判断是否真的相同。也就是说 hashCode 帮助我们大大缩小了查找成本。\n为什么不只提供 hashCode() 方法呢？\n这是因为两个对象的hashCode 值相等并不代表两个对象就相等。\n为什么两个对象有相同的 hashCode 值，它们也不一定是相等的？\n因为 hashCode() 所使用的哈希算法也许刚好会让多个对象传回相同的哈希值。越糟糕的哈希算法越容易碰撞，但这也与数据值域分布的特性有关（所谓哈希碰撞也就是指的是不同的对象得到相同的 hashCode )。\n总结下来就是：\n如果两个对象的hashCode 值相等，那这两个对象不一定相等（哈希碰撞）。 如果两个对象的hashCode 值相等并且equals()方法也返回 true，我们才认为这两个对象相等。 如果两个对象的hashCode 值不相等，我们就可以直接认为这两个对象不相等。 为什么重写equals()时必须重写hashCode()方法？\n因为两个相等的对象的 hashCode 值必须是相等。也就是说如果 equals 方法判断两个对象是相等的，那这两个对象的 hashCode 值也要相等。\n如果重写 equals() 时没有重写 hashCode() 方法的话就可能会导致 equals 方法判断是相等的两个对象，hashCode 值却不相等。\n13.4.5 两个不相等的对象有可能具有相同的hashCode吗 # ==有可能== **两个不相等的对象有可能具有相同的哈希码。**哈希码是由对象的哈希函数生成的一个整数值，用于支持快速查找和比较对象。 然而，由于哈希码的范围通常比对象的数量小得多，因此不同的对象可能会产生相同的哈希码。这种情况被称为哈希冲突。 哈希算法设计的目标是将不同的输入均匀分布在哈希码空间中，但无法避免完全消除冲突。因此，当发生哈希冲突时，哈希算法会使用特定的策略（例如链表或树结构）来处理这些冲突，以确保不同的对象可以存储在同一个哈希桶中。 综上所述，虽然不同的对象可能具有相同的哈希码，但哈希码仅用于初步判断对象是否可能相等，最终的相等性检查还需要通过 equals() 方法进行。因此，在重写 equals() 方法时，也应该相应地重写 hashCode() 方法，以尽量减少哈希冲突的发生。\n13.4.6 值传递和引用传递 # 值传递和引用传递是程序中常用的参数传递方式。\n值传递是指在函数调用时，将实际参数的值复制一份传递给形式参数，在函数内对形式参数的修改不会影响到实际参数的值。这意味着函数内部对形参的改变不会影响到函数外部的变量。在值传递中，对形参的修改只作用于函数内部。 引用传递是指在函数调用时，将实际参数的引用或地址传递给形式参数，函数内部对形参的修改会影响到实际参数。这意味着函数内部对形参的改变会影响到函数外部的变量。在引用传递中，对形参的修改会直接作用于函数外部的变量。 需要注意的是，引用传递实际上传递的是对象的引用或地址，并不是对象本身。对于基本数据类型（如整数、浮点数等），虽然也可以通过指针进行引用传递，但由于基本数据类型的值通常较小，因此通常采用值传递的方式。\n13.5 Objects类 # Objects类所在包是在java.util包下，因此在使用的时候需要进行导包。并且Objects类是被final修饰的，因此该类不能被继承。**Objects类提供了一些对象常见操作的方法。比如判断对象是否相等，判断对象是否为null等等。**我们可以发现Objects类中无无参构造方法，因此我们不能使用new关键字去创建Objects的对象。同时我们可以发现Objects类中所提供的方法都是静态的。因此我们可以通过类名直接去调用这些方法。\n常见方法：\npublic static String toString(Object o) // 获取对象的字符串表现形式 public static boolean equals(Object a, Object b)\t// 比较两个对象是否相等 public static boolean isNull(Object obj)\t// 判断对象是否为null public static boolean nonNull(Object obj)\t// 判断对象是否不为null 了解的方法：\npublic static \u0026lt;T\u0026gt; T requireNonNull(T obj)\t// 检查对象是否不为null,如果为null直接抛出异常；如果不是null返回该对象； public static \u0026lt;T\u0026gt; T requireNonNullElse(T obj, T defaultObj) // 检查对象是否不为null，如果不为null，返回该对象；如果为null返回defaultObj值 public static \u0026lt;T\u0026gt; T requireNonNullElseGet(T obj, Supplier\u0026lt;? extends T\u0026gt; supplier)\t// 检查对象是否不为null，如果不为null，返回该对象；如果\t// 为null,返回由Supplier所提供的值 13.6 BigIntrger类 # 基本数值类型都有一个表达范围，如果超过这个范围就会有数值溢出的风险。\n在 Java 中，64 位 long 整型是最大的整数类型。\nBigInteger，可以理解为：大的整数。理论上最大到42亿的21亿次方，基本上在内存撑爆之前，都无法达到这个上限。但相对于常规整数类型的运算来说，BigInteger 运算的效率会相对较低。\nBigInteger所在包是在java.math包下，因此在使用的时候就需要进行导包。我们可以使用BigInteger类进行大整数的计算。\n常见构造方法：\npublic BigInteger(int num, Random rnd) //获取随机大整数，范围：[0 ~ 2的num次方-1] public BigInteger(String val) //获取指定的大整数 public BigInteger(String val, int radix) //获取指定进制的大整数 下面这个不是构造，而是一个静态方法获取BigInteger对象 public static BigInteger valueOf(long val) //静态方法获取BigInteger的对象，内部有优化 如果BigInteger表示的数字没有超出long的范围，可以用静态方法获取。 如果BigInteger表示的超出long的范围，可以用构造方法获取。 对象一旦创建，BigInteger内部记录的值不能发生改变。 只要进行计算都会产生一个新的BigInteger对象 常见成员方法：\nBigDecimal类中使用最多的还是提供的进行四则运算的方法，如下：\npublic BigInteger add(BigInteger val)\t//加法 public BigInteger subtract(BigInteger val)\t//减法 public BigInteger multiply(BigInteger val)\t//乘法 public BigInteger divide(BigInteger val)\t//除法 public BigInteger[] divideAndRemainder(BigInteger val)\t//除法，获取商和余数 public boolean equals(Object x) //比较是否相同 public BigInteger pow(int exponent) //次幂、次方 public BigInteger max/min(BigInteger val) //返回较大值/较小值 public int intValue(BigInteger val) //转为int类型整数，超出范围数据有误 底层存储方式：\n对于计算机而言，其实是没有数据类型的概念的，都是0101010101，数据类型是编程语言自己规定的，所以在实际存储的时候，先把具体的数字变成二进制，每32个bit为一组，存储在数组中。\n数组中最多能存储元素个数：21亿多\n数组中每一位能表示的数字：42亿多\n理论上，BigInteger能表示的最大数字为：42亿的21亿次方。\n但是还没到这个数字，电脑的内存就会撑爆，所以一般认为BigInteger是无限的。\n存储方式如图所示：\n13.7 BigDecimal类 # 为什么浮点数运算的时候会有精度丢失的风险？\n这个和计算机保存浮点数的机制有很大关系。我们知道计算机是二进制的，而且计算机在表示一个数字时，宽度是有限的，无限循环的小数存储在计算机时，只能被截断，所以就会导致小数精度发生损失的情况。这也就是解释了为什么浮点数没有办法用二进制精确表示。\nBigDecimal 可以实现对浮点数的运算，不会造成精度丢失。通常情况下，大部分需要浮点数精确运算结果的业务场景（比如涉及到钱的场景）都是通过 BigDecimal 来做的。\nBigDecimal所在包是在java.math包下，因此在使用的时候就需要进行导包。我们可以使用BigDecimal类进行更加精准的数据计算。\n构造方法：\n常见成员方法：\npublic BigDecimal add(BigDecimal value)\t// 加法运算 public BigDecimal subtract(BigDecimal value)\t// 减法运算 public BigDecimal multiply(BigDecimal value)\t// 乘法运算 public BigDecimal divide(BigDecimal value)\t// 除法运算 如果使用BigDecimal类型的数据进行除法运算的时候，得到的结果是一个无限循环小数，那么就会报错：ArithmeticException。\n针对这个问题怎么解决，此时我们就需要使用到BigDecimal类中另外一个divide方法，如下所示：\nBigDecimal divide(BigDecimal divisor, int scale, int roundingMode) 上述divide方法参数说明：\ndivisor:\t除数对应的BigDecimal对象； scale:\t精确的位数； roundingMode:\t取舍模式； 取舍模式被封装到了RoundingMode这个枚举类中（关于枚举我们后期再做重点讲解），在这个枚举类中定义了很多种取舍方式。最常见的取舍方式有如下几个： UP(直接进1) ， FLOOR(直接删除) ， HALF_UP(4舍五入),我们可以通过如下格式直接访问这些取舍模式：枚举类名.变量名 后期在进行两个数的除法运算的时候，我们常常使用的是可以设置取舍模式的divide方法。\n底层存储方式：\n把数据看成字符串，遍历得到里面的每一个字符，把这些字符在ASCII码表上的值，都存储到数组中。\n13.7.1 BigDecimal常见陷阱 # 13.7.1.1 使用BigDecimal的构造函数传入浮点数 # 其实这个问题我们在使用Float、Double等浮点类型进行计算时，也会经常遇到，如1-0.9f，输出结果是0.100000024。因为 0.9 无法被精确表示为有限位数的二进制小数。在转换为二进制时可能会产生近似值。因此，在进行减法运算时，实际上是对近似值进行计算，而不是对准确的 0.9 进行计算。这导致了精度丢失，最终的计算结果也是一个近似值。因此，输出结果不是准确的 0.1，而是一个近似值。我们在创建BigDecimal对象时，有初始值使用BigDecimal.valueOf()的方式，可以避免出现精度问题。\n@Test public void bigDecimalDemo2(){ BigDecimal bigDecimal1 = new BigDecimal(0.01); BigDecimal bigDecimal2 = BigDecimal.valueOf(0.01); System.out.println(\u0026#34;bigDecimal1 = \u0026#34; + bigDecimal1); System.out.println(\u0026#34;bigDecimal2 = \u0026#34; + bigDecimal2); } Output：\nbigDecimal1 = 0.01000000000000000020816681711721685132943093776702880859375 bigDecimal2 = 0.01 为什么会出现差异？\n在使用new BigDecimal()实际上是将 0.01 转换为二进制近似值，并将其存储为 BigDecimal 对象。因此，结果中存在微小的误差，即输出结果为0.01000000000000000020816681711721685132943093776702880859375。 而BigDecimal.valueOf()不同，其内部是先将double转为String，因此不存在精度问题。\nTIPS:\n使用整数或长整数作为参数构造：\nBigDecimal(int val)：使用一个 int 类型的整数值创建 BigDecimal。\n○BigDecimal(long val)：使用一个 long 类型的整数值创建 BigDecimal。\n使用字符串作为参数构造：\nBigDecimal(String val)：使用一个字符串表示的数值创建 BigDecimal。该字符串可以包含整数部分、小数部分和指数部分。 使用双精度浮点数作为参数构造：\nBigDecimal(double val)：使用一个 double 类型的浮点数值创建 BigDecimal。注意，由于浮点数精度可能丢失，建议使用字符串或其他方法构造 BigDecimal，以避免精度损失问题。 使用基于 BigInteger 的构造方法：\nBigDecimal(BigInteger val)：使用一个 BigInteger 对象来创建 BigDecimal。 13.7.1.2 使用equals()方法进行数值比较 # 日常项目我们是如何进行BigDecimal数值比较呢？使用equals方法还是compareTo方法？如果使用的是equals方法，那就需要注意啦。看一下示例：\nmal bigDecimal1 = new BigDecimal(\u0026#34;0.01\u0026#34;); BigDecimal bigDecimal2 = new BigDecimal(\u0026#34;0.010\u0026#34;); System.out.println(bigDecimal1.equals(bigDecimal2)); System.out.println(bigDecimal1.compareTo(bigDecimal2)); } Output：\nfalse 0 观察结果可以知道使用equals比较结果是不相等的；compareTo的结果为0代表两个数相等；\ncompareTo实现了Comparable接口，比较的是值的大小，返回的值为-1-小于，0-等于，1-大于。 为什么equals返回的是false？\npublic boolean equals(Object x) { if (!(x instanceof BigDecimal)) return false; BigDecimal xDec = (BigDecimal) x; if (x == this) return true; if (scale != xDec.scale) return false; long s = this.intCompact; long xs = xDec.intCompact; if (s != INFLATED) { if (xs == INFLATED) xs = compactValFor(xDec.intVal); return xs == s; } else if (xs != INFLATED) return xs == compactValFor(this.intVal); return this.inflated().equals(xDec.inflated()); } 我们观察equals的实现逻辑可以知道，BigDecimal重写了equals方法，重写后的关键代码：\nif (scale != xDec.scale) return false; 也就是会比较两个数值的精度，精度不同返回false。\n","date":"11 March 2025","externalUrl":null,"permalink":"/posts/1741665094216-%E5%B8%B8%E8%A7%81api%E5%AF%B9%E8%B1%A1%E5%85%8B%E9%9A%86/","section":"Posts","summary":"","title":"常见API\u0026对象克隆","type":"posts"},{"content":" 时间\u0026amp;包装类 # 1.1 Date类 # java.util.Date类 表示特定的瞬间，精确到毫秒。\npublic Date()：从运行程序的此时此刻到时间原点经历的毫秒值,转换成Date对象，分配Date对象并初始化此对象，以表示分配它的时间（精确到毫秒）。 public Date(long date)：将指定参数的毫秒值date,转换成Date对象，分配Date对象并初始化此对象，以表示自从标准基准时间（称为“历元（epoch）”，即1970年1月1日00:00:00 GMT）以来的指定毫秒数。 tips: 由于中国处于东八区（GMT+08:00）是比世界协调时间/格林尼治时间（GMT）快8小时的时区，当格林尼治标准时间为0:00时，东八区的标准时间为08:00。\n简单来说：使用无参构造，可以自动设置当前系统时间的毫秒时刻；指定long类型的构造参数，可以自定义毫秒时刻。\nDate类中的多数方法已经过时，常用的方法有：\npublic long getTime() 把日期对象转换成对应的时间毫秒值。 public void setTime(long time) 把方法参数给定的毫秒值设置给日期对象 1.2 SimpleDateFormat类 # java.text.SimpleDateFormat 是日期/时间格式化类，我们通过这个类可以帮我们完成日期和文本之间的转换,也就是可以在Date对象与String对象之间进行来回转换。\n格式化：按照指定的格式，把Date对象转换为String对象。 解析：按照指定的格式，把String对象转换为Date对象。 由于DateFormat为抽象类，不能直接使用，所以需要常用的子类java.text.SimpleDateFormat。这个类需要一个模式（格式）来指定格式化或解析的标准。构造方法为：\npublic SimpleDateFormat(String pattern)：用给定的模式和默认语言环境的日期格式符号构造SimpleDateFormat。参数pattern是一个字符串，代表日期时间的自定义格式。 常用的格式规则为：\n标识字母（区分大小写） 含义 y 年 M 月 d 日 H 时 m 分 s 秒 备注：更详细的格式规则，可以参考SimpleDateFormat类的API文档。\nDateFormat类的常用方法有：\npublic String format(Date date)：将Date对象格式化为字符串。\npublic Date parse(String source)：将字符串解析为Date对象。\n//1.定义一个字符串表示时间 String str = \u0026#34;2023-11-11 11:11:11\u0026#34;; //2.利用空参构造创建simpleDateFormat对象 // 细节: //创建对象的格式要跟字符串的格式完全一致 SimpleDateFormat sdf = new SimpleDateFormat(\u0026#34;yyyy-MM-dd HH:mm:ss\u0026#34;); 1.3 Calendar类 # java.util.Calendar类表示一个“日历类”，可以进行日期运算。它是一个抽象类，不能创建对象，我们可以使用它的子类：java.util.GregorianCalendar类。 有两种方式可以获取GregorianCalendar对象： 直接创建GregorianCalendar对象； 通过Calendar的静态方法getInstance()方法获取GregorianCalendar对象 方法名 说明 public static Calendar getInstance() 获取一个它的子类GregorianCalendar对象。 public int get(int field) 获取某个字段的值。field参数表示获取哪个字段的值，\n可以使用Calender中定义的常量来表示：\nCalendar.YEAR : 年\nCalendar.MONTH ：月\nCalendar.DAY_OF_MONTH：月中的日期\nCalendar.HOUR：小时\nCalendar.MINUTE：分钟\nCalendar.SECOND：秒\nCalendar.DAY_OF_WEEK：星期 public void set(int field,int value) 设置某个字段的值 public void add(int field,int amount) 为某个字段增加/减少指定的值 1.4 JDK8时间相关类 # JDK8时间类类名 作用 ZoneId 时区 Instant 时间戳 ZoneDateTime 带时区的时间 DateTimeFormatter 用于时间的格式化和解析 LocalDate 年、月、日 LocalTime 时、分、秒 LocalDateTime 年、月、日、时、分、秒 Duration 时间间隔（秒，纳，秒） Period 时间间隔（年，月，日） ChronoUnit 时间间隔（所有单位） 1.5 包装类 # Java提供了两个类型系统，基本类型与引用类型，使用基本类型在于效率，然而很多情况，会创建对象使用，因为对象可以做更多的功能，如果想要我们的基本类型像对象一样操作，就可以使用基本类型对应的包装类。\n包装数据类型‌是Java编程语言中的一个重要概念，用于将基本数据类型（如byte、short、int、long、float、double、char、boolean）封装为对象类型。这样做的主要目的是为了弥补Java作为面向对象语言在处理基本数据类型时的一些不足，确保“一切皆对象”的原则得以实现‌。\n基本类型 对应的包装类（位于java.lang包中） byte Byte short Short int Integer long Long float Float double Double char Character boolean Boolean Integer类：\nInteger类概述\n包装一个对象中的原始类型 int 的值\nInteger类构造方法及静态方法\n方法名 说明 public Integer(int value) 根据 int 值创建 Integer 对象(过时) public Integer(String s) 根据 String 值创建 Integer 对象(过时) public static Integer valueOf(int i) 返回表示指定的 int 值的 Integer 实例 public static Integer valueOf(String s) 返回保存指定String值的 Integer 对象 static string tobinarystring(int i) 得到二进制 static string tooctalstring(int i) 得到八进制 static string toHexstring(int i) 得到十六进制 static int parseInt(string s) 将字符串类型的整数转成int类型的整数 1.5.1 装箱与拆箱 # 基本类型与对应的包装类对象之间，来回转换的过程称为”装箱“与”拆箱“：\n装箱：从基本类型转换为对应的包装类对象。 拆箱：从包装类对象转换为对应的基本类型。 用Integer与 int为例：（看懂代码即可）\n基本数值\u0026mdash;-\u0026gt;包装对象\nInteger i = new Integer(4);//使用构造函数函数 Integer iii = Integer.valueOf(4);//使用包装类中的valueOf方法 包装对象\u0026mdash;-\u0026gt;基本数值\nint num = i.intValue(); 自动装箱与自动拆箱：\n由于我们经常要做基本类型与包装类之间的转换，从Java 5（JDK 1.5）开始，基本类型与包装类的装箱、拆箱动作可以自动完成。\n如果频繁拆装箱的话，也会严重影响系统的性能。我们应该尽量避免不必要的拆装箱操作。\n1.5.2 基本类型与包装类型的区别 # 用途：除了定义一些常量和局部变量之外，我们在其他地方比如方法参数、对象属性中很少会使用基本类型来定义变量。并且，包装类型可用于泛型，而基本类型不可以。\n存储方式：基本数据类型的局部变量存放在 Java 虚拟机栈中的局部变量表中，基本数据类型的成员变量（未被 static 修饰 ）存放在 Java 虚拟机的堆中。包装类型属于对象类型，我们知道几乎所有对象实例都存在于堆中。\n占用空间：相比于包装类型（对象类型）， 基本数据类型占用的空间往往非常小。\n默认值：成员变量包装类型不赋值就是 null ，而基本类型有默认值且不是 null。\n比较方式：对于基本数据类型来说，== 比较的是值。对于包装数据类型来说，== 比较的是对象的内存地址。所有整型包装类对象之间值的比较，全部使用 equals() 方法。\n为什么说是几乎所有对象实例都存在于堆中呢？ 这是因为 HotSpot 虚拟机引入了 JIT 优化之后，会对对象进行逃逸分析，如果发现某一个对象并没有逃逸到方法外部，那么就可能通过标量替换来实现栈上分配，而避免堆上分配内存。\n基本数据类型存放在栈中是一个常见的误区， 基本数据类型的存储位置取决于它们的作用域和声明方式。如果它们是局部变量，那么它们会存放在栈中；如果它们是成员变量，那么它们会存放在堆/方法区/元空间中。\n1.5.3 包装类型的缓存机制 # Java 基本数据类型的包装类型的大部分都用到了缓存机制来提升性能。\nByte,Short,Integer,Long 这 4 种包装类默认创建了数值 [-128，127] 的相应类型的缓存数据，Character 创建了数值在 [0,127] 范围的缓存数据，Boolean 直接返回 True or False。\n如果超出对应范围仍然会去创建新的对象，缓存的范围区间的大小只是在性能和资源之间的权衡。\n两种浮点数类型的包装类 Float,Double 并没有实现缓存机制。\n所有整型包装类对象之间值的比较，全部使用 equals 方法比较。\n1.5.4 基本类型与字符串之间的转换 # 基本类型转换为String\n转换方式 方式一：直接在数字后加一个空字符串 方式二：通过String类静态方法valueOf() String转换成基本类型\n除了Character类之外，其他所有包装类都具有parseXxx静态方法可以将字符串参数转换为对应的基本类型：\npublic static byte parseByte(String s)：将字符串参数转换为对应的byte基本类型。 public static short parseShort(String s)：将字符串参数转换为对应的short基本类型。 public static int parseInt(String s)：将字符串参数转换为对应的int基本类型。 public static long parseLong(String s)：将字符串参数转换为对应的long基本类型。 public static float parseFloat(String s)：将字符串参数转换为对应的float基本类型。 public static double parseDouble(String s)：将字符串参数转换为对应的double基本类型。 public static boolean parseBoolean(String s)：将字符串参数转换为对应的boolean基本类型。 注意:如果字符串参数的内容无法正确转换为对应的基本类型，则会抛出java.lang.NumberFormatException异常。\n底层原理：\n建议：获取Integer对象的时候不要自己new，而是采取直接赋值或者静态方法valueOf的方式\n因为在实际开发中，-128~127之间的数据，用的比较多。如果每次使用都是new对象，那么太浪费内存了。\n所以，提前把这个范围之内的每一个数据都创建好对象，如果要用到了不会创建新的，而是返回已经创建好的对象。\n1.5.5 int 和 Integer 的区别 # int和Integer之间的区别主要在以下几个方面：\n数据类型：int是Java的基本数据类型，而Integer是int的包装类，属于引用类型。 可空性：int是基本数据类型，它不能为null。而Integer是一个对象，可以为null。 自动装箱与拆箱：int可以直接赋值给Integer，这个过程称为自动装箱；而Integer也可以直接赋值给int，这个过程称为自动拆箱。 性能和内存开销：由于int是基本数据类型，它的值直接存储在栈内存中，占用的空间较小且访问速度快。而Integer是对象，它的值存储在堆内存中，占用的空间相对较大，并且访问速度较慢。因此，频繁使用的整数推荐使用int，不需要使用对象特性时可以避免使用Integer。 总的来说，int是基本数据类型，适用于简单的整数运算和存储，没有对象的特性和可空性。而Integer是int的包装类，可以作为对象使用，具有更多的方法和一些方便的功能，如转换、比较等，但相对会带来一些性能和内存开销。\n","date":"11 March 2025","externalUrl":null,"permalink":"/posts/1741665209773-%E6%97%B6%E9%97%B4%E7%B1%BB%E5%8C%85%E8%A3%85%E7%B1%BB/","section":"Posts","summary":"","title":"时间类\u0026包装类","type":"posts"},{"content":" 正则表达式 # 1.1 正则表达式的概念 # 正则表达式就是用来验证各种字符串的规则。它内部描述了一些规则，我们可以验证用户输入的字符串是否匹配这个规则。\n1.2 正则表达式-字符类 # 语法示例： [abc]：代表a或者b，或者c字符中的一个。 [^abc]：代表除a,b,c以外的任何字符。 [a-z]：代表a-z的所有小写字符中的一个。 [A-Z]：代表A-Z的所有大写字符中的一个。 [0-9]：代表0-9之间的某一个数字字符。 [a-zA-Z0-9]：代表a-z或者A-Z或者0-9之间的任意一个字符。 [a-dm-p]：a 到 d 或 m 到 p之间的任意一个字符。 1.3 正则表达式-逻辑运算符 # 语法示例：\n\u0026amp;\u0026amp;：并且 | ：或者 \\ ：转义字符（改变后面那个字符原本的含义，就是把原本的识别改为普通字符，如\u0026quot;\\\u0026quot;\u0026quot;） 1.4 正则表达式-预定义字符 # 语法示例：\n\u0026ldquo;.\u0026rdquo; ： 匹配任何字符。 \u0026ldquo;\\d\u0026rdquo;：任何数字[0-9]的简写； \u0026ldquo;\\D\u0026rdquo;：任何非数字[^0-9]的简写； \u0026ldquo;\\s\u0026rdquo;： 空白字符：[ \\t\\n\\x0B\\f\\r] 的简写 \u0026ldquo;\\S\u0026rdquo;： 非空白字符：[^\\s] 的简写 \u0026ldquo;\\w\u0026rdquo;：单词字符：[a-zA-Z_0-9]的简写 \u0026ldquo;\\W\u0026rdquo;：非单词字符：[^\\w] 1.5 正则表达式-数量词 # 语法示例：\nX? : 0次或1次 X* : 0次到多次 X+ : 1次或多次 X{n} : 恰好n次 X{n,} : 至少n次 X{n,m}: n到m次(n和m都是包含的) 1.6 本地数据爬取 # Pattern：表示正则表达式 Matcher：文本匹配器，作用按照正则表达式的规则去读取字符串，从头开始读取。 在大串中去找符合匹配规则的子串。\n//1.获取正则表达式的对象 Pattern p = Pattern.compile(\u0026#34;Java\\\\d{0,2}\u0026#34;); //2.获取文本匹配器的对象 //拿着m去读取str，找符合p规则的子串 Matcher m = p.matcher(str); //3.利用循环获取 while (m.find()) { String s = m.group(); System.out.println(s); } 1.7 贪婪爬取和非贪婪爬取 # 只写+和表示贪婪匹配，如果在+和后面加问号表示非贪婪爬取 +? 非贪婪匹配 *? 非贪婪匹配 贪婪爬取:在爬取数据的时候尽可能的多获取数据 非贪婪爬取:在爬取数据的时候尽可能的少获取数据 举例： 如果获取数据：ab+ 贪婪爬取获取结果:abbbbbbbbbbbb 非贪婪爬取获取结果:ab 1.8 String的split方法中使用正则表达式 # String类的split()方法原型：\npublic String[] split(String regex) //参数regex表示正则表达式。可以将当前字符串中匹配regex正则表达式的符号作为\u0026#34;分隔符\u0026#34;来切割字符串。 1.9 String类的replaceAll方法中使用正则表达式 # String类的replaceAll()方法原型： public String replaceAll(String regex,String newStr) //参数regex表示一个正则表达式。可以将当前字符串中匹配regex正则表达式的字符串替换为newStr。 1.10 正则表达式-分组括号( ) # 细节：如何识别组号？\n只看左括号，不看有括号，按照左括号的顺序，从左往右，依次为第一组，第二组，第三组等等\n// \\\\组号:表示把第X组的内容再出来用一次 String regex1 = \u0026#34;(.).+\\\\1\u0026#34;; System.out.println(\u0026#34;a123a\u0026#34;.matches(regex1)); 忽略大小写的写法:\n//(?i) ：表示忽略后面数据的大小写 //忽略abc的大小写 String regex = \u0026#34;(?i)abc\u0026#34;; //a需要一模一样，忽略bc的大小写 String regex = \u0026#34;a(?i)bc\u0026#34;; //ac需要一模一样，忽略b的大小写 String regex = \u0026#34;a((?i)b)c\u0026#34;; ","date":"11 March 2025","externalUrl":null,"permalink":"/posts/1741665184380-%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/","section":"Posts","summary":"","title":"正则表达式","type":"posts"},{"content":"","date":"11 March 2025","externalUrl":null,"permalink":"/tags/%E9%9B%86%E5%90%88/","section":"Tags","summary":"","title":"集合","type":"tags"},{"content":" static \u0026amp; 继承 # Java中成员（变量和方法）等是存在属性的，Java通过static关键字来进行区分。static关键字在Java开发非常的重要，对于理解面向对象非常关键。\n关于 static 关键字的使用，它可以用来修饰的成员变量和成员方法，被static修饰的成员是属于类的是放在静态区中，没有static修饰的成员变量和方法则是属于对象的。我们上面案例中的成员变量都是没有static修饰的，所以属于每个对象。\n1.1 static关键字 # 1.1.1 定义格式和使用 # static是静态的意思。 static可以修饰成员变量或者修饰方法。\n静态变量及其访问：\n有static修饰成员变量，说明这个成员变量是属于类的，这个成员变量称为类变量或者静态成员变量。 直接用 类名访问即可。因为类只有一个，所以静态成员变量在内存区域中也只存在一份。所有的对象都可以共享这个变量。\n静态变量是通过类名来访问的，例如StaticVariableExample.staticVar（如果被 private关键字修饰就无法这样访问了）。\n通常情况下，静态变量会被 final 关键字修饰成为常量。\n实例变量及其访问：\n无static修饰的成员变量属于每个对象的， 这个成员变量叫实例变量，之前我们写成员变量就是实例成员变量。\n需要注意的是：实例成员变量属于每个对象，必须创建类的对象才可以访问。\n格式：对象.实例成员变量\n静态方法及其访问：\n有static修饰成员方法，说明这个成员方法是属于类的，这个成员方法称为类方法或者静态方法。 直接用 类名访问即可。因为类只有一个，所以静态方法在内存区域中也只存在一份。所有的对象都可以共享这个方法。\n与静态成员变量一样，静态方法也是直接通过类名.方法名称即可访问。\n实例方法及其访问：\n无static修饰的成员方法属于每个对象的，这个成员方法也叫做实例方法。\n需要注意的是：实例方法是属于每个对象，必须创建类的对象才可以访问。\n1.1.2 静态方法和实例方法有何不同? # 1、调用方式\n在外部调用静态方法时，可以使用 类名.方法名 的方式，也可以使用 对象.方法名 的方式，而实例方法只有后面这种方式。也就是说，调用静态方法可以无需创建对象 。\n不过，需要注意的是一般不建议使用 对象.方法名 的方式来调用静态方法。这种方式非常容易造成混淆，静态方法不属于类的某个对象而是属于这个类。\n因此，一般建议使用 类名.方法名 的方式来调用静态方法。\n2、访问类成员是否存在限制\n静态方法在访问本类的成员时，只允许访问静态成员（即静态成员变量和静态方法），不允许访问实例成员（即实例成员变量和实例方法），而实例方法不存在这个限制。\n1.2 继承 # 假如多个类中存在相同属性和行为时，我们可以将这些内容抽取到单独一个类中，那么多个类无需再定义这些属性和行为，只要继承那一个类即可。\n其中，多个类可以称为子类，单独被继承的那一个类称为父类、超类（superclass）或者基类。\n1.2.1 继承的含义 # 继承描述的是事物之间的所属关系，这种关系是：is-a 的关系。父类更通用，子类更具体。我们通过继承，可以使多种事物之间形成一种关系体系。\n继承：就是子类继承父类的属性和行为，使得子类对象可以直接具有与父类相同的属性、相同的行为。子类可以直接访问父类中的非私有的属性和行为。\n不同类型的对象，相互之间经常有一定数量的共同点，但同时，每一个对象还定义了额外的特性使得他们与众不同。==继承是使用已存在的类的定义作为基础建立新类的技术，新类的定义可以增加新的数据或新的功能，也可以用父类的功能，但不能选择性地继承父类。==\n子类拥有父类对象所有的属性和方法（包括私有属性和私有方法），但是父类中的私有属性和方法子类是无法访问，只是拥有。\n子类可以拥有自己属性和方法，即子类可以对父类进行扩展。\n子类可以用自己的方式实现父类的方法（方法重写）。\n继承的好处：\n通过使用继承，可以快速地创建新的类，可以提高代码的重用，程序的可维护性，节省大量创建新类的时间 ，提高我们的开发效率。 使类与类之间产生了关系。 1.2.2 继承的格式 # 通过 extends 关键字，可以声明一个子类继承另外一个父类。\nclass 父类 { ... } class 子类 extends 父类 { ... } Java是单继承的，一个类只能继承一个直接父类，跟现实世界很像，但是Java中的子类是更加强大的。\n1.2.3 子类不能继承的内容 # 子类不能继承父类的构造方法。\n值得注意的是子类可以继承父类的私有成员（成员变量，方法），只是子类无法直接访问而已，可以通过getter/setter方法访问父类的private成员变量。\n1.2.4 继承后的特点—成员变量 # 成员变量不重名:\n如果子类父类中出现不重名的成员变量，这时的访问是没有影响的。\n成员变量重名:\n如果子类父类中出现重名的成员变量，这时的访问是有影响的。子父类中出现了同名的成员变量时，子类会优先访问自己对象中的成员变量。如果此时想访问父类成员变量,我们可以使用super关键字。\nsuper访问父类成员变量:\n子父类中出现了同名的成员变量时，在子类中需要访问父类中非私有成员变量时，需要使用super 关键字，修饰父类成员变量，类似于之前学过的 this 。\nsuper代表的是父类对象的引用，this代表的是当前对象的引用。\nFu 类中的成员变量是非私有的，子类中可以直接访问。若Fu 类中的成员变量私有了，子类是不能直接访问的。通常编码时，我们遵循封装的原则，使用private修饰成员变量，那么访问父类的私有成员变量就可以使用在父类中提供公共的getXxx方法和setXxx方法。\n1.2.5 继承后的特点——成员方法 # 成员方法不重名：\n如果子类父类中出现不重名的成员方法，这时的调用是没有影响的。对象调用方法时，会先在子类中查找有没有对应的方法，若子类中存在就会执行子类中的方法，若子类中不存在就会执行父类中相应的方法。\n成员方法重名:\n如果子类父类中出现重名的成员方法，则创建子类对象调用该方法的时候，子类对象会优先调用自己的方法。\n1.2.6 方法重写 # 1.2.6.1 概念 # 方法重写 ：子类中出现与父类一模一样的方法时（返回值类型，方法名和参数列表都相同），会出现覆盖效果，也称为重写或者复写。声明不变，重新实现。\n发生在子父类之间的关系。子类继承了父类的方法，但是子类觉得父类的这方法不足以满足自己的需求，子类重新写了一个与父类同名的方法，以便覆盖父类的该方法。\n重载和重写有什么区别？\n重载就是同样的一个方法能够根据输入数据的不同，做出不同的处理，也就是同一个类中多个同名方法根据不同的传参来执行不同的逻辑处理。\n重写就是当子类继承自父类的相同方法，输入数据一样，但要做出有别于父类的响应时，你就要覆盖父类方法\n重载发生在同一个类中（或者父类和子类之间），方法名必须相同，参数类型不同、个数不同、顺序不同，方法返回值和访问修饰符可以不同。\n《Java 核心技术》这本书是这样介绍重载的：\n如果多个方法(比如 StringBuilder 的构造方法)有相同的名字、不同的参数， 便产生了重载。\n编译器必须挑选出具体执行哪个方法，它通过用各个方法给出的参数类型与特定方法调用所使用的值类型进行匹配来挑选出相应的方法。 如果编译器找不到匹配的参数， 就会产生编译时错误， 因为根本不存在匹配， 或者没有一个比其他的更好(这个过程被称为重载解析(overloading resolution))。\nJava 允许重载任何方法， 而不只是构造器方法。\n重写发生在运行期，是子类对父类的允许访问的方法的实现过程进行重新编写。\n方法名、参数列表必须相同，子类方法返回值类型应比父类方法返回值类型更小或相等，抛出的异常范围小于等于父类，访问修饰符范围大于等于父类。 如果父类方法访问修饰符为 private/final/static 则子类就不能重写该方法，但是被 static 修饰的方法能够被再次声明。 构造方法无法被重写 综上：重写就是子类对父类方法的重新改造，外部样子不能改变，内部逻辑可以改变。\n区别点 重载方法 重写方法 发生范围 同一个类 子类 参数列表 必须修改 一定不能修改 返回类型 可修改 子类方法返回值类型应比父类方法返回值类型更小或相等 异常 可修改 子类方法声明抛出的异常类应比父类方法声明抛出的异常类更小或相等； 访问修饰符 可修改 一定不能做更严格的限制（可以降低限制） 发生阶段 编译期 运行期 方法的重写要遵循“两同两小一大”\n“两同”即方法名相同、形参列表相同；\n“两小”指的是子类方法返回值类型应比父类方法返回值类型更小或相等，子类方法声明抛出的异常类应比父类方法声明抛出的异常类更小或相等；\n“一大”指的是子类方法的访问权限应比父类方法的访问权限更大或相等。\n关于 重写的返回值类型 这里需要额外多说明一下，上面的表述不太清晰准确：如果方法的返回类型是 void 和基本数据类型，则返回值重写时不可修改。但是如果方法的返回值是引用类型，重写时是可以返回该引用类型的子类的\n1.2.6.2 @Override重写注解 # @Override:注解，重写注解校验\n这个注解标记的方法，就说明这个方法必须是重写父类的方法，否则编译阶段报错。\n建议重写都加上这个注解，一方面可以提高代码的可读性，一方面可以防止重写出错。\n注意事项：\n方法重写是发生在子父类之间的关系。 子类方法覆盖父类方法，必须要保证权限大于等于父类权限。 子类方法覆盖父类方法，返回值类型、函数名和参数列表都要一模一样。 1.2.6.3 构造器是否可以被重写 # **构造器在Java中是一种特殊的方法，用于创建和初始化对象。**与其他普通方法不同，构造器的名称必须与类名一致，并且没有返回类型。 **在Java中，构造器不能被直接重写。**子类无法定义与父类相同名称和参数的构造器。这是因为构造器是用于创建对象并初始化其状态的特殊方法，它与类的实例化密切相关。如果允许子类重写构造器，那么可能会导致对象的创建和初始化过程出现混乱，破坏了类的结构和设计原则。 然而，**子类可以通过调用父类的构造器来完成对继承的父类的初始化操作。**在子类的构造器中可以使用关键字super来调用父类的构造器，并传递相应的参数。这样可以确保父类的构造器得到正确地执行，从而完成对父类属性的初始化。 总结起来，构造器本身不能被重写，但子类可以通过调用父类的构造器来实现对父类的初始化操作。\n1.2.7 继承后的特点—构造方法 # 构造方法的定义格式和作用：\n构造方法的名字是与类名一致的。所以子类是无法继承父类构造方法的。 构造方法的作用是初始化对象成员变量数据的。所以子类的初始化过程中，必须先执行父类的初始化动作。子类的构造方法中默认有一个super() ，表示调用父类的构造方法，父类成员变量初始化后，才可以给子类使用。（先有爸爸，才能有儿子） 继承后子类构方法器特点:子类所有构造方法的第一行都会默认先调用父类的无参构造方法\n子类构造方法执行的时候，都会在第一行默认先调用父类无参数构造方法一次。 子类构造方法的第一行都隐含了一个**super()**去调用父类无参数构造方法，**super()**可以省略不写。 1.2.8 super(\u0026hellip;)和this(\u0026hellip;) # 子类有参数构造方法只是初始化了自己对象中的成员变量，而父类中的成员变量依然是没有数据的，怎么解决这个问题呢，我们可以借助与super(\u0026hellip;)去调用父类构造方法，以便初始化继承自父类对象的成员变量。\n关于super与this的例子：\nclass Person { private String name =\u0026#34;凤姐\u0026#34;; private int age = 20; public Person() { System.out.println(\u0026#34;父类无参\u0026#34;); } public Person(String name , int age){ this.name = name ; this.age = age ; } // getter/setter省略 } class Student extends Person { private double score = 100; public Student() { //super(); // 调用父类无参构造方法,默认就存在，可以不写，必须再第一行 System.out.println(\u0026#34;子类无参\u0026#34;); } public Student(String name ， int age，double score) { super(name ,age);// 调用父类有参构造方法Person(String name , int age)初始化name和age this.score = score; System.out.println(\u0026#34;子类有参\u0026#34;); } // getter/setter省略 } public class Demo07 { public static void main(String[] args) { // 调用子类有参数构造方法 Student s2 = new Student(\u0026#34;张三\u0026#34;，20，99); System.out.println(s2.getScore()); // 99 System.out.println(s2.getName()); // 输出 张三 System.out.println(s2.getAge()); // 输出 20 } } 子类的每个构造方法中均有默认的super()，调用父类的空参构造。手动调用父类构造会覆盖默认的super()。\nsuper() 和 this() 都必须是在构造方法的第一行，所以不能同时出现。\nsuper(..)是根据参数去确定调用父类哪个构造方法的。\n1.2.8.1 super(…)案例图解 # 父类空间优先于子类对象产生\n在每次创建子类对象时，先初始化父类空间，再创建其子类对象本身。目的在于子类对象中包含了其对应的父类空间，便可以包含其父类的成员，如果父类成员非private修饰，则子类可以随意使用父类成员。代码体现在子类的构造七调用时，一定先调用父类的构造方法。理解图解如下：\n1.2.8.2 this(\u0026hellip;)用法演示 # this(\u0026hellip;)\n默认是去找本类中的其他构造方法，根据参数来确定具体调用哪一个构造方法。 为了借用其他构造方法的功能。 1.2.9 继承的特点 # Java只支持单继承，不支持多继承。\n一个类可以有多个子类。\n可以多层继承。\n顶层父类是Object类。所有的类默认继承Object，作为父类。\n关于不支持多继承：\n==Java不直接支持多继承，即一个类不能同时继承多个父类。==这是由设计上的考虑和语言特性决定的。 Java中选择了单继承的设计，主要出于以下几个原因：\n继承的复杂性：多继承会引入菱形继承等复杂性问题。当一个类同时继承自多个父类时，可能会出现命名冲突、方法重复实现等问题，导致代码难以理解和维护。 接口的存在：Java提供了接口（Interface）的概念来解决多继承的问题。接口允许一个类实现多个接口，从而达到类似多继承的效果。接口与类的分离可以降低代码的耦合度，并且使得类的设计更加灵活和可扩展。 单一职责原则：Java鼓励使用组合而非继承的方式，遵循设计原则中的单一职责原则。通过将功能划分为独立的类，然后在需要时进行组合，可以实现更灵活、可复用的代码结构，提高代码的可维护性。 尽管Java不支持直接的多继承，**但可以使用接口或抽象类等方式来模拟部分多继承的功能。**接口提供了一种更灵活、更安全的多继承方式，允许类实现多个接口并获得各个接口的方法声明，同时避免了多继承的复杂性问题。\n","date":"7 March 2025","externalUrl":null,"permalink":"/posts/1741323987049-java-static%E7%BB%A7%E6%89%BF/","section":"Posts","summary":"","title":"java static\u0026继承","type":"posts"},{"content":" Java基础概念 # 1.1 注释 # 注释是对代码的解释和说明文字。\njava中的注释分为三种：单行注释、多行注释、文档注释。\n注释的内容不会参与编译和运行，仅仅是对代码的解释说明。\n单行注释：通常用于解释方法内某单行代码的作用。 多行注释：通常用于解释一段代码的作用。 文档注释：通常用于生成 Java 开发文档。 1.2 关键字 # 有一些标识符，Java 语言已经赋予了其特殊的含义，只能用于特定的地方，这些特殊的标识符就是 关键字 。简单来说，==关键字是被赋予特殊含义的标识符== 。比如，在我们的日常生活中，如果我们想要开一家店，则要给这个店起一个名字，起的这个“名字”就叫标识符。但是我们店的名字不能叫“警察局”，因为“警察局”这个名字已经被赋予了特殊的含义，而“警察局”就是我们日常生活中的关键字。\n当我们在代码中写了关键字之后，程序在运行的时候，就知道要做什么事情了。\nJava 语言中的关键字：\n分类 关键字 访问控制 private protected public 类，方法和变量修饰符 abstract class extends final implements interface native new static strictfp synchronized transient volatile enum 程序控制 break continue return do while if else for instanceof switch case default assert 错误处理 try catch throw throws finally 包相关 import package 基本类型 boolean byte char double float int long short 变量引用 super this void 保留字 goto const Tips：所有的关键字都是小写的，在 IDE 中会以特殊颜色显示。\ndefault 这个关键字很特殊，既属于程序控制，也属于类，方法和变量修饰符，还属于访问控制。\n在程序控制中，当在 switch 中匹配不到任何情况时，可以使用 default 来编写默认匹配的情况。 在类，方法和变量修饰符中，从 JDK8 开始引入了默认方法，可以使用 default 关键字来定义一个方法的默认实现。 在访问控制中，如果一个方法前没有任何修饰符，则默认会有一个修饰符 default，但是这个修饰符加上了就会报错。 注意：虽然 true, false, 和 null 看起来像关键字但实际上他们是字面值，同时也不可以作为标识符来使用。\n官方文档：https://docs.oracle.com/javase/tutorial/java/nutsandbolts/_keywords.html\n1.3 Class # 表示定义一个类，创建一个类。\n==类：Java项目最基本的组成单元，一个完整的java项目有可能会有成千上万个类来组成。==\nclass后买你跟随的就是这个类的名字，简称类名。\n在类名后面会有一对大括号，表示这个类的内容。\npublic class HelloWorld{ } 1.4 字面量 # 作用：告诉程序员，数据在程序中的书写格式，用于表达源代码中一个固定值的表示法。\n字面量类型 说明 程序中的写法 整数 不带小数的数字 666，-88 小数 带小数的数字 13.14，-5.21 字符 必须使用单引号，有且仅能一个字符 ‘A’，‘0’， ‘我’ 字符串 必须使用双引号，内容可有可无 “HelloWorld”，“黑马程序员” 布尔值 布尔值，表示真假，只有两个值：true，false true 、false 空值 一个特殊的值，空值 值是：null 1.5 变量 # ==变量是存储数据的基本单位，它允许程序员在代码中使用易于记忆的名称来代表内存地址。==\n变量是在程序中临时存储数据的容器，但是这个容器中只能存一个值。\n变量的定义格式：\n数据类型 变量名=数据值；（int a =0;）\n数据类型：限定了变量当中能存储什么类型的数据。\n变量名：其实就是这个容器的名字。\n数据值：真正存储在容器中的数据。\n分号：表示语句的结束，就跟以前写作文时候的句号是一样的。\n变量的注意事项：\n变量名不能重复\n**在一条语句中，可以定义多个变量。**但是这种方式影响代码的阅读，所以了解一下即可。\nint a,b,c; 变量在使用之前必须要赋值。\n1.6 数据类型 # 1.6.1 基本数据类型 # java语言数据类型分为：**引用数据类型和基本数据类型。**除了基本数据类型的数据均称为引用数据类型。\n基本数据类型的四类八种：\n数据类型 关键字 内存占用 取值范围 整数 byte 1 负的2的7次方 ~ 2的7次方-1(-128~127) short 2 负的2的15次方 ~ 2的15次方-1(-32768~32767) int 4 负的2的31次方 ~ 2的31次方-1 long 8 负的2的63次方 ~ 2的63次方-1 浮点数 float 4 1.401298e-45 ~ 3.402823e+38 double 8 4.9000000e-324 ~ 1.797693e+308 字符 char 2 0-65535 布尔 boolean 1 true，false ​\te+38表示是乘以10的38次方，同样，e-45表示乘以10的负45次方。\n在java中整数默认是int类型，浮点数默认是double类型。\nbyte类型的取值范围：-128 ~ 127\nint类型的大概取值范围：-21亿多 ~ 21亿多\n整数类型和小数类型的取值范围大小关系：\n​\tdouble \u0026gt; float \u0026gt; long \u0026gt; int \u0026gt; short \u0026gt; byte\n如果要定义一个long类型的变量，那么在数据值的后面需要加上L后缀，否则将作为整型解析。（大小写都可以，建议大写。）\n如果要定义一个float类型的变量，那么在数据值的后面需要加上F后缀，否则将无法通过编译。（大小写都可以）\n对于 boolean，官方文档未明确定义，它依赖于 JVM 厂商的具体实现。逻辑上理解是占用 1 位，但是实际中会考虑计算机高效存储因素。\n另外，**Java 的每种基本类型所占存储空间的大小不会像其他大多数语言那样随机器硬件架构的变化而变化。**这种所占存储空间大小的不变性是 Java 程序比用其他大多数语言编写的程序更具可移植性的原因之一。\n1.6.2 char型变量能存贮一个中文汉字吗 # 在Java中，==char类型是用来表示单个字符的数据类型，它采用Unicode编码，可以存储各种字符，包括中文汉字。== 由于Unicode编码使用16位来表示一个字符，char类型占用2个字节的内存空间。而**中文汉字通常使用UTF-8编码，一个中文字符占用3个字节的存储空间。**因此，将一个中文汉字直接赋值给char类型的变量可能会出现问题，因为无法完整地表示一个中文字符。 如果要在char类型中表示一个中文汉字，可以使用Unicode转义序列。\\u后面跟着表示字符的四位十六进制值，通过转义序列可以正确地表示一个中文汉字。例如，字符 \u0026lsquo;中\u0026rsquo; 的Unicode编码为\u0026rsquo;\\u4e2d\u0026rsquo;，我们可以使用char类型变量去存储这个中文汉字：char ch = \u0026lsquo;\\u4e2d\u0026rsquo;;。 需要注意的是，对于一个完整的中文字符，建议使用更适合的数据类型，如String类型来存储。 char类型主要用于表示单个字符，而不是用于存储复杂字符集合。\n1.7 标识符 # 在我们编写程序的时候，需要大量地为程序、类、变量、方法等取名字，于是就有了 标识符 。简单来说， ==标识符就是一个名字== 。\n1.7.1硬性要求 # 必须要这么做，否则代码会报错。\n必须由数字、字母、下划线_、美元符号$组成。 数字不能开头 不能是关键字 区分大小写的。 1.7.2 软件建议 # 1.7.2.1 小驼峰命名法 # 适用于变量名和方法名\n如果是一个单词，那么全部小写，比如：name\n如果是多个单词，那么从第二个单词开始，首字母大写，比如：firstName、maxAge\n1.7.2.2 大驼峰命名法 # 适用于类名\n如果是一个单词，那么首字母大写。比如：Demo、Test。\n如果是多个单词，那么每一个单词首字母都需要大写。比如：HelloWorld\n不管起什么名字，都要做到见名知意。\n1.7.2.3阿里巴巴命名规范细节： # 尽量不要用拼音。但是一些国际通用的拼音可视为英文单词。\n正确：alibaba、hangzhou、nanjing\n错误：jiage、dazhe\n平时在给变量名、方法名、类名起名字的时候，不要使用下划线或美元符号。\n错误：_name\n正确：name\n1.8 层级结构 # 结构分类\nproject（项目、工程） module（模块） package（包） class（类） 结构介绍\nproject（项目、工程）\n​\t淘宝、京东、黑马程序员网站都属于一个个项目，IDEA中就是一个个的Project。\nmodule（模块）\n​\t在一个项目中，可以存放多个模块，**不同的模块可以存放项目中不同的业务功能代码。**为了更好的管理代码，我们会把代码分别放在多个模块中存放。\npackage（包）\n​\t一个模块中又有很多的业务，为了把这些业务区分的更加清楚，就会用包来管理这些不同的业务。\nclass（类）\n​\t就是真正写代码的地方。Java项目最基本的组成单元。\n","date":"7 March 2025","externalUrl":null,"permalink":"/posts/1741323825874-java-%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/","section":"Posts","summary":"","title":"java 基础概念","type":"posts"},{"content":" 多态\u0026amp;包\u0026amp;权限修饰符\u0026amp;final # 1.1 多态 # 多态是继封装、继承之后，面向对象的第三大特性。\n多态是出现在继承或者实现关系中的。\n==顾名思义，表示一个对象具有多种的状态，具体表现为父类的引用指向子类的实例。==\n多态体现的格式：\n父类类型 变量名 = new 子类/实现类构造器; 变量名.方法名(); 多态的特点：\n对象类型和引用类型之间具有继承（类）/实现（接口）的关系；（前提） 引用类型变量发出的方法调用的到底是哪个类中的方法，必须在程序运行期间才能确定； 多态不能调用“只在子类存在但在父类不存在”的方法； 如果子类重写了父类的方法，真正执行的是子类重写的方法，如果子类没有重写父类的方法，执行的是父类的方法。 多态的使用场景：\n如果没有多态，带参数的方法只能传递一种固定的参数，其他相近类型的参数想要调用这个方法就必须再定义一次，而使用多态，我们就可以将方法的形参定义为共同的父类。\n注意：\n当一个方法的形参是一个类，我们可以传递这个类所有的子类对象。 当一个方法的形参是一个接口，我们可以传递这个接口所有的实现类对象。 而且多态还可以根据传递的不同对象来调用不同类中的方法。 1.1.1 多态的定义和前提 # 多态： 是指同一行为，具有多个不同表现形式。\n前提【重点】\n有继承或者实现关系\n方法的重写【意义体现：不重写，无意义】\n父类引用指向子类对象【格式体现】\n父类类型：指子类对象继承的父类类型，或者实现的父接口类型。\n1.1.2 多态的运行特点 # 调用成员变量时：编译看左边，运行看左边\n调用成员方法时：编译看左边，运行看右边\n1.1.3 多态的弊端 # 我们已经知道多态编译阶段是看左边父类类型的，如果子类有些独有的功能，此时多态的写法就无法访问子类独有功能了。\n1.1.4 引用类型转换 # 转型原因：\n​\t多态的写法无法访问子类独有功能。\n当使用多态方式调用方法时，首先检查父类中是否有该方法，如果没有，则编译错误。也就是说，不能调用子类拥有，而父类没有的方法。\n1.1.4.1 向上转型（自动转换） # 向上转型：多态本身是子类类型向父类类型向上转换（自动转换）的过程，这个过程是默认的。 当父类引用指向一个子类对象时，便是向上转型。 原因是：父类类型相对与子类来说是大范围的类型，所以子类范围小可以直接自动转型给父类类型的变量。\n1.1.4.2 向下转型（强制转换） # 向下转型：父类类型向子类类型向下转换的过程，这个过程是强制的。 一个已经向上转型的子类对象，将父类引用转为子类引用，可以使用强制类型转换的格式，便是向下转型。\n使用格式：\n子类类型 变量名 = (子类类型) 父类变量名; 如:Aniaml a = new Cat(); Cat c =(Cat) a; 子类之间不能互相转换，会出现ClassCastException异常。\n1.1.4.3 instanceof 关键字 # 为了避免ClassCastException的发生，Java提供了 instanceof 关键字，给引用变量做类型的校验，格式如下：\n变量名 instanceof 数据类型 如果变量属于该数据类型或者其子类类型，返回true。 如果变量不属于该数据类型或者其子类类型，返回false。 JDK14的时候提出了新特性，把判断和强转合并成了一行：\n//新特性 //先判断a是否为Dog类型，如果是，则强转成Dog类型，转换之后变量名为d //如果不是，则不强转，结果直接是false if(a instanceof Dog d){ d.lookHome(); }else if(a instanceof Cat c){ c.catchMouse(); }else{ System.out.println(\u0026#34;没有这个类型，无法转换\u0026#34;); } 1.2 包 # 包在操作系统中其实就是一个文件夹。包是用来分门别类的管理技术，不同的技术类放在不同的包下，方便管理和维护。\n包名一般是公司域名的倒写。例如：黑马是www.itheima.com,包名就可以定义成com.itheima.技术名称。 包名必须用”.“连接。 包名的每个路径名必须是一个合法的标识符，而且不能是Java的关键字。 什么时候需要导包？\n​\t情况一：在使用Java中提供的非核心包中的类时\n​\t情况二：使用自己写的其他包中的类时\n什么时候不需要导包？\n​\t情况一：在使用Java核心包（java.lang）中的类时\n​\t情况二：在使用自己写的同一个包中的类时\n使用不同包下的相同类时，我们需要使用全类名的形式：\n//拷贝全类名的快捷键：选中类名crtl + shift + alt + c 或者用鼠标点copy，再点击copy Reference com.itheima.homework.demo1.Student s1 = new com.itheima.homework.demo1.Student(); 1.3 权限修饰符 # 在Java中提供了四种访问权限，使用不同的访问权限修饰符修饰时，被修饰的内容会有不同的访问权限，我们之前已经学习过了public 和 private，接下来我们研究一下protected和默认修饰符的作用。\npublic：公共的，所有地方都可以访问。\nprotected：本类 ，本包，其他包中的子类都可以访问。\n默认（没有修饰符）：本类 ，本包可以访问。\n注：默认是空着不写，会由系统自动添加default关键字，如果手动写了default会报错\nprivate：私有的，当前类可以访问。 public \u0026gt; protected \u0026gt; 默认 \u0026gt; private\n不同权限的访问能力：\npublic protected 默认 private 同一类中 √ √ √ √ 同一包中的类 √ √ √ 不同包的子类 √ √ 不同包中的无关类 √ 可见，public具有最大权限。private则是最小权限。\n编写代码时，如果没有特殊的考虑，建议这样使用权限：\n成员变量使用private ，隐藏细节。 构造方法使用 public ，方便创建对象。 成员方法使用public ，方便调用方法。 小贴士：不加权限修饰符，就是默认权限\n1.4 final 关键字 # 有一个方法我不想别人去改写里面内容，那么Java提供了final 关键字，表示修饰的内容不可变。\nfinal： 不可改变，最终的含义。可以用于修饰类、方法和变量。\n类：被修饰的类，不能被继承。 方法：被修饰的方法，不能被重写。 变量：被修饰的变量，有且仅能被赋值一次。 局部变量（就是写在方法内的）被final修饰后，只能赋值一次，不能再更改。\n成员变量（就是类内方法外）涉及到初始化的问题，初始化方式有显示初始化和构造方法初始化，只能选择其中一个：\n显示初始化(在定义成员变量的时候立马赋值)（常用）； public class Student { final int num = 10; } 构造方法初始化(在构造方法中赋值一次)（不常用，了解即可）。\n注意：每个构造方法中都要赋值一次！\npublic class Student { final int num = 10; final int num2; public Student() { this.num2 = 20; // this.num2 = 20; } public Student(String name) { this.num2 = 20; // this.num2 = 20; } } 被final修饰的常量名称，一般都有书写规范，所有字母都大写。\n","date":"7 March 2025","externalUrl":null,"permalink":"/posts/1741324029063-java-%E5%A4%9A%E6%80%81%E5%8C%85%E6%9D%83%E9%99%90%E4%BF%AE%E9%A5%B0%E7%AC%A6final/","section":"Posts","summary":"","title":"java 多态\u0026包\u0026权限修饰符\u0026final","type":"posts"},{"content":" 字符串 # 1.1 String类 # String 类代表字符串，Java 程序中的所有字符串文字（例如“abc”）都被实现为此类的实例。也就是说，**Java 程序中所有的双引号字符串，都是 String 类的对象。**String 类在 java.lang 包下，所以使用的时候不需要导包！\nString类的特点：\n==字符串不可变==，它们的值在创建后不能被更改 虽然 String 的值是不可变的，但是它们可以被共享 字符串效果上相当于字符数组( char[] )，但是底层原理是字节数组( byte[] ) 字符型常量和字符串常量的区别：\n**形式：**字符常量是单引号引起的一个字符，字符串常量是双引号引起的0个或若干个字符。 **含义：**字符常量相当于一个整型值（ASCII值），可以参加表达式运算；字符串常量代表一个地址值（该字符串在内存中存放的位置）。 **占内存大小：**字符常量只占2个字节；字符串常量占若干个字节。 String为什么是不可变的？\nString 类中使用 final 关键字修饰字符数组来保存字符串，所以String 对象是不可变的。\npublic final class String implements java.io.Serializable, Comparable\u0026lt;String\u0026gt;, CharSequence { private final char value[]; //... } 修正：我们知道被 final 关键字修饰的类不能被继承，修饰的方法不能被重写，修饰的变量是基本数据类型则值不能改变，修饰的变量是引用类型则不能再指向其他对象。因此，final 关键字修饰的数组保存字符串并不是 String 不可变的根本原因，因为这个数组保存的字符串是可变的（final 修饰引用类型变量的情况）。\nString 真正不可变有下面几点原因：\n保存字符串的数组被 final 修饰且为私有的，并且String 类没有提供/暴露修改这个字符串的方法。 String 类被 final 修饰导致其不能被继承，进而避免了子类破坏 String 不可变。 Java 9 为何要将 String 的底层实现由 char[] 改成了 byte[] ?\n新版的 String 其实支持两个编码方案：Latin-1 和 UTF-16。如果字符串中包含的汉字没有超过 Latin-1 可表示范围内的字符，那就会使用 Latin-1 作为编码方案。Latin-1 编码方案下，byte 占一个字节(8 位)，char 占用 2 个字节（16），byte 相较 char 节省一半的内存空间。\nJDK 官方就说了绝大部分字符串对象只包含 Latin-1 可表示的字符。\n1.1.1 String类的构造方法 # 常用的构造方法\n方法名 说明 public String() 创建一个空白字符串对象，不含有任何内容 public String(char[] chs) 根据字符数组的内容，来创建字符串对象 public String(byte[] bys) 根据字节数组的内容，来创建字符串对象 String s = “abc”; 直接赋值的方式创建字符串对象，内容就是abc 创建字符串对象两种方式的区别：\nJava中字符串可以通过两种方式创建：==使用字符串字面量直接赋值给变量或使用关键字new创建一个新的String对象。==它们之间有以下区别：\n使用字符串字面量赋值给变量时，Java会使用字符串常量池来管理字符串对象，可以提高性能和节省内存。而使用new String创建的字符串对象则在堆内存中独立分配内存空间，每次调用都会创建一个新的对象，因此内存消耗更大。 使用字符串字面量赋值给变量的字符串是不可变的，即不能改变其内容。而使用new String创建的字符串对象是可变的，可以通过调用方法或者使用赋值运算符修改其内容。 使用字符串字面量赋值给变量的字符串比较时，如果多个变量引用相同的字符串字面量，则它们实际上引用的是同一个对象，因此比较它们的引用时将返回true。而使用new String创建的字符串对象，即使内容相同，它们也是不同的对象，因此比较它们的引用时将返回false。 1.1.2 字符串的比较 # ==号的作用：\n比较基本数据类型：比较的是具体的值 比较引用数据类型：比较的是对象地址值 equals方法的作用：\n方法介绍：\npublic boolean equals(String s) 比较两个字符串内容是否相同、区分大小写(不是地址值) 注：equals方法本身在比较引用数据类型时比较的也是对象地址值，但是String类重写了equals方法，所以我们用String类带的equals方法比较字符串时比较的是字符串内容。\n1.1.3 字符串常量池的作用 # 字符串常量池 是 JVM 为了提升性能和减少内存消耗针对字符串（String 类）专门开辟的一块区域，主要目的是为了避免字符串的重复创建。\n==String s1 = new String(\u0026ldquo;abc\u0026rdquo;);这句话创建了几个字符串对象？==\n先说答案：会创建 1 或 2 个字符串对象。\n字符串常量池中不存在 \u0026ldquo;abc\u0026rdquo;：会创建 2 个 字符串对象。一个在字符串常量池中，由 ldc 指令触发创建。一个在堆中，由 new String() 创建，并使用常量池中的 \u0026ldquo;abc\u0026rdquo; 进行初始化。 字符串常量池中已存在 \u0026ldquo;abc\u0026rdquo;：会创建 1 个 字符串对象。该对象在堆中，由 new String() 创建，并使用常量池中的 \u0026ldquo;abc\u0026rdquo; 进行初始化。 1.1.4 String类能被继承吗 # 在Java中，String类是被final关键字修饰的，即不可继承。final关键字表示一个类不允许被其他类继承，也就是说，String类不能被任何其他类继承。 这是因为String类具有不可变性和安全性，这些特性可以防止一些潜在的问题，如字符串池中的重用和安全性漏洞。 如果String类能被继承，子类有可能修改原字符串的值，这将破坏字符串对象的不可变性。此外，String类的方法和变量都被设计成private、final和static的，这说明它们不能被重写或隐藏。如果String类可以被继承，这些设计决策将被打破，可能产生更多的问题。 因此，尽管我们不能从String类派生出新的子类，但我们可以使用String类提供的方法来操作和处理字符串。例如，我们可以使用String类的concat()方法连接两个字符串，或使用indexOf()方法查找子串在字符串中的位置等。String类已经包含了大量的方法，可以满足大多数字符串操作的需求。\n1.2 StringBuilder # StringBuilder 可以看成是一个容器，创建之后里面的内容是可变的。\n当我们在拼接字符串和反转字符串的时候会使用到\n关于StringBuilder的添加、反转与打印：\npublic class StringBuilderDemo3 { public static void main(String[] args) { //1.创建对象 StringBuilder sb = new StringBuilder(\u0026#34;abc\u0026#34;); //2.添加元素 /*sb.append(1); sb.append(2.3); sb.append(true);*/ //反转 sb.reverse(); //获取长度 int len = sb.length(); System.out.println(len); //打印 //普及： //因为StringBuilder是Java已经写好的类 //java在底层对他做了一些特殊处理。 //打印对象不是地址值而是属性值。 System.out.println(sb); } } 字符串拼接用 “ + ” 还是 StringBuilder ？\nJava 语言本身并不支持运算符重载，“+”和“+=”是专门为 String 类重载过的运算符，也是 Java 中仅有的两个重载过的运算符。\n字符串对象通过“+”的字符串拼接方式，实际上是通过 StringBuilder 调用 append() 方法实现的，拼接完成之后调用 toString() 得到一个 String 对象 。\n不过，在循环内使用“+”进行字符串的拼接的话，存在比较明显的缺陷：编译器不会创建单个 StringBuilder 以复用，会导致创建过多的 StringBuilder 对象。\nStringBuilder 对象是在循环内部被创建的，这意味着每循环一次就会创建一个 StringBuilder 对象。如果直接使用 StringBuilder 对象进行字符串拼接的话，就不会存在这个问题了。\n在 JDK 9 中，字符串相加“+”改为用动态方法 makeConcatWithConstants() 来实现，通过提前分配空间从而减少了部分临时对象的创建。然而这种优化主要针对简单的字符串拼接，如： a+b+c 。对于循环中的大量拼接操作，仍然会逐个动态分配内存（类似于两个两个 append 的概念），并不如手动使用 StringBuilder 来进行拼接效率高。\n1.3 StringBuffer（比较分析） # 可变性\nStringBuilder 与 StringBuffer 都继承自 AbstractStringBuilder 类，在 AbstractStringBuilder 中也是使用字符数组保存字符串，不过没有使用 final 和 private 关键字修饰，最关键的是这个 AbstractStringBuilder 类还提供了很多修改字符串的方法比如 append 方法。\n线程安全性\nString 中的对象是不可变的，也就可以理解为常量，线程安全。AbstractStringBuilder 是 StringBuilder 与 StringBuffer 的公共父类，定义了一些字符串的基本操作，如 expandCapacity、append、insert、indexOf 等公共方法。StringBuffer 对方法加了同步锁或者对调用的方法加了同步锁，所以是线程安全的。StringBuilder 并没有对方法进行加同步锁，所以是非线程安全的。\n性能\n每次对 String 类型进行改变的时候，都会生成一个新的 String 对象，然后将指针指向新的 String 对象。StringBuffer 每次都会对 StringBuffer 对象本身进行操作，而不是生成新的对象并改变对象引用。相同情况下使用 StringBuilder 相比使用 StringBuffer 仅能获得 10%~15% 左右的性能提升，但却要冒多线程不安全的风险。\n对于三者使用的总结：\n操作少量的数据: 适用 String 单线程操作字符串缓冲区下操作大量数据: 适用 StringBuilder 多线程操作字符串缓冲区下操作大量数据: 适用 StringBuffer 1.4 StringJoiner # StringJoiner跟StringBuilder一样，也可以看成是一个容器，创建之后里面的内容是可变的。 作用：提高字符串的操作效率，而且代码编写特别简洁，但是目前市场上很少有人用。 JDK8出现的 基本使用：\n//1.创建一个对象，并指定中间的间隔符号 StringJoiner sj = new StringJoiner(\u0026#34;---\u0026#34;); //2.添加元素 sj.add(\u0026#34;aaa\u0026#34;).add(\u0026#34;bbb\u0026#34;).add(\u0026#34;ccc\u0026#34;); //3.打印结果 System.out.println(sj);//aaa---bbb---ccc //1.创建对象 StringJoiner sj = new StringJoiner(\u0026#34;, \u0026#34;,\u0026#34;[\u0026#34;,\u0026#34;]\u0026#34;); //2.添加元素 sj.add(\u0026#34;aaa\u0026#34;).add(\u0026#34;bbb\u0026#34;).add(\u0026#34;ccc\u0026#34;); int len = sj.length(); System.out.println(len);//15 //3.打印 System.out.println(sj);//[aaa, bbb, ccc] String str = sj.toString(); System.out.println(str);//[aaa, bbb, ccc] 1.5 关于字符串的扩展 # 字符串存储的内存原理\nString s = “abc”；直接赋值\n特点：\n​\t此时字符串abc是存在字符串常量池中的。\n​\t先检查字符串常量池中有没有字符串abc，如果有，不会创建新的，而是直接复用。如果没有abc，才会创建一个新的。\n所以，直接赋值的方式，代码简单，而且节约内存。\nnew出来的字符串\n看到new关键字，一定是在堆里面开辟了一个小空间。\nString s1 = new String（“abc”）；\nString s2 = “abc”；\ns1记录的是new出来的，在堆里面的地址值。\ns2是直接赋值的，所以记录的是字符串常量池中的地址值。\n==号比较的到底是什么？\n如果比较的是基本数据类型：比的是具体的数值是否相等。\n如果比较的是引用数据类型：比的是地址值是否相等。\n结论：==只能用于比较基本数据类型。不能比较引用数据类型。\n1.6 String#intern方法（了解） # String.intern() 是一个 native (本地) 方法，用来处理字符串常量池中的字符串对象引用。它的工作流程可以概括为以下两种情况：\n常量池中已有相同内容的字符串对象：如果字符串常量池中已经有一个与调用 intern() 方法的字符串内容相同的 String 对象，intern() 方法会直接返回常量池中该对象的引用。\n常量池中没有相同内容的字符串对象：如果字符串常量池中还没有一个与调用 intern() 方法的字符串内容相同的对象，intern() 方法会将当前字符串对象的引用添加到字符串常量池中，并返回该引用。\n代码示例：\npublic class StringInternExample { public static void main(String[] args) { String s1 = new String(\u0026#34;example\u0026#34;); String s2 = \u0026#34;example\u0026#34;; String s3 = s1.intern(); System.out.println(s1 == s2); // 输出 false System.out.println(s2 == s3); // 输出 true } } 总结：\nintern() 方法的主要作用是确保字符串引用在常量池中的唯一性。 当调用 intern() 时，如果常量池中已经存在相同内容的字符串，则返回常量池中已有对象的引用；否则，将该字符串添加到常量池并返回其引用。 1.7 String类型的变量和常量做“ + ”运算时发生了什么？ # 先来看字符串不加 final 关键字拼接的情况（JDK1.8）：\nString str1 = \u0026#34;str\u0026#34;; String str2 = \u0026#34;ing\u0026#34;; String str3 = \u0026#34;str\u0026#34; + \u0026#34;ing\u0026#34;; String str4 = str1 + str2; String str5 = \u0026#34;string\u0026#34;; System.out.println(str3 == str4);//false System.out.println(str3 == str5);//true System.out.println(str4 == str5);//false 对于编译期可以确定值的字符串，也就是常量字符串 ，jvm 会将其存入字符串常量池。并且，字符串常量拼接得到的字符串常量在编译阶段就已经被存放字符串常量池，这个得益于编译器的优化。\n在编译过程中，Javac 编译器（下文中统称为编译器）会进行一个叫做 常量折叠(Constant Folding) 的代码优化。常量折叠会把常量表达式的值求出来作为常量嵌在最终生成的代码中，这是 Javac 编译器会对源代码做的极少量优化措施之一(代码优化几乎都在即时编译器中进行)。\n对于 String str3 = \u0026quot;str\u0026quot; + \u0026quot;ing\u0026quot;; 编译器会给你优化成 String str3 = \u0026quot;string\u0026quot;; 。\n并不是所有的常量都会进行折叠，只有编译器在程序编译期就可以确定值的常量才可以：\n基本数据类型( byte、boolean、short、char、int、float、long、double)以及字符串常量。 final 修饰的基本数据类型和字符串变量 字符串通过 “+”拼接得到的字符串、基本数据类型之间算数运算（加减乘除）、基本数据类型的位运算（\u0026laquo;、\u0026raquo;、\u0026raquo;\u0026gt; ） 引用的值在程序编译期是无法确定的，编译器无法对其进行优化。\n不过，字符串使用 final 关键字声明之后，可以让编译器当做常量来处理。\n示例代码：\nfinal String str1 = \u0026#34;str\u0026#34;; final String str2 = \u0026#34;ing\u0026#34;; // 下面两个表达式其实是等价的 String c = \u0026#34;str\u0026#34; + \u0026#34;ing\u0026#34;;// 常量池中的对象 String d = str1 + str2; // 常量池中的对象 System.out.println(c == d);// true 被 final 关键字修饰之后的 String 会被编译器当做常量来处理，编译器在程序编译期就可以确定它的值，其效果就相当于访问常量。\n如果 ，编译器在运行时才能知道其确切值的话，就无法对其优化。\n1.8 Java中变量和常量的区别 # 在java中，变量和常量是两个不同的概念，他们有以下几点区别：\n可变性：\n变量是可以被修改的，其值可以在程序的执行过程中改变。\n常量是不可被修改的，其值在定义后不能再被改变。\n声明与赋值：\n变量需要先声明，并可以在声明后进行赋值。声明时需要指定变量的类型 ==常量在定义时需要使用final关键字进行修饰== 内存空间：\n变量在内存中占用一块存储空间，可以改变这个存储空间中的值。 常量通常会被编译器在编译时直接替换为对应的值，所以在内存中不会为常量分配额外的存储空间，而是直接使用常量的值。 使用场景：\n变量用于存储会发生变化的数据，例如计数器、临时结果等，在程序的执行过程中可以根据需要改变其值。 常量用于表示不可变的数据，例如数学常数、配置项等，在程序中通常希望保持其固定的值，避免误操作导致值的变化。 总结来说，变量是可变的并且需要先声明后赋值，而常量是不可变的并且需要在定义时进行初始化赋值。变量占用内存空间且值可以改变，而常量通常会被编译器直接替换为对应的值，不占用额外的内存空间。变量用于存储会发生变化的数据，常量用于表示不可变的数据。\n","date":"7 March 2025","externalUrl":null,"permalink":"/posts/1741323961758-java-%E5%AD%97%E7%AC%A6%E4%B8%B2/","section":"Posts","summary":"","title":"java 字符串","type":"posts"},{"content":" 循环高级 # 1.1 无线循环 # 概念：\n​\t又叫死循环。循环一直停不下来。\nfor格式：\nfor(;;){ System.out.println(\u0026#34;循环执行一直在打印内容\u0026#34;); } 解释：\n初始化语句可以空着不写，表示循环之前不定义任何的控制变量。\n条件判断语句可以空着不写，如果不写，默认表示true，循环一直进行。\n条件控制语句可以空着不写，表示每次循环体执行完毕后，控制变量不做任何变化。\nwhile格式：\nwhile(true){ System.out.println(\u0026#34;循环执行一直在打印内容\u0026#34;); } 解释：\n​\t小括号里面就不能省略了，true一定要写出来，否则代码会报错。\ndo\u0026hellip;while格式：\ndo{ System.out.println(\u0026#34;循环执行一直在打印内容\u0026#34;); }while(true); 解释：\n​\t小括号里面就不能省略了，true一定要写出来，否则代码会报错。\n无限循环的注意事项：\n最为常用的格式：while 无限循环下面不能再写其他代码了，因为永远执行不到。 1.2 条件控制语句 # break continue break:\n​\t不能单独存在的。可以用在switch和循环中，表示结束，跳出的意思。\ncontinue:\n​\t不能单独存在的。只能存在于循环当中。\n​\t表示：跳过本次循环，继续执行下次循环。\n1.3 continue \u0026amp; break \u0026amp; return 的区别 # 在循环结构中，当循环条件不满足或者循环次数达到要求时，循环会正常结束。但是，有时候可能需要在循环的过程中，当发生了某种条件之后 ，提前终止循环，这就需要用到下面几个关键词：\ncontinue：指跳出当前的这一次循环，继续下一次循环。 break：指跳出整个循环体，继续执行循环下面的语句。 return 用于跳出所在方法，结束该方法的运行。return 一般有两种用法：\nreturn;：直接使用 return 结束方法执行，用于没有返回值函数的方法 return value;：return 一个特定值，用于有返回值函数的方法 1.4 for-each 与常规for循环 # for-each循环形式如下：\nfor(element_type element : collection){ //在此处执行针对 element 的操作 } 示例：\npublic class Main { public static void main(Stringl args[]){ int a[] = new int[]{1,2,3,4,5};\tfor (int i : a){ System.out.println( i + \u0026#34;、\u0026#34;);\t} } } 在Java中，for-each循环（也称为增强型for循环）和常规for循环有一些差异，包括它们在执行效率上的区别。下面是它们之间的一些比较：\n执行效率：在大多数情况下，常规for循环的执行效率比for-each循环高。这是因为for-each循环需要额外的步骤来获取集合或数组中的元素，而常规for循环可以直接通过索引访问元素，避免了额外的开销。 可变性：常规for循环具有更大的灵活性，可以在循环过程中修改计数器，从而控制循环的行为。而for-each循环是只读的，不能在循环过程中修改集合或数组的元素。 代码简洁性：for-each循环通常比常规for循环更加简洁易读，尤其在遍历集合或数组时。使用for-each循环可以减少迭代器或索引变量的声明和管理，使代码更加清晰。 尽管常规for循环在执行效率上可能更高，但在大多数实际情况下，两者之间的性能差异不会对程序性能产生显著影响。因此，根据具体的使用场景和代码可读性的需求，可以选择使用for-each循环或常规for循环。在只需要遍历集合或数组而不修改其中元素的情况下，for-each循环是一个方便且简洁的选择。\n","date":"7 March 2025","externalUrl":null,"permalink":"/posts/1741323895545-java-%E5%BE%AA%E7%8E%AF%E9%AB%98%E7%BA%A7/","section":"Posts","summary":"","title":"java 循环高级","type":"posts"},{"content":" 抽象类\u0026amp;接口\u0026amp;内部类 # 1.1 抽象类 # ==我们把没有方法体的方法称为抽象方法。Java语法规定，包含抽象方法的类就是抽象类。==\n抽象方法 ： 没有方法体的方法。 抽象类：包含抽象方法的类。 1.1.1 abstract抽象方法 # 使用abstract 关键字修饰方法，该方法就成了抽象方法，抽象方法只包含一个方法名，而没有方法体。\n定义格式：\n修饰符 abstract 返回值类型 方法名 (参数列表)； 1.1.2 抽象类 # 如果一个类包含抽象方法，那么该类必须是抽象类。注意：抽象类不一定有抽象方法，但是有抽象方法的类必须定义成抽象类。\n定义格式：\nabstract class 类名字 { } 要求：继承抽象类的子类必须重写父类所有的抽象方法。否则，该子类也必须声明为抽象类。\n此时的方法重写，是子类对父类抽象方法的完成实现，我们将这种方法重写的操作，也叫做实现方法。\n1.1.3 抽象类的特征 # 抽象类的特征总结起来可以说是 有得有失\n有得：抽象类得到了拥有抽象方法的能力。\n有失：==抽象类失去了创建对象的能力。==\n其他成员（构造方法，实例方法，静态方法等）抽象类都是具备的。\n抽象类不能创建对象，如果创建，编译无法通过而报错。只能创建其非抽象子类的对象。\n理解：假设创建了抽象类的对象，调用抽象的方法，而抽象方法没有具体的方法体，没有意义。\n抽象类中，可以有构造方法，是供子类创建对象时，初始化父类成员使用的。\n理解：子类的构造方法中，有默认的super()，需要访问父类构造方法。\n抽象类中，不一定包含抽象方法，但是有抽象方法的类必定是抽象类。\n理解：未包含抽象方法的抽象类，目的就是不想让调用者创建该类对象，通常用于某些特殊的类结构设计。\n抽象类的子类，必须重写抽象父类中所有的抽象方法，否则子类也必须定义成抽象类，编译无法通过而报错。\n理解：假设不重写所有抽象方法，则类中可能包含抽象方法。那么创建对象后，调用抽象的方法，没有意义。\n抽象类存在的意义是为了被子类继承。\n理解：抽象类中已经实现的是模板中确定的成员，抽象类不确定如何实现的定义成抽象方法，交给具体的子类去实现。\n1.2 接口 # 接口是更加彻底的抽象，JDK7之前，包括JDK7，接口中全部是抽象方法。接口同样是不能创建对象的。\n定义格式：\n//接口的定义格式： interface 接口名称{ // 抽象方法 } // 接口的声明：interface // 接口名称：首字母大写，满足“驼峰模式” 在JDK7，包括JDK7之前，接口中的只有包含：抽象方法和常量\n1.2.1 接口和抽象类的比较 # 接口和抽象类的共同点：\n实例化：接口和抽象类都不能直接实例化，只能被实现（接口）或继承（抽象类）后才能创建具体的对象。 抽象方法：接口和抽象类都可以包含抽象方法。抽象方法没有方法体，必须在子类或实现类中实现。 接口和抽象类的区别：\n设计目的：接口主要用于对类的行为进行约束，你实现了某个接口就具有了对应的行为。抽象类主要用于代码复用，强调的是所属关系。\n继承和实现：一个类只能继承一个类（包括抽象类），因为 Java 不支持多继承。但一个类可以实现多个接口，一个接口也可以继承多个其他接口。\n成员变量：接口中的成员变量只能是 public static final 类型的，不能被修改且必须有初始值。抽象类的成员变量可以有任何修饰符（private, protected, public），可以在子类中被重新定义或赋值。\n方法：\nJava 8 之前，接口中的方法默认是 public abstract ，也就是只能有方法声明。自 Java 8 起，可以在接口中定义 default（默认） 方法和 static （静态）方法。 自 Java 9 起，接口可以包含 private 方法。\n抽象类可以包含抽象方法和非抽象方法。抽象方法没有方法体，必须在子类中实现。非抽象方法有具体实现，可以直接在抽象类中使用或在子类中重写。\n在 Java 8 及以上版本中，接口引入了新的方法类型：default 方法、static 方法和 private 方法。这些方法让接口的使用更加灵活。\nJava 8 引入的default 方法用于提供接口方法的默认实现，可以在实现类中被覆盖。这样就可以在不修改实现类的情况下向现有接口添加新功能，从而增强接口的扩展性和向后兼容性。\nJava 8 引入的static 方法无法在实现类中被覆盖，只能通过接口名直接调用（ MyInterface.staticMethod()），类似于类中的静态方法。static 方法通常用于定义一些通用的、与接口相关的工具方法，一般很少用。\nJava 9 允许在接口中使用 private 方法。private方法可以用于在接口内部共享代码，不对外暴露。\n1.2.2 抽象方法 # 注意：接口中的抽象方法默认会自动加上public abstract修饰程序员无需自己手写！！ 按照规范：以后接口中的抽象方法建议不要写上public abstract。因为没有必要啊，默认会加上。\n1.2.3 常量 # 在接口中定义的成员变量默认会加上： public static final修饰。也就是说在接口中定义的成员变量实际上是一个常量。这里是使用public static final修饰后，变量值就不可被修改，并且是静态化的变量可以直接用接口名访问，所以也叫常量。常量必须要给初始值。常量命名规范建议字母全部大写，多个单词用下划线连接。\n1.2.4 案例演示 # public interface InterF { // 抽象方法！ // public abstract void run(); void run(); // public abstract String getName(); String getName(); // public abstract int add(int a , int b); int add(int a , int b); // 它的最终写法是： // public static final int AGE = 12 ; int AGE = 12; //常量 String SCHOOL_NAME = \u0026#34;黑马程序员\u0026#34;; } 1.2.5 接口的实现 # 类与接口的关系为实现关系，即类实现接口，该类可以称为接口的实现类，也可以称为接口的子类。实现的动作类似继承，格式相仿，只是关键字不同，实现使用 implements关键字。\n/**接口的实现： 在Java中接口是被实现的，实现接口的类称为实现类。 实现类的格式:*/ class 类名 implements 接口1,接口2,接口3...{ } 类实现接口的要求和意义:\n必须重写实现的全部接口中所有抽象方法。 如果一个类实现了接口，但是没有重写完全部接口的全部抽象方法，这个类也必须定义成抽象类。 意义：接口体现的是一种规范，接口对实现类是一种强制性的约束，要么全部完成接口申明的功能，要么自己也定义成抽象类。这正是一种强制性的规范。 类与接口之间的关系是多实现的，一个类可以同时实现多个接口。\nJava中，接口与接口之间是可以多继承的：也就是一个接口可以同时继承多个接口。大家一定要注意：\n类与接口是实现关系\n接口与接口是继承关系\n接口继承接口就是把其他接口的抽象方法与本接口进行了合并，关键字是extends\n1.3 内部类 # 将一个类A定义在另一个类B里面，里面的那个类A就称为内部类，B则称为外部类。可以把内部类理解成寄生，外部类理解成宿主。\n一个事物内部还有一个独立的事物，内部的事物脱离外部的事物无法独立使用\n人里面有一颗心脏。 汽车内部有一个发动机。 为了实现更好的封装性。 1.3.1 内部类的分类 # 按定义的位置来分\n成员内部类，类定义在了成员位置 (类中方法外称为成员位置，无static修饰的内部类) {定义在一个类的内部，并且不是静态的。成员内部类可以访问外部类的所有成员，包括私有成员。在创建内部类对象时，需要先创建外部类对象，然后通过外部类对象来创建内部类对象。} 静态内部类，类定义在了成员位置 (类中方法外称为成员位置，有static修饰的内部类) {定义在一个类的内部，并且是静态的。与成员内部类不同，静态内部类不能访问外部类的非静态成员，但可以访问外部类的静态成员。在创建静态内部类对象时，不需要先创建外部类对象，可以直接通过类名来创建。} 局部内部类，类定义在方法内 {定义在一个方法或作用域块中的类，它的作用域被限定在方法或作用域块中。局部内部类可以访问外部方法或作用域块中的 final 变量和参数。} 匿名内部类，没有名字的内部类，可以在方法中，也可以在类中方法外。 {没有定义名称的内部类，通常用于创建实现某个接口或继承某个类的对象。匿名内部类会在定义时立即创建对象，因此通常用于简单的情况，而不用于复杂的类结构。} 成员内部类特点：\n无static修饰的内部类，属于外部类对象的。 宿主：外部类对象。 内部类的使用格式：\n外部类.内部类。 // 访问内部类的类型都是用 外部类.内部类 获取成员内部类对象的两种方式：\n方式一：外部直接创建成员内部类的对象\n外部类.内部类 变量 = new 外部类（）.new 内部类（）; 方式二：在外部类中定义一个方法提供内部类的对象\n案例演示\n方式一： public class Test { public static void main(String[] args) { // 宿主：外部类对象。 // Outer out = new Outer(); // 创建内部类对象。 Outer.Inner oi = new Outer().new Inner(); oi.method(); } } class Outer { // 成员内部类，属于外部类对象的。 // 拓展：成员内部类不能定义静态成员。 public class Inner{ // 这里面的东西与类是完全一样的。 public void method(){ System.out.println(\u0026#34;内部类中的方法被调用了\u0026#34;); } } } 方式二： public class Outer { String name; private class Inner{ static int a = 10; } public Inner getInstance(){ return new Inner(); } } public class Test { public static void main(String[] args) { Outer o = new Outer(); System.out.println(o.getInstance()); } } 编写成员内部类的注意点：\n成员内部类可以被一些修饰符所修饰，比如： private，默认，protected，public，static等 在成员内部类里面，JDK16之前不能定义静态变量，JDK16开始才可以定义静态变量。 创建内部类对象时，对象中有一个隐含的Outer.this记录外部类对象的地址值。（请参见3.6节的内存图） 详解：\n​\t内部类被private修饰，外界无法直接获取内部类的对象，只能通过3.3节中的方式二获取内部类的对象\n​\t被其他权限修饰符修饰的内部类一般用3.3节中的方式一直接获取内部类的对象\n​\t内部类被static修饰是成员内部类中的特殊情况，叫做静态内部类下面单独学习。\n​\t内部类如果想要访问外部类的成员变量，外部类的变量必须用final修饰，JDK8以前必须手动写final，JDK8之后不需要手动写，JDK默认加上。\n成员内部类内存图：\n1.3.2 静态内部类 # 静态内部类是一种特殊的成员内部类。 有static修饰，属于外部类本身的。 总结：静态内部类与其他类的用法完全一样。只是访问的时候需要加上外部类.内部类。 拓展1:静态内部类可以直接访问外部类的静态成员。 拓展2:静态内部类不可以直接访问外部类的非静态成员，如果要访问需要创建外部类的对象。 拓展3:静态内部类中没有银行的Outer.this。 内部类的使用格式：\n外部类.内部类。 静态内部类对象的创建格式：\n外部类.内部类 变量 = new 外部类.内部类构造器; 调用方法的格式：\n调用非静态方法的格式：先创建对象，用对象调用 调用静态方法的格式：外部类名.内部类名.方法名(); 1.3.3 局部内部类 # 局部内部类 ：定义在方法中的类。\n1.3.4 匿名内部类 # 匿名内部类 ：是内部类的简化写法。他是一个隐含了名字的内部类。开发中，最常用到的内部类就是匿名内部类了。\n格式：\nnew 类名或者接口名() { 重写方法; }; 包含了：\n继承或者实现关系\n方法重写\n创建对象\n所以从语法上来讲，这个整体其实是匿名内部类对象\n实际上，如果我们希望定义一个只要使用一次的类，就可考虑使用匿名内部类。匿名内部类的本质作用\n是为了简化代码。\n之前我们使用接口时，似乎得做如下几步操作：\n定义子类 重写接口中的方法 创建子类对象 调用重写后的方法 我们的目的，最终只是为了调用方法，那么能不能简化一下，把以上四步合成一步呢？匿名内部类就是做这样的快捷方式。\n匿名内部类必须继承一个父类或者实现一个父接口。\n匿名内部类格式\nnew 父类名或者接口名(){ // 方法重写 @Override public void method() { // 执行语句 } }; 匿名内部类特点\n定义一个没有名字的内部类 这个类实现了父类，或者父类接口 匿名内部类会创建这个没有名字的类的对象 1.3.5 静态内部类与非静态内部类的区别 # 在Java中，静态内部类和非静态内部类都是一种嵌套在其他类中的内部类。它们之间有以下几点区别：\n实例化方式：静态内部类可以直接通过外部类名来实例化，而非静态内部类必须要通过外部类的实例来实例化。 对外部类的引用：静态内部类不持有对外部类实例的引用，而非静态内部类则会持有对外部类实例的引用。这意味着在静态内部类中不能直接访问外部类的非静态成员（方法或字段），而非静态内部类可以。 生命周期：静态内部类的生命周期与外部类相互独立，即使外部类实例被销毁，静态内部类仍然存在。非静态内部类的生命周期与外部类实例绑定，只有在外部类实例存在时才能创建非静态内部类的实例。 访问权限：静态内部类对外部类的访问权限与其他类一样，根据访问修饰符而定。非静态内部类可以访问外部类的所有成员，包括私有成员。 ","date":"7 March 2025","externalUrl":null,"permalink":"/posts/1741324059033-java-%E6%8A%BD%E8%B1%A1%E7%B1%BB%E6%8E%A5%E5%8F%A3%E5%86%85%E9%83%A8%E7%B1%BB/","section":"Posts","summary":"","title":"java 抽象类\u0026接口\u0026内部类","type":"posts"},{"content":" 方法 # 1.1方法的定义和调用 # 方法是程序中最小的执行单元。\n方法必须先创建才可以使用，该过程成为方法的定义。 方法创建后并不是直接可以运行的，需要手动使用后，才执行，该过程称为方法调用。 无参数方法定义和调用：\n定义格式：\npublic static void 方法名 ( ) { // 方法体; } 调用格式：\n方法名(); 注意：\n​\t方法必须先定义，后调用，否则程序将报错\n带参数方法定义和调用：\n定义格式：\n参数：由数据类型和变量名组成： 数据类型 变量名\npublic static void 方法名 (参数1) { 方法体; } public static void 方法名 (参数1, 参数2, 参数3...) { 方法体; } 注意：\n方法定义时，参数中的数据类型与变量名都不能缺少，缺少任意一个程序将报错 方法定义时，多个参数之间使用逗号( ，)分隔 调用格式：\n方法名(参数)； 方法名(参数1,参数2); 方法调用时，参数的数量与类型必须与方法定义中的设置相匹配，否则程序将报错\n带返回值方法的定义和调用：\n定义格式：\npublic static 数据类型 方法名 ( 参数 ) { return 数据 ; } 注意：\n​\t方法定义时return后面的返回值与方法定义上的数据类型要匹配，否则程序将报错\n调用格式：\n方法名 ( 参数 ) ; 数据类型 变量名 = 方法名 ( 参数 ) ; 方法的返回值通常会使用变量接收，否则该返回值将无意义\n1.2 可变长参数 # 从 Java5 开始，Java 支持定义可变长参数，所谓可变长参数就是允许在调用方法时传入不定长度的参数。就比如下面这个方法就可以接受 0 个或者多个参数。\npublic static void method1(String... args) { //...... } 另外，可变参数只能作为函数的最后一个参数，但其前面可以有也可以没有任何其他参数。\npublic static void method2(String arg1, String... args) { //...... } 遇到方法重载的情况怎么办呢？会优先匹配固定参数还是可变参数的方法呢？\n会优先匹配固定参数的方法，因为固定参数的方法匹配度更高。Java 的可变参数编译后实际会被转换成一个数组。\n1.3 方法的注意事项 # 方法不能嵌套定义 void表示无返回值，可以省略return，也可以单独的书写return，后面不加数据 方法的通用格式：\npublic static 返回值类型 方法名(参数) { 方法体; return 数据 ; } 解释：\npublic static 修饰符，目前先记住这个格式\n返回值类型\t方法操作完毕之后返回的数据的数据类型\n​\t如果方法操作完毕，没有数据返回，这里写void，而且方法体中一般不写return\n方法名\t调用方法时候使用的标识\n参数\t由数据类型和变量名组成，多个参数之间用逗号隔开\n方法体\t完成功能的代码块\nreturn\t如果方法操作完毕，有数据返回，用于把数据返回给调用者\n定义方法时，要做到两个明确：\n明确返回值类型：主要是明确方法操作完毕之后是否有数据返回，如果没有，写void；如果有，写对应的数据类型 明确参数：主要是明确参数的类型和数量 调用方法时的注意：\nvoid类型的方法，直接调用即可 非void类型的方法，推荐用变量接收调用 静态方法1为什么不能调用非静态成员？\n静态方法是属于类的，在类加载的时候就会分配内存，可以通过类名直接访问。而非静态成员属于实例对象，只有在对象实例化之后才存在，需要通过类的实例对象去访问。\n在类的非静态成员不存在的时候静态方法就已经存在了，此时调用在内存中还不存在的非静态成员，属于非法操作。\n关于静态方法更多内容参考：静态方法\n1.4 方法重载 # 方法重载指同一个类中定义的多个方法之间的关系，满足下列条件的多个方法相互构成重载\n多个方法在同一个类中 多个方法具有相同的方法名 多个方法的参数不相同，类型不同或者数量不同 注意：\n重载仅对应方法的定义，与方法的调用无关，调用方式参照标准格式 重载仅针对同一个类中方法的名称与参数进行识别，与返回值无关，换句话说不能通过返回值来判定两个方法是否相互构成重载 静态方法（Static Method）是属于类而不是类的实例的方法。它可以在不创建类的实例的情况下被调用。静态方法通常用于执行与类相关的操作，而不需要访问或修改特定实例的状态。在Java中，声明静态方法需要使用static关键字。静态方法可以直接属于类，而不是类的实例。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"7 March 2025","externalUrl":null,"permalink":"/posts/1741323931762-java-%E6%96%B9%E6%B3%95/","section":"Posts","summary":"","title":"java 方法","type":"posts"},{"content":" Java概述 # 1.1 Java是什么？ # 计算机语言：人与计算机之间进行信息交流沟通的一种特殊语言。\n==Java是一门非常火的计算机语言。==\n1.2 JDK的安装目录介绍 # 目录名称 说明 bin 该目录下存放了JDK的各种工具命令。javac和java就放在这个目录。 conf 该目录下存放了JDK的相关配置文件。 include 该目录下存放了一些平台特定的头文件。 jmods 该目录下存放了JDK的各种模块。 legal 该路径下存放了JDK各模块的授权文档。 lib 该路径下存放了JDK工具的一些补充jar包。 1.3 BUG # 在电脑系统或程序中，隐藏着的未被发现的缺陷或问题统称为bug(漏洞)。\n1.4 Java的三大平台 # 1.4.1 JavaSE # Java 平台标准版，Java 编程语言的基础，它包含了==支持 Java 应用程序开发和运行的核心类库以及虚拟机等核心组件==。Java SE 可以用于构建桌面应用程序或简单的服务器应用程序。\n1.4.2 JavaME # java语言的小型版，==用于嵌入式消费类电子设备或者小型移动设备的开发。==\n其中最为主要的还是小型移动设备的开发（手机）。渐渐的没落了，已经被安卓和IOS给代替了，不过安卓也是用Java来开发的。\n1.4.3 JavaEE # Java 平台企业版，建立在 Java SE 的基础上，==包含了支持企业级应用程序开发和部署的标准和规范==（比如 Servlet、JSP、EJB、JDBC、JPA、JTA、JavaMail、JMS）。 Java EE 可以用于构建分布式、可移植、健壮、可伸缩和安全的服务端 Java 应用程序，例如 Web 应用程序。\n1.5 Java的主要特性 # 面向对象（封装，继承，多态） 安全性（Java 语言本身的设计就提供了多重安全防护机制如访问权限修饰符、限制程序直接访问操作系统资源） 支持多线程（ C++ 语言没有内置的多线程机制，因此必须调用操作系统的多线程功能来进行多线程程序设计，而 Java 语言却提供了多线程支持） 简单易用（语法简单，上手容易） 开源 跨平台（ Java 虚拟机实现平台无关性） 修正：C++11 开始（2011 年的时候）,C++就引入了多线程库，在 windows、linux、macos 都可以使用std::thread和std::async来创建线程。参考链接：http://www.cplusplus.com/reference/thread/thread/?kw=thread\n1.6 Java语言跨平台的原理 # 操作系统本身是不认识java语言的。 针对于不同的操作系统，java提供了不同的虚拟机（JVM）。 虚拟机会把java语言翻译成操作系统可以看的懂的语言。\n1.7 JVM \u0026amp; JRE \u0026amp; JDK # ==JVM，java虚拟机。==\n==JRE，java运行环境，包含了JVM和java的核心类库（Java API）==\n==JDK,称为java开发工具，包含了jre和开发工具。==\n当我们在安装时，只需要安装JDK即可，它包含了java的运行环境和虚拟机。\n1.7.1 JVM # Java 虚拟机（Java Virtual Machine, JVM）是运行 Java 字节码的虚拟机。==JVM 有针对不同系统的特定实现（Windows，Linux，macOS），目的是使用相同的字节码，它们都会给出相同的结果==。字节码和不同系统的 JVM 实现是 Java 语言“一次编译，随处可以运行”的关键所在。\n如下图所示，不同编程语言（Java、Groovy、Kotlin、JRuby、Clojure \u0026hellip;）通过各自的编译器编译成 .class 文件，并最终通过 JVM 在不同平台（Windows、Mac、Linux）上运行。\nJVM并不止有一种，只要满足JVM规范，每个公司、组织或者个人都可以开发自己的专属JVM，我们平时接触到的 HotSpot VM 仅仅是是 JVM 规范的一种实现而已，我们可以在Java SE Specifications 上找到各个版本的 JDK 对应的 JVM 规范。\n下面这张图是 JVM 的大致结构模型。\n1.7.2 JDK和JRE # ==JDK（Java Development Kit）是一个功能齐全的 Java 开发工具包，供开发者使用，用于创建和编译 Java 程序==。它包含了 JRE（Java Runtime Environment），以及编译器 javac 和其他工具，如 javadoc（文档生成器）、jdb（调试器）、jconsole（监控工具）、javap（反编译工具）等。\n==JRE是运行已编译 Java 程序所需的环境==，主要包含以下两个部分：\nJVM : 也就是我们上面提到的 Java 虚拟机。 Java 基础类库（Class Library）：一组标准的类库，提供常用的功能和 API（如 I/O 操作、网络通信、数据结构等）。 简单来说，JRE 只包含运行 Java 程序所需的环境和类库，而 JDK 不仅包含 JRE，还包括用于开发和调试 Java 程序的工具。\n如果需要编写、编译 Java 程序或使用 Java API 文档，就需要安装 JDK。某些需要 Java 特性的应用程序（如 JSP 转换为 Servlet 或使用反射）也可能需要 JDK 来编译和运行 Java 代码。因此，即使不进行 Java 开发工作，有时也可能需要安装 JDK。\n下图清晰展示了 JDK、JRE 和 JVM 的关系。\n从 JDK 9 开始，就不需要区分 JDK 和 JRE 的关系了，取而代之的是模块系统（JDK 被重新组织成 94 个模块）+ jlink 工具 (随 Java 9 一起发布的新命令行工具，用于生成自定义 Java 运行时映像，该映像仅包含给定应用程序所需的模块) 。并且，从 JDK 11 开始，Oracle 不再提供单独的 JRE 下载。\n1.8 Java语言的运行 # Java 程序从源代码到运行的过程如下图所示：\n我们需要格外注意的是 .class-\u0026gt;机器码 这一步。**在这一步 JVM 类加载器首先加载字节码文件，然后通过解释器逐行解释执行，这种方式的执行速度会相对比较慢。**而且，有些方法和代码块是经常需要被调用的(也就是所谓的热点代码)，所以后面引进了 JIT（Just in Time Compilation） 编译器，而 JIT 属于运行时编译。**当 JIT 编译器完成第一次编译后，其会将字节码对应的机器码保存下来，下次可以直接使用。**而我们知道，机器码的运行效率肯定是高于 Java 解释器的。这也解释了我们为什么经常会说 Java 是编译与解释共存的语言。\n扩展：有关JIT实现的细节：JVM C1、C2编译器\nHotSpot1 采用了惰性评估(Lazy Evaluation)的做法，根据二八定律，消耗大部分系统资源的只有那一小部分的代码（热点代码），而这也就是 JIT 所需要编译的部分。JVM 会根据代码每次被执行的情况收集信息并相应地做出一些优化，因此执行的次数越多，它的速度就越快。\nJDK、JRE、JVM、JIT\n这四者的关系如下图所示。\n为什么说 Java 语言“编译与解释并存”？\n因为 Java 语言既具有编译型语言的特征，也具有解释型语言的特征。Java 程序要经过先编译，后解释两个步骤，由 Java 编写的程序需要先经过编译步骤，生成字节码（.class 文件），这种字节码必须由 Java 解释器来解释执行。\n我们可以将高级编程语言2按照程序的执行方式分为两种：\n编译型：编译型语言会通过编译器将源代码一次性翻译成可被该平台执行的机器码。一般情况下，编译语言的执行速度比较快，开发效率比较低。常见的编译性语言有 C、C++、Go、Rust 等等。\n解释型：解释型语言会通过解释器一句一句的将代码解释（interpret）为机器代码后再执行。解释型语言开发效率比较快，执行速度比较慢。常见的解释性语言有 Python、JavaScript、PHP 等等。\n为了改善解释语言的效率而发展出的即时编译技术，已经缩小了这两种语言间的差距。这种技术混合了编译语言与解释型语言的优点，它像编译语言一样，先把程序源代码编译成字节码。到执行期时，再将字节码直译，之后执行。Java与LLVM是这种技术的代表产物。\n相关阅读：基本功 | Java 即时编译器原理解析及实践\n1.8.1 JIT与AOT # JDK 9 引入了一种新的编译模式 AOT(Ahead of Time Compilation) 。和 JIT 不同的是，这种编译模式会在程序被执行前就将其编译成机器码，属于静态编译（C、 C++，Rust，Go 等语言就是静态编译）。**AOT 避免了 JIT 预热等各方面的开销，可以提高 Java 程序的启动速度，避免预热时间长。**并且，AOT 还能减少内存占用和增强 Java 程序的安全性（AOT 编译后的代码不容易被反编译和修改），特别适合云原生场景。\nJIT 与 AOT 两者的关键指标对比:\n可以看出，AOT 的主要优势在于启动时间、内存占用和打包体积。JIT 的主要优势在于具备更高的极限处理能力，可以降低请求的最大延迟。\n既然 AOT 这么多优点，那为什么不全部使用这种编译方式呢？\nAOT 更适合当下的云原生场景，对微服务架构的支持也比较友好。除此之外，==AOT 编译无法支持 Java 的一些动态特性==，如反射、动态代理、动态加载、JNI（Java Native Interface）等。然而，很多框架和库（如 Spring、CGLIB）都用到了这些特性。如果只使用 AOT 编译，那就没办法使用这些框架和库了，或者说需要针对性地去做适配和优化。举个例子，CGLIB 动态代理使用的是 ASM 技术，而这种技术大致原理是运行时直接在内存中生成并加载修改后的字节码文件也就是 .class 文件，如果全部使用 AOT 提前编译，也就不能使用 ASM 技术了。为了支持类似的动态特性，所以选择使用 JIT 即时编译器。\n1.9 Java和C++的区别 # Java 不提供指针来直接访问内存，程序内存更加安全 Java 的类是单继承的，C++ 支持多重继承；虽然 Java 的类不可以多继承，但是接口可以多继承。 Java 有自动内存管理垃圾回收机制(GC)，不需要程序员手动释放无用内存。 C ++同时支持方法重载和操作符重载，但是 Java 只支持方法重载（操作符重载增加了复杂性，这与 Java 最初的设计思想不符）。 …… HotSpot是较新的Java虚拟机，用来代替JIT(Just in Time)，可以大大提高Java运行的性能。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n高级编程语言：是一种独立于机器，面向过程或对象的语言。 高级语言是参照数学语言而设计的近似于日常会话的语言。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"7 March 2025","externalUrl":null,"permalink":"/posts/1741323804725-java-%E6%A6%82%E8%BF%B0/","section":"Posts","summary":"","title":"java 概述","type":"posts"},{"content":" 流程控制语句 # 流程控制语句分类：\n​\t顺序结构\n​\t判断和选择结构(if, switch)\n​\t循环结构(for, while, do…while)\n1.1 顺序结构 # 顺序结构是程序中最简单最基本的流程控制，没有特定的语法结构，按照代码的先后顺序，依次执行，程序中大多数的代码都是这样执行的。\n1.2 判断语句：if语句 # 1.2.1 if语句格式 1 # 格式： if (关系表达式) { 语句体;\t} 执行流程：\n①首先计算关系表达式的值\n②如果关系表达式的值为true就执行语句体\n③如果关系表达式的值为false就不执行语句体\n④继续执行后面的语句内容\n如果我们要对一个布尔类型的变量进行判断，不要写 == ，直接把变量写在小括号中即可。\n如果大括号中的语句体只有一条，那么大括号可以省略不写\n如果大括号省略了，那么if只能控制距离他最近的那一条语句。\n**建议：**自己不要去写，如果别人这么写了，你要能看懂即可。\n1.2.2 if语句格式 2 # 格式： if (关系表达式) { 语句体1;\t} else { 语句体2;\t} 执行流程：\n①首先计算关系表达式的值\n②如果关系表达式的值为true就执行语句体1\n③如果关系表达式的值为false就执行语句体2\n④继续执行后面的语句内容\n1.2.3 if语句格式 3 # 格式： if (关系表达式1) { 语句体1;\t} else if (关系表达式2) { 语句体2;\t} … else { 语句体n+1; } 执行流程：\n①首先计算关系表达式1的值\n②如果值为true就执行语句体1；如果值为false就计算关系表达式2的值\n③如果值为true就执行语句体2；如果值为false就计算关系表达式3的值\n④…\n⑤如果没有任何关系表达式为true，就执行语句体n+1。\n1.2.4 switch语句 # switch (表达式) { case 1: 语句体1; break; case 2: 语句体2; break; ... default: 语句体n+1; break; } 执行流程：\n首先计算出表达式的值 其次，和case依次比较，一旦有对应的值，就会执行相应的语句，在执行的过程中，遇到break就会结 束。 最后，如果所有的case都和表达式的值不匹配，就会执行default语句体部分，然后程序结束掉。 switch的扩展知识：\ndefault的位置和省略情况\ndefault可以放在任意位置，也可以省略\ncase穿透\n不写break会引发case穿透现象\nswitch在JDK12的新特性\nint number = 10; switch (number) { case 1 -\u0026gt; System.out.println(\u0026#34;一\u0026#34;); case 2 -\u0026gt; System.out.println(\u0026#34;二\u0026#34;); case 3 -\u0026gt; System.out.println(\u0026#34;三\u0026#34;); default -\u0026gt; System.out.println(\u0026#34;其他\u0026#34;); } switch和if第三种格式各自的使用场景 1.3 循环结构 # 1.3.1 for循环结构 # 循环语句可以在满足循环条件的情况下，反复执行某一段代码，这段被重复执行的代码被称为循环体语句，当反复 执行这个循环体时，需要在合适的时候把循环判断条件修改为false，从而结束循环，否则循环将一直执行下去，形成死循环。\nfor循环格式：\nfor (初始化语句;条件判断语句;条件控制语句) { 循环体语句; } 格式解释：\n初始化语句： 用于表示循环开启时的起始状态，简单说就是循环开始的时候什么样 条件判断语句：用于表示循环反复执行的条件，简单说就是判断循环是否能一直执行下去 循环体语句： 用于表示循环反复执行的内容，简单说就是循环反复执行的事情 条件控制语句：用于表示循环执行中每次变化的内容，简单说就是控制循环是否能执行下去 执行流程：\n①执行初始化语句\n②执行条件判断语句，看其结果是true还是false\n​ 如果是false，循环结束\n​ 如果是true，继续执行\n③执行循环体语句\n④执行条件控制语句\n⑤回到②继续\n1.3.2 while循环 # 循环格式：\n初始化语句; while(条件判断语句){ 循环体; 条件控制语句; } 1.3.3 do····while循环 # 格式：\n初始化语句; do{ 循环体; 条件控制语句; }while(条件判断语句); 特点：\n​\t先执行，再判断。\n","date":"7 March 2025","externalUrl":null,"permalink":"/posts/1741323871069-java-%E6%B5%81%E7%A8%8B%E6%8E%A7%E5%88%B6%E8%AF%AD%E5%8F%A5/","section":"Posts","summary":"","title":"java 流程控制语句","type":"posts"},{"content":" 运算符 # 1.1 运算符与表达式 # 运算符\n​\t就是对常量或者变量进行操作的符号。\n​\t比如： + - * /\n表达式\n​\t用运算符把常量或者变量连接起来的，符合Java语法的式子就是表达式。\n​\t比如：a + b 这个整体就是表达式。\n​\t而其中+是算术运算符的一种，所以这个表达式也称之为算术表达式。\n1.2 算术运算符 # 分类：\n+ - * / % 运算特点：\n+ - * :跟小学数学中一模一样没有任何区别. /： 1.整数相除结果只能得到整除，如果结果想要是小数，必须要有小数参数。 2.小数直接参与运算，得到的结果有可能是不精确的。 案例： System.out.println( 10 / 3);//3 System.out.println(10.0 / 3);//3.3333333333333335 %：取模、取余。 他做的也是除法运算，只不过获取的是余数而已。 案例： System.out.println(10 % 2);//0 System.out.println(10 % 3);//1 应用场景： //可以利用取模来判断一个数是奇数还是偶数 System.out.println(15 % 2);//1 奇数 1.3 隐式转换 # 也叫自动类型提升。\n​\t==就是把一个取值范围小的数据或者变量，赋值给另一个取值范围大的变量。此时不需要我们额外写代码单独实现，是程序自动帮我们完成的。==\n两种提升规则：\n取值范围小的，和取值范围大的进行运算，小的会先提升为大的，再进行运算。 byte、short、char三种类型的数据在运算的时候，都会直接先提升为int，然后再进行运算。 取值范围从小到大的关系：\n​\tbyte \u0026lt; short \u0026lt; int \u0026lt; long \u0026lt; float \u0026lt; double\n1.4 强制转换 # 如果要把一个取值范围大的数据或者变量赋值给另一个取值范围小的变量。是不允许直接操作。\n​\t如果一定要这么干，就需要加入强制转换。\n书写格式：\n​\t目标数据类型 变量名 = （目标数据类型）被强转的数据；\n简单理解：\n​\t要转成什么类型的，那么就在小括号中写什么类型就可以了。\n注意点：\n​\t强制转换有可能会导致数据发生错误。（数据的精度丢失）\n1.5 字符串的 + 操作 # 当 + 操作中出现字符串时，此时就是字符串的连接符，会将前后的数据进行拼接，并产生一个新的字符串。 当连续进行 + 操作时，从左到右逐个执行的。 1.6 字符的 + 操作 # 当+操作中出现了字符，会拿着字符到计算机内置的ASCII码表中去查对应的数字，然后再进行计算。\nASCII码表中：\n​\t\u0026lsquo;a\u0026rsquo; \u0026mdash;\u0026ndash; 97\n​\t\u0026lsquo;A\u0026rsquo; \u0026mdash;\u0026ndash; 65\n1.7 自增自减运算符 # ++ 自增运算符 -- 自减运算符 ++：就是把变量里面的值 +1\n\u0026ndash;：就是把变量里面的值 -1\n使用方式：\n放在变量的前面，我们叫做先++。 比如：++a 放在变量的后面，我们叫做后++。 比如：a++ 注意点：\n​\t不管是先++，还是后++。单独写在一行的时候，运算结果是一模一样的。\n先++ 与 后++ 的区别：\n无论前++，后++，最后都会自增1，区别在于是先自增，还是先参与运算。(自减与自增类似)。\n​ 前++：先进行+1操作。\n​ 后++：后进行+1操作。\n1.8 赋值运算符 # 最为常用的：\t=\n运算过程：就是把等号右边的结果赋值给左边的变量\n1.9 扩展赋值运算符 # 分类：\n​\t+=、-=、*=、/=、%=\n运算规则：\n​\t就是把左边跟右边进行运算，把最终的结果赋值给左边，对右边没有任何影响。\n注意点：\n​ 扩展的赋值运算符中隐层还包含了一个强制转换。\n以+=为例。\na += b ;实际上相当于 a = (byte)(a + b);\n1.10 关系运算符 # 又叫比较运算符，其实就是拿着左边跟右边进行了判断而已。\n符号 解释 == 就是判断左边跟右边是否相等，如果成立就是true，如果不成立就是false != 就是判断左边跟右边是否不相等，如果成立就是true，如果不成立就是false \u0026gt; 就是判断左边是否大于右边，如果成立就是true，如果不成立就是false \u0026gt;= 就是判断左边是否大于等于右边，如果成立就是true，如果不成立就是false \u0026lt; 就是判断左边是否小于右边，如果成立就是true，如果不成立就是false \u0026lt;= 就是判断左边是否小于等于右边，如果成立就是true，如果不成立就是false 注意点：\n关系运算符最终的结果一定是布尔类型的。要么是true，要么是false 在写 == 的时候，千万不要写成 = 1.11 逻辑运算符 # \u0026amp; 和 | 的使用：\n\u0026amp;：逻辑与（而且）\n​\t两边都为真，结果才是真，只要有一个为假，那么结果就是假。\n|：逻辑或（或者）\n​\t两边都为假，结果才是假，只要有一个为真，那么结果就是真。\n^（异或）的使用：\n​\t在以后用的不多，了解一下即可。\n计算规则：如果两边相同，结果为false，如果两边不同，结果为true\n!（取反）的使用：\n​\t是取反，也叫做非。\n计算规则：false取反就是true，true取反就是false\n温馨提示：取反最多只用一个。\n1.12 短路逻辑运算符 # \u0026amp;\u0026amp;：\n​\t运算结果跟\u0026amp;是一模一样的，只不过具有短路效果。\n||：\n​\t运算结果跟|是一模一样的。只不过具有短路效果。\n逻辑核心：\n​\t当左边不能确定整个表达式的结果，右边才会执行。\n​\t当左边能确定整个表达式的结果，那么右边就不会执行了。从而提高了代码的运行效率。\n1.13 三元运算符 # 又叫做：三元表达式或者问号冒号表达式。\n格式：\n​\t关系表达式 ？ 表达式1 ：表达式2 ；\n计算规则：\n计算关系表达式的值。 如果关系表达式的值为真，那么执行表达式1。 如果关系表达式的值为假，那么执行表达式2。 注意点：\n​\t三元运算符的最终结果一定要被使用，要么赋值给一个变量，要么直接打印出来。\n1.14 运算符的优先级 # 在Java中涉及了很多的运算符，每一种运算符都有各自的优先级。但是这些优先级不需要记忆。\n咱们只要知道其中一点：\n​\t小括号优先于所有。\n1.15 移位运算符 # 移位运算符是最基本的运算符之一，几乎每种编程语言都包含这一运算符。移位操作中，被操作的数据被视为二进制数，移位就是将其向左或向右移动若干位的运算。\n移位运算符在各种框架以及 JDK 自身的源码中使用还是挺广泛的，HashMap（JDK1.8） 中的 hash 方法的源码就用到了移位运算符：\nstatic final int hash(Object key) { int h; // key.hashCode()：返回散列值也就是hashcode // ^：按位异或 // \u0026gt;\u0026gt;\u0026gt;:无符号右移，忽略符号位，空位都以0补齐 return (key == null) ? 0 : (h = key.hashCode()) ^ (h \u0026gt;\u0026gt;\u0026gt; 16); } 使用移位运算符的主要原因：\n高效：移位运算符直接对应于处理器的移位指令。现代处理器具有专门的硬件指令来执行这些移位操作，这些指令通常在一个时钟周期内完成。相比之下，乘法和除法等算术运算在硬件层面上需要更多的时钟周期来完成。\n节省内存：通过移位操作，可以使用一个整数（如 int 或 long）来存储多个布尔值或标志位，从而节省内存。\n移位运算符最常用于快速乘以或除以 2 的幂次方。除此之外，它还在以下方面发挥着重要作用：\n位字段管理：例如存储和操作多个布尔值。 哈希算法和加密解密：通过移位和与、或等操作来混淆数据。 数据压缩：例如霍夫曼编码通过移位运算符可以快速处理和操作二进制数据，以生成紧凑的压缩格式。 数据校验：例如 CRC（循环冗余校验）通过移位和多项式除法生成和校验数据完整性。。 内存对齐：通过移位操作，可以轻松计算和调整数据的对齐地址。 Java 中有三种移位运算符：\n\u0026lt;\u0026lt; :左移运算符，向左移若干位，高位丢弃，低位补零。x \u0026lt;\u0026lt; n,相当于 x 乘以 2 的 n 次方(不溢出的情况下)。 \u0026gt;\u0026gt; :带符号右移，向右移若干位，高位补符号位，低位丢弃。正数高位补 0,负数高位补 1。x \u0026gt;\u0026gt; n,相当于 x 除以 2 的 n 次方。 \u0026gt;\u0026gt;\u0026gt; :无符号右移，忽略符号位，空位都以 0 补齐。 虽然移位运算本质上可以分为左移和右移，但在实际应用中，右移操作需要考虑符号位的处理方式。\n由于 double，float 在二进制中的表现比较特殊，因此不能来进行移位操作。\n移位操作符实际上支持的类型只有int和long，编译器在对short、byte、char类型进行移位前，都会将其转换为int类型再操作。\n如果移位的位数超过数值所占有的位数会怎样？\n当 int 类型左移/右移位数大于等于 32 位操作时，会先求余（%）后再进行左移/右移操作。也就是说左移/右移 32 位相当于不进行移位操作（32%32=0），左移/右移 42 位相当于左移/右移 10 位（42%32=10）。当 long 类型进行左移/右移操作时，由于 long 对应的二进制是 64 位，因此求余操作的基数也变成了 64。\n也就是说：x\u0026lt;\u0026lt;42等同于x\u0026lt;\u0026lt;10，x\u0026gt;\u0026gt;42等同于x\u0026gt;\u0026gt;10，x \u0026gt;\u0026gt;\u0026gt;42等同于x \u0026gt;\u0026gt;\u0026gt; 10。\n","date":"7 March 2025","externalUrl":null,"permalink":"/posts/1741323849157-java-%E8%BF%90%E7%AE%97%E7%AC%A6/","section":"Posts","summary":"","title":"java 运算符","type":"posts"},{"content":" 面向对象 # 1.1 类和对象 # 客观存在的事务皆为对象，所以我们也常常说万物皆对象。\n类：\n==类是对现实生活中一类具有共同属性和行为的事物的抽象== 类是对象的数据类型，类是具有相同属性和行为的一组对象的集合 简单理解：类就是对现实事物的一种描述 类的组成：\n属性：指事物的特征，例如：手机事物（品牌，价格，尺寸） 行为：指事物能执行的操作，例如：手机事物（打电话，发短信） 类和对象的关系：\n类：类是对现实生活中一类具有共同属性和行为的事物的抽象 对象：是能够看得到摸的着的真实存在的实体 简单理解：类是对事物的一种描述，对象则为具体存在的事物 1.1.1 类的定义 # 类的组成是由属性和行为两部分组成\n属性：在类中通过成员变量来体现（类中方法外的变量） 行为：在类中通过成员方法来体现（和前面的方法相比去掉static关键字即可） 类的定义步骤：\n①定义类\n②编写类的成员变量\n③编写类的成员方法\npublic class 类名 { // 成员变量 变量1的数据类型 变量1； 变量2的数据类型 变量2; … // 成员方法 方法1; 方法2;\t} 1.1.2 对象的使用 # 创建对象的格式：\n​\t类名 对象名 = new 类名();\nnew 运算符，new 创建对象实例（对象实例在堆内存中），对象引用指向对象实例（对象引用存放在栈内存中）。\n一个对象引用可以指向 0 个或 1 个对象（一根绳子可以不系气球，也可以系一个气球）； 一个对象可以有 n 个引用指向它（可以用 n 条绳子系住一个气球）。 对象的相等和引用相等的区别\n对象的相等一般比较的是内存中存放的内容是否相等。 引用相等一般比较的是他们指向的内存地址是否相等。 调用成员的格式：\n​\t对象名.成员变量\n​\t对象名.成员方法();\n1.1.3 面向对象和面向过程的区别 # 面向过程编程（Procedural-Oriented Programming，POP）和面向对象编程（Object-Oriented Programming，OOP）是两种常见的编程范式，两者的主要区别在于解决问题的方式不同：\n面向过程编程（POP）：面向过程把解决问题的过程拆成一个个方法，通过一个个方法的执行解决问题。 面向对象编程（OOP）：面向对象会先抽象出对象，然后用对象执行方法的方式解决问题。 相比较于 POP，OOP 开发的程序一般具有下面这些优点：\n易维护：由于良好的结构和封装性，OOP 程序通常更容易维护。 易复用：通过继承和多态，OOP 设计使得代码更具复用性，方便扩展功能。 易扩展：模块化设计使得系统扩展变得更加容易和灵活。 POP 的编程方式通常更为简单和直接，适合处理一些较简单的任务。\nPOP 和 OOP 的性能差异主要取决于它们的运行机制，而不仅仅是编程范式本身。\n1.1.4 创建对象的几种额外方式 # 在Java中，有以下几种常见的方式来创建对象：\n使用new关键字：这是最常见的创建对象的方式。通过调用类的构造函数，使用new关键字可以在内存中分配一个新的对象。\n使用反射：Java的反射机制允许在运行时动态地创建对象。通过获取类的Class对象，并调用其构造函数，可以实现对象的创建。\n使用newInstance()方法：某些类提供了newInstance()方法来创建对象，这种方式只适用于具有默认无参构造函数的类。\n使用clone()方法：如果类实现了Cloneable接口，就可以使用clone()方法创建对象的副本。\n使用对象的反序列化：通过将对象序列化到一个字节流中，然后再进行反序列化，可以创建对象的副本。\n其中，使用new关键字是最常见和推荐的创建对象的方式。其他方式通常在特定场景下使用，如需要动态创建对象或创建对象的副本等情况。\n1.2 对象内存图 # 1.2.1 单个对象内存图 # 成员变量使用过程 成员方法调用过程 1.2.2 多个对象内存图 # 成员变量使用过程 成员方法调用过程 总结\n多个对象在堆内存中，都有不同的内存划分，成员变量存储在各自的内存区域中，成员方法多个对象共用的一份\n1.3 成员变量和局部变量 # 成员变量和局部变量的区别：\n语法形式不同：从语法形式上看，==成员变量是属于类的，而局部变量是在代码块或方法中定义的变量或是方法的参数==；成员变量可以被 public,private,static 等修饰符所修饰，而局部变量不能被访问控制修饰符及 static 所修饰；但是，成员变量和局部变量都能被 final 所修饰。 存储方式不同：从变量在内存中的存储方式来看，如果成员变量是使用 static 修饰的，那么这个成员变量是属于类的，如果没有使用 static 修饰，这个成员变量是属于实例的。而==对象存在于堆内存，局部变量则存在于栈内存==。\n生存时间不同：从变量在内存中的生存时间上看，==成员变量是对象的一部分，它随着对象的创建而存在，而局部变量随着方法的调用而自动生成，随着方法的调用结束而消亡==。\n默认值不同：从变量是否有默认值来看，==成员变量如果没有被赋初始值，则会自动以类型的默认值而赋值==（一种情况例外:被 final 修饰的成员变量也必须显式地赋值）。而==局部变量则不会自动赋值，必须先定义，赋值才能使用==\n为什么成员变量有默认值？\n先不考虑变量类型，如果没有默认值，变量存储的是内存地址对应的任意随机值，程序读取该值运行会出现意外。 默认值有两种设置方式：手动和自动，根据第一点，没有手动赋值一定要自动赋值。成员变量在运行时可借助反射等方法手动赋值，而局部变量不行。 对于编译器（javac）来说，局部变量没赋值很好判断，可以直接报错。而成员变量可能是运行时赋值，无法判断，误报“没默认值”又会影响用户体验，所以采用自动赋默认值。 1.4 封装 # 1.4.1 封装思想 # 封装概述 是面向对象三大特征之一（封装，继承，多态）\n==封装是指把一个对象的状态信息（也就是属性）隐藏在对象内部，不允许外部对象直接访问对象的内部信息。但是可以提供一些可以被外界访问的方法来操作属性。==\n如果属性不想被外界访问，我们大可不必提供方法给外界访问。但是如果一个类没有提供给外界访问的方法，那么这个类也没有什么意义了。\n封装代码实现 将类的某些信息隐藏在类内部，不允许外部程序直接访问，而是通过该类提供的方法来实现对隐藏信息的操作和访问 成员变量private，提供对应的getXxx()/setXxx()方法\n1.4.2 private关键字 # private是一个修饰符，可以用来修饰成员（成员变量，成员方法）\n被private修饰的成员，只能在本类进行访问，针对private修饰的成员变量，如果需要被其他类使用，提供相应的操作 提供“get变量名()”方法，用于获取成员变量的值，方法用public修饰 提供“set变量名(参数)”方法，用于设置成员变量的值，方法用public修饰 1.4.3 this关键字 # this修饰的变量用于指代成员变量，其主要作用是区分局部变量和成员变量的重名问题 方法的形参如果与成员变量同名，不带this修饰的变量指的是形参，而不是成员变量 方法的形参没有与成员变量同名，不带this修饰的变量指的是成员变量 我们以实体类中的set方法为例，因为set方法的形参和成员变量同名，所以带this的是成员变量，idea自动生成的set方法如下：\npublic void setA(int a) { this.a = a; } 除此之外，在全参构造时，情况也与此类似\n1.5 构造方法 # 1.5.1 构造方法概述 # 构造方法是一种特殊的方法\n作用：创建对象 Student stu = new Student();\n格式：\npublic class 类名{\n​ 修饰符 类名( 参数 ) {\n​ }\n}\n功能：主要是完成对象数据的初始化\n1.5.2 构造方法的注意事项 # 构造方法的创建 如果没有定义构造方法，系统将给出一个默认的无参数构造方法 如果定义了构造方法，系统将不再提供默认的构造方法\n构造方法的重载 如果自定义了带参构造方法，还要使用无参数构造方法，就必须再写一个无参数构造方法\n推荐的使用方式 无论是否使用，都手工书写无参数构造方法\n重要功能 可以使用带参构造，为成员变量进行初始化\n如果一个类没有声明构造方法，该程序能正确执行吗？\n构造方法是一种特殊的方法，主要作用是完成对象的初始化工作。\n如果一个类没有声明构造方法，也可以执行，因为一个类即使没有声明构造方法也会有默认的不带参数的构造方法。如果我们自己添加了类的构造方法（无论是否有参），Java 就不会添加默认的无参数的构造方法了。\n我们一直在不知不觉地使用构造方法，这也是为什么我们在创建对象的时候后面要加一个括号（因为要调用无参的构造方法）。如果我们重载了有参的构造方法，记得都要把无参的构造方法也写出来（无论是否用到）。\n构造方法有哪些特点？是否可被override?\n构造方法具有以下特点：\n名称与类名相同：构造方法的名称必须与类名完全一致。 没有返回值：构造方法没有返回类型，且不能使用 void 声明。 自动执行：在生成类的对象时，构造方法会自动执行，无需显式调用。 构造方法不能被重写（override），但可以被重载（overload）。因此，一个类中可以有多个构造方法，这些构造方法可以具有不同的参数列表，以提供不同的对象初始化方式。\n1.5.3 标准类制作 # ① 类名需要见名知意\n② 成员变量使用private修饰\n③ 提供至少两个构造方法\n无参构造方法 带全部参数的构造方法 ④ get和set方法\n​\t提供每一个成员变量对应的setXxx()/getXxx()\n⑤ 如果还有其他行为，也需要写上\n","date":"7 March 2025","externalUrl":null,"permalink":"/posts/1741323945921-java-%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/","section":"Posts","summary":"","title":"java 面向对象","type":"posts"},{"content":" Java值传递详解 # 1.1 形参 \u0026amp; 实参 # 方法的定义可能会用到 参数（有参的方法），参数在程序语言中分为：\n实参（实际参数，Arguments）：用于传递给函数/方法的参数，必须有确定的值。 形参（形式参数，Parameters）：用于定义函数/方法，接收实参，不需要有确定的值。 String hello = \u0026#34;Hello!\u0026#34;; // hello 为实参 sayHello(hello); // str 为形参 void sayHello(String str) { System.out.println(str); } 1.2 值传递 \u0026amp; 引用传递 # 程序设计语言将实参传递给方法（或函数）的方式分为两种：\n值传递：方法接收的是实参值的拷贝，会创建副本。 引用传递：方法接收的直接是实参所引用的对象在堆中的地址，不会创建副本，对形参的修改将影响到实参。 很多程序设计语言（比如 C++、 Pascal )提供了两种参数传递的方式，不过，在 Java 中只有值传递。\n1.3 为什么Java只有值传递 # 为什么说 Java 只有值传递呢？ 不需要太多废话，我通过 3 个例子来给大家证明。\n1.3.1 案例1：传递基本参数类型 # 代码：\npublic static void main(String[] args) { int num1 = 10; int num2 = 20; swap(num1, num2); System.out.println(\u0026#34;num1 = \u0026#34; + num1); System.out.println(\u0026#34;num2 = \u0026#34; + num2); } public static void swap(int a, int b) { int temp = a; a = b; b = temp; System.out.println(\u0026#34;a = \u0026#34; + a); System.out.println(\u0026#34;b = \u0026#34; + b); } 输出：\na = 20 b = 10 num1 = 10 num2 = 20 解析：\n在 swap() 方法中，a、b 的值进行交换，并不会影响到 num1、num2。因为，a、b 的值，只是从 num1、num2 的复制过来的。也就是说，a、b 相当于 num1、num2 的副本，副本的内容无论怎么修改，都不会影响到原件本身。\n通过上面例子，我们已经知道了一个方法不能修改一个基本数据类型的参数，而对象引用作为参数就不一样，请看案例 2。\n1.3.2 案例2：传递引用类型参数1 # 代码：\npublic static void main(String[] args) { int[] arr = { 1, 2, 3, 4, 5 }; System.out.println(arr[0]); change(arr); System.out.println(arr[0]); } public static void change(int[] array) { // 将数组的第一个元素变为0 array[0] = 0; } 输出：\n1 0 解析：\n看了这个案例很多人肯定觉得 Java 对引用类型的参数采用的是引用传递。\n实际上，并不是的，这里传递的还是值，不过，这个值是实参的地址罢了！\n也就是说 change 方法的参数拷贝的是 arr （实参）的地址，因此，它和 arr 指向的是同一个数组对象。这也就说明了为什么方法内部对形参的修改会影响到实参。\n为了更强有力地反驳 Java 对引用类型的参数采用的不是引用传递，我们再来看下面这个案例！\n1.3.3 案例3：传递引用类型参数2 # public class Person { private String name; // 省略构造函数、Getter\u0026amp;Setter方法 } public static void main(String[] args) { Person xiaoZhang = new Person(\u0026#34;小张\u0026#34;); Person xiaoLi = new Person(\u0026#34;小李\u0026#34;); swap(xiaoZhang, xiaoLi); System.out.println(\u0026#34;xiaoZhang:\u0026#34; + xiaoZhang.getName()); System.out.println(\u0026#34;xiaoLi:\u0026#34; + xiaoLi.getName()); } public static void swap(Person person1, Person person2) { Person temp = person1; person1 = person2; person2 = temp; System.out.println(\u0026#34;person1:\u0026#34; + person1.getName()); System.out.println(\u0026#34;person2:\u0026#34; + person2.getName()); } 输出:\nperson1:小李 person2:小张 xiaoZhang:小张 xiaoLi:小李 解析：\n怎么回事？？？两个引用类型的形参互换并没有影响实参啊！\n注：引用传递在对引用类型参数进行传递时同样是传递地址，两个引用类型的形参呼唤同样不会影响实参。\nswap 方法的参数 person1 和 person2 只是拷贝的实参 xiaoZhang 和 xiaoLi 的地址。因此， person1 和 person2 的互换只是拷贝的两个地址的互换罢了，并不会影响到实参 xiaoZhang 和 xiaoLi 。\n1.4 引用传递是怎么样的 # 看到这里，相信你已经知道了 Java 中只有值传递，是没有引用传递的。 但是，引用传递到底长什么样呢？下面以 C++ 的代码为例，让你看一下引用传递的庐山真面目。\n#include \u0026lt;iostream\u0026gt; void incr(int\u0026amp; num) { std::cout \u0026lt;\u0026lt; \u0026#34;incr before: \u0026#34; \u0026lt;\u0026lt; num \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34;; num++; std::cout \u0026lt;\u0026lt; \u0026#34;incr after: \u0026#34; \u0026lt;\u0026lt; num \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34;; } int main() { int age = 10; std::cout \u0026lt;\u0026lt; \u0026#34;invoke before: \u0026#34; \u0026lt;\u0026lt; age \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34;; incr(age); std::cout \u0026lt;\u0026lt; \u0026#34;invoke after: \u0026#34; \u0026lt;\u0026lt; age \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34;; } 输出结果：\ninvoke before: 10 incr before: 10 incr after: 11 invoke after: 11 分析：可以看到，在 incr 函数中对形参的修改，可以影响到实参的值。要注意：这里的 incr 形参的数据类型用的是 int\u0026amp; 才为引用传递，如果是用 int 的话还是值传递哦！\n1.5 为什么Java不引入引用传递 # 引用传递看似很好，能在方法内就直接把实参的值修改了，但是，为什么 Java 不引入引用传递呢？\n注意：以下为个人观点看法，并非来自于 Java 官方：\n出于安全考虑，方法内部对值进行的操作，对于调用者都是未知的（把方法定义为接口，调用方不关心具体实现）。你也想象一下，如果拿着银行卡去取钱，取的是 100，扣的是 200，是不是很可怕。 Java 之父 James Gosling 在设计之初就看到了 C、C++ 的许多弊端，所以才想着去设计一门新的语言 Java。在他设计 Java 的时候就遵循了简单易用的原则，摒弃了许多开发者一不留意就会造成问题的“特性”，语言本身的东西少了，开发者要学习的东西也少了。 1.6 总结 # Java 中将实参传递给方法（或函数）的方式是 值传递：\n如果参数是基本类型的话，很简单，传递的就是基本类型的字面量值的拷贝，会创建副本。 如果参数是引用类型，传递的就是实参所引用的对象在堆中地址值的拷贝，同样也会创建副本。 ","date":"6 March 2025","externalUrl":null,"permalink":"/posts/1741275961641-java-%E5%80%BC%E4%BC%A0%E9%80%92%E8%AF%A6%E8%A7%A3/","section":"Posts","summary":"","title":"java 值传递详解","type":"posts"},{"content":" Java序列化详解 # 1.1 序列化和反序列化 # 在计算机网络中，==序列化（Serialization）和反序列化（Deserialization）是指将数据结构或对象转换成可传输或存储的格式，以及从该格式还原成原始数据结构或对象的过程。==序列化是为了在网络中传输数据或将数据存储到磁盘等介质时，能够方便地将数据转换成字节流。反序列化则是将接收到的字节流还原成原始的数据结构或对象。\nJava的序列化过程就是指将Java对象转换为字节流的过程，可以将这些字节流保存到文件中或通过网络传输。 序列化的主要目的是 实现对象的持久化存储和传输，让对象可以在不同的计算机或不同的时间点被重建和使用。通过序列化，可以将对象的状态以字节的形式保存下来，并且在需要的时候进行恢复，从而实现了对象的跨平台传输和持久化存储。\n简单来说：\n序列化：将数据结构或对象转换成可以存储或传输的形式，通常是二进制字节流，也可以是 JSON, XML 等文本格式 反序列化：将在序列化过程中所生成的数据转换为原始数据结构或者对象的过程 对于 Java 这种面向对象编程语言来说，我们序列化的都是对象（Object）也就是实例化后的类(Class)，但是在 C++这种半面向对象的语言中，struct(结构体)定义的是数据结构类型，而 class 对应的是对象类型。\n序列化和反序列化常见应用场景：\n对象在进行网络传输（比如远程方法调用 RPC 的时候）之前需要先被序列化，接收到序列化的对象之后需要再进行反序列化； 将对象存储到文件之前需要进行序列化，将对象从文件中读取出来需要进行反序列化； 将对象存储到数据库（如 Redis）之前需要用到序列化，将对象从缓存数据库中读取出来需要反序列化； 将对象存储到内存之前需要进行序列化，从内存中读取出来之后需要进行反序列化。 维基百科是如是介绍序列化的：\n序列化（serialization）在计算机科学的数据处理中，是指将数据结构或对象状态转换成可取用格式（例如存成文件，存于缓冲，或经由网络中发送），以留待后续在相同或另一台计算机环境中，能恢复原先状态的过程。依照序列化格式重新获取字节的结果时，可以利用它来产生与原始对象相同语义的副本。对于许多对象，像是使用大量引用的复杂对象，这种序列化重建的过程并不容易。面向对象中的对象序列化，并不概括之前原始对象所关系的函数。这种过程也称为对象编组（marshalling）。从一系列字节提取数据结构的反向操作，是反序列化（也称为解编组、deserialization、unmarshalling）。\n综上：序列化的主要目的是通过网络传输对象或者说是将对象存储到文件系统、数据库、内存中。\n序列化协议对应于 TCP/IP 4 层模型的哪一层？\n我们知道网络通信的双方必须要采用和遵守相同的协议。TCP/IP 四层模型是下面这样的，序列化协议属于哪一层呢？\n应用层 传输层 网络层 网络接口层 如上图所示，OSI 七层协议模型中，表示层做的事情主要就是对应用层的用户数据进行处理转换为二进制流。反过来的话，就是将二进制流转换成应用层的用户数据。这不就对应的是序列化和反序列化么？\n因为，OSI 七层协议模型中的应用层、表示层和会话层对应的都是 TCP/IP 四层模型中的应用层，所以序列化协议属于 TCP/IP 协议应用层的一部分。\n1.2 初始协议 # **在网络通信中，通信双方需要遵循一定的协议来确保正确、有效地进行数据交换。协议定义了通信的规则、格式以及消息的含义。**协议可以包括序列化和反序列化的规范，以确保数据在传输过程中能够正确地被解析。\n例如，常见的网络协议如HTTP、TCP、UDP等都规定了数据传输的格式和交互方式。对于数据的序列化和反序列化，有时候也需要使用特定的协议，例如JSON、XML、Protocol Buffers等。\n**初识协议是指对于通信过程中双方之间要遵循的规定、约定或规则。**这些规定定义了通信的格式、数据交换方式、消息的含义等，确保通信的双方能够理解和正确地处理彼此发送和接收的信息。协议在计算机网络、分布式系统、通信领域等都起到了关键的作用。\n协议可以分为多种类型，其中两个主要的类别是通信协议和传输协议。\n通信协议：\n**通信协议定义了通信双方之间的交流规则，包括消息的格式、语法、语义和同步方式。**一些常见的通信协议包括：\nHTTP（Hypertext Transfer Protocol）： 用于在Web浏览器和Web服务器之间传递信息，基于请求-响应模型。\nFTP（File Transfer Protocol）： 用于在客户端和服务器之间传输文件。\nSMTP（Simple Mail Transfer Protocol）： 用于在邮件客户端和邮件服务器之间传输电子邮件。\nDNS（Domain Name System）： 用于将域名映射到IP地址。\n传输协议：\n**传输协议定义了数据在网络中的传输方式，**包括数据的分段、重组、错误处理等。两个常见的传输协议是：\nTCP（Transmission Control Protocol）： 提供可靠的、面向连接的通信。TCP保证数据的可靠性，确保数据按照正确的顺序到达目的地。\nUDP（User Datagram Protocol）： 提供不可靠的、无连接的通信。UDP不保证数据的可靠性，但通常速度更快。\n序列化协议:\n在分布式系统中，**序列化协议定义了数据在网络上传输时的格式，以及如何将数据结构转换为字节流，以便在网络上传输。**一些常见的序列化协议包括：\nJSON（JavaScript Object Notation）： 一种轻量级的数据交换格式，易于阅读和编写，但性能较差。\nXML（eXtensible Markup Language）： 一种可扩展的标记语言，常用于表示结构化数据，易于阅读和编写，但性能较差。\nProtocol Buffers（protobuf）： 由Google开发的二进制序列化协议，具有高效的编码和解码速度。\n了解和遵循协议对于确保系统之间的正确通信和数据交换至关重要。协议的设计考虑到了性能、可扩展性、可读性等方面的因素，因此在设计和开发过程中需要谨慎选择和遵循适当的协议。\nJDK 自带的序列化方式一般不会用 ，因为序列化效率低并且存在安全问题。比较常用的序列化协议有 Hessian、Kryo、Protobuf、ProtoStuff，这些都是基于二进制的序列化协议。\n1.2.1 JDK自带的序列化方式 # JDK 自带的序列化，只需实现 java.io.Serializable(/ˈsɪərɪəlaɪzəbl/)接口即可。\n@AllArgsConstructor @NoArgsConstructor @Getter @Builder @ToString public class RpcRequest implements Serializable { private static final long serialVersionUID = 1905122041950251207L; private String requestId; private String interfaceName; private String methodName; private Object[] parameters; private Class\u0026lt;?\u0026gt;[] paramTypes; private RpcMessageTypeEnum rpcMessageTypeEnum; } 所有的非静态、非瞬态的字段都可以被序列化。 使用Java的序列化机制，可以通过ObjectOutputStream将对象转换为字节流并写入文件或网络流中。反之，通过ObjectInputStream可以从字节流中读取数据并还原为对象。\nserialVersionUID 有什么用？\n序列化号 serialVersionUID 属于版本控制的作用。反序列化时，会检查 serialVersionUID 是否和当前类的 serialVersionUID 一致。如果 serialVersionUID 不一致则会抛出 InvalidClassException 异常。强烈推荐每个序列化类都手动指定其 serialVersionUID，如果不手动指定，那么编译器会动态生成默认的 serialVersionUID。\nserialVersionUID 不是被 static 变量修饰了吗？为什么还会被“序列化”？\nstatic 修饰的变量是静态变量，位于方法区，本身是不会被序列化的。 static 变量是属于类的而不是对象。你反序列之后，static 变量的值就像是默认赋予给了对象一样，看着就像是 static 变量被序列化，实际只是假象罢了。\n🐛 修正（参见：issue#2174）：static 修饰的变量是静态变量，属于类而非类的实例，本身是不会被序列化的。然而，serialVersionUID 是一个特例，serialVersionUID 的序列化做了特殊处理。当一个对象被序列化时，serialVersionUID 会被写入到序列化的二进制流中；在反序列化时，也会解析它并做一致性判断，以此来验证序列化对象的版本一致性。如果两者不匹配，反序列化过程将抛出 InvalidClassException，因为这通常意味着序列化的类的定义已经发生了更改，可能不再兼容。\n官方说明如下：\nA serializable class can declare its own serialVersionUID explicitly by declaring a field named \u0026quot;serialVersionUID\u0026quot; that must be static, final, and of type long;\n如果想显式指定 serialVersionUID ，则需要在类中使用 static 和 final 关键字来修饰一个 long 类型的变量，变量名字必须为 \u0026quot;serialVersionUID\u0026quot; 。\n也就是说，serialVersionUID 只是用来被 JVM 识别，实际并没有被序列化。\n如果有些字段不想进行序列化怎么办？\n对于不想进行序列化的变量，可以使用 transient (/ˈtrænziənt/)关键字修饰。\ntransient 关键字的作用是：阻止实例中那些用此关键字修饰的的变量序列化；当对象被反序列化时，被 transient 修饰的变量值不会被持久化和恢复。\n关于 transient 还有几点注意：\ntransient 只能修饰变量，不能修饰类和方法。 transient 修饰的变量，在反序列化后变量值将会被置成类型的默认值。例如，如果是修饰 int 类型，那么反序列后结果就是 0。 static 变量因为不属于任何对象(Object)，所以无论有没有 transient 关键字修饰，均不会被序列化。 为什么不推荐使用 JDK 自带的序列化？\n我们很少或者说几乎不会直接使用 JDK 自带的序列化方式，主要原因有下面这些原因：\n不支持跨语言调用 : 如果调用的是其他语言开发的服务的时候就不支持了。 性能差：相比于其他序列化框架性能更低，主要原因是序列化之后的字节数组体积较大，导致传输成本加大。 存在安全问题：序列化和反序列化本身并不存在问题。但当输入的反序列化的数据可被用户控制，那么攻击者即可通过构造恶意输入，让反序列化产生非预期的对象，在此过程中执行构造的任意代码。相关阅读：应用安全:JAVA 反序列化漏洞之殇 - Cryin、Java 反序列化安全漏洞怎么回事? - Monica。 1.2.1.1 ObjectOutputStream类 # java.io.ObjectOutputStream 类，将Java对象的原始数据类型写出到文件,实现对象的持久存储。\n构造方法：\npublic ObjectOutputStream(OutputStream out) ： 创建一个指定OutputStream的ObjectOutputStream。\n序列化操作：\n一个对象要想序列化，必须满足两个条件: 该类必须实现java.io.Serializable 接口，Serializable 是一个标记接口，不实现此接口的类将不会使任何状态序列化或反序列化，会抛出NotSerializableException 。 该类的所有属性必须是可序列化的。如果有一个属性不需要可序列化的，则该属性必须注明是瞬态的，使用transient 关键字修饰。 写出对象方法 public final void writeObject (Object obj) : 将指定的对象写出。 1.2.1.2 ObjectInputStream类 # ObjectInputStream反序列化流，将之前使用ObjectOutputStream序列化的原始数据恢复为对象。\n构造方法\npublic ObjectInputStream(InputStream in) ： 创建一个指定InputStream的ObjectInputStream。\n反序列化操作1\n如果能找到一个对象的class文件，我们可以进行反序列化操作，调用ObjectInputStream读取对象的方法：\npublic final Object readObject () : 读取一个对象。 对于JVM可以反序列化对象，它必须是能够找到class文件的类。如果找不到该类的class文件，则抛出一个 ClassNotFoundException 异常。\n反序列化操作2\n**另外，当JVM反序列化对象时，能找到class文件，但是class文件在序列化对象之后发生了修改，那么反序列化操作也会失败，抛出一个InvalidClassException异常。**发生这个异常的原因如下：\n该类的序列版本号与从流中读取的类描述符的版本号不匹配 该类包含未知数据类型 该类没有可访问的无参数构造方法 Serializable 接口给需要序列化的类，提供了一个序列版本号。serialVersionUID 该版本号的目的在于验证序列化的对象和对应类是否版本匹配。\n1.2.2 Kryo # Kryo 是一个高性能的序列化/反序列化工具，由于其变长存储特性并使用了字节码生成机制，拥有较高的运行速度和较小的字节码体积。\n另外，Kryo 已经是一种非常成熟的序列化实现了，已经在 Twitter、Groupon、Yahoo 以及多个著名开源项目（如 Hive、Storm）中广泛的使用。\nguide-rpc-framework 就是使用的 kryo 进行序列化，序列化和反序列化相关的代码如下：\n/** * Kryo serialization class, Kryo serialization efficiency is very high, but only compatible with Java language * * @author shuang.kou * @createTime 2020年05月13日 19:29:00 */ @Slf4j public class KryoSerializer implements Serializer { /** * Because Kryo is not thread safe. So, use ThreadLocal to store Kryo objects */ private final ThreadLocal\u0026lt;Kryo\u0026gt; kryoThreadLocal = ThreadLocal.withInitial(() -\u0026gt; { Kryo kryo = new Kryo(); kryo.register(RpcResponse.class); kryo.register(RpcRequest.class); return kryo; }); @Override public byte[] serialize(Object obj) { try (ByteArrayOutputStream byteArrayOutputStream = new ByteArrayOutputStream(); Output output = new Output(byteArrayOutputStream)) { Kryo kryo = kryoThreadLocal.get(); // Object-\u0026gt;byte:将对象序列化为byte数组 kryo.writeObject(output, obj); kryoThreadLocal.remove(); return output.toBytes(); } catch (Exception e) { throw new SerializeException(\u0026#34;Serialization failed\u0026#34;); } } @Override public \u0026lt;T\u0026gt; T deserialize(byte[] bytes, Class\u0026lt;T\u0026gt; clazz) { try (ByteArrayInputStream byteArrayInputStream = new ByteArrayInputStream(bytes); Input input = new Input(byteArrayInputStream)) { Kryo kryo = kryoThreadLocal.get(); // byte-\u0026gt;Object:从byte数组中反序列化出对象 Object o = kryo.readObject(input, clazz); kryoThreadLocal.remove(); return clazz.cast(o); } catch (Exception e) { throw new SerializeException(\u0026#34;Deserialization failed\u0026#34;); } } } GitHub 地址：https://github.com/EsotericSoftware/kryo 。\n1.2.3 Protobuf # Protobuf 出自于 Google，性能还比较优秀，也支持多种语言，同时还是跨平台的。就是在使用中过于繁琐，因为你需要自己定义 IDL 文件和生成对应的序列化代码。这样虽然不灵活，但是，另一方面导致 protobuf 没有序列化漏洞的风险。\nProtobuf 包含序列化格式的定义、各种语言的库以及一个 IDL 编译器。正常情况下你需要定义 proto 文件，然后使用 IDL 编译器编译成你需要的语言\n一个简单的 proto 文件如下：\n// protobuf的版本 syntax = \u0026#34;proto3\u0026#34;; // SearchRequest会被编译成不同的编程语言的相应对象，比如Java中的class、Go中的struct message Person { //string类型字段 string name = 1; // int 类型字段 int32 age = 2; } GitHub 地址：https://github.com/protocolbuffers/protobuf。\n1.2.4 ProtoStuff # 由于 Protobuf 的易用性较差，它的哥哥 Protostuff 诞生了。\nprotostuff 基于 Google protobuf，但是提供了更多的功能和更简易的用法。虽然更加易用，但是不代表 ProtoStuff 性能更差。\nGitHub 地址：https://github.com/protostuff/protostuff。\n1.2.5 Hessian # Hessian 是一个轻量级的，自定义描述的二进制 RPC 协议。Hessian 是一个比较老的序列化实现了，并且同样也是跨语言的。\nDubbo2.x 默认启用的序列化方式是 Hessian2 ,但是，Dubbo 对 Hessian2 进行了修改，不过大体结构还是差不多。\n1.2.6 总结 # Kryo 是专门针对 Java 语言序列化方式并且性能非常好，如果你的应用是专门针对 Java 语言的话可以考虑使用，并且 Dubbo 官网的一篇文章中提到说推荐使用 Kryo 作为生产环境的序列化方式。(文章地址：https://cn.dubbo.apache.org/zh-cn/docsv2.7/user/serialization/）。\n像 Protobuf、 ProtoStuff、hessian 这类都是跨语言的序列化方式，如果有跨语言需求的话可以考虑使用。\n除了我上面介绍到的序列化方式的话，还有像 Thrift，Avro 这些。\n","date":"6 March 2025","externalUrl":null,"permalink":"/posts/1741276121143-java-%E5%BA%8F%E5%88%97%E5%8C%96%E8%AF%A6%E8%A7%A3/","section":"Posts","summary":"","title":"java 序列化详解","type":"posts"},{"content":"","date":"6 March 2025","externalUrl":null,"permalink":"/tags/%E5%80%BC%E4%BC%A0%E9%80%92/","section":"Tags","summary":"","title":"值传递","type":"tags"},{"content":"","date":"6 March 2025","externalUrl":null,"permalink":"/tags/%E5%BA%8F%E5%88%97%E5%8C%96/","section":"Tags","summary":"","title":"序列化","type":"tags"},{"content":"","externalUrl":null,"permalink":"/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"","externalUrl":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":"","externalUrl":null,"permalink":"/series/","section":"Series","summary":"","title":"Series","type":"series"}]